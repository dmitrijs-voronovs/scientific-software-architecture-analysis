id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767:196,Modifiability,config,configuration,196,"The removed `-Xms2g` was saying ""Never run sbt, ever, without less than 2g of memory"". Meanwhile, Intellij has its own ""[Maximum Heap Size](https://www.jetbrains.com/help/idea/sbt.html#82b10b37)"" configuration value for the amount of memory required to import an sbt project. The IDE doesn't use this for running tests, so it does not need to be as large as the sbt options one uses for `sbt test` from the command line. The net effect of having the Intellij maximum less than 2g and the sbt opts _minimum_ at 2g caused a cryptic error of: . ```; Error while importing sbt project:. Error occurred during initialization of VM; Initial heap size set to a larger value than the maximum heap size; ```. This PR still leaves .sbtopts maximum amount of memory for running `sbt test` at 4g. It just no longer states that the JVM should start at 2g of memory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767
https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767:313,Testability,test,tests,313,"The removed `-Xms2g` was saying ""Never run sbt, ever, without less than 2g of memory"". Meanwhile, Intellij has its own ""[Maximum Heap Size](https://www.jetbrains.com/help/idea/sbt.html#82b10b37)"" configuration value for the amount of memory required to import an sbt project. The IDE doesn't use this for running tests, so it does not need to be as large as the sbt options one uses for `sbt test` from the command line. The net effect of having the Intellij maximum less than 2g and the sbt opts _minimum_ at 2g caused a cryptic error of: . ```; Error while importing sbt project:. Error occurred during initialization of VM; Initial heap size set to a larger value than the maximum heap size; ```. This PR still leaves .sbtopts maximum amount of memory for running `sbt test` at 4g. It just no longer states that the JVM should start at 2g of memory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767
https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767:392,Testability,test,test,392,"The removed `-Xms2g` was saying ""Never run sbt, ever, without less than 2g of memory"". Meanwhile, Intellij has its own ""[Maximum Heap Size](https://www.jetbrains.com/help/idea/sbt.html#82b10b37)"" configuration value for the amount of memory required to import an sbt project. The IDE doesn't use this for running tests, so it does not need to be as large as the sbt options one uses for `sbt test` from the command line. The net effect of having the Intellij maximum less than 2g and the sbt opts _minimum_ at 2g caused a cryptic error of: . ```; Error while importing sbt project:. Error occurred during initialization of VM; Initial heap size set to a larger value than the maximum heap size; ```. This PR still leaves .sbtopts maximum amount of memory for running `sbt test` at 4g. It just no longer states that the JVM should start at 2g of memory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767
https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767:772,Testability,test,test,772,"The removed `-Xms2g` was saying ""Never run sbt, ever, without less than 2g of memory"". Meanwhile, Intellij has its own ""[Maximum Heap Size](https://www.jetbrains.com/help/idea/sbt.html#82b10b37)"" configuration value for the amount of memory required to import an sbt project. The IDE doesn't use this for running tests, so it does not need to be as large as the sbt options one uses for `sbt test` from the command line. The net effect of having the Intellij maximum less than 2g and the sbt opts _minimum_ at 2g caused a cryptic error of: . ```; Error while importing sbt project:. Error occurred during initialization of VM; Initial heap size set to a larger value than the maximum heap size; ```. This PR still leaves .sbtopts maximum amount of memory for running `sbt test` at 4g. It just no longer states that the JVM should start at 2g of memory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-445947767
https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-446070591:74,Availability,error,error,74,Thx for the pointer to the outdated docs. Removed that section since that error should no longer occur in IntelliJ.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4476#issuecomment-446070591
https://github.com/broadinstitute/cromwell/pull/4479#issuecomment-445960949:24,Testability,assert,asserted,24,@aednichols Yes...! Now asserted,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4479#issuecomment-445960949
https://github.com/broadinstitute/cromwell/issues/4480#issuecomment-445969081:269,Security,Hash,Hash,269,"1. JMUI features! (Bec); 2. Keys and Directories in WDL. Possibly the After keyword as well.(Chris!); 3. Womtool as a service, /describe endpoint (Adam); 4. PAPI v2 Boot Disk Auto-sizing--WDL & CWL (Jeff?); 5. Call Caching Names for Backends (Miguel); 6. Size and File Hash for DRS files (Saloni); 7. Progress on Horizontal Cromwell (Khalid & Miguel?)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4480#issuecomment-445969081
https://github.com/broadinstitute/cromwell/issues/4482#issuecomment-464202824:32,Integrability,depend,dependencies,32,Are you creating a .zip file of dependencies to submit to Cromwell alongside the root WDL?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4482#issuecomment-464202824
https://github.com/broadinstitute/cromwell/pull/4486#issuecomment-446341396:139,Testability,test,tests,139,"@geoffjentry I *think* this is coincidence (I'm trying to debug presumably unrelated `after` problems), but it's quite possible that those tests hit my ""stalled"" condition too since they appear to be showing the same symptoms. In which case we might get some more useful debug clues out of this",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4486#issuecomment-446341396
https://github.com/broadinstitute/cromwell/pull/4486#issuecomment-446341726:212,Availability,failure,failures,212,"@cjllanwarne got it, thanks. I did note that you said ""one class"" before commenting :) The belief **is** that those WFs are getting stuck and it's not just a dilation issue, so it'll be interesting to see if the failures dry up after this merges",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4486#issuecomment-446341726
https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811:258,Integrability,interface,interface,258,See #4414 for more info. We needed a reproducible test for deadlocks. This adds PR adds a deadlock-creating-test at the high-level using multiple cromwells in a Docker Compose. FYI- an earlier PR #4415 added very-very-low level deadlocks at the SQL/Database interface level.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811
https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811:50,Testability,test,test,50,See #4414 for more info. We needed a reproducible test for deadlocks. This adds PR adds a deadlock-creating-test at the high-level using multiple cromwells in a Docker Compose. FYI- an earlier PR #4415 added very-very-low level deadlocks at the SQL/Database interface level.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811
https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811:108,Testability,test,test,108,See #4414 for more info. We needed a reproducible test for deadlocks. This adds PR adds a deadlock-creating-test at the high-level using multiple cromwells in a Docker Compose. FYI- an earlier PR #4415 added very-very-low level deadlocks at the SQL/Database interface level.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4488#issuecomment-446621811
https://github.com/broadinstitute/cromwell/pull/4489#issuecomment-446668372:582,Deployability,update,update,582,"Given that:; - The WDL spec today is un-opinionated on the size of an `Int`; - The WDL `Int` is defined as 64 bit in the upcoming https://github.com/openwdl/wdl/pull/250; - NB: swap the red and green diffs in your head because Jeff merged it too soon and this is a placeholder ""if we for some reason needed to revert"" PR; - And assuming that people are not currently writing workflows specifically relying on an explosion if their Ints are above 2^16. I suggest you just default to making anything WDL produce`WomLong`s in all new situations, since we'll probably sweep through and update everything else at some point soon",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4489#issuecomment-446668372
https://github.com/broadinstitute/cromwell/pull/4489#issuecomment-446668372:194,Energy Efficiency,green,green,194,"Given that:; - The WDL spec today is un-opinionated on the size of an `Int`; - The WDL `Int` is defined as 64 bit in the upcoming https://github.com/openwdl/wdl/pull/250; - NB: swap the red and green diffs in your head because Jeff merged it too soon and this is a placeholder ""if we for some reason needed to revert"" PR; - And assuming that people are not currently writing workflows specifically relying on an explosion if their Ints are above 2^16. I suggest you just default to making anything WDL produce`WomLong`s in all new situations, since we'll probably sweep through and update everything else at some point soon",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4489#issuecomment-446668372
https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453077307:123,Modifiability,extend,extend,123,"Currently biscayne in WDL and application.conf is equal to draft-2, maybe you can at least base it on version 1.0 and then extend?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453077307
https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453310373:180,Modifiability,config,config,180,@geoffjentry if you put something like:; ```wdl; version biscayne; ```; then cromwell executes it as if it is draft-2. If I try to make biscayne the default version in application config it also executes it as if it is draft-2 (like not knowing about ~{varible} symbols instead of ${variable} and functions like as_map),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453310373
https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453310373:283,Modifiability,variab,variable,283,@geoffjentry if you put something like:; ```wdl; version biscayne; ```; then cromwell executes it as if it is draft-2. If I try to make biscayne the default version in application config it also executes it as if it is draft-2 (like not knowing about ~{varible} symbols instead of ${variable} and functions like as_map),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453310373
https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453547478:76,Safety,avoid,avoid,76,"hey @antonkulaga, sorry for the confusion - we switched to `development` to avoid having to fork the openWDL grammars:; ```wdl; version development. # ...; ```. Hope that helps!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4491#issuecomment-453547478
https://github.com/broadinstitute/cromwell/pull/4492#issuecomment-448339714:8,Testability,test,test,8,One can test that it works before merging by going to the papi2 Cron job on the gotc Jenkins and running it on this branch (and optionally adding `-i bcbio_prealign` in the second job parameter to only run prealign so that it doesn't take 12h),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4492#issuecomment-448339714
https://github.com/broadinstitute/cromwell/pull/4493#issuecomment-450958692:33,Usability,learn,learn,33,Closing until I have a chance to learn me some jq for great good,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4493#issuecomment-450958692
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447969594:158,Testability,log,logs,158,"Hey Dan!. 1. did you happen to save the metadata file from this run? ; 2. It seems like the outputs were generated for the BaseRecalibrator task, but did the logs ever say “<job-name>....transitioned from running to Done” for any of the BaseRecalibrator shards?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447969594
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447976105:295,Availability,error,error,295,"Hi Ruchi,. 1. I have the metadata from a later run which failed in the same way, it's [here](https://gist.github.com/dtenenba/87ba6eaad666071625da6cfe98db9f61). 2. Yes, it seems like most of the BaseRecalibrator tasks transitioned from running to Done.; I see this in the logs, right before the error:. ```; 2018-12-17 17:11:25,368 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:5:1]: Status change from Running to Succeeded; 2018-12-17 17:11:25,437 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:10:1]: Status change from Running to Succeeded; 2018-12-17 17:11:27,559 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:1:1]: Status change from Initializing to Running; 2018-12-17 17:11:36,844 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:9:1]: Status change from Initializing to Running; 2018-12-17 17:11:51,970 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:15:1]: Status change from Initializing to Running; 2018-12-17 17:11:53,801 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:11:1]: Status change from Running to Succeeded; 2018-12-17 17:11:55,351 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:7:1]: Status change ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447976105
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447976105:272,Testability,log,logs,272,"Hi Ruchi,. 1. I have the metadata from a later run which failed in the same way, it's [here](https://gist.github.com/dtenenba/87ba6eaad666071625da6cfe98db9f61). 2. Yes, it seems like most of the BaseRecalibrator tasks transitioned from running to Done.; I see this in the logs, right before the error:. ```; 2018-12-17 17:11:25,368 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:5:1]: Status change from Running to Succeeded; 2018-12-17 17:11:25,437 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:10:1]: Status change from Running to Succeeded; 2018-12-17 17:11:27,559 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:1:1]: Status change from Initializing to Running; 2018-12-17 17:11:36,844 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:9:1]: Status change from Initializing to Running; 2018-12-17 17:11:51,970 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:15:1]: Status change from Initializing to Running; 2018-12-17 17:11:53,801 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:11:1]: Status change from Running to Succeeded; 2018-12-17 17:11:55,351 cromwell-system-akka.dispatchers.backend-dispatcher-3452 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(2951ea9d)PreProcessingForVariantDiscovery_GATK4.BaseRecalibrator:7:1]: Status change ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-447976105
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742:47,Availability,error,errors,47,With the rate throttled BOTH the jobDefinition errors AND the Too Many Requests errors have both been eliminated for a workflow that has 133 independent shards. However severe throttling of the job rate seems like something you need to be presented with up front as this only is acceptable for long running jobs with independent processes.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742:80,Availability,error,errors,80,With the rate throttled BOTH the jobDefinition errors AND the Too Many Requests errors have both been eliminated for a workflow that has 133 independent shards. However severe throttling of the job rate seems like something you need to be presented with up front as this only is acceptable for long running jobs with independent processes.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742:14,Performance,throttle,throttled,14,With the rate throttled BOTH the jobDefinition errors AND the Too Many Requests errors have both been eliminated for a workflow that has 133 independent shards. However severe throttling of the job rate seems like something you need to be presented with up front as this only is acceptable for long running jobs with independent processes.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-469868742
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342:138,Performance,concurren,concurrently,138,"The issue at play is that the AWS backend uses about 3-4 Batch API calls when Cromwell submits a job. Also Cromwell submits multiple jobs concurrently. Altogether, this hits the Batch API request limit pretty quickly. It's worth noting that the requests from Cromwell are to get jobs on a Batch Job Queue. If you are starting with a ""cold"" Batch environment, it will take a couple minutes for an instance to spin up. Batch will then place as many of the queued jobs as it can on instances. So in effect you should still get plenty of parallelism, despite jobs having been queued at a throttled rate initially.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342:299,Performance,Queue,Queue,299,"The issue at play is that the AWS backend uses about 3-4 Batch API calls when Cromwell submits a job. Also Cromwell submits multiple jobs concurrently. Altogether, this hits the Batch API request limit pretty quickly. It's worth noting that the requests from Cromwell are to get jobs on a Batch Job Queue. If you are starting with a ""cold"" Batch environment, it will take a couple minutes for an instance to spin up. Batch will then place as many of the queued jobs as it can on instances. So in effect you should still get plenty of parallelism, despite jobs having been queued at a throttled rate initially.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342:454,Performance,queue,queued,454,"The issue at play is that the AWS backend uses about 3-4 Batch API calls when Cromwell submits a job. Also Cromwell submits multiple jobs concurrently. Altogether, this hits the Batch API request limit pretty quickly. It's worth noting that the requests from Cromwell are to get jobs on a Batch Job Queue. If you are starting with a ""cold"" Batch environment, it will take a couple minutes for an instance to spin up. Batch will then place as many of the queued jobs as it can on instances. So in effect you should still get plenty of parallelism, despite jobs having been queued at a throttled rate initially.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342:572,Performance,queue,queued,572,"The issue at play is that the AWS backend uses about 3-4 Batch API calls when Cromwell submits a job. Also Cromwell submits multiple jobs concurrently. Altogether, this hits the Batch API request limit pretty quickly. It's worth noting that the requests from Cromwell are to get jobs on a Batch Job Queue. If you are starting with a ""cold"" Batch environment, it will take a couple minutes for an instance to spin up. Batch will then place as many of the queued jobs as it can on instances. So in effect you should still get plenty of parallelism, despite jobs having been queued at a throttled rate initially.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342
https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342:584,Performance,throttle,throttled,584,"The issue at play is that the AWS backend uses about 3-4 Batch API calls when Cromwell submits a job. Also Cromwell submits multiple jobs concurrently. Altogether, this hits the Batch API request limit pretty quickly. It's worth noting that the requests from Cromwell are to get jobs on a Batch Job Queue. If you are starting with a ""cold"" Batch environment, it will take a couple minutes for an instance to spin up. Batch will then place as many of the queued jobs as it can on instances. So in effect you should still get plenty of parallelism, despite jobs having been queued at a throttled rate initially.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4496#issuecomment-470358342
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:49,Availability,error,error,49,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:392,Deployability,update,updates,392,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:884,Deployability,update,update,884,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:89,Safety,abort,aborts,89,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:153,Safety,Abort,Aborting,153,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:223,Safety,Abort,Aborting,223,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:258,Safety,abort,abort,258,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:505,Safety,abort,aborted,505,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:716,Safety,abort,abort,716,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:754,Safety,abort,abort,754,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:926,Safety,abort,abort,926,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480:28,Usability,simpl,simple,28,"The Rawls behavior is not a simple ""retry on any error"". Here's what I'm seeing:; * User aborts a submission in FireCloud.; * Rawls marks submission as `Aborting`; * In a background actor, Rawls finds all workflows inside `Aborting` submissions and sends an abort request to Cromwell.; * In a background actor, Rawls periodically queries Cromwell for the status of each active workflow, then updates its db based on Cromwell's response; * if all workflows in a submission are complete (failed, succeeded, aborted), the submission is marked as complete. In the aberrant workflow cases I checked, Cromwell is returning a status of `Running` or `Submitted` from its workflow-status endpoint, but returns a 404 from its abort endpoint. I suspect that 1) the abort request will never succeed; 2) the workflow status endpoint's response will never change, and therefore 3) Rawls will never update its db and will be stuck trying to abort the workflow forever.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4497#issuecomment-448063480
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562686264:179,Integrability,synchroniz,synchronizing,179,"@natechols IIRC it has to do with Docker (evidenced by me asking that question above). When you're mounting a volume into a Docker container there are a handful of ways to handle synchronizing permissions from the container and the host system - all of them have serious flaws. This was the flawed approach we chose to go with here. You're correct that if one's not using Docker it's not at all necessary, branching that behavior was just never prioritized.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562686264
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693:186,Deployability,configurat,configuration,186,"@geoffjentry That makes sense, thanks. Given the current code structure it's not at all clear to me how Docker-dependent branching would fit in - maybe this would be easier as a boolean configuration option adjacent to `workflow-log-dir`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693:111,Integrability,depend,dependent,111,"@geoffjentry That makes sense, thanks. Given the current code structure it's not at all clear to me how Docker-dependent branching would fit in - maybe this would be easier as a boolean configuration option adjacent to `workflow-log-dir`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693:186,Modifiability,config,configuration,186,"@geoffjentry That makes sense, thanks. Given the current code structure it's not at all clear to me how Docker-dependent branching would fit in - maybe this would be easier as a boolean configuration option adjacent to `workflow-log-dir`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693:229,Testability,log,log-dir,229,"@geoffjentry That makes sense, thanks. Given the current code structure it's not at all clear to me how Docker-dependent branching would fit in - maybe this would be easier as a boolean configuration option adjacent to `workflow-log-dir`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693
https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693:88,Usability,clear,clear,88,"@geoffjentry That makes sense, thanks. Given the current code structure it's not at all clear to me how Docker-dependent branching would fit in - maybe this would be easier as a boolean configuration option adjacent to `workflow-log-dir`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4499#issuecomment-562687693
https://github.com/broadinstitute/cromwell/issues/4500#issuecomment-448275384:192,Testability,Test,TestFailedException,192,"Adding this case to `string_escaping.wdl`, we see; ```; ScalaTestFailureLocation: wdl.draft3.transforms.ast2wdlom.WdlFileToWdlomSpec at (WdlFileToWdlomSpec.scala:44); org.scalatest.exceptions.TestFailedException: Failed to create WDLOM:; Unrecognized token on line 12, column 26:. String quote = "" \"" ""; ^; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4500#issuecomment-448275384
https://github.com/broadinstitute/cromwell/issues/4500#issuecomment-478110758:216,Testability,test,tested,216,"The root cause is that the regex; ```; (.*?)(?=\\$\\{|~\\{|\""); ```; used in the parser matches the string; ```; ""leading text \"" trailing text""; ```; as two separate chunks, `leading text \` and ` trailing text` as tested on regexr.com",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4500#issuecomment-478110758
https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210:184,Deployability,update,update,184,"When I first looked at this I thought it was not in our power to change because the standard said something different, but I believe the standard allows for `{}` and we simply need to update the parser in OpenWDL (and then Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210
https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210:56,Energy Efficiency,power,power,56,"When I first looked at this I thought it was not in our power to change because the standard said something different, but I believe the standard allows for `{}` and we simply need to update the parser in OpenWDL (and then Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210
https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210:169,Usability,simpl,simply,169,"When I first looked at this I thought it was not in our power to change because the standard said something different, but I believe the standard allows for `{}` and we simply need to update the parser in OpenWDL (and then Cromwell).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-477711210
https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-478249212:55,Deployability,update,updated,55,"Yeah - if it's a bug in the hermes grammar that can be updated w/o voting. If the spec is wrong, that requires a vote",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4501#issuecomment-478249212
https://github.com/broadinstitute/cromwell/issues/4504#issuecomment-451299222:72,Testability,test,tests,72,The feature is to be removed. I wouldn't put any effort into fixing the tests. Whether or not you want to put the effort in to excise the feature now is up to you for now :),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4504#issuecomment-451299222
https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212:856,Integrability,wrap,wrapper,856,"Hi @TMiguelT, I worked on relative imports in Cromwell quite recently. The ideas about specifying the ""start point"" within the zip file did come up, but in the end people seemed more interested in relative HTTP imports (which is what I focussed on). I have two potential ideas for you which hopefully don't need Cromwell code changes. Hopefully these will help you - if not let us know!. ## Submit by URL. If you have a new version of Cromwell - since these changes were relatively recent - then you could try submitting the workflow to Cromwell by URL (based on your relative path, I'd guess the github hosted location you want would be https://raw.githubusercontent.com/h3abionet/h3agatk/1.0.1/workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl). ## Call into the relatively nested file. If submit by URL is out, you could perhaps make a top level ""wrapper"" workflow which immediately imports and calls `workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl`. This should let you access it while keeping it's location relative to the other files in the repo safe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212
https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212:1067,Safety,safe,safe,1067,"Hi @TMiguelT, I worked on relative imports in Cromwell quite recently. The ideas about specifying the ""start point"" within the zip file did come up, but in the end people seemed more interested in relative HTTP imports (which is what I focussed on). I have two potential ideas for you which hopefully don't need Cromwell code changes. Hopefully these will help you - if not let us know!. ## Submit by URL. If you have a new version of Cromwell - since these changes were relatively recent - then you could try submitting the workflow to Cromwell by URL (based on your relative path, I'd guess the github hosted location you want would be https://raw.githubusercontent.com/h3abionet/h3agatk/1.0.1/workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl). ## Call into the relatively nested file. If submit by URL is out, you could perhaps make a top level ""wrapper"" workflow which immediately imports and calls `workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl`. This should let you access it while keeping it's location relative to the other files in the repo safe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212
https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212:989,Security,access,access,989,"Hi @TMiguelT, I worked on relative imports in Cromwell quite recently. The ideas about specifying the ""start point"" within the zip file did come up, but in the end people seemed more interested in relative HTTP imports (which is what I focussed on). I have two potential ideas for you which hopefully don't need Cromwell code changes. Hopefully these will help you - if not let us know!. ## Submit by URL. If you have a new version of Cromwell - since these changes were relatively recent - then you could try submitting the workflow to Cromwell by URL (based on your relative path, I'd guess the github hosted location you want would be https://raw.githubusercontent.com/h3abionet/h3agatk/1.0.1/workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl). ## Call into the relatively nested file. If submit by URL is out, you could perhaps make a top level ""wrapper"" workflow which immediately imports and calls `workflows/GATK/GATK-complete-WES-Workflow-h3abionet.cwl`. This should let you access it while keeping it's location relative to the other files in the repo safe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449025212
https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449248258:103,Availability,down,down,103,"Hi Chris, thanks for the reply. Both of these workarounds are good, and it's nice to have them written down. Having said this I think the issue is actually that Cromwell isn't correctly implementing the CWL spec, because the H3ABio workflow is technically correct to use relative imports. I think it would be good for us to have a way to solve this without having to change the CWL itself (which is why my two suggestions would only involve changing the Cromwell submission but not the CWL).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4505#issuecomment-449248258
https://github.com/broadinstitute/cromwell/pull/4506#issuecomment-451268847:98,Usability,clear,cleared,98,"I think we should close this as it is under heavy construction, and re-reviewed once the dust has cleared",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4506#issuecomment-451268847
https://github.com/broadinstitute/cromwell/issues/4507#issuecomment-449268020:550,Integrability,depend,depending,550,"I've had a quick look at the code but I'm struggling with the Scala as usual, so I don't think I'd be up to making a PR to fix this. Will the tmpdirMin and outdirMin statements both map to `disk XXX SSD`, or will they be different disks with a specific mount path? I suppose they should be separate, in order to make sure each has at least the amount of disk space specified. And if they are different disks, how will I know where to mount them? I can't work out what the TMPDIR and HOME are being set to in a Cromwell job, and actually it will vary depending on the backend, I imagine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4507#issuecomment-449268020
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451239350:11,Testability,test,tests,11,"Yes, those tests broke and we have issue https://github.com/broadinstitute/cromwell/issues/4504 to address them. For now I have merged PR https://github.com/broadinstitute/cromwell/pull/4502 which ignores them. I think merging `develop` into your branch will fix it (that's what happens for the ""PR"" build and it passeD)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451239350
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451263303:84,Performance,perform,performance,84,"Were you able to test whether the move from `runTransaction` to `runAction` affects performance?. Apologies if you already shared this at yesterday's refinement, I was still on vacation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451263303
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451263303:17,Testability,test,test,17,"Were you able to test whether the move from `runTransaction` to `runAction` affects performance?. Apologies if you already shared this at yesterday's refinement, I was still on vacation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451263303
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451267229:238,Performance,perform,performance,238,"@aednichols we didn't talk about it yesterday since some folks were out, so we can talk at the next refinement instead. Short story is... we weren't actually batching those requests anyway from a database perspective so I don't think any performance was lost. I also have a cool trick to share about how to see actually what the database is doing that i used to figure this out.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-451267229
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-452773467:211,Availability,rollback,rollback,211,"I dug up the source for my statement about autocommit:. >If autocommit mode is enabled, each SQL statement forms a single transaction on its own. https://dev.mysql.com/doc/refman/5.7/en/innodb-autocommit-commit-rollback.html",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-452773467
https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-452773467:211,Deployability,rollback,rollback,211,"I dug up the source for my statement about autocommit:. >If autocommit mode is enabled, each SQL statement forms a single transaction on its own. https://dev.mysql.com/doc/refman/5.7/en/innodb-autocommit-commit-rollback.html",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508#issuecomment-452773467
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608:370,Availability,error,error,370,"Thanks for reporting, @asmoe4. A few questions:; - Which Cromwell version are you using?; - Have you ever run this workflow successfully on a previous version of Cromwell?; - Does the workflow run on a backend other than AWS? You could try e.g. the [local backend](https://cromwell.readthedocs.io/en/stable/backends/Local/). ---. Developer notes:; - I've never seen the error message `error in opening zip file` before, a quick Google suggests it's coming straight out of `java.util.zip`; - The only recent zip change I can think of is one that Shouldn't Break Anything, https://github.com/broadinstitute/cromwell/pull/4399. If this is a regression (based on reported Cromwell version), that's where I'd start looking.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608:385,Availability,error,error,385,"Thanks for reporting, @asmoe4. A few questions:; - Which Cromwell version are you using?; - Have you ever run this workflow successfully on a previous version of Cromwell?; - Does the workflow run on a backend other than AWS? You could try e.g. the [local backend](https://cromwell.readthedocs.io/en/stable/backends/Local/). ---. Developer notes:; - I've never seen the error message `error in opening zip file` before, a quick Google suggests it's coming straight out of `java.util.zip`; - The only recent zip change I can think of is one that Shouldn't Break Anything, https://github.com/broadinstitute/cromwell/pull/4399. If this is a regression (based on reported Cromwell version), that's where I'd start looking.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608:376,Integrability,message,message,376,"Thanks for reporting, @asmoe4. A few questions:; - Which Cromwell version are you using?; - Have you ever run this workflow successfully on a previous version of Cromwell?; - Does the workflow run on a backend other than AWS? You could try e.g. the [local backend](https://cromwell.readthedocs.io/en/stable/backends/Local/). ---. Developer notes:; - I've never seen the error message `error in opening zip file` before, a quick Google suggests it's coming straight out of `java.util.zip`; - The only recent zip change I can think of is one that Shouldn't Break Anything, https://github.com/broadinstitute/cromwell/pull/4399. If this is a regression (based on reported Cromwell version), that's where I'd start looking.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451199608
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451241462:65,Testability,test,tested,65,@aednichols . * I'm running cromwell server using v36. I haven't tested cromwell 35 in server mode. ; * This same workflow has been run successfully on local backend using both Cromwell version 35 and 36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451241462
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451259859:15,Availability,error,error,15,"I get the same error message when e.g. renaming an arbitrary `.txt` file to `.zip` - that's not necessarily what's happening, but a clue that the zip itself may be bad.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451259859
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451259859:21,Integrability,message,message,21,"I get the same error message when e.g. renaming an arbitrary `.txt` file to `.zip` - that's not necessarily what's happening, but a clue that the zip itself may be bad.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451259859
https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451260898:191,Availability,down,downloaded,191,"I'm using `tar` to create `*.zip` like below on a Mac OS; ```; tar -czvf workflow.zip sub_wf.wdl; ```. Also, if you are running a local server, I'm assuming there's a place where zip file is downloaded and unzip to? Do you know where on local machine that is running server does that zip file get unzipped to?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509#issuecomment-451260898
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:945,Deployability,pipeline,pipelines,945,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:458,Energy Efficiency,monitor,monitoring,458,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:676,Energy Efficiency,monitor,monitoring,676,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:757,Energy Efficiency,monitor,monitor,757,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:968,Energy Efficiency,monitor,monitoring,968,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862:552,Security,expose,exposed,552,"> Is this run on all jobs? If so Is it potentially something a user would want to turn off?. Yes, it runs on all jobs by default. I'm not sure if users would explicitly want to turn it off, since it doesn't interfere with anything as far as I can tell, and the pricing issue is virtually non-existent. > Also did you produce that graph manually? Is there a way to generate it easily for a workflow?. Yep, the graph can be easily produced through Stackdriver monitoring console with a few clicks, or a link to it can be constructed programmatically and exposed to the user. The graph is interactive, so there's no need to ""pre-render"" it - it is constructed dynamically by the monitoring console, based on user inputs and/or the link. > Can you include your monitor python/image code in this PR? Would be easier to maintain that way. Sure! Is there a folder path you'd prefer to keep it at? Perhaps I could put it under `supportedBackends/google/pipelines/v2alpha1/src/monitoring`?. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451492862
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152:217,Deployability,pipeline,pipelines,217,"I'm concerned that the awesomeness of this will be lost if there's not a dead-simple way to get the graph. But I can accept that as a feature request on this already nice PR. Put the code in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`, please and thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152:264,Energy Efficiency,monitor,monitor,264,"I'm concerned that the awesomeness of this will be lost if there's not a dead-simple way to get the graph. But I can accept that as a feature request on this already nice PR. Put the code in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`, please and thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152:78,Usability,simpl,simple,78,"I'm concerned that the awesomeness of this will be lost if there's not a dead-simple way to get the graph. But I can accept that as a feature request on this already nice PR. Put the code in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`, please and thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451494152
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451496022:72,Energy Efficiency,monitor,monitor,72,"Nope as far as I know, it's turned on by default (and is used by GCP to monitor most resources): https://cloud.google.com/service-usage/docs/enabled-service#default",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451496022
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451507377:26,Modifiability,config,configurable,26,Please make this behavior configurable and defaulting to off,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451507377
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789:247,Energy Efficiency,monitor,monitoring,247,"Alright, would you prefer to expose it as a workflow (or Cromwell) option? Something like `monitoring_image` and if it's not defined, then the action is skipped. This way, one can also use an alternative image with their custom logic (incl. other monitoring APIs).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789:29,Security,expose,expose,29,"Alright, would you prefer to expose it as a workflow (or Cromwell) option? Something like `monitoring_image` and if it's not defined, then the action is skipped. This way, one can also use an alternative image with their custom logic (incl. other monitoring APIs).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789:228,Testability,log,logic,228,"Alright, would you prefer to expose it as a workflow (or Cromwell) option? Something like `monitoring_image` and if it's not defined, then the action is skipped. This way, one can also use an alternative image with their custom logic (incl. other monitoring APIs).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451511789
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516304:84,Energy Efficiency,Monitor,Monitoring,84,"Hmm, another moment is the Cromwell SA used by the GCE instances will need to have `Monitoring Metric Writer` role to be able to write metrics. I'll verify what happens when they don't. This is not an issue if the SA is Default Compute Engine account though.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516304
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509:130,Availability,avail,available,130,"that's a good question. I'd say to wire it in the same way as the current monitoring script option (don't have that answer easily available to me atm). . re why default off, i've learned to be conservative w/ these sorts of things",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509:74,Energy Efficiency,monitor,monitoring,74,"that's a good question. I'd say to wire it in the same way as the current monitoring script option (don't have that answer easily available to me atm). . re why default off, i've learned to be conservative w/ these sorts of things",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509:179,Usability,learn,learned,179,"that's a good question. I'd say to wire it in the same way as the current monitoring script option (don't have that answer easily available to me atm). . re why default off, i've learned to be conservative w/ these sorts of things",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451516509
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217:120,Deployability,pipeline,pipelines,120,"I exposed this as `monitoring_image` workflow option, and included the Dockerfile & script in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`. Should we also add a CI script that builds the image?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217:167,Energy Efficiency,monitor,monitor,167,"I exposed this as `monitoring_image` workflow option, and included the Dockerfile & script in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`. Should we also add a CI script that builds the image?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217:2,Security,expose,exposed,2,"I exposed this as `monitoring_image` workflow option, and included the Dockerfile & script in `supportedBackends/google/pipelines/v2alpha1/src/main/resources/cromwell-monitor/`. Should we also add a CI script that builds the image?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-451601217
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901:274,Energy Efficiency,monitor,monitoring,274,"There's another concern here that PAPIv2 doesn't ([currently](https://groups.google.com/forum/#!topic/google-genomics-discuss/newaE3R-cwY)) terminate background containers nicely once all non-background actions terminate. I.e. it uses SIGKILL, which cannot be caught in our monitoring container, and hence so far it has not been able to report the last timepoint. However, to work around that I'll add one more action, which will be _non-background_, and will run after the user action. This 2nd action will be assigned to the same `pidNamespace` as the monitoring action (which possible with PAPIv2), and hence will have access to the PID of the monitoring action and will then kill it ""nicely"" with SIGTERM, and wait for it to terminate - something like this: `killall python && wait`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901:554,Energy Efficiency,monitor,monitoring,554,"There's another concern here that PAPIv2 doesn't ([currently](https://groups.google.com/forum/#!topic/google-genomics-discuss/newaE3R-cwY)) terminate background containers nicely once all non-background actions terminate. I.e. it uses SIGKILL, which cannot be caught in our monitoring container, and hence so far it has not been able to report the last timepoint. However, to work around that I'll add one more action, which will be _non-background_, and will run after the user action. This 2nd action will be assigned to the same `pidNamespace` as the monitoring action (which possible with PAPIv2), and hence will have access to the PID of the monitoring action and will then kill it ""nicely"" with SIGTERM, and wait for it to terminate - something like this: `killall python && wait`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901:647,Energy Efficiency,monitor,monitoring,647,"There's another concern here that PAPIv2 doesn't ([currently](https://groups.google.com/forum/#!topic/google-genomics-discuss/newaE3R-cwY)) terminate background containers nicely once all non-background actions terminate. I.e. it uses SIGKILL, which cannot be caught in our monitoring container, and hence so far it has not been able to report the last timepoint. However, to work around that I'll add one more action, which will be _non-background_, and will run after the user action. This 2nd action will be assigned to the same `pidNamespace` as the monitoring action (which possible with PAPIv2), and hence will have access to the PID of the monitoring action and will then kill it ""nicely"" with SIGTERM, and wait for it to terminate - something like this: `killall python && wait`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901
https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901:622,Security,access,access,622,"There's another concern here that PAPIv2 doesn't ([currently](https://groups.google.com/forum/#!topic/google-genomics-discuss/newaE3R-cwY)) terminate background containers nicely once all non-background actions terminate. I.e. it uses SIGKILL, which cannot be caught in our monitoring container, and hence so far it has not been able to report the last timepoint. However, to work around that I'll add one more action, which will be _non-background_, and will run after the user action. This 2nd action will be assigned to the same `pidNamespace` as the monitoring action (which possible with PAPIv2), and hence will have access to the PID of the monitoring action and will then kill it ""nicely"" with SIGTERM, and wait for it to terminate - something like this: `killall python && wait`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510#issuecomment-452087901
https://github.com/broadinstitute/cromwell/issues/4511#issuecomment-452370658:48,Safety,abort,abort-status-issues,48,"> Could this be related to #4497?. Perhaps, but abort-status-issues have generally been associated with `METADATA_ENTRY` and `WORKFLOW_STORE_ENTRY` getting out of sync. Those two tables are technically in different sub-systems, with `WORKFLOW_STORE_ENTRY` internally tracking running workflows for the engine and `METADATA_ENTRY` reporting back statuses to external users. However, in the above issue, I believe this is a new case of the two ""reporter"" tables `METADATA_ENTRY` and now `WORKFLOW_METADATA_SUMMARY_ENTRY` out of (expected) sync. The way to further diagnose any of these issues would be to look for rows in each of the three tables-- filtered by the aberrant workflow ids-- and see which of the tables are not in the desired state.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4511#issuecomment-452370658
https://github.com/broadinstitute/cromwell/issues/4512#issuecomment-464244268:113,Testability,test,test,113,"WDL maps can't be heterogeneous; updating the workflow to use object fixes the issue. ```; version 1.0. workflow test {; ; Map[String, String] m = {""a"": ""a"", ""b"": ""b""}; String s = ""string"". output {; File write_attempt = write_json(object {m: m, s: s}); }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4512#issuecomment-464244268
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451570239:153,Integrability,depend,dependencies,153,We're expecting the resolver to look at the root of the submitted zip file when resolving files. We treat all imports as full paths from the root of the dependencies file structure.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451570239
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451605450:425,Testability,log,logical,425,"It's also possible that it was an accidental byproduct of the wiring to get things working with CWL and WES (both CWL & WDL) as they have a very different behavior than traditional Cromwell/WDL. . In the latter case the main WF is always placed at the root and everything stems from that, but in the former cases (and IMO a far, far, far, far more sane policy) the set of files are provided and one provides a pointer to the logical root",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451605450
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883:480,Deployability,update,update,480,"According to the PR description, the WDL 1.0 spec did not have an opinion here, so we let our 1.0 implementation change. The `development` version of WDL says; >In the event that there is no protocol the import is resolved **relative** to the location of the current document. If a protocol-less import starts with `/` it will be interpreted as starting from the root of the host in the resolved URL. so I think it would be most pragmatic to close this issue with a documentation-update PR. @tlangs does this sound fair to you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883:191,Integrability,protocol,protocol,191,"According to the PR description, the WDL 1.0 spec did not have an opinion here, so we let our 1.0 implementation change. The `development` version of WDL says; >In the event that there is no protocol the import is resolved **relative** to the location of the current document. If a protocol-less import starts with `/` it will be interpreted as starting from the root of the host in the resolved URL. so I think it would be most pragmatic to close this issue with a documentation-update PR. @tlangs does this sound fair to you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883:282,Integrability,protocol,protocol-less,282,"According to the PR description, the WDL 1.0 spec did not have an opinion here, so we let our 1.0 implementation change. The `development` version of WDL says; >In the event that there is no protocol the import is resolved **relative** to the location of the current document. If a protocol-less import starts with `/` it will be interpreted as starting from the root of the host in the resolved URL. so I think it would be most pragmatic to close this issue with a documentation-update PR. @tlangs does this sound fair to you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451608883
https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451699830:312,Modifiability,portab,portable,312,"Ultimately the question of how to resolve imports needs to be part of the WDL spec itself. NB that's not ""zip imports"" but rather just if everything is relative to the root workflow document or if everything is relative to the WDL at hand. Allowing for the behavior to be user defined makes WDL documents be non-portable. IMO it doesn't make much sense to add a switch into Cromwell to add support for the discarded angle of what was already a confusing grey area considering that the correct behavior has already been clarified for future spec versions. Updating the WDLs in question is the correct course of action here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4515#issuecomment-451699830
https://github.com/broadinstitute/cromwell/pull/4516#issuecomment-452047854:110,Usability,feedback,feedback,110,@rebrown1395 unassigning myself as there's currently nothing for me to do here: there are no reviewers and no feedback.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4516#issuecomment-452047854
https://github.com/broadinstitute/cromwell/issues/4518#issuecomment-454047093:302,Safety,safe,safety,302,"Thanks for pointing this out, @antonkulaga - this looks to me like a bug in our draft-2 and 1.0 support. I think this is probably something that could possibly be improved in a future WDL spec version. IMO ideally we wouldn't have to have a ""mixed"" return type function (since it plays badly with type-safety,) I think I'd prefer `read_json_object` and `read_json_array`, for example - but that would be up to the openWDL group, and this is definitely a bug in our interpretation for now!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4518#issuecomment-454047093
https://github.com/broadinstitute/cromwell/issues/4519#issuecomment-464203099:36,Availability,error,error,36,Do you happen to have the resulting error handy?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4519#issuecomment-464203099
https://github.com/broadinstitute/cromwell/issues/4520#issuecomment-452071787:6,Availability,failure,failures,6,"All 3 failures also emit:; ```; - should return pagination metadata only when page and pagesize query params are specified *** FAILED *** (9 seconds, 457 milliseconds); java.sql.SQLTransientConnectionException: db - Connection is not available, request timed out after 3608ms.; at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:14); at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:453); at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:46); at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:37); at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:249); at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:248); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4520#issuecomment-452071787
https://github.com/broadinstitute/cromwell/issues/4520#issuecomment-452071787:234,Availability,avail,available,234,"All 3 failures also emit:; ```; - should return pagination metadata only when page and pagesize query params are specified *** FAILED *** (9 seconds, 457 milliseconds); java.sql.SQLTransientConnectionException: db - Connection is not available, request timed out after 3608ms.; at com.zaxxer.hikari.pool.HikariPool.createTimeoutException(HikariPool.java:548); at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:186); at com.zaxxer.hikari.pool.HikariPool.getConnection(HikariPool.java:145); at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:83); at slick.jdbc.hikaricp.HikariCPJdbcDataSource.createConnection(HikariCPJdbcDataSource.scala:14); at slick.jdbc.JdbcBackend$BaseSession.<init>(JdbcBackend.scala:453); at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:46); at slick.jdbc.JdbcBackend$DatabaseDef.createSession(JdbcBackend.scala:37); at slick.basic.BasicBackend$DatabaseDef.acquireSession(BasicBackend.scala:249); at slick.basic.BasicBackend$DatabaseDef.acquireSession$(BasicBackend.scala:248); ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4520#issuecomment-452071787
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:182,Availability,failure,failure,182,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4374,Availability,Error,ErrorHandling,4374,:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4401,Availability,Error,ErrorHandling,4401,st.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9872,Availability,Error,ErrorHandling,9872,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9899,Availability,Error,ErrorHandling,9899,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:190,Integrability,message,message,190,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:249,Performance,concurren,concurrent,249,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:325,Performance,concurren,concurrent,325,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:398,Performance,concurren,concurrent,398,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4526,Performance,Concurren,ConcurrentRestrictions,4526,mework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(Cro,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4580,Performance,Concurren,ConcurrentRestrictions,4580,nTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4695,Performance,concurren,concurrent,4695,$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAtte,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4756,Performance,concurren,concurrent,4756,; at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Even,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4832,Performance,concurren,concurrent,4832,cala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Even,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4893,Performance,concurren,concurrent,4893,eater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.con,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4977,Performance,concurren,concurrent,4977,nit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:5663,Performance,concurren,concurrent,5663,ce.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at c,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:5747,Performance,concurren,concurrent,5747,til.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:5823,Performance,concurren,concurrent,5823,til.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:5896,Performance,concurren,concurrent,5896,nt.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10024,Performance,Concurren,ConcurrentRestrictions,10024,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10078,Performance,Concurren,ConcurrentRestrictions,10078,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10193,Performance,concurren,concurrent,10193,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10254,Performance,concurren,concurrent,10254,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10330,Performance,concurren,concurrent,10330,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10391,Performance,concurren,concurrent,10391,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:10475,Performance,concurren,concurrent,10475,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:36,Testability,Test,TestFailedDueToTimeoutException,36,2667. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:1061,Testability,Test,TestSuite,1061,n: The code passed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(En,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:1083,Testability,Test,TestSuite,1083,ed to eventually never returned normally. Attempted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410);,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:1122,Testability,Test,TestSuite,1122,empted 210 times over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(L,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:1145,Testability,Test,TestSuite,1145, over 3.3447279390999998 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(List.scala:389); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3567,Testability,Test,TestRunner,3567,uite.scala:1147); at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitV,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3588,Testability,Test,TestFramework,3588,at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(Concurrent,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3621,Testability,Test,TestRunner,3621,ala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.Compl,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3636,Testability,Test,TestFramework,3636,romwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3669,Testability,Test,TestFramework,3669,terAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3737,Testability,Test,TestFramework,3737,la:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3770,Testability,Test,TestFramework,3770,l.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$R,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3789,Testability,Test,TestFramework,3789,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3822,Testability,Test,TestFramework,3822,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3855,Testability,Test,TestFramework,3855,scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3912,Testability,Test,TestFramework,3912,ndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolEx,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:3945,Testability,Test,TestFramework,3945,ell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4002,Testability,Test,TestFramework,4002,atest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4035,Testability,Test,TestFunction,4035,ellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4054,Testability,Test,TestFramework,4054,ala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.la,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4087,Testability,Test,Tests,4087,pecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); C,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4112,Testability,Test,Tests,4112,$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scala,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4137,Testability,Test,Tests,4137,t org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:4166,Testability,Test,Tests,4166,perEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did n,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:5122,Testability,Test,TestFailedException,5122,$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(Workf,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:6559,Testability,Test,TestSuite,6559,:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(En,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:6581,Testability,Test,TestSuite,6581,runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410);,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:6620,Testability,Test,TestSuite,6620,on0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(L,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:6643,Testability,Test,TestSuite,6643,12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$2(WorkflowFailSlowSpec.scala:18); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(List.scala:389); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9065,Testability,Test,TestRunner,9065,uite.scala:1147); at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitV,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9086,Testability,Test,TestFramework,9086,at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(Concurrent,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9119,Testability,Test,TestRunner,9119,ala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.Compl,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9134,Testability,Test,TestFramework,9134,romwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9167,Testability,Test,TestFramework,9167,terAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9235,Testability,Test,TestFramework,9235,la:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9268,Testability,Test,TestFramework,9268,l.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$R,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9287,Testability,Test,TestFramework,9287,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9320,Testability,Test,TestFramework,9320,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9353,Testability,Test,TestFramework,9353,scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9410,Testability,Test,TestFramework,9410,ndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolEx,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9443,Testability,Test,TestFramework,9443,ell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9500,Testability,Test,TestFramework,9500,atest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9533,Testability,Test,TestFunction,9533,ellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9552,Testability,Test,TestFramework,9552,ala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.la,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9585,Testability,Test,Tests,9585,pecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); `,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9610,Testability,Test,Tests,9610,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9635,Testability,Test,Tests,9635,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593:9664,Testability,Test,Tests,9664,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-453539593
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:188,Availability,failure,failure,188,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4380,Availability,Error,ErrorHandling,4380,:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4407,Availability,Error,ErrorHandling,4407,st.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9878,Availability,Error,ErrorHandling,9878,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9905,Availability,Error,ErrorHandling,9905,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:196,Integrability,message,message,196,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:255,Performance,concurren,concurrent,255,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:331,Performance,concurren,concurrent,331,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:404,Performance,concurren,concurrent,404,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4532,Performance,Concurren,ConcurrentRestrictions,4532,mework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(Cro,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4586,Performance,Concurren,ConcurrentRestrictions,4586,nTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4701,Performance,concurren,concurrent,4701,$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAtte,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4762,Performance,concurren,concurrent,4762,; at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Even,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4838,Performance,concurren,concurrent,4838,cala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Even,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4899,Performance,concurren,concurrent,4899,eater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.con,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4983,Performance,concurren,concurrent,4983,nit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:5669,Performance,concurren,concurrent,5669,ce.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at c,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:5753,Performance,concurren,concurrent,5753,til.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:5829,Performance,concurren,concurrent,5829,til.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:5902,Performance,concurren,concurrent,5902,nt.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10030,Performance,Concurren,ConcurrentRestrictions,10030,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10084,Performance,Concurren,ConcurrentRestrictions,10084,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10199,Performance,concurren,concurrent,10199,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10260,Performance,concurren,concurrent,10260,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10336,Performance,concurren,concurrent,10336,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10397,Performance,concurren,concurrent,10397,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:10481,Performance,concurren,concurrent,10481,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:42,Testability,Test,TestFailedDueToTimeoutException,42,Build 3730. ```; org.scalatest.exceptions.TestFailedDueToTimeoutException: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:1067,Testability,Test,TestSuite,1067,n: The code passed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(En,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:1089,Testability,Test,TestSuite,1089,ed to eventually never returned normally. Attempted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410);,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:1128,Testability,Test,TestSuite,1128,empted 210 times over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(L,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:1151,Testability,Test,TestSuite,1151, over 3.3499629773500006 minutes. Last failure message: Submitted did not equal Failed.; at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:432); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(List.scala:389); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3573,Testability,Test,TestRunner,3573,uite.scala:1147); at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitV,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3594,Testability,Test,TestFramework,3594,at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(Concurrent,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3627,Testability,Test,TestRunner,3627,ala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.Compl,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3642,Testability,Test,TestFramework,3642,romwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3675,Testability,Test,TestFramework,3675,terAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3743,Testability,Test,TestFramework,3743,la:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3776,Testability,Test,TestFramework,3776,l.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$R,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3795,Testability,Test,TestFramework,3795,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3828,Testability,Test,TestFramework,3828,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3861,Testability,Test,TestFramework,3861,scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3918,Testability,Test,TestFramework,3918,ndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolEx,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:3951,Testability,Test,TestFramework,3951,ell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4008,Testability,Test,TestFramework,4008,atest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4041,Testability,Test,TestFunction,4041,ellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4060,Testability,Test,TestFramework,4060,ala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.la,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4093,Testability,Test,Tests,4093,pecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); C,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4118,Testability,Test,Tests,4118,$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scala,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4143,Testability,Test,Tests,4143,t org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:4172,Testability,Test,Tests,4172,perEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did n,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:5128,Testability,Test,TestFailedException,5128,$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Cause: org.scalatest.exceptions.TestFailedException: Submitted did not equal Failed; at org.scalatest.MatchersHelper$.indicateFailure(MatchersHelper.scala:346); at org.scalatest.Matchers$ShouldMethodHelper$.shouldMatcher(Matchers.scala:6668); at org.scalatest.Matchers$AnyShouldWrapper.should(Matchers.scala:6716); at cromwell.CromwellTestKitSpec.verifyWorkflowState(CromwellTestKitSpec.scala:377); at cromwell.CromwellTestKitSpec.$anonfun$runWdl$1(CromwellTestKitSpec.scala:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(Workf,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:6565,Testability,Test,TestSuite,6565,:323); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(En,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:6587,Testability,Test,TestSuite,6587,runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410);,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:6626,Testability,Test,TestSuite,6626,on0$mcV$sp.java:12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(L,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:6649,Testability,Test,TestSuite,6649,12); at org.scalatest.concurrent.Eventually.makeAValiantAttempt$1(Eventually.scala:395); at org.scalatest.concurrent.Eventually.tryTryAgain$1(Eventually.scala:409); at org.scalatest.concurrent.Eventually.eventually(Eventually.scala:439); at org.scalatest.concurrent.Eventually.eventually$(Eventually.scala:391); at cromwell.CromwellTestKitSpec.eventually(CromwellTestKitSpec.scala:251); at cromwell.CromwellTestKitSpec.runWdl(CromwellTestKitSpec.scala:323); at cromwell.WorkflowFailSlowSpec.$anonfun$new$4(WorkflowFailSlowSpec.scala:30); at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); at org.scalatest.Transformer.apply(Transformer.scala:22); at org.scalatest.Transformer.apply(Transformer.scala:20); at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); at cromwell.CromwellTestKitWordSpec.withFixture(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.invokeWithFixture$1(WordSpecLike.scala:1076); at org.scalatest.WordSpecLike.$anonfun$runTest$1(WordSpecLike.scala:1088); at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289); at org.scalatest.WordSpecLike.runTest(WordSpecLike.scala:1088); at org.scalatest.WordSpecLike.runTest$(WordSpecLike.scala:1070); at cromwell.CromwellTestKitWordSpec.runTest(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$runTests$1(WordSpecLike.scala:1147); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:396); at scala.collection.immutable.List.foreach(List.scala:389); at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384); at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:373); at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:410); at scala.collection.immutable.List.foreach(List.scala:389); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9071,Testability,Test,TestRunner,9071,uite.scala:1147); at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitV,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9092,Testability,Test,TestFramework,9092,at org.scalatest.Suite.run$(Suite.scala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(Concurrent,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9125,Testability,Test,TestRunner,9125,ala:1129); at cromwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.Compl,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9140,Testability,Test,TestFramework,9140,romwell.CromwellTestKitSpec.org$scalatest$BeforeAndAfterAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9173,Testability,Test,TestFramework,9173,terAll$$super$run(CromwellTestKitSpec.scala:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9241,Testability,Test,TestFramework,9241,la:251); at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9274,Testability,Test,TestFramework,9274,l.liftedTree1$1(BeforeAndAfterAll.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$R,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9293,Testability,Test,TestFramework,9293,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9326,Testability,Test,TestFramework,9326,.scala:213); at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.jav,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9359,Testability,Test,TestFramework,9359,scala:210); at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9416,Testability,Test,TestFramework,9416,ndAfterAll.run$(BeforeAndAfterAll.scala:208); at cromwell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolEx,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9449,Testability,Test,TestFramework,9449,ell.CromwellTestKitWordSpec.org$scalatest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9506,Testability,Test,TestFramework,9506,atest$WordSpecLike$$super$run(CromwellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9539,Testability,Test,TestFunction,9539,ellTestKitSpec.scala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9558,Testability,Test,TestFramework,9558,ala:250); at org.scalatest.WordSpecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.la,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9591,Testability,Test,Tests,9591,pecLike.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); `,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9616,Testability,Test,Tests,9616,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9641,Testability,Test,Tests,9641,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030:9670,Testability,Test,Tests,9670,Like.$anonfun$run$1(WordSpecLike.scala:1192); at org.scalatest.SuperEngine.runImpl(Engine.scala:521); at org.scalatest.WordSpecLike.run(WordSpecLike.scala:1192); at org.scalatest.WordSpecLike.run$(WordSpecLike.scala:1190); at cromwell.CromwellTestKitWordSpec.run(CromwellTestKitSpec.scala:250); at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314); at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:507); at sbt.TestRunner.runTest$1(TestFramework.scala:113); at sbt.TestRunner.run(TestFramework.scala:124); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.$anonfun$apply$1(TestFramework.scala:282); at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:246); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFramework$$anon$2$$anonfun$$lessinit$greater$1.apply(TestFramework.scala:282); at sbt.TestFunction.apply(TestFramework.scala:294); at sbt.Tests$.processRunnable$1(Tests.scala:347); at sbt.Tests$.$anonfun$makeSerial$1(Tests.scala:353); at sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:46); at sbt.std.Transform$$anon$4.work(System.scala:67); at sbt.Execute.$anonfun$submit$2(Execute.scala:269); at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16); at sbt.Execute.work(Execute.scala:278); at sbt.Execute.$anonfun$submit$1(Execute.scala:269); at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4521#issuecomment-467169030
https://github.com/broadinstitute/cromwell/pull/4522#issuecomment-469444875:79,Usability,guid,guide,79,"I'm going to close this PR as clutter, but I will leave the branch intact as a guide for if (hopefully when!) we circle back to this functionality",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4522#issuecomment-469444875
https://github.com/broadinstitute/cromwell/pull/4523#issuecomment-452067058:22,Energy Efficiency,green,greenness,22,👍 LGTM pending Travis greenness!. [![Approved with PullApprove](https://img.shields.io/badge/two_reviewers-approved-brightgreen.svg)](https://pullapprove.com/broadinstitute/cromwell/pull-request/4523/?utm_source=github-pr&utm_medium=comment-badge&utm_campaign=broadinstitute/cromwell),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4523#issuecomment-452067058
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452098681:36,Testability,test,tests,36,It really takes 30 seconds for unit tests to get a connection? 🤢,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452098681
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452130807:11,Testability,log,logical,11,Is there a logical reason why it takes so long or is this just turning the knob up higher and hoping for the best?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452130807
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458:79,Availability,down,downstream,79,"@geoffjentry yes, this is turning the knob higher and hoping for the best. The downstream tests succeeded except for the one that depended on cross-talking with the failed test...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458:130,Integrability,depend,depended,130,"@geoffjentry yes, this is turning the knob higher and hoping for the best. The downstream tests succeeded except for the one that depended on cross-talking with the failed test...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458:90,Testability,test,tests,90,"@geoffjentry yes, this is turning the knob higher and hoping for the best. The downstream tests succeeded except for the one that depended on cross-talking with the failed test...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458
https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458:172,Testability,test,test,172,"@geoffjentry yes, this is turning the knob higher and hoping for the best. The downstream tests succeeded except for the one that depended on cross-talking with the failed test...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4525#issuecomment-452358458
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156:62,Integrability,depend,dependent,62,"At a guess, because the implementation of globbing is backend-dependent (or really, filesystem dependent) and therefore depends on having a task for context.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156:95,Integrability,depend,dependent,95,"At a guess, because the implementation of globbing is backend-dependent (or really, filesystem dependent) and therefore depends on having a task for context.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156:120,Integrability,depend,depends,120,"At a guess, because the implementation of globbing is backend-dependent (or really, filesystem dependent) and therefore depends on having a task for context.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452187156
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452408474:147,Modifiability,portab,portability,147,"Thanks for the explanation. ""It'll be a huge headache"" is good enough for me. Is there any danger in using glob_tasks as above in terms of backend portability?. Also, could I ask what you mean here by ""backend""? Do you mean Cromwell itself, as opposed to another WMS that might implement WDL, or do you mean it in the sense of the backend definition specified in the Cromwell conf file (ie Google Cloud vs SLURM etc)?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452408474
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217:16,Modifiability,portab,portability,16,"@oneillkza . re portability: If you're concerned about portability and I understand what you're trying to do, this won't do what you want. If what you're trying to say is ""For every file in this location, DoSomething(File)"" and you want to be portable to the cloud backends the problem your going to have is that the tasks run on a VM with a local filesystem but the files you want to glob will be in object storage (e.g. GCS, S3). You could make those files an input to the task, they'd get localized to the VM and you'd be good to go, but now we're back to the original problem - if you knew all of the files you wouldn't need a glob :). I **think** you can get what you want by using the relatively new [Directory](hub.com/openwdl/wdl/blob/master/versions/development/SPEC.md#types) type, which is in the developmental version of WDL and unofficially supported by Cromwell at the moment. What I'm picturing is supplying a Directory input to `glob_tasks`, and then globbing out the files that you want from there (unless you're literally trying to get **all** the files in a Directory, in which case just use a Directory type in the first place). cc'ing @cjllanwarne in case I've misspoke somewhere in here, he's a lot more knowledgable on the fine details. re backends: The words I use are an artifact of how Cromwell is constructed but I draw a mental distinction between the workflow engine itself (e.g. Cromwell, Nextflow, Snakemake, etc) and the underlying job execution platform (e.g. local machine, SLURM, SGE, GCP, AWS). They're often tightly coupled but aren't necessarily that way. There's increasing desire for engines which can compute across multiple execution platforms within the same workflow - so in Cromwell terms perhaps some of your `call`s are run on a local SLURM cluster backend, some are run on GCP backend, and some on AWS backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217:55,Modifiability,portab,portability,55,"@oneillkza . re portability: If you're concerned about portability and I understand what you're trying to do, this won't do what you want. If what you're trying to say is ""For every file in this location, DoSomething(File)"" and you want to be portable to the cloud backends the problem your going to have is that the tasks run on a VM with a local filesystem but the files you want to glob will be in object storage (e.g. GCS, S3). You could make those files an input to the task, they'd get localized to the VM and you'd be good to go, but now we're back to the original problem - if you knew all of the files you wouldn't need a glob :). I **think** you can get what you want by using the relatively new [Directory](hub.com/openwdl/wdl/blob/master/versions/development/SPEC.md#types) type, which is in the developmental version of WDL and unofficially supported by Cromwell at the moment. What I'm picturing is supplying a Directory input to `glob_tasks`, and then globbing out the files that you want from there (unless you're literally trying to get **all** the files in a Directory, in which case just use a Directory type in the first place). cc'ing @cjllanwarne in case I've misspoke somewhere in here, he's a lot more knowledgable on the fine details. re backends: The words I use are an artifact of how Cromwell is constructed but I draw a mental distinction between the workflow engine itself (e.g. Cromwell, Nextflow, Snakemake, etc) and the underlying job execution platform (e.g. local machine, SLURM, SGE, GCP, AWS). They're often tightly coupled but aren't necessarily that way. There's increasing desire for engines which can compute across multiple execution platforms within the same workflow - so in Cromwell terms perhaps some of your `call`s are run on a local SLURM cluster backend, some are run on GCP backend, and some on AWS backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217:243,Modifiability,portab,portable,243,"@oneillkza . re portability: If you're concerned about portability and I understand what you're trying to do, this won't do what you want. If what you're trying to say is ""For every file in this location, DoSomething(File)"" and you want to be portable to the cloud backends the problem your going to have is that the tasks run on a VM with a local filesystem but the files you want to glob will be in object storage (e.g. GCS, S3). You could make those files an input to the task, they'd get localized to the VM and you'd be good to go, but now we're back to the original problem - if you knew all of the files you wouldn't need a glob :). I **think** you can get what you want by using the relatively new [Directory](hub.com/openwdl/wdl/blob/master/versions/development/SPEC.md#types) type, which is in the developmental version of WDL and unofficially supported by Cromwell at the moment. What I'm picturing is supplying a Directory input to `glob_tasks`, and then globbing out the files that you want from there (unless you're literally trying to get **all** the files in a Directory, in which case just use a Directory type in the first place). cc'ing @cjllanwarne in case I've misspoke somewhere in here, he's a lot more knowledgable on the fine details. re backends: The words I use are an artifact of how Cromwell is constructed but I draw a mental distinction between the workflow engine itself (e.g. Cromwell, Nextflow, Snakemake, etc) and the underlying job execution platform (e.g. local machine, SLURM, SGE, GCP, AWS). They're often tightly coupled but aren't necessarily that way. There's increasing desire for engines which can compute across multiple execution platforms within the same workflow - so in Cromwell terms perhaps some of your `call`s are run on a local SLURM cluster backend, some are run on GCP backend, and some on AWS backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452418217
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452452934:364,Availability,down,down,364,"Thanks @geoffjentry !. Yeah, I'd realised that I needed to pass an absolute path into the workflow I'm trying to run, which works for running on our local SLURM cluster, but definitely wouldn't be portable or the ""right"" way to create the workflow. It sounds like the Directory type would be the right way to do this in future, and as you say, passing a Directory down to a task to pick the needed files out. . In the meanwhile, do you know if Cromwell's CWL implementation supports the CWL Directory type? Switching to CWL might also make sense for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452452934
https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452452934:197,Modifiability,portab,portable,197,"Thanks @geoffjentry !. Yeah, I'd realised that I needed to pass an absolute path into the workflow I'm trying to run, which works for running on our local SLURM cluster, but definitely wouldn't be portable or the ""right"" way to create the workflow. It sounds like the Directory type would be the right way to do this in future, and as you say, passing a Directory down to a task to pick the needed files out. . In the meanwhile, do you know if Cromwell's CWL implementation supports the CWL Directory type? Switching to CWL might also make sense for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526#issuecomment-452452934
https://github.com/broadinstitute/cromwell/pull/4532#issuecomment-452743778:88,Testability,test,test,88,"Not trolling but is there really anything to review here? Seems like this is a ""fix the test by making it current"" and that means importing Brad's work. I.e. there are no judgement calls being made here by the author @aednichols for me to review",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4532#issuecomment-452743778
https://github.com/broadinstitute/cromwell/pull/4532#issuecomment-452746834:45,Energy Efficiency,green,green,45,@danbills we do still need pullapprove to go green prior to merging,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4532#issuecomment-452746834
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554372:166,Deployability,Pipeline,Pipelines,166,"Hi @TMiguelT - I fully agree that Cromwell should support some of the more degenerate base images like busybox and alpine. This is partially historical (at one point Pipelines API required Bash so we had no reason to not just use bash ourselves), and going forward it's more been a lack of putting in enough testing of these sorts of containers to keep ourselves honest - we **intend** to be more agnostic but things fall through here and there",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554372
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554372:308,Testability,test,testing,308,"Hi @TMiguelT - I fully agree that Cromwell should support some of the more degenerate base images like busybox and alpine. This is partially historical (at one point Pipelines API required Bash so we had no reason to not just use bash ourselves), and going forward it's more been a lack of putting in enough testing of these sorts of containers to keep ourselves honest - we **intend** to be more agnostic but things fall through here and there",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554372
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554527:91,Testability,test,testing,91,Note to implementer: Please make sure we use both busybox & alpine in enough places in our testing suites that we'll know if something regresses,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453554527
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680:171,Testability,test,testing,171,"I think it's reasonable to assume the Bash shell, since's it's mostly ubiquitous now (or maybe it could be rewritten to work with `sh`?). Adding Alpine and Busybox to the testing suite sounds like an excellent idea. Is this as simple as just reducing the use of newer flags/utilities and ensuring those tests pass?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680:303,Testability,test,tests,303,"I think it's reasonable to assume the Bash shell, since's it's mostly ubiquitous now (or maybe it could be rewritten to work with `sh`?). Adding Alpine and Busybox to the testing suite sounds like an excellent idea. Is this as simple as just reducing the use of newer flags/utilities and ensuring those tests pass?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680:227,Usability,simpl,simple,227,"I think it's reasonable to assume the Bash shell, since's it's mostly ubiquitous now (or maybe it could be rewritten to work with `sh`?). Adding Alpine and Busybox to the testing suite sounds like an excellent idea. Is this as simple as just reducing the use of newer flags/utilities and ensuring those tests pass?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453705680
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453708063:65,Testability,test,tests,65,"I did just see that both Alpine & Busybox **are** in some of our tests, so it helps make the point that we do try here :) Clearly we're not hitting **this**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453708063
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453708063:122,Usability,Clear,Clearly,122,"I did just see that both Alpine & Busybox **are** in some of our tests, so it helps make the point that we do try here :) Clearly we're not hitting **this**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-453708063
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-460417893:273,Availability,failure,failures,273,When I tried to reproduce this locally Cromwell completed the workflow successfully despite the fact that `find` had been invoked with invalid syntax and no placeholder `.file`s had been created in my empty directories. It looks like our wrapper script is not checking for failures at this point.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-460417893
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-460417893:238,Integrability,wrap,wrapper,238,When I tried to reproduce this locally Cromwell completed the workflow successfully despite the fact that `find` had been invoked with invalid syntax and no placeholder `.file`s had been created in my empty directories. It looks like our wrapper script is not checking for failures at this point.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-460417893
https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-461988230:23,Usability,clear,clear,23,"Yes, sorry that wasn't clear. This should be fixed in Cromwell 37 thanks to @DavyCats contribution in #4597.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4536#issuecomment-461988230
https://github.com/broadinstitute/cromwell/issues/4537#issuecomment-460891681:37,Testability,log,logged,37,I'd say this is a dupe of an issue I logged a while back #4364,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4537#issuecomment-460891681
https://github.com/broadinstitute/cromwell/issues/4538#issuecomment-482190924:113,Availability,down,down,113,"@cjllanwarne I've run into this issue also, while I can work around it currently, it will likely become an issue down the road when trying to build workflows comprising of scatter operations when you want to collect up the results.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4538#issuecomment-482190924
https://github.com/broadinstitute/cromwell/pull/4539#issuecomment-453343693:78,Testability,test,tests,78,"Temporarily closing until my JsonUtils ""improvements"" no longer disrupt other tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4539#issuecomment-453343693
https://github.com/broadinstitute/cromwell/issues/4540#issuecomment-462355219:21,Testability,log,logging,21,closed per hog limit logging,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4540#issuecomment-462355219
https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-453807479:139,Deployability,deploy,deployed,139,"@geoffjentry Thanks for the quick response and the suggestion. I wrote a quick wdl script, that runs on cromwell + local backend, but when deployed on the AWS batch backend it fails in the same way..; The script `exampleWorkflows/bbmap.wdl` is: . ```; task bbmaptask {; File f1; File f2; command {; reformat.sh maxcalledquality=40 in=${f1} in2=${f2} out=${f1}.ref.fq.gz out2=${f2}.ref.fq.gz; }; output {; Array[File] response = glob(""*R?.ref.fq.gz""); }; runtime {; docker: ""*********.dkr.ecr.us-east-1.amazonaws.com/ngs/bbmap:v37.64""; }. }. workflow bbmapwf{; 	call bbmaptask; }; ```. The input file `exampleInput/fastq.s3.wdl.json`; ```; {; ""bbmapwf.bbmaptask.f1"": ""s3://bucket/fastq.20180820-150001/DA0000317_WSU-DLCL_R_02_01_02_S36_R1_001.fastq.gz"",; ""bbmapwf.bbmaptask.f2"": ""s3://bucket/fastq.20180820-150001/DA0000317_WSU-DLCL_R_02_01_02_S36_R2_001.fastq.gz""; }. ```. I run cromwell as:. ```; java -Dconfig.file=awsbatch/aws.conf -jar cromwell-36.jar run -i exampleInput/fastq.s3.wdl.json exampleWorkflows/bbmap.wdl. ```. Thanks for your help",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-453807479
https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024:167,Modifiability,config,configure-aws-batch-cfn,167,"@kmavrommatis - Curious how your AWS Batch environment was setup. Did you use the Cfn templates provided [here](https://docs.opendata.aws/genomics-workflows/aws-batch/configure-aws-batch-cfn/), or build it manually?. It is important that the job instance profile associated with the compute environment has the correct access permissions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024
https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024:319,Security,access,access,319,"@kmavrommatis - Curious how your AWS Batch environment was setup. Did you use the Cfn templates provided [here](https://docs.opendata.aws/genomics-workflows/aws-batch/configure-aws-batch-cfn/), or build it manually?. It is important that the job instance profile associated with the compute environment has the correct access permissions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-454188024
https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228:83,Availability,error,error,83,"Anyone have a concrete solution to this, we are also getting the permission denied error with our aws batch setup. We have even included chmod 777 in the cloud init script to ensure that directory is accessible.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228
https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228:200,Security,access,accessible,200,"Anyone have a concrete solution to this, we are also getting the permission denied error with our aws batch setup. We have even included chmod 777 in the cloud init script to ensure that directory is accessible.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542#issuecomment-531922228
https://github.com/broadinstitute/cromwell/issues/4545#issuecomment-458180807:100,Testability,test,testing,100,"In the future I think we should break this kind of ticket up into smaller pieces, in this case.:. * testing; * fiab; * live",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4545#issuecomment-458180807
https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-464246825:70,Modifiability,config,config,70,FWIW that parser is a 3rd party library (https://github.com/lightbend/config),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-464246825
https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266:305,Availability,error,error,305,"@TMiguelT I looked into this and we are using the latest version of the configuration library, so short of someone submitting a PR to fix their parsing issue, there is not much we can do. Lightbend recommends a linting tool, http://www.hoconlint.com/, which when run on your sample file gives the correct error message!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266
https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266:72,Deployability,configurat,configuration,72,"@TMiguelT I looked into this and we are using the latest version of the configuration library, so short of someone submitting a PR to fix their parsing issue, there is not much we can do. Lightbend recommends a linting tool, http://www.hoconlint.com/, which when run on your sample file gives the correct error message!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266
https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266:311,Integrability,message,message,311,"@TMiguelT I looked into this and we are using the latest version of the configuration library, so short of someone submitting a PR to fix their parsing issue, there is not much we can do. Lightbend recommends a linting tool, http://www.hoconlint.com/, which when run on your sample file gives the correct error message!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266
https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266:72,Modifiability,config,configuration,72,"@TMiguelT I looked into this and we are using the latest version of the configuration library, so short of someone submitting a PR to fix their parsing issue, there is not much we can do. Lightbend recommends a linting tool, http://www.hoconlint.com/, which when run on your sample file gives the correct error message!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549#issuecomment-465173266
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219:459,Deployability,upgrade,upgrade,459,"Hi @Redmar-van-den-Berg, you're correct, there appears to be a bug in our draft-2 parser which is failing to catch this. To answer ""which is correct"", the requirement to wrap values in arrays was not being enforced correctly but it now is. In your example you can do this with the array literal syntax, eg:; ```wdl; call ls {; input: files = [ i ]; }; ```. I have added a test for our WDL 1.0 support which **is** catching this properly, so if you're able to upgrade your workflows from WDL draft-2 to WDL 1.0, then `womtool validate` will give you the correct answer. If not, I'll leave this open as a bug since it certainly *should* be picked up by womtool. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219:170,Integrability,wrap,wrap,170,"Hi @Redmar-van-den-Berg, you're correct, there appears to be a bug in our draft-2 parser which is failing to catch this. To answer ""which is correct"", the requirement to wrap values in arrays was not being enforced correctly but it now is. In your example you can do this with the array literal syntax, eg:; ```wdl; call ls {; input: files = [ i ]; }; ```. I have added a test for our WDL 1.0 support which **is** catching this properly, so if you're able to upgrade your workflows from WDL draft-2 to WDL 1.0, then `womtool validate` will give you the correct answer. If not, I'll leave this open as a bug since it certainly *should* be picked up by womtool. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219:525,Security,validat,validate,525,"Hi @Redmar-van-den-Berg, you're correct, there appears to be a bug in our draft-2 parser which is failing to catch this. To answer ""which is correct"", the requirement to wrap values in arrays was not being enforced correctly but it now is. In your example you can do this with the array literal syntax, eg:; ```wdl; call ls {; input: files = [ i ]; }; ```. I have added a test for our WDL 1.0 support which **is** catching this properly, so if you're able to upgrade your workflows from WDL draft-2 to WDL 1.0, then `womtool validate` will give you the correct answer. If not, I'll leave this open as a bug since it certainly *should* be picked up by womtool. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219:372,Testability,test,test,372,"Hi @Redmar-van-den-Berg, you're correct, there appears to be a bug in our draft-2 parser which is failing to catch this. To answer ""which is correct"", the requirement to wrap values in arrays was not being enforced correctly but it now is. In your example you can do this with the array literal syntax, eg:; ```wdl; call ls {; input: files = [ i ]; }; ```. I have added a test for our WDL 1.0 support which **is** catching this properly, so if you're able to upgrade your workflows from WDL draft-2 to WDL 1.0, then `womtool validate` will give you the correct answer. If not, I'll leave this open as a bug since it certainly *should* be picked up by womtool. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-454545219
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607:135,Availability,error,error,135,"I am running into the same bug on Terra. Not sure what version of Cromwell it is using. My wdl validates however, I get the a run time error. ```; Failed to evaluate input 'fastq1' (reason 1 of 1): No coercion defined from wom value(s) '""gs://fc-secure-46b3886a-473a-49ef-8073-022230a526ac/6463b025-27cf-4649-b6d0-59f860bdf18b/bam2FastQStarAlignWorkflow/a4a0d2f2-cc8b-41d8-a5b5-61cf6c2d0bd4/call-bamToFastq/cacheCopy/GTEX-1192X-0011-R10a-SM-DO941.1.fastq.gz""' of type 'File' to 'Array[File]'.; ```. adding '[' and ']' resolved the run time issue; ```; call starWorkflow.star_fastq_list {; input:; star_index = starIndex,; fastq1 = [ bamToFastq.firstEndFastq ],; fastq2 = [ bamToFastq.secondEndFastq ],; prefix = sampleId; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607:407,Performance,cache,cacheCopy,407,"I am running into the same bug on Terra. Not sure what version of Cromwell it is using. My wdl validates however, I get the a run time error. ```; Failed to evaluate input 'fastq1' (reason 1 of 1): No coercion defined from wom value(s) '""gs://fc-secure-46b3886a-473a-49ef-8073-022230a526ac/6463b025-27cf-4649-b6d0-59f860bdf18b/bam2FastQStarAlignWorkflow/a4a0d2f2-cc8b-41d8-a5b5-61cf6c2d0bd4/call-bamToFastq/cacheCopy/GTEX-1192X-0011-R10a-SM-DO941.1.fastq.gz""' of type 'File' to 'Array[File]'.; ```. adding '[' and ']' resolved the run time issue; ```; call starWorkflow.star_fastq_list {; input:; star_index = starIndex,; fastq1 = [ bamToFastq.firstEndFastq ],; fastq2 = [ bamToFastq.secondEndFastq ],; prefix = sampleId; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607:95,Security,validat,validates,95,"I am running into the same bug on Terra. Not sure what version of Cromwell it is using. My wdl validates however, I get the a run time error. ```; Failed to evaluate input 'fastq1' (reason 1 of 1): No coercion defined from wom value(s) '""gs://fc-secure-46b3886a-473a-49ef-8073-022230a526ac/6463b025-27cf-4649-b6d0-59f860bdf18b/bam2FastQStarAlignWorkflow/a4a0d2f2-cc8b-41d8-a5b5-61cf6c2d0bd4/call-bamToFastq/cacheCopy/GTEX-1192X-0011-R10a-SM-DO941.1.fastq.gz""' of type 'File' to 'Array[File]'.; ```. adding '[' and ']' resolved the run time issue; ```; call starWorkflow.star_fastq_list {; input:; star_index = starIndex,; fastq1 = [ bamToFastq.firstEndFastq ],; fastq2 = [ bamToFastq.secondEndFastq ],; prefix = sampleId; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607
https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607:246,Security,secur,secure-,246,"I am running into the same bug on Terra. Not sure what version of Cromwell it is using. My wdl validates however, I get the a run time error. ```; Failed to evaluate input 'fastq1' (reason 1 of 1): No coercion defined from wom value(s) '""gs://fc-secure-46b3886a-473a-49ef-8073-022230a526ac/6463b025-27cf-4649-b6d0-59f860bdf18b/bam2FastQStarAlignWorkflow/a4a0d2f2-cc8b-41d8-a5b5-61cf6c2d0bd4/call-bamToFastq/cacheCopy/GTEX-1192X-0011-R10a-SM-DO941.1.fastq.gz""' of type 'File' to 'Array[File]'.; ```. adding '[' and ']' resolved the run time issue; ```; call starWorkflow.star_fastq_list {; input:; star_index = starIndex,; fastq1 = [ bamToFastq.firstEndFastq ],; fastq2 = [ bamToFastq.secondEndFastq ],; prefix = sampleId; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550#issuecomment-1148945607
https://github.com/broadinstitute/cromwell/pull/4551#issuecomment-454808901:79,Testability,test,tests,79,need travis to flag this as OK before merging. the seemingly unrelated papi v1 tests are failing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4551#issuecomment-454808901
https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-459790343:4,Deployability,update,updates,4,Any updates on this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-459790343
https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925:125,Availability,error,error,125,"@aednichols I want to reopen, because Map[String, MyStruct] also crashes and because if you claim it is about types than the error should appear when I validate with latest womtool and not in a runtime!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925
https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925:152,Security,validat,validate,152,"@aednichols I want to reopen, because Map[String, MyStruct] also crashes and because if you claim it is about types than the error should appear when I validate with latest womtool and not in a runtime!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464240925
https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464256509:99,Deployability,release,release,99,@aednichols I use development version (until recently cromwell:develop was more stable than latest release) and my cromwell container is based on cromwell:develop,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4555#issuecomment-464256509
https://github.com/broadinstitute/cromwell/pull/4559#issuecomment-455640456:33,Deployability,hotfix,hotfix,33,"@orodeh I don't think we'll do a hotfix for this back into 36, but the better news is that 37 isn't too far away, so it shouldn't be too long before this gets released.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4559#issuecomment-455640456
https://github.com/broadinstitute/cromwell/pull/4559#issuecomment-455640456:159,Deployability,release,released,159,"@orodeh I don't think we'll do a hotfix for this back into 36, but the better news is that 37 isn't too far away, so it shouldn't be too long before this gets released.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4559#issuecomment-455640456
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1214,Availability,Error,Error,1214,"broadinstitute/cromwell/blob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(Con",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:2312,Availability,robust,robustPoll,2312,rent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:2640,Availability,robust,robustPoll,2640,c(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.di,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4933,Availability,alive,alive,4933,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:418,Deployability,release,release,418,"I wanted to second this, as we're setting the same issue submitting to PBSPro clusters; with the latest Cromwell development version. Looking through the code, it appears to; originate from https://github.com/broadinstitute/cromwell/blob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecu",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4312,Deployability,configurat,configuration,4312,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:342,Modifiability,config,config,342,"I wanted to second this, as we're setting the same issue submitting to PBSPro clusters; with the latest Cromwell development version. Looking through the code, it appears to; originate from https://github.com/broadinstitute/cromwell/blob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecu",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:349,Modifiability,Config,ConfigAsyncJobExecutionActor,349,"I wanted to second this, as we're setting the same issue submitting to PBSPro clusters; with the latest Cromwell development version. Looking through the code, it appears to; originate from https://github.com/broadinstitute/cromwell/blob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecu",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1818,Modifiability,config,config,1818,"[2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1880,Modifiability,Config,ConfigAsyncJobExecutionActor,1880,"Actor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:2155,Modifiability,config,config,2155,l fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(C,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:2206,Modifiability,Config,ConfigAsyncJobExecutionActor,2206,r; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.Actor,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:3098,Modifiability,config,config,3098,"ecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionAct",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:3158,Modifiability,Config,ConfigAsyncJobExecutionActor,3158,"patchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecuti",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:3892,Modifiability,config,config,3892,"scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script};",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:3949,Modifiability,Config,ConfigAsyncJobExecutionActor,3949,"172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_i",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4019,Modifiability,config,config,4019,"a.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localizat",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4076,Modifiability,Config,ConfigAsyncJobExecutionActor,4076,"end.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-li",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4312,Modifiability,config,configuration,4312,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4394,Modifiability,config,config,4394,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4401,Modifiability,Config,ConfigBackendLifecycleActorFactory,4401,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4438,Modifiability,config,config,4438,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1177,Performance,concurren,concurrent,1177,"te from https://github.com/broadinstitute/cromwell/blob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsync",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1230,Performance,concurren,concurrent,1230,"ob/33c58ef22b6a8edc4c1912c1416225c79d298f76/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.s",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1292,Performance,concurren,concurrent,1292,"sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionA",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1323,Performance,concurren,concurrent,1323,"config/ConfigAsyncJobExecutionActor.scala; which was tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobEx",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1387,Performance,concurren,concurrent,1387,"as tweaked since the last release in a change from @cjllanwarne (https://github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retr",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1459,Performance,concurren,concurrent,1459,"/github.com/broadinstitute/cromwell/commit/33c58ef22b6a8edc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:1516,Performance,concurren,concurrent,1516,"dc4c1912c1416225c79d298f76#diff-39fe7186c2383fc1135f29a9c05e4e57) but I don't; grasp the scope of the change enough to know if this triggers it. In our CWL run, the jobs get submitted to the cluster and run okay based on the; work directories in `cromwell-execution` but the polling dies with:; ```; [2019-01-17 12:34:15,18] [info] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Status change from - to Running; [2019-01-17 12:34:16,27] [ESC[38;5;220mwarnESC[0m] DispatchedConfigAsyncJobExecutionActor [ESC[38;5;2mf2e0c573ESC[0malignment_to_rec:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); at scala.concurrent.Promise$.fromTry(Promise.scala:138); at scala.concurrent.Future$.fromTry(Future.scala:635); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:691); at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:691); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:983); at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:977); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.sca",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4518,Performance,queue,queue,4518,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:4796,Performance,queue,queue,4796,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345:5091,Security,hash,hashing-strategy,5091,"JobExecutionActor.scala:211); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more; ```; This is our configuration for PBS:; ```; PBSPRO {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; ; runtime-attributes = """"""; Int cpu = 1; Int memory_mb = 2048; String queue = ""normal""; String account = """"; String walltime = ""48:00:00""; ; Int? cpuMin; Int? cpuMax; Int? memoryMin; Int? memoryMax; String? outDirMin; String? outDirMax; String? tmpDirMin; String? tmpDirMax; """"""; submit = """"""; qsub -V -l wd -N ${job_name} -o ${out} -e ${err} -q ${queue} -l walltime=${walltime} -l ncpus=${cpu} -l mem=${memory_mb}mb -- /usr/bin/env bash ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+).*""; filesystems {. local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hashing-strategy: ""path""; }; }; }. }; }; ```; Thanks for any tips or pointers.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-455621345
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:611,Availability,Error,Error,611,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:1721,Availability,robust,robustPoll,1721,Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:2052,Availability,robust,robustPoll,2052,dAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3753,Availability,error,error,3753,"kka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(Sta",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3914,Availability,Error,Error,3914,"tch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActo",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:5024,Availability,robust,robustPoll,5024,Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:5355,Availability,robust,robustPoll,5355,dAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:1223,Modifiability,config,config,1223,"dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:1285,Modifiability,Config,ConfigAsyncJobExecutionActor,1285,"8] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunctio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:1563,Modifiability,config,config,1563,va.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroun,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:1614,Modifiability,Config,ConfigAsyncJobExecutionActor,1614,a.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:2516,Modifiability,config,config,2516,"r.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:2576,Modifiability,Config,ConfigAsyncJobExecutionActor,2576,"figAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.Standard",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3320,Modifiability,config,config,3320,"Function$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3377,Modifiability,Config,ConfigAsyncJobExecutionActor,3377,"a.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3448,Modifiability,config,config,3448,"r.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsy",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3505,Modifiability,Config,ConfigAsyncJobExecutionActor,3505,"s.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backe",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4526,Modifiability,config,config,4526,"ctor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4588,Modifiability,Config,ConfigAsyncJobExecutionActor,4588,"tionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunctio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4866,Modifiability,config,config,4866,va.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroun,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4917,Modifiability,Config,ConfigAsyncJobExecutionActor,4917,a.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:5819,Modifiability,config,config,5819,"r.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:5879,Modifiability,Config,ConfigAsyncJobExecutionActor,5879,"figAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.Standard",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:6623,Modifiability,config,config,6623,"ala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more; ```. Works as expected with cromwell-36",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:6680,Modifiability,Config,ConfigAsyncJobExecutionActor,6680,"ala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more; ```. Works as expected with cromwell-36",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:6751,Modifiability,config,config,6751,"ala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more; ```. Works as expected with cromwell-36",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:6808,Modifiability,Config,ConfigAsyncJobExecutionActor,6808,"ala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustPoll(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:89); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:211); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more; ```. Works as expected with cromwell-36",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:574,Performance,concurren,concurrent,574,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:628,Performance,concurren,concurrent,628,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:691,Performance,concurren,concurrent,691,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:722,Performance,concurren,concurrent,722,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:787,Performance,concurren,concurrent,787,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:860,Performance,concurren,concurrent,860,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:918,Performance,concurren,concurrent,918,"Seeing the same thing on grid engine with cromwell-37. grid engine job dispatches and completes just fine but cromwell throws the following:. ```; [2019-02-13 22:18:19,77] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: job id: 8550357; [2019-02-13 22:18:19,78] [info] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Status change from - to Running; [2019-02-13 22:18:20,81] [warn] DispatchedConfigAsyncJobExecutionActor [bc35173dmyWorkflow.myTask:NA:1]: Fatal exception polling for status. Job will fail.; java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cro",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3877,Performance,concurren,concurrent,3877,".scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.Dispatched",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3931,Performance,concurren,concurrent,3931,"oExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:3994,Performance,concurren,concurrent,3994,"inPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJob",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4025,Performance,concurren,concurrent,4025,"39); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBa",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4090,Performance,concurren,concurrent,4090,"ker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4163,Performance,concurren,concurrent,4163,"ead.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncB",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710:4221,Performance,concurren,concurrent,4221,"otImplementedError: This should not happen, please report this; 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:697); 	at scala.util.Try$.apply(Try.scala:209); 	... 25 more. [2019-02-13 22:18:20,91] [error] WorkflowManagerActor Workflow bc35173d-fde7-4727-8ae1-d4d3f132296c failed (during ExecutingWorkflowState): java.util.concurrent.ExecutionException: Boxed Error; 	at scala.concurrent.impl.Promise$.resolver(Promise.scala:83); 	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); 	at scala.concurrent.impl.Promise$KeptPromise$.apply(Promise.scala:402); 	at scala.concurrent.Promise$.fromTry(Promise.scala:138); 	at scala.concurrent.Future$.fromTry(Future.scala:635); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.standard.StandardAsyncExecutionActor.pollStatusAsync$(StandardAsyncExecutionActor.scala:697); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatusAsync(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll(StandardAsyncExecutionActor.scala:989); 	at cromwell.backend.standard.StandardAsyncExecutionActor.poll$(StandardAsyncExecutionActor.scala:983); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.poll(ConfigAsyncJobExecutionActor.scala:211); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustPoll$1(AsyncBackendJobExecutionActor.scala:76); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecution",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-463475710
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464943989:203,Availability,error,error,203,I also hit this while experimenting with using singularity with cromwell. Just replicating https://github.com/kundajelab/atac-seq-pipeline/blob/master/docs/tutorial_local_singularity.md locally. Get the error with cromwell-37 and with a fresh build of develop branch. Works with cromwell-36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464943989
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464943989:130,Deployability,pipeline,pipeline,130,I also hit this while experimenting with using singularity with cromwell. Just replicating https://github.com/kundajelab/atac-seq-pipeline/blob/master/docs/tutorial_local_singularity.md locally. Get the error with cromwell-37 and with a fresh build of develop branch. Works with cromwell-36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464943989
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252:65,Availability,alive,alive,65,"Able to replicate the break from v36 to v37, I switched my check-alive in my config to use scontrol and it succeeded:; ```; ""check-alive"": ""scontrol show job ${job_id}"",; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252:131,Availability,alive,alive,131,"Able to replicate the break from v36 to v37, I switched my check-alive in my config to use scontrol and it succeeded:; ```; ""check-alive"": ""scontrol show job ${job_id}"",; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252:77,Modifiability,config,config,77,"Able to replicate the break from v36 to v37, I switched my check-alive in my config to use scontrol and it succeeded:; ```; ""check-alive"": ""scontrol show job ${job_id}"",; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573:289,Availability,alive,alive,289,"I just gave this a try in my facility. It still fails. My current work around is to use cromwell version 0.32 (via conda package). Cheers. On Tue, 19 Feb 2019 at 15:53, Michael Franklin <notifications@github.com>; wrote:. > Able to replicate the break from v36 to v37, I switched my check-alive in; > my config to use scontrol and it succeeded:; >; > ""check-alive"": ""scontrol show job ${job_id}"",; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAdrHHALXNpvY-NDgAF3uYIRY7EyP3zqks5vO4M_gaJpZM4aEezy>; > .; >. -- ; Nicholas Yue; Graphics - Arnold, Alembic, RenderMan, OpenGL, HDF5; Custom Dev - C++ porting, OSX, Linux, Windows; http://au.linkedin.com/in/nicholasyue; https://vimeo.com/channels/naiadtools",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573:358,Availability,alive,alive,358,"I just gave this a try in my facility. It still fails. My current work around is to use cromwell version 0.32 (via conda package). Cheers. On Tue, 19 Feb 2019 at 15:53, Michael Franklin <notifications@github.com>; wrote:. > Able to replicate the break from v36 to v37, I switched my check-alive in; > my config to use scontrol and it succeeded:; >; > ""check-alive"": ""scontrol show job ${job_id}"",; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAdrHHALXNpvY-NDgAF3uYIRY7EyP3zqks5vO4M_gaJpZM4aEezy>; > .; >. -- ; Nicholas Yue; Graphics - Arnold, Alembic, RenderMan, OpenGL, HDF5; Custom Dev - C++ porting, OSX, Linux, Windows; http://au.linkedin.com/in/nicholasyue; https://vimeo.com/channels/naiadtools",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573
https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573:304,Modifiability,config,config,304,"I just gave this a try in my facility. It still fails. My current work around is to use cromwell version 0.32 (via conda package). Cheers. On Tue, 19 Feb 2019 at 15:53, Michael Franklin <notifications@github.com>; wrote:. > Able to replicate the break from v36 to v37, I switched my check-alive in; > my config to use scontrol and it succeeded:; >; > ""check-alive"": ""scontrol show job ${job_id}"",; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-464982252>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAdrHHALXNpvY-NDgAF3uYIRY7EyP3zqks5vO4M_gaJpZM4aEezy>; > .; >. -- ; Nicholas Yue; Graphics - Arnold, Alembic, RenderMan, OpenGL, HDF5; Custom Dev - C++ porting, OSX, Linux, Windows; http://au.linkedin.com/in/nicholasyue; https://vimeo.com/channels/naiadtools",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560#issuecomment-465869573
https://github.com/broadinstitute/cromwell/issues/4561#issuecomment-459040378:28,Performance,perform,performance,28,#4598 is related (not great performance in JMUI use cases) but not the same.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4561#issuecomment-459040378
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:355,Availability,down,down,355,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:269,Performance,cache,cache,269,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:438,Security,hash,hashing,438,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:386,Usability,clear,clear,386,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894:476,Usability,simpl,simple,476,"Hi @dtenenba , we fully appreciate the importance of call caching and are looking into this. can I confirm a few things:. * that this is occurring on different files each run?; * you are seeing it every run of non-trivial size; * You have experienced at least one call-cache success run of any workflow (including a trivial one). This will help me narrow down what is going on. . To be clear, this should be working and we are aware that hashing is not a manual process but a simple value lookup.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457307894
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546:715,Performance,Cache,Cache,715,"I have run: ; Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; Inputs: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-inputs.json. Now three times directly with the same input data and every single time for every single task (so the file that is the result of the first task from a previous run of this workflow does not get reused for the second task fo the current run of the workflow, and so on for all the tasks in the entire workflow) I have gotten this:. ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""..."",; ""runtime attribute"": {; ""docker"": ""..."",; ""continueOnReturnCode"": ""..."",; ""failOnStderr"": ""...""; },; ""output expression"": {; ""File output_fastq"": ""..""; },; ""input count"": "".."",; ""backend name"": ""..."",; ""command template"": ""..."",; ""input"": {; ""String base_file_name"": ""..."",; ""File input_bam"": ""...""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; ```. So it's not timing out anymore (I replaced hashes with '...'), but never, ever having a `""hit"": true`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546:730,Security,hash,hashes,730,"I have run: ; Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; Inputs: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-inputs.json. Now three times directly with the same input data and every single time for every single task (so the file that is the result of the first task from a previous run of this workflow does not get reused for the second task fo the current run of the workflow, and so on for all the tasks in the entire workflow) I have gotten this:. ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""..."",; ""runtime attribute"": {; ""docker"": ""..."",; ""continueOnReturnCode"": ""..."",; ""failOnStderr"": ""...""; },; ""output expression"": {; ""File output_fastq"": ""..""; },; ""input count"": "".."",; ""backend name"": ""..."",; ""command template"": ""..."",; ""input"": {; ""String base_file_name"": ""..."",; ""File input_bam"": ""...""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; ```. So it's not timing out anymore (I replaced hashes with '...'), but never, ever having a `""hit"": true`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546:1170,Security,hash,hashes,1170,"I have run: ; Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; Inputs: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-inputs.json. Now three times directly with the same input data and every single time for every single task (so the file that is the result of the first task from a previous run of this workflow does not get reused for the second task fo the current run of the workflow, and so on for all the tasks in the entire workflow) I have gotten this:. ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""hashes"": {; ""output count"": ""..."",; ""runtime attribute"": {; ""docker"": ""..."",; ""continueOnReturnCode"": ""..."",; ""failOnStderr"": ""...""; },; ""output expression"": {; ""File output_fastq"": ""..""; },; ""input count"": "".."",; ""backend name"": ""..."",; ""command template"": ""..."",; ""input"": {; ""String base_file_name"": ""..."",; ""File input_bam"": ""...""; }; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache""; ```. So it's not timing out anymore (I replaced hashes with '...'), but never, ever having a `""hit"": true`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457360546
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457361555:57,Testability,test,test,57,"I'm also not sure what a ""non-trivial size"" is, but this test data/workflow isn't a Hello World workflow, but also isn't a 15 step, 3 whole genomes variant calling workflow either. I have never, in my testing, ever seen a `""hit"": true`. Perhaps someone else here has.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457361555
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457361555:201,Testability,test,testing,201,"I'm also not sure what a ""non-trivial size"" is, but this test data/workflow isn't a Hello World workflow, but also isn't a 15 step, 3 whole genomes variant calling workflow either. I have never, in my testing, ever seen a `""hit"": true`. Perhaps someone else here has.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457361555
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457367934:402,Security,hash,hashDifferential,402,"Also I just compared two of the workflow runs:; ```; {; ""callA"": {; ""executionStatus"": ""Done"",; ""allowResultReuse"": false,; ""callFqn"": ""Panel_BWA_GATK4_Samtools_Var_Annotate_Split.BwaMem"",; ""jobIndex"": 0,; ""workflowId"": ""X""; },; ""callB"": {; ""executionStatus"": ""Done"",; ""allowResultReuse"": true,; ""callFqn"": ""Panel_BWA_GATK4_Samtools_Var_Annotate_Split.BwaMem"",; ""jobIndex"": 0,; ""workflowId"": ""Y""; },; ""hashDifferential"": []; }; ```. ???? But yet no data reuse.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457367934
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457394714:62,Security,hash,hashing,62,"Thanks for your help, this is great info. I see a part of our hashing code that is likely causing an issue here, will report back with more early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457394714
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:72,Availability,error,error,72,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:219,Availability,down,down,219,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:262,Availability,error,error,262,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:116,Integrability,depend,dependent,116,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:317,Integrability,message,message,317,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:489,Integrability,message,message,489,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:295,Security,hash,hashFailures,295,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:842,Security,checksum,checksum,842,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:958,Security,hash,hash,958,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:416,Testability,test,tests,416,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:543,Testability,test,tests,543,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066:747,Testability,test,tests,747,"This might be conflating two issues, but in case it is related, another error we are consistently seeing that seems dependent on which docker container we use (which may be a red herring, but that's all I can narrow it down to), we'll run something and get this error: ; ```; ""callCaching"": {; ""hashFailures"": [; {; ""message"": ""[Attempted 1 time(s)] - NoSuchFileException: s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""s3://s3.amazonaws.com/some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz""; }; ]; }; ],; ```. Meanwhile, the input location of the input file is this:; ```; ""inputs"": {; ""input_fastq"": {; ""format"": null,; ""location"": ""s3://some-bucket/cromwell-tests/Kraken2_test_input.fastq.gz"",; ""size"": null,; ""secondaryFiles"": [],; ""contents"": null,; ""checksum"": null,; ""class"": ""File""; },; ```; So it's being given a valid S3 URL but then when it's trying to get the hash, it's looking at an invalid S3 URL (the one with s3.amazonaws.com isn't valid, but wasn't supplied by us). Thoughts? Is this a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-457651066
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-459409119:16,Deployability,release,release,16,I'm caught in a release cycle but believe the relevant code belongs here for others watching:. https://github.com/broadinstitute/cromwell/blob/fc43c6954eb47912930e4c28f73781a112fdfbf8/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-459409119
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:516,Availability,error,errors,516,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:844,Availability,error,errors,844,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:976,Availability,failure,failure,976,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:968,Security,hash,hashing,968,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:1069,Security,hash,hashing,1069,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:291,Testability,log,logs,291,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:437,Testability,log,log,437,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:455,Testability,log,log,455,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084:489,Testability,log,log,489,"New thoughts/additional info. . I just tried a workflow that evaluates all the way to the end successfully (and had been run before on the same data and no, call caching didn't happen, as is expected with AWS backend), with the exception of adding workflow options to specify the output and logs directories for the final results. . Interestingly enough the new prefixes were generated but files were not transferred over EXCEPT for the log. The workflow log transferred just fine. In the log there appears to be no errors or indication that the intended outputs were not successfully transferred over. . I'm looking at the workflow status, and while all the files were made correctly (so all tasks completed successfully), but the workflow as a whole failed b/c it knows it failed to transfer over the output data. However again, there are no errors indicated in the metadata indicating why no files were copied. . I'm wondering if this too would be expected to be a hashing failure? Are the identities of the files created that are intended as outputs defined by the hashing? Would this behavior be expected given the current issues with call caching? Or is this a new issue?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-462857084
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467537877:253,Usability,guid,guidance,253,"This is prohibitive for us to make progress using AWS. Between call caching not working AND the inability of Cromwell to stage input and output data from S3, this breaks it all. @wleepang is this data staging issue partly something AWS can provide some guidance on? It seems specific to AWS as the backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467537877
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845:226,Availability,error,errors,226,"@vortexing - task input and output data staging is handled by the `ecs-proxy` container that is installed when you create a custom AMI with ""cromwell"" settings. If you are not seeing data move in/out a good place to check for errors is the Cloudwatch log for a task that didn't have it's data staged correctly. Append `-proxy` to the job's cloudwatch log url to get the logging generated by the `ecs-proxy`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845:96,Deployability,install,installed,96,"@vortexing - task input and output data staging is handled by the `ecs-proxy` container that is installed when you create a custom AMI with ""cromwell"" settings. If you are not seeing data move in/out a good place to check for errors is the Cloudwatch log for a task that didn't have it's data staged correctly. Append `-proxy` to the job's cloudwatch log url to get the logging generated by the `ecs-proxy`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845:251,Testability,log,log,251,"@vortexing - task input and output data staging is handled by the `ecs-proxy` container that is installed when you create a custom AMI with ""cromwell"" settings. If you are not seeing data move in/out a good place to check for errors is the Cloudwatch log for a task that didn't have it's data staged correctly. Append `-proxy` to the job's cloudwatch log url to get the logging generated by the `ecs-proxy`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845:351,Testability,log,log,351,"@vortexing - task input and output data staging is handled by the `ecs-proxy` container that is installed when you create a custom AMI with ""cromwell"" settings. If you are not seeing data move in/out a good place to check for errors is the Cloudwatch log for a task that didn't have it's data staged correctly. Append `-proxy` to the job's cloudwatch log url to get the logging generated by the `ecs-proxy`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845:370,Testability,log,logging,370,"@vortexing - task input and output data staging is handled by the `ecs-proxy` container that is installed when you create a custom AMI with ""cromwell"" settings. If you are not seeing data move in/out a good place to check for errors is the Cloudwatch log for a task that didn't have it's data staged correctly. Append `-proxy` to the job's cloudwatch log url to get the logging generated by the `ecs-proxy`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-467676845
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844:87,Availability,error,error,87,"Hi @wleepang , I looked at the `-proxy` logs for one of the jobs that failed with this error and saw (among other things):. ```; download failed: s3://fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam to ../cromwell_root/fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam [Errno 28] No space left on device; ```. So it seems like maybe this is a scratch space issue? I thought that Cromwell/AWS batch just automatically created more scratch space when it was needed, but that seems to not be happening. Any suggestions for troubleshooting the problem?. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844:129,Availability,down,download,129,"Hi @wleepang , I looked at the `-proxy` logs for one of the jobs that failed with this error and saw (among other things):. ```; download failed: s3://fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam to ../cromwell_root/fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam [Errno 28] No space left on device; ```. So it seems like maybe this is a scratch space issue? I thought that Cromwell/AWS batch just automatically created more scratch space when it was needed, but that seems to not be happening. Any suggestions for troubleshooting the problem?. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844:40,Testability,log,logs,40,"Hi @wleepang , I looked at the `-proxy` logs for one of the jobs that failed with this error and saw (among other things):. ```; download failed: s3://fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam to ../cromwell_root/fh-ctr-public-reference-data/workflow_testing_data/WDL/unpaired-panel-consensus-variants-human/smallTestData.unmapped.bam [Errno 28] No space left on device; ```. So it seems like maybe this is a scratch space issue? I thought that Cromwell/AWS batch just automatically created more scratch space when it was needed, but that seems to not be happening. Any suggestions for troubleshooting the problem?. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468377844
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:143,Deployability,install,installed,143,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:360,Deployability,install,installed,360,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:103,Energy Efficiency,monitor,monitoring,103,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:345,Energy Efficiency,monitor,monitor,345,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:377,Energy Efficiency,monitor,monitor,377,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:531,Energy Efficiency,monitor,monitor,531,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:180,Modifiability,config,configured,180,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:756,Performance,Queue,Queue,756,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:597,Testability,log,log,597,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:608,Testability,log,log,608,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942:626,Testability,log,log,626,"@dtenenba - the space on the scratch mount point (for cromwell it is `/cormwell_root`) is managed by a monitoring tool `ebs-autoscale` that is installed when creating a custom AMI configured for Cromwell, and then referencing that AMI when creating Batch compute environments. Running out of space points to one or more of the following:. * the monitor is not installed; * the monitor is looking at the wrong location in the filesystem. If you've created a custom AMI, I suggest launching an instance with it and checking that the monitor is watching the correct location. Do this by checking the log: `/var/log/ebs-autoscale.log`. If it's not, you'll need to recreate both the AMI and the Batch Compute Environment, and associate the new CE with your Job Queue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468794942
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468801301:43,Testability,log,log,43,"Thanks @wleepang ,. Here is what's in that log:. ```; [Fri Mar 1 20:11:08 UTC 2019] Starting Docker EBS autoscaling; [Fri Mar 1 20:11:11 UTC 2019] EBS Autoscaling mountpoint: /scratch; [Fri Mar 1 20:11:11 UTC 2019] Region = us-west-2.; [Fri Mar 1 20:11:11 UTC 2019] Threshold -> 50 :: Used% -> 1%; ```. So it looks like it is watching the `/scratch` mount point. ; However, in the job definition that is being run, I see the following:. ```; ""volumes"": [; {; ""host"": {; ""sourcePath"": ""/cromwell_root/Panel_BWA_GATK4_Samtools_Var_Annotate_Split/SamToFastq/57f71856-abbf-4442-a80d-3f532e4eac01/Some(0)/1""; },; ""name"": ""local-disk""; }; ],. ```. So it looks like it's writing data to `/cromwell_root` not `/scratch`. How do I get jobs to write their data to `/scratch`? . Should I create a new AMI and change the scratch mount point from `/scratch` to `/cromwell_root`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468801301
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468811536:359,Testability,log,log,359,"I created a new AMI using the stack at https://s3.amazonaws.com/aws-genomics-workflows/templates/aws-genomics-ami.template.yaml and I specified `/cromwell_root` as the scratch mount point. . ![image](https://user-images.githubusercontent.com/2286826/53666338-b97c5a80-3c22-11e9-800e-65ffe5fd84d5.png). However, when I then ran an instance of the new AMI, the log shows the same result as before:. ```; [Fri Mar 1 20:58:15 UTC 2019] EBS Autoscaling mountpoint: /scratch; ```. There is a `/scratch` directory but no `/cromwell_root` directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468811536
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705:163,Availability,failure,failure,163,"Now I am having trouble running the stack again (I've edited it to change the default of ScratchMountPoint to /cromwell_root). I deleted the old stacks. Getting a failure when trying to create the ec2 instance, but there is no helpful error as to why. . Is it possible to change the value of AWS_CROMWELL_LOCAL_DISK? Where do I change that? In the config file somewhere? If I could change that from /cromwell_root to /scratch then things ought to work with my existing AMI....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705:235,Availability,error,error,235,"Now I am having trouble running the stack again (I've edited it to change the default of ScratchMountPoint to /cromwell_root). I deleted the old stacks. Getting a failure when trying to create the ec2 instance, but there is no helpful error as to why. . Is it possible to change the value of AWS_CROMWELL_LOCAL_DISK? Where do I change that? In the config file somewhere? If I could change that from /cromwell_root to /scratch then things ought to work with my existing AMI....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705:348,Modifiability,config,config,348,"Now I am having trouble running the stack again (I've edited it to change the default of ScratchMountPoint to /cromwell_root). I deleted the old stacks. Getting a failure when trying to create the ec2 instance, but there is no helpful error as to why. . Is it possible to change the value of AWS_CROMWELL_LOCAL_DISK? Where do I change that? In the config file somewhere? If I could change that from /cromwell_root to /scratch then things ought to work with my existing AMI....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468828705
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468834266:154,Availability,error,error,154,"Sorry for the noise. I've succeeded in creating an AMI where the scratch partition is called /cromwell_root. I have submitted a job which failed with the error under discussion before, and I'm waiting to see what happens....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468834266
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468964262:338,Deployability,update,updated,338,"So it appears that what I did (creating a new AMI with the Scratch Mount Point set to `/cromwell_root` instead of the default `/scratch`) cleared up this particular issue. However, I don't think we should close the issue yet because it doesn't appear to be documented anywhere that this is what you need to do. Until the documentation is updated I'd like to see the issue remain open. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468964262
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468964262:138,Usability,clear,cleared,138,"So it appears that what I did (creating a new AMI with the Scratch Mount Point set to `/cromwell_root` instead of the default `/scratch`) cleared up this particular issue. However, I don't think we should close the issue yet because it doesn't appear to be documented anywhere that this is what you need to do. Until the documentation is updated I'd like to see the issue remain open. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468964262
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468973849:163,Deployability,update,update,163,"Whoops, yeah, I thought I was writing in an issue that was exclusively about the I/O stuff, but neglected to scroll up. Never mind. Side issue solved (pending doc update), main issue not yet solved.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-468973849
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:401,Availability,error,errors,401,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:178,Deployability,update,updated,178,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:387,Deployability,configurat,configuration,387,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:387,Modifiability,config,configuration,387,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:375,Safety,avoid,avoid,375,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885:300,Security,validat,validation,300,"@dtenenba , @vortexing - The [docs](https://docs.opendata.aws/genomics-workflows) for creating the genomics workflow environment (i.e. AWS Batch and related resources) have been updated. Use of custom AMIs has been deprecated in favor of using EC2 Launch Templates. There's also additional parameter validation under the hood around setting up an environment for Cromwell to avoid these configuration errors.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-470339885
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479638582:8,Testability,test,test,8,"We will test (and I will fix that one missing json - basically I broke it up into two input jsons, one for parameters, and one indicating the batch file). I'll report back with the fixed links of what I run.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479638582
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866:52,Availability,error,error,52,@geoffjentry I had trouble building this pr:. ```; [error] /work/engine/src/main/scala/cromwell/webservice/SwaggerService.scala:3:35: imported `CromwellApiService' is permanently hidden by definition of object CromwellApiService in package webservice; [error] import cromwell.webservice.routes.CromwellApiService; [error] ^; ```. Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866:253,Availability,error,error,253,@geoffjentry I had trouble building this pr:. ```; [error] /work/engine/src/main/scala/cromwell/webservice/SwaggerService.scala:3:35: imported `CromwellApiService' is permanently hidden by definition of object CromwellApiService in package webservice; [error] import cromwell.webservice.routes.CromwellApiService; [error] ^; ```. Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866:315,Availability,error,error,315,@geoffjentry I had trouble building this pr:. ```; [error] /work/engine/src/main/scala/cromwell/webservice/SwaggerService.scala:3:35: imported `CromwellApiService' is permanently hidden by definition of object CromwellApiService in package webservice; [error] import cromwell.webservice.routes.CromwellApiService; [error] ^; ```. Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866:287,Integrability,rout,routes,287,@geoffjentry I had trouble building this pr:. ```; [error] /work/engine/src/main/scala/cromwell/webservice/SwaggerService.scala:3:35: imported `CromwellApiService' is permanently hidden by definition of object CromwellApiService in package webservice; [error] import cromwell.webservice.routes.CromwellApiService; [error] ^; ```. Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479678866
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479690208:67,Testability,test,test,67,"Sorry for the noise, `sbt clean` did seem to do the trick. We will test & let you know.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-479690208
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:1048,Availability,error,error,1048,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:656,Performance,Cache,Cache,656,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:6,Testability,test,test,6,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:46,Testability,test,tested,46,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:981,Testability,test,test,981,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623:1239,Testability,test,test,1239,"First test (@dtenenba built the PR 4412 and I tested it):. Workflow: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; First input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; Second input json: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. and... drumroll please...... IT WORKED!!!!!!!!!!! ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": true,; ""result"": ""Cache Hit: 98bc2232-f147-419f-9351-49a07daa1720:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"",; ```; And the workflow is ""generating"" the files WAY faster than it should be if it were doing it de novo, so we seem to be getting the correct outputs moved into the new workflow directory as well. . Caveats: ; I did test it with an actual batch and it failed with the job definition error. But as long as PR 4412 was not intended to fix THAT issue as well, I can say it appears on the first pass that call caching with AWS backend might very well be working with an outside test!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563#issuecomment-480313623
https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457355868:0,Availability,Ping,Pinging,0,Pinging @danbills to ask whether the above sample output is sufficient for your use case or whether we need another ticket for a part II,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457355868
https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457693674:233,Safety,sanity check,sanity check,233,"Is the idea that we can sum up the jobs run per group and then we have the total # of jobs running?. I think this is sufficient, but I'd still like to add logging to job token manager in addition to this, even if nothing more than a sanity check on the numbers we're seeing here. Assuming the first part is true, by all means merge!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457693674
https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457693674:155,Testability,log,logging,155,"Is the idea that we can sum up the jobs run per group and then we have the total # of jobs running?. I think this is sufficient, but I'd still like to add logging to job token manager in addition to this, even if nothing more than a sanity check on the numbers we're seeing here. Assuming the first part is true, by all means merge!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4567#issuecomment-457693674
https://github.com/broadinstitute/cromwell/issues/4572#issuecomment-557277899:297,Availability,down,down,297,@cjllanwarne not having this consume the imports of a workflow has actually lead us to create our own service for describing workfklows as a json schema. having a JSON schema returned is actually quite practical since we can build some pretty UI's around it with existing tools. Is this still low down on the priority list?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4572#issuecomment-557277899
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456953574:37,Performance,perform,performance,37,"Note: in terms of actually improving performance, the answer will likely be Akka/thread pool type things that were discussed in #ftfy before break",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456953574
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477:149,Performance,cache,cache,149,"Excellent point from @cjllanwarne: we are protected from the ""workshop scenario"" - many users validating the same WF at the same time - by the Rawls cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477:94,Security,validat,validating,94,"Excellent point from @cjllanwarne: we are protected from the ""workshop scenario"" - many users validating the same WF at the same time - by the Rawls cache",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958477
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958825:108,Security,expose,expose,108,"However it'd be lovely to have defense in depth in case they ever changed something :). Also, if we want to expose the API directly to the outside world (which is likely sooner than later)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456958825
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771:229,Performance,concurren,concurrent,229,"AC:. **Case 1:** ; Benchmark the behavior of these endpoints given a few different style of workflows:; Option A: Hello World workflow; Option B: Five Dollar Genome workflow; Option C: CGA Production Workflow. For each case, run concurrent requests to the `/describe` endpoint , benchmark the response time and do so for a variety of concurrent requests: 15, 30, 50, 100... **Case 2:**; Another case can be to see how many raw GitHub pages we can resolve (via http imports) before we start seeing issues from Github -- and observe we fail gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771:293,Performance,response time,response time,293,"AC:. **Case 1:** ; Benchmark the behavior of these endpoints given a few different style of workflows:; Option A: Hello World workflow; Option B: Five Dollar Genome workflow; Option C: CGA Production Workflow. For each case, run concurrent requests to the `/describe` endpoint , benchmark the response time and do so for a variety of concurrent requests: 15, 30, 50, 100... **Case 2:**; Another case can be to see how many raw GitHub pages we can resolve (via http imports) before we start seeing issues from Github -- and observe we fail gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771:334,Performance,concurren,concurrent,334,"AC:. **Case 1:** ; Benchmark the behavior of these endpoints given a few different style of workflows:; Option A: Hello World workflow; Option B: Five Dollar Genome workflow; Option C: CGA Production Workflow. For each case, run concurrent requests to the `/describe` endpoint , benchmark the response time and do so for a variety of concurrent requests: 15, 30, 50, 100... **Case 2:**; Another case can be to see how many raw GitHub pages we can resolve (via http imports) before we start seeing issues from Github -- and observe we fail gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771:19,Testability,Benchmark,Benchmark,19,"AC:. **Case 1:** ; Benchmark the behavior of these endpoints given a few different style of workflows:; Option A: Hello World workflow; Option B: Five Dollar Genome workflow; Option C: CGA Production Workflow. For each case, run concurrent requests to the `/describe` endpoint , benchmark the response time and do so for a variety of concurrent requests: 15, 30, 50, 100... **Case 2:**; Another case can be to see how many raw GitHub pages we can resolve (via http imports) before we start seeing issues from Github -- and observe we fail gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771:279,Testability,benchmark,benchmark,279,"AC:. **Case 1:** ; Benchmark the behavior of these endpoints given a few different style of workflows:; Option A: Hello World workflow; Option B: Five Dollar Genome workflow; Option C: CGA Production Workflow. For each case, run concurrent requests to the `/describe` endpoint , benchmark the response time and do so for a variety of concurrent requests: 15, 30, 50, 100... **Case 2:**; Another case can be to see how many raw GitHub pages we can resolve (via http imports) before we start seeing issues from Github -- and observe we fail gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-456965771
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134:72,Performance,concurren,concurrency,72,"~~The CGA ""CPU WDL"" validates pretty quickly. With 10,000 requests at a concurrency of 20, the 99% latency is just 249 ms~~. This was actually not doing exactly what I expected: it was failing to parse. At least we know parsing attempts are fast!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134:99,Performance,latency,latency,99,"~~The CGA ""CPU WDL"" validates pretty quickly. With 10,000 requests at a concurrency of 20, the 99% latency is just 249 ms~~. This was actually not doing exactly what I expected: it was failing to parse. At least we know parsing attempts are fast!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134:20,Security,validat,validates,20,"~~The CGA ""CPU WDL"" validates pretty quickly. With 10,000 requests at a concurrency of 20, the 99% latency is just 249 ms~~. This was actually not doing exactly what I expected: it was failing to parse. At least we know parsing attempts are fast!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340134
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340601:171,Security,validat,validate,171,"Womtool on the command line takes wildly longer, probably all due to JVM startup cost; ```; anichols@wm97a-a85 ~/Dropbox/Broad Institute/Bugs/cromwell-4573 $ time womtool validate cpu_WDL.wdl . real	0m3.585s; user	0m7.393s; sys	0m0.552s; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458340601
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241:42,Performance,cache,cache,42,"Note:. There exists an optional namespace cache in the WDL draft-2 version of `validateNamespace`. WaaS uses only `getWomBundle` and `createExecutable`, so it currently has no interaction with the cache for any language version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241:197,Performance,cache,cache,197,"Note:. There exists an optional namespace cache in the WDL draft-2 version of `validateNamespace`. WaaS uses only `getWomBundle` and `createExecutable`, so it currently has no interaction with the cache for any language version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241:79,Security,validat,validateNamespace,79,"Note:. There exists an optional namespace cache in the WDL draft-2 version of `validateNamespace`. WaaS uses only `getWomBundle` and `createExecutable`, so it currently has no interaction with the cache for any language version.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-458589241
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469451689:115,Modifiability,config,configured,115,"Idea for how to make this CI compatible; - Use apachebench Docker; - Serve HTTP imports from a Mock Server Docker, configured using its rest API",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469451689
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469451689:95,Testability,Mock,Mock,95,"Idea for how to make this CI compatible; - Use apachebench Docker; - Serve HTTP imports from a Mock Server Docker, configured using its rest API",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469451689
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469454962:14,Testability,test,test,14,"Five cases to test:; 1. Vanilla WDL; 2. Chet CPU WDL; 3. WDL with HTTP imports, imports are instant; 4. WDL with HTTP imports, imports take a few seconds; 5. WDL with HTTP imports, imports time out; - mock server waits longer than `HttpResolver#innerResolver`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469454962
https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469454962:201,Testability,mock,mock,201,"Five cases to test:; 1. Vanilla WDL; 2. Chet CPU WDL; 3. WDL with HTTP imports, imports are instant; 4. WDL with HTTP imports, imports take a few seconds; 5. WDL with HTTP imports, imports time out; - mock server waits longer than `HttpResolver#innerResolver`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4573#issuecomment-469454962
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:713,Availability,degraded,degraded,713,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:149,Deployability,Configurat,ConfigurationFiles,149,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:189,Deployability,configurat,configuration-file,189,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:295,Deployability,configurat,configuration,295,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:57,Modifiability,config,config,57,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:149,Modifiability,Config,ConfigurationFiles,149,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:189,Modifiability,config,configuration-file,189,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:295,Modifiability,config,configuration,295,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274:731,Performance,perform,performance,731,"Hm. This looks like a conf bug on our side, but [is your config file importing application.conf](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/#creating-your-first-configuration-file)? That file contains other overrides that cromwell should have over the default `akka` configuration. The bug here is that application.conf is only supposed to contain overrides, while reference.conf should contain newly defined resources. Since the `services` block are cromwell's services, they should be newly defined in reference.conf. That would then allow anyone who accidentally doesn't pick up our application.conf to *at least* have the reference `services`, plus the original `akka` values with degraded cromwell performance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577#issuecomment-457755274
https://github.com/broadinstitute/cromwell/pull/4578#issuecomment-457335175:120,Deployability,upgrade,upgrade,120,Not sure about switching from the canonical repo to an unknown source for something like this. Also it might be nice to upgrade from jq 1.5 to the 1.6 that was released a couple of months ago if we're going to change this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4578#issuecomment-457335175
https://github.com/broadinstitute/cromwell/pull/4578#issuecomment-457335175:160,Deployability,release,released,160,Not sure about switching from the canonical repo to an unknown source for something like this. Also it might be nice to upgrade from jq 1.5 to the 1.6 that was released a couple of months ago if we're going to change this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4578#issuecomment-457335175
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027:137,Availability,down,download,137,"Hi @ruchim ,; Thanks for asking.; For example, normally, in the alignment, we need to provide the big fasta files as input.; So, it will download from s3 for each single job.; We have all the reference files in our EFS. For our own usage, we mount the EFS into every job definition. So the batch job can access the EFS directly. They don't need to download every time from S3.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027:348,Availability,down,download,348,"Hi @ruchim ,; Thanks for asking.; For example, normally, in the alignment, we need to provide the big fasta files as input.; So, it will download from s3 for each single job.; We have all the reference files in our EFS. For our own usage, we mount the EFS into every job definition. So the batch job can access the EFS directly. They don't need to download every time from S3.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027:304,Security,access,access,304,"Hi @ruchim ,; Thanks for asking.; For example, normally, in the alignment, we need to provide the big fasta files as input.; So, it will download from s3 for each single job.; We have all the reference files in our EFS. For our own usage, we mount the EFS into every job definition. So the batch job can access the EFS directly. They don't need to download every time from S3.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-493492027
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-583565273:4,Deployability,update,update,4,any update on this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-583565273
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786:166,Deployability,deploy,deploys,166,This would be useful to us as well. We have a similar case where we have a large reference collection that we don't want to have to fetch every time. For our now AWS deploys we can override the submit-docker parameter to add the mount. But this isn't exposed for this backend. It would be nice if we could fully customize the docker command similar to what is possible with ConfigBackendLifecycleActorFactory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786:374,Modifiability,Config,ConfigBackendLifecycleActorFactory,374,This would be useful to us as well. We have a similar case where we have a large reference collection that we don't want to have to fetch every time. For our now AWS deploys we can override the submit-docker parameter to add the mount. But this isn't exposed for this backend. It would be nice if we could fully customize the docker command similar to what is possible with ConfigBackendLifecycleActorFactory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786:251,Security,expose,exposed,251,This would be useful to us as well. We have a similar case where we have a large reference collection that we don't want to have to fetch every time. For our now AWS deploys we can override the submit-docker parameter to add the mount. But this isn't exposed for this backend. It would be nice if we could fully customize the docker command similar to what is possible with ConfigBackendLifecycleActorFactory.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-754945786
https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-765076130:95,Availability,down,download,95,"I also want to bind FSx in ECS container.Like @hurchu ,I hava refrence in FSx, I don't want to download every time from S3.; This is my vision, EC2 has two additional filesystems, /fsx /cromwell_root(ebs autoscaling), Container on EC2 mount this two filesystems in itself.Now there is only cromwell_root(ebs filesystem) in container.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4579#issuecomment-765076130
https://github.com/broadinstitute/cromwell/pull/4581#issuecomment-461599283:33,Testability,test,tests,33,I think this solution is failing tests because it also deletes directories used by `DirectoryResolver` that _did not_ come from unzipping imports,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4581#issuecomment-461599283
https://github.com/broadinstitute/cromwell/pull/4585#issuecomment-457671476:80,Security,access,access,80,"We received a workaround from Travis support and I was able to rotate the Vault access token. Follow details over at https://support.travis-ci.com/hc/en-us/requests/3231 but the TL;DR is to use the travis rest-api **V3**, not the travis web-ui nor the travis cli.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4585#issuecomment-457671476
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457697601:528,Availability,robust,robust,528,"Hi @chapmanb - CWL support was out of scope for the group who did the AWS Batch backend support. Some things might work, but others will not. In particular things like `cwl.inputs.json` and `cwl.output.json` with special control files definitely won't work as that requires special wiring on the part of a backend (i.e. not at the Cromwell engine/WOM layer) in order to be successful. We'll get to this eventually but is not on our immediate roadmap. We'd certainly welcome contributions if other groups were interested in more robust AWS/CWL support in Cromwell (that's more of a general comment to any potentially interested parties who see this)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457697601
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457730223:195,Testability,test,test,195,"Jeff;; Thanks for the confirmation that this is expected. My goal was to get this at a point where we understood what the CWL limitations and roadblocks are and have an easy way to replicate and test so we can move it forward when we have resources. I'll finish the bcbio automation, write up documentation, then sync with the AWS team as well to see about their ability to contribute/debug. I'm excited to be making some progress on this and appreciate knowing this is where we're expecting to be.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457730223
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457733172:225,Usability,learn,learned,225,"@chapmanb Definitely. In particular I expect your WFs to have a rough go of things in AWS just because you do lean so heavily on those sorts of constructs, as we discovered w/ the Google backend. The hope is that the lessons learned over there make it a much easier path in AWS but it'l still wind up as work needing to be done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-457733172
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459109317:460,Testability,test,test,460,"@wleepang Ultimately the answer will be ""Look at how the PAPI2 backend handles CWL, map the concepts to Batch, and there ya go"", but unfortunately there wasn't one single PR to make CWL work in PAPI2. Prior to the fall it was in a state of it sorta worked, but very poorly on the kinds of special case scenarios we're talking about. At that point Thibault embarked on a project with @chapmanb to make sure it worked for `bcbio` (which IMO is sort of a torture test for these kinds of CWL constructs). . The further bad news is that there's still not a single PR, but from digging around a bit this seems to be a decent start: #4358 #4371 #4386 #4448",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459109317
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224:236,Deployability,pipeline,pipelines,236,"IIRC (which is really not guaranteed), as far as the localization of `cwl.inputs.json` is concerned in PAPI 2, [this bit](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L686) is what maps the cloud path of ""ad hoc files"" to the localized path (which the AWS equivalent [doesn't have](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchAsyncBackendJobExecutionActor.scala#L420)).; So it's possible the `cwl.inputs.json` is actually localized but not to the right place and so the tool can't find it.; Again my memory is fading quickly so don't take this as 💯 :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224:292,Deployability,pipeline,pipelines,292,"IIRC (which is really not guaranteed), as far as the localization of `cwl.inputs.json` is concerned in PAPI 2, [this bit](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L686) is what maps the cloud path of ""ad hoc files"" to the localized path (which the AWS equivalent [doesn't have](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchAsyncBackendJobExecutionActor.scala#L420)).; So it's possible the `cwl.inputs.json` is actually localized but not to the right place and so the tool can't find it.; Again my memory is fading quickly so don't take this as 💯 :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224:309,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,309,"IIRC (which is really not guaranteed), as far as the localization of `cwl.inputs.json` is concerned in PAPI 2, [this bit](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L686) is what maps the cloud path of ""ad hoc files"" to the localized path (which the AWS equivalent [doesn't have](https://github.com/broadinstitute/cromwell/blob/aeca54929b5d85e7961ac01a784c08a129cfc265/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchAsyncBackendJobExecutionActor.scala#L420)).; So it's possible the `cwl.inputs.json` is actually localized but not to the right place and so the tool can't find it.; Again my memory is fading quickly so don't take this as 💯 :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-459299224
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-506510217:580,Availability,fault,fault,580,"Hi @geoffjentry . I'm currently trying to figure out how to fix this issue, but I'm just starting to understand this project. Therefore, I want to clarify a few things.; As far as I understand, the problem is that some special (ad hoc) files are placed in ""/cromwell_root/path/to/input_file.txt"", while Cromwell expects them to be in ""/cromwell_root/ad_hoc_file.txt"" in order to execute them.; But what exactly is wrong here? It seems like either adhoc files are placed in the wrong directory and must be moved to ""/cromwell_root"" or their location is correct and it's Cromwell's fault that it tries to find them in the wrong directory. Which of these options is correct?; Also, I see you assigned yourself to this issue. Does this mean that help is no longer needed?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-506510217
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549:385,Deployability,pipeline,pipelines,385,"Hi - sorry I had missed the original question from @myazinn and needed to dig into ad hoc files a bit before opining on first #5057 from @Kirvolque and now #5064. I'm still not in a position where I can answer definitively but my first question would be why not follow the pattern from the [GCP backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L716) and [TES backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/tes/src/main/scala/cromwell/backend/impl/tes/TesAsyncBackendJobExecutionActor.scala#L95) and modify the `mapCommandLineWomFile` function in `AwsAsyncBackendJobExecutionActor`. . It's entirely possible that something about the AWS backend's wiring would lead to that not being the right choice, but that's what I want to understand.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549:441,Deployability,pipeline,pipelines,441,"Hi - sorry I had missed the original question from @myazinn and needed to dig into ad hoc files a bit before opining on first #5057 from @Kirvolque and now #5064. I'm still not in a position where I can answer definitively but my first question would be why not follow the pattern from the [GCP backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L716) and [TES backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/tes/src/main/scala/cromwell/backend/impl/tes/TesAsyncBackendJobExecutionActor.scala#L95) and modify the `mapCommandLineWomFile` function in `AwsAsyncBackendJobExecutionActor`. . It's entirely possible that something about the AWS backend's wiring would lead to that not being the right choice, but that's what I want to understand.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549:458,Deployability,Pipeline,PipelinesApiAsyncBackendJobExecutionActor,458,"Hi - sorry I had missed the original question from @myazinn and needed to dig into ad hoc files a bit before opining on first #5057 from @Kirvolque and now #5064. I'm still not in a position where I can answer definitively but my first question would be why not follow the pattern from the [GCP backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiAsyncBackendJobExecutionActor.scala#L716) and [TES backend](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/tes/src/main/scala/cromwell/backend/impl/tes/TesAsyncBackendJobExecutionActor.scala#L95) and modify the `mapCommandLineWomFile` function in `AwsAsyncBackendJobExecutionActor`. . It's entirely possible that something about the AWS backend's wiring would lead to that not being the right choice, but that's what I want to understand.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509691549
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:417,Deployability,integrat,integration,417,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:417,Integrability,integrat,integration,417,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:1230,Security,Access,AccessDeniedException,1230,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:151,Testability,log,logging,151,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:429,Testability,test,test,429,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:588,Testability,test,test,588,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:686,Testability,test,test,686,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587:928,Testability,test,test,928,"@geoffjentry, thanks for the answer :); Actually, we tried to do something similar to how it was done in GCP (or TES) but it didn't work out. We added logging to the `mapCommandLineWomFile` method so that we can see what `womFiles` Cromwell passes to this method. And it turns out Cromwell never passes ""ad hoc"" files to this method, therefore `asAdHocFile`, for example, always returns `None`. In particular, in our integration test (PR #5057) it passes only two womFiles with values something like ; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test`; and; `s3://bucket-name/cromwell-execution/cwl_temp_file_some-numbers.cwl/some-numbers/call-test/tmp.59740063`; I'm not sure, but it looks like the first `womValue` somehow related to the `runtimeEnvironment` field in the `StandardAsyncExecutionActor`. The second value is something else too, since ""ad hoc"" files are placed in `call-test` directory.; It is possible that we misunderstood something, but for now, it looks like a dead-end.; By the way, we also tried to override `localizeAdHocValues` method `AwsBatchAsyncBackendJobExecutionActor` so that it would copy ""ad hoc"" files to the ""/cromwell_root"" directory. It fails with an AccessDeniedException.; I hope this gives you an understanding of why we came to the proposed solutions. As I said, perhaps we misunderstood something, so we will be happy if you can give us some hint.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509765587
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509812726:264,Availability,ping,ping,264,Ah. Now that you say this I'm betting it fails due to how the proxy sidecar works. My quick thought is that the approach in #5064 is likely better but I need to dig into more how the AWS localization is working in the first place. In the meantime I'll try to also ping @elerch and @wleepang in case they have thoughts here.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509812726
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509815272:44,Deployability,update,updates,44,"Okay, thanks. I look forward to hearing any updates from you.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509815272
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509830998:219,Security,Access,AccessDeniedException,219,"Hi @cjllanwarne.; Yes, you correctly understood the problem. We haven't tried this option, because we were fixated on one approach :); In general, your idea should solve the problem. Although I have a suspicion that an AccessDeniedException may be thrown there too. Anyway, I will try to do so and tell you the result.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-509830998
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-511458740:507,Energy Efficiency,schedul,schedule,507,"Hi @myazinn and @Kirvolque - sorry for the delay here, the conversation last week wound up with Chris & I chatting w/ @wleepang from AWS, this looks like another case where the required bits of information are split across multiple people. I'm going to **try** to figure out what needs figuring out this week, but we'll see. If that winds up not working out, one thought Lee & I had was that we could set up a 3-way call next week. Both he & I will be in Basel next week which seemed like it'd be easier to schedule with you all instead of finding a time which worked for him on the west coast of the US and you all",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-511458740
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-511602109:93,Energy Efficiency,schedul,schedule,93,@myazinn hey - the more i look at the rest of my week the more i'm thinking we might as well schedule the call :) Can you email me - `jgentry` with hostname `broadinstitute.org`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-511602109
https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-518429696:276,Testability,test,tests,276,"Hi @chapmanb -; We made another [PR](https://github.com/broadinstitute/cromwell/pull/5097), that should solve the problem. And we believe that this time it is the right solution :); Sorry for bothering, but can you please check if it solves your problem? II tried to run your tests myself, but I failed to do it for some reason.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586#issuecomment-518429696
https://github.com/broadinstitute/cromwell/issues/4587#issuecomment-467545872:180,Availability,error,error,180,Note: We currently can't test CWLs on AWS with v37 Cromwell because of the input/output staging issue I mentioned over with the call caching problems. We just get the input/output error and the jobs won't move forward enough to even see what other issues might arise. . Related to:; https://github.com/broadinstitute/cromwell/issues/4563. That's a deal breaker for our institution. @wleepang These are all related.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4587#issuecomment-467545872
https://github.com/broadinstitute/cromwell/issues/4587#issuecomment-467545872:25,Testability,test,test,25,Note: We currently can't test CWLs on AWS with v37 Cromwell because of the input/output staging issue I mentioned over with the call caching problems. We just get the input/output error and the jobs won't move forward enough to even see what other issues might arise. . Related to:; https://github.com/broadinstitute/cromwell/issues/4563. That's a deal breaker for our institution. @wleepang These are all related.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4587#issuecomment-467545872
https://github.com/broadinstitute/cromwell/issues/4594#issuecomment-458194462:10,Deployability,update,updated,10,"Are there updated acceptance criteria for this ticket, or can this be marked as complete? This currently works on the caas-dev server:. ```; $ curl https://cromwell.caas-dev.broadinstitute.org/engine/v1/status 2>/dev/null | jq .; {; ""ok"": true,; ""systems"": {; ""Cromwell"": {; ""ok"": true; },; ""Sam"": {; ""ok"": true; }; }; }; $ ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4594#issuecomment-458194462
https://github.com/broadinstitute/cromwell/issues/4595#issuecomment-458252514:240,Availability,error,error,240,"Looks like this logic assumes that the array has at least one element:; https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomObject.scala#L83. So we just need to add a case for when it's empty. EDIT: The error is thrown earlier, and tells us that it can't even recognize `WomCompositeType` as `WomObjectType` in this case for some reason.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4595#issuecomment-458252514
https://github.com/broadinstitute/cromwell/issues/4595#issuecomment-458252514:16,Testability,log,logic,16,"Looks like this logic assumes that the array has at least one element:; https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomObject.scala#L83. So we just need to add a case for when it's empty. EDIT: The error is thrown earlier, and tells us that it can't even recognize `WomCompositeType` as `WomObjectType` in this case for some reason.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4595#issuecomment-458252514
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459067446:63,Testability,log,logic,63,"wow -- that is one ugly lookin' query! with all the ""and true"" logic I'm guessing it's generated. lmk if you want an extra pair of tuning eyes to bounce things off of",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459067446
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459106279:869,Performance,perform,performant,869,"A handcrafted version of this query: . ```; select; x2.`WORKFLOW_EXECUTION_UUID`,; x2.`WORKFLOW_NAME`,; x2.`WORKFLOW_STATUS`,; x2.`START_TIMESTAMP`,; x2.`END_TIMESTAMP`,; x2.`SUBMISSION_TIMESTAMP`,; x2.`WORKFLOW_METADATA_SUMMARY_ENTRY_ID` ; from; WORKFLOW_METADATA_SUMMARY_ENTRY x2 ; join; (; select; WORKFLOW_EXECUTION_UUID ; from; CUSTOM_LABEL_ENTRY ; where; CUSTOM_LABEL_KEY = 'submissionIdKey' ; and CUSTOM_LABEL_VALUE = 'submissionIdValue'; ) s ; on x2.WORKFLOW_EXECUTION_UUID = s.WORKFLOW_EXECUTION_UUID ; join; (; select; WORKFLOW_EXECUTION_UUID ; from; CUSTOM_LABEL_ENTRY ; where; (; CUSTOM_LABEL_KEY = 'caas-collection-name' ; and CUSTOM_LABEL_VALUE = 'me@gmail.com'; ) ; or (; CUSTOM_LABEL_KEY = 'caas-collection-name' ; and CUSTOM_LABEL_VALUE = 'miguel-collection'; ); ) c ; on c.WORKFLOW_EXECUTION_UUID = x2.WORKFLOW_EXECUTION_UUID; ```. begets a much more performant`EXPLAIN` . ```; mysql> explain select x2.`WORKFLOW_EXECUTION_UUID`, x2.`WORKFLOW_NAME`, x2.`WORKFLOW_STATUS`, x2.`START_TIMESTAMP`, x2.`END_TIMESTAMP`, x2.`SUBMISSION_TIMESTAMP`, x2.`WORKFLOW_METADATA_SUMMARY_ENTRY_ID` from WORKFLOW_METADATA_SUMMARY_ENTRY x2 join (select WORKFLOW_EXECUTION_UUID from CUSTOM_LABEL_ENTRY where CUSTOM_LABEL_KEY = 'submissionIdKey' and CUSTOM_LABEL_VALUE = 'submissionIdValue') s on x2.WORKFLOW_EXECUTION_UUID = s.WORKFLOW_EXECUTION_UUID join (select WORKFLOW_EXECUTION_UUID from CUSTOM_LABEL_ENTRY where (CUSTOM_LABEL_KEY = 'caas-collection-name' and CUSTOM_LABEL_VALUE = 'me@gmail.com') or (CUSTOM_LABEL_KEY = 'caas-collection-name' and CUSTOM_LABEL_VALUE = 'miguel-collection')) c on c.WORKFLOW_EXECUTION_UUID = x2.WORKFLOW_EXECUTION_UUID;; +----+-------------+--------------------+--------+---------------------------------------------+----------------------------------------+---------+---------------------------+------+------------------------------------+; | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |; +----+-------------+---------------",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459106279
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459176050:1779,Performance,perform,performantEXPLAIN,1779,", Jan 30, 2019 at 3:58 PM mcovarr <notifications@github.com> wrote:. > A handcrafted version of this query:; >; > select; > x2.`WORKFLOW_EXECUTION_UUID`,; > x2.`WORKFLOW_NAME`,; > x2.`WORKFLOW_STATUS`,; > x2.`START_TIMESTAMP`,; > x2.`END_TIMESTAMP`,; > x2.`SUBMISSION_TIMESTAMP`,; > x2.`WORKFLOW_METADATA_SUMMARY_ENTRY_ID`; > from; > WORKFLOW_METADATA_SUMMARY_ENTRY x2; > join; > (; > select; > WORKFLOW_EXECUTION_UUID; > from; > CUSTOM_LABEL_ENTRY; > where; > CUSTOM_LABEL_KEY = 'submissionIdKey'; > and CUSTOM_LABEL_VALUE = 'submissionIdValue'; > ) s; > on x2.WORKFLOW_EXECUTION_UUID = s.WORKFLOW_EXECUTION_UUID; > join; > (; > select; > WORKFLOW_EXECUTION_UUID; > from; > CUSTOM_LABEL_ENTRY; > where; > (; > CUSTOM_LABEL_KEY = 'caas-collection-name'; > and CUSTOM_LABEL_VALUE = 'me@gmail.com'; > ); > or (; > CUSTOM_LABEL_KEY = 'caas-collection-name'; > and CUSTOM_LABEL_VALUE = 'miguel-collection'; > ); > ) c; > on c.WORKFLOW_EXECUTION_UUID = x2.WORKFLOW_EXECUTION_UUID; >; > begets a much more performantEXPLAIN; >; > mysql> explain select x2.`WORKFLOW_EXECUTION_UUID`, x2.`WORKFLOW_NAME`, x2.`WORKFLOW_STATUS`, x2.`START_TIMESTAMP`, x2.`END_TIMESTAMP`, x2.`SUBMISSION_TIMESTAMP`, x2.`WORKFLOW_METADATA_SUMMARY_ENTRY_ID` from WORKFLOW_METADATA_SUMMARY_ENTRY x2 join (select WORKFLOW_EXECUTION_UUID from CUSTOM_LABEL_ENTRY where CUSTOM_LABEL_KEY = 'submissionIdKey' and CUSTOM_LABEL_VALUE = 'submissionIdValue') s on x2.WORKFLOW_EXECUTION_UUID = s.WORKFLOW_EXECUTION_UUID join (select WORKFLOW_EXECUTION_UUID from CUSTOM_LABEL_ENTRY where (CUSTOM_LABEL_KEY = 'caas-collection-name' and CUSTOM_LABEL_VALUE = 'me@gmail.com') or (CUSTOM_LABEL_KEY = 'caas-collection-name' and CUSTOM_LABEL_VALUE = 'miguel-collection')) c on c.WORKFLOW_EXECUTION_UUID = x2.WORKFLOW_EXECUTION_UUID;; > +----+-------------+--------------------+--------+---------------------------------------------+----------------------------------------+---------+---------------------------+------+---------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459176050
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199:59,Modifiability,rewrite,rewrites,59,"Contradicting what I said in standup today, the performant rewrites of the labels query actually _*are*_ using the new non-unique key+value index I created on `CUSTOM_LABEL_ENTRY` (see the fourth row of the `EXPLAIN` above referencing `IDX_KEY_VALUE` as its `key`). I confirmed that without that index performance reverts to being terrible. The version of the query generated by Slick doesn't use the index and still performs terribly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199:48,Performance,perform,performant,48,"Contradicting what I said in standup today, the performant rewrites of the labels query actually _*are*_ using the new non-unique key+value index I created on `CUSTOM_LABEL_ENTRY` (see the fourth row of the `EXPLAIN` above referencing `IDX_KEY_VALUE` as its `key`). I confirmed that without that index performance reverts to being terrible. The version of the query generated by Slick doesn't use the index and still performs terribly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199:302,Performance,perform,performance,302,"Contradicting what I said in standup today, the performant rewrites of the labels query actually _*are*_ using the new non-unique key+value index I created on `CUSTOM_LABEL_ENTRY` (see the fourth row of the `EXPLAIN` above referencing `IDX_KEY_VALUE` as its `key`). I confirmed that without that index performance reverts to being terrible. The version of the query generated by Slick doesn't use the index and still performs terribly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199
https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199:417,Performance,perform,performs,417,"Contradicting what I said in standup today, the performant rewrites of the labels query actually _*are*_ using the new non-unique key+value index I created on `CUSTOM_LABEL_ENTRY` (see the fourth row of the `EXPLAIN` above referencing `IDX_KEY_VALUE` as its `key`). I confirmed that without that index performance reverts to being terrible. The version of the query generated by Slick doesn't use the index and still performs terribly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598#issuecomment-459406199
https://github.com/broadinstitute/cromwell/issues/4602#issuecomment-489482319:332,Availability,avail,available,332,"Hey @ylipacbio, I'm not from Cromwell but wanted to throw out a comment. For Cromwell to pull files, a [_Filesystem_](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/) needs to be implemented in Scala. . As far as I'm aware, Amazon's EFS is **NOT** implemented, and cannot be configured to work with Cromwell. The available filesystems are ftp, s3, demo-dos, gcs, oss, http (and unix). If you know some scala, [this](https://github.com/broadinstitute/cromwell/tree/develop/filesystems) might be good place to start on how to implement one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4602#issuecomment-489482319
https://github.com/broadinstitute/cromwell/issues/4602#issuecomment-489482319:294,Modifiability,config,configured,294,"Hey @ylipacbio, I'm not from Cromwell but wanted to throw out a comment. For Cromwell to pull files, a [_Filesystem_](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/) needs to be implemented in Scala. . As far as I'm aware, Amazon's EFS is **NOT** implemented, and cannot be configured to work with Cromwell. The available filesystems are ftp, s3, demo-dos, gcs, oss, http (and unix). If you know some scala, [this](https://github.com/broadinstitute/cromwell/tree/develop/filesystems) might be good place to start on how to implement one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4602#issuecomment-489482319
https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464240535:90,Deployability,patch,patched,90,@vanajasmy - you need to create a custom AMI for your compute environment that includes a patched ecs-agent that is specific for cromwell. See the following documentation on how to do this:. https://docs.opendata.aws/genomics-workflows/aws-batch/create-custom-ami/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464240535
https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953:332,Availability,error,error,332,"Thanks @wleepang for the response. I was using the custom AMI as specified in the link. But I also had a LaunchTemplate that will mount EFS to batch computes. The problem was my userData in the LT had this line ""yum update"" that updated everything including the ECS-agent to the latest version and then it failed with the specified error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953
https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953:216,Deployability,update,update,216,"Thanks @wleepang for the response. I was using the custom AMI as specified in the link. But I also had a LaunchTemplate that will mount EFS to batch computes. The problem was my userData in the LT had this line ""yum update"" that updated everything including the ECS-agent to the latest version and then it failed with the specified error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953
https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953:229,Deployability,update,updated,229,"Thanks @wleepang for the response. I was using the custom AMI as specified in the link. But I also had a LaunchTemplate that will mount EFS to batch computes. The problem was my userData in the LT had this line ""yum update"" that updated everything including the ECS-agent to the latest version and then it failed with the specified error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4604#issuecomment-464252953
https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197:100,Availability,down,downgrade,100,We will likely need to upgrade liquibase at some point but for the moment PR #4619 does a temporary downgrade. Issue #4618 tracks that MariaDB needs to be CI tested to make sure this doesn't re-occur. Thanks for the report!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197
https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197:23,Deployability,upgrade,upgrade,23,We will likely need to upgrade liquibase at some point but for the moment PR #4619 does a temporary downgrade. Issue #4618 tracks that MariaDB needs to be CI tested to make sure this doesn't re-occur. Thanks for the report!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197
https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197:158,Testability,test,tested,158,We will likely need to upgrade liquibase at some point but for the moment PR #4619 does a temporary downgrade. Issue #4618 tracks that MariaDB needs to be CI tested to make sure this doesn't re-occur. Thanks for the report!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4605#issuecomment-461564197
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:9,Availability,error,error,9,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:285,Availability,ERROR,ERROR,285,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:458,Availability,Error,Error,458,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:482,Availability,failure,failures,482,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:495,Availability,failure,failure,495,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:600,Availability,failure,failure,600,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:668,Availability,failure,failures,668,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:681,Availability,failure,failure,681,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:852,Availability,ERROR,ERROR,852,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:908,Availability,down,down,908,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1133,Availability,failure,failures,1133,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1146,Availability,failure,failure,1146,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1251,Availability,failure,failure,1251,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1319,Availability,failure,failures,1319,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1332,Availability,failure,failure,1332,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2752,Availability,failure,failures,2752,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2765,Availability,failure,failure,2765,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2870,Availability,failure,failure,2870,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2938,Availability,failure,failures,2938,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2951,Availability,failure,failure,2951,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:3569,Availability,failure,failures,3569,"concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:944); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3978); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3914); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2491); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2449); 	at com.mysql.jdbc.StatementImpl.executeInternal(S",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:3582,Availability,failure,failure,3582,"concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:944); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3978); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3914); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2491); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2449); 	at com.mysql.jdbc.StatementImpl.executeInternal(S",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:535,Deployability,UPDATE,UPDATE,535,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:802,Deployability,release,released,802,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1186,Deployability,UPDATE,UPDATE,1186,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1438,Deployability,Update,UpdateVisitor,1438,"arne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.ru",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1458,Deployability,Update,UpdateVisitor,1458,"r: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1580,Deployability,update,update,1580,"(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1632,Deployability,update,update,1632,"; WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1718,Deployability,update,updateSchema,1718,"s/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseExceptio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1815,Deployability,update,updateSchema,1815,"019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; S",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2805,Deployability,UPDATE,UPDATE,2805,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2039,Energy Efficiency,adapt,adapted,2039,"lure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatemen",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:631,Integrability,message,message,631,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1282,Integrability,message,message,1282,"munshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2901,Integrability,message,message,2901,"la:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures[%]%:failure' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(D",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1890,Modifiability,Enhance,EnhancedSqlDatabase,1890,"stem. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_K",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:1995,Modifiability,Enhance,EnhancedSqlDatabase,1995,"set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2039,Modifiability,adapt,adapted,2039,"lure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatemen",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2486,Performance,concurren,concurrent,2486,"base.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2571,Performance,concurren,concurrent,2571,"ase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:818,Testability,log,log,818,"The next error is:; ```; 2019-01-31 19:38:58,499 INFO - changelog.xml: changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi: ChangeSet changesets/replace_empty_custom_labels.xml::custom_labels_not_null::rmunshi ran successfully in 661ms; 2019-01-31 19:38:58,563 ERROR - changelog.xml: changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Change Set changesets/failure_metadata.xml::failure_to_message::cjllanwarne failed. Error: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 2019-01-31 19:38:58,618 INFO - changesets/failure_metadata.xml::failure_to_message::cjllanwarne: Successfully released change log lock; 2019-01-31 19:38:58,637 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::failure_to_message::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$Enhanc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2181,Usability,Simpl,SimpleJdbcAction,2181,"ATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcEx",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103:2251,Usability,Simpl,SimpleJdbcAction,2251," FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures[%]%:failure' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = CONCAT(TRIM(TRAILING ':failure' FROM METADATA_KEY), "":message""); WHERE METADATA_KEY LIKE ""%failures[%]%:failure""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459580103
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:259,Availability,ERROR,ERROR,259,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:422,Availability,Error,Error,422,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:446,Availability,failure,failures,446,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:618,Availability,failure,failures,618,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:796,Availability,ERROR,ERROR,796,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:852,Availability,down,down,852,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1072,Availability,failure,failures,1072,"metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1244,Availability,failure,failures,1244,"metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2676,Availability,failure,failures,2676,"tils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures%causedBy:%' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Delegating",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2848,Availability,failure,failures,2848,"tils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures%causedBy:%' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Delegating",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:3478,Availability,failure,failures,3478," 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures%causedBy:%' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at com.mysql.jdbc.Util.handleNewInstance(Util.java:425); 	at com.mysql.jdbc.Util.getInstance(Util.java:408); 	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:944); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3978); 	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3914); 	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2530); 	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2683); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2491); 	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2449); 	at com.mysql.jdbc.StatementImpl.executeInternal(S",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:498,Deployability,UPDATE,UPDATE,498,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:746,Deployability,release,released,746,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1124,Deployability,UPDATE,UPDATE,1124,"metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1362,Deployability,Update,UpdateVisitor,1362,"ure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.ru",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1382,Deployability,Update,UpdateVisitor,1382,":causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1504,Deployability,update,update,1504,"A_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1556,Deployability,update,update,1556,"ausedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1642,Deployability,update,updateSchema,1642,"0:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseExceptio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1739,Deployability,update,updateSchema,1739,"d change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2728,Deployability,UPDATE,UPDATE,2728,"tils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures%causedBy:%' in 'where clause'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Delegating",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1963,Energy Efficiency,adapt,adapted,1963,"re_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1814,Modifiability,Enhance,EnhancedSqlDatabase,1814,"tantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1919,Modifiability,Enhance,EnhancedSqlDatabase,1919,"n failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteState",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:1963,Modifiability,adapt,adapted,1963,"re_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2410,Performance,concurren,concurrent,2410,"base.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2495,Performance,concurren,concurrent,2495,"ase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column '%failures%causedBy:%' in",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:762,Testability,log,log,762,"Then; ```; 2019-01-31 20:10:51,323 INFO - changelog.xml: changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne: ChangeSet changesets/failure_metadata.xml::remove_failure_timestamp::cjllanwarne ran successfully in 5ms; 2019-01-31 20:10:51,428 ERROR - changelog.xml: changesets/failure_metadata.xml::causedByLists::cjllanwarne: Change Set changesets/failure_metadata.xml::causedByLists::cjllanwarne failed. Error: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 2019-01-31 20:10:51,492 INFO - changesets/failure_metadata.xml::causedByLists::cjllanwarne: Successfully released change log lock; 2019-01-31 20:10:51,531 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::causedByLists::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at c",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2105,Usability,Simpl,SimpleJdbcAction,2105,"ailed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809:2175,Usability,Simpl,SimpleJdbcAction,2175,"KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column '%failures%causedBy:%' in 'where clause' [Failed SQL: UPDATE METADATA_ENTRY; SET METADATA_KEY = REPLACE(METADATA_KEY, ""causedBy:"", ""causedBy[0]:""); WHERE METADATA_KEY LIKE ""%failures%causedBy:%""]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDat",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459583809
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:270,Availability,ERROR,ERROR,270,"Lastly,; ```; 2019-01-31 20:30:56,569 INFO - changelog.xml: changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne: ChangeSet changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne ran successfully in 8ms; 2019-01-31 20:30:56,593 ERROR - changelog.xml: changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Change Set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSER",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:449,Availability,Error,Error,449,"Lastly,; ```; 2019-01-31 20:30:56,569 INFO - changelog.xml: changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne: ChangeSet changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne ran successfully in 8ms; 2019-01-31 20:30:56,593 ERROR - changelog.xml: changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Change Set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSER",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:889,Availability,failure,failures,889,"Lastly,; ```; 2019-01-31 20:30:56,569 INFO - changelog.xml: changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne: ChangeSet changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne ran successfully in 8ms; 2019-01-31 20:30:56,593 ERROR - changelog.xml: changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Change Set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSER",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:1671,Availability,ERROR,ERROR,1671,"STAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_I",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:1727,Availability,down,down,1727,"DATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:2371,Availability,failure,failures,2371," CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:4815,Availability,failure,failures,4815,".jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatem",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:1621,Deployability,release,released,1621,"STAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_I",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3085,Deployability,Update,UpdateVisitor,3085,"JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.ru",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3105,Deployability,Update,UpdateVisitor,3105,", METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.sc",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3227,Deployability,update,update,3227,"), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadP",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3279,Deployability,update,update,3279,"TTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3365,Deployability,update,updateSchema,3365,"[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseExceptio",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3462,Deployability,update,updateSchema,3462,"_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3686,Energy Efficiency,adapt,adapted,3686,"1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.C",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:708,Integrability,message,message,708,"Lastly,; ```; 2019-01-31 20:30:56,569 INFO - changelog.xml: changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne: ChangeSet changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne ran successfully in 8ms; 2019-01-31 20:30:56,593 ERROR - changelog.xml: changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Change Set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSER",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:902,Integrability,message,message,902,"Lastly,; ```; 2019-01-31 20:30:56,569 INFO - changelog.xml: changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne: ChangeSet changesets/failure_metadata.xml::deduplicate_failure_messages::cjllanwarne ran successfully in 8ms; 2019-01-31 20:30:56,593 ERROR - changelog.xml: changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Change Set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSER",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:1402,Integrability,message,message,1402,"e_metadata.xml::guaranteed_caused_bys::cjllanwarne failed. Error: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:messag",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:2190,Integrability,message,message,2190,"B_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:2384,Integrability,message,message,2384," CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:2884,Integrability,message,message,2884,"bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:4634,Integrability,message,message,4634,".services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquiba",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:4828,Integrability,message,message,4828,".jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatem",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:5328,Integrability,message,message,5328,"read.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:309); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:55); 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:113); 	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1277); 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1259); 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:582); 	... 16 common frames omitted; Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column ':causedBy[]' in 'field list'; 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingC",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3537,Modifiability,Enhance,EnhancedSqlDatabase,3537,"_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_R",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3642,Modifiability,Enhance,EnhancedSqlDatabase,3642,"X OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FRO",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3686,Modifiability,adapt,adapted,3686,"1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.C",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:4133,Performance,concurren,concurrent,4133,"base.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCAT",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:4218,Performance,concurren,concurrent,4218,"ase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RE",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:1637,Testability,log,log,1637,"STAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_INDEX OR (t2.JOB_SCATTER_INDEX IS NULL AND t1.JOB_SCATTER_INDEX IS NULL)); 	 AND (t2.JOB_RETRY_ATTEMPT = t1.JOB_RETRY_ATTEMPT OR (t2.JOB_RETRY_ATTEMPT IS NULL AND t1.JOB_RETRY_ATTEMPT IS NULL)); AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 2019-01-31 20:30:56,617 INFO - changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne: Successfully released change log lock; 2019-01-31 20:30:56,631 ERROR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/failure_metadata.xml::guaranteed_caused_bys::cjllanwarne:; Reason: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKFLOW_EXECUTION_UUID = t1.WORKFLOW_EXECUTION_UUID; 	 AND (t2.CALL_FQN = t1.CALL_FQN OR (t2.CALL_FQN IS NULL AND t1.CALL_FQN IS NULL)); 	 AND (t2.JOB_SCATTER_INDEX = t1.JOB_SCATTER_I",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3828,Usability,Simpl,SimpleJdbcAction,3828,"AND t2.METADATA_KEY LIKE CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message';",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701:3898,Usability,Simpl,SimpleJdbcAction,3898,"ATA_KEY), "":causedBy[%""); AND t2.METADATA_JOURNAL_ID <> t1.METADATA_JOURNAL_ID; )]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:619); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:51); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:79); 	at liquibase.Liquibase.update(Liquibase.java:214); 	at liquibase.Liquibase.update(Liquibase.java:192); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:62); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:34); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:155); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: Unknown column ':causedBy[]' in 'field list' [Failed SQL: INSERT INTO METADATA_ENTRY (WORKFLOW_EXECUTION_UUID, METADATA_KEY, CALL_FQN, JOB_SCATTER_INDEX, JOB_RETRY_ATTEMPT, METADATA_TIMESTAMP); SELECT t1.WORKFLOW_EXECUTION_UUID, CONCAT(TRIM(TRAILING ':message' FROM t1.METADATA_KEY), "":causedBy[]""), t1.CALL_FQN, t1.JOB_SCATTER_INDEX, t1.JOB_RETRY_ATTEMPT, t1.METADATA_TIMESTAMP; FROM METADATA_ENTRY AS t1; WHERE METADATA_KEY LIKE '%failures[%]%:message'; AND NOT EXISTS (SELECT *; 	FROM METADATA_ENTRY AS t2; 	WHERE t2.WORKF",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4606#issuecomment-459609701
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460261256:67,Testability,test,tested,67,"> looks good to me. why the do not merge label?. Because I haven't tested it yet with PAPI v2, and am not sure how to do so. But if a cromwell expert is confident it looks good, that's OK with me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460261256
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110:196,Energy Efficiency,battery,battery,196,@pshapiro4broad you flatter me. But yeah we should probably come up w/ a centaur test that makes sure it is actually working as intended. The good news is that our travis PR tests conduct a whole battery of papi v2 tests and those pass so this didn't break anything :smile:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110:81,Testability,test,test,81,@pshapiro4broad you flatter me. But yeah we should probably come up w/ a centaur test that makes sure it is actually working as intended. The good news is that our travis PR tests conduct a whole battery of papi v2 tests and those pass so this didn't break anything :smile:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110:174,Testability,test,tests,174,@pshapiro4broad you flatter me. But yeah we should probably come up w/ a centaur test that makes sure it is actually working as intended. The good news is that our travis PR tests conduct a whole battery of papi v2 tests and those pass so this didn't break anything :smile:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110:215,Testability,test,tests,215,@pshapiro4broad you flatter me. But yeah we should probably come up w/ a centaur test that makes sure it is actually working as intended. The good news is that our travis PR tests conduct a whole battery of papi v2 tests and those pass so this didn't break anything :smile:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460273110
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656:295,Deployability,install,install,295,"The following could be used as the command body of a Centaur WDL to test this feature (copy-paste-edited from Thibault's [`docker_size_gcr.wdl`](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_size/docker_size_gcr.wdl)):; ```; apt-get install --assume-yes jq > /dev/null; NAME=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/name`; ZONE=`basename \`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/zone\``; PROJECT=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/project/project-id`; curl -s -H ""Authorization: Bearer `gcloud auth print-access-token`"" ""https://www.googleapis.com/compute/v1/projects/$PROJECT/zones/$ZONE/instances/$NAME?fields=cpuPlatform"" | jq -r '.cpuPlatform'; ```; Run on one of Jeff's legion GCE VMs this produces. ```; Intel Haswell; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656:695,Security,Authoriz,Authorization,695,"The following could be used as the command body of a Centaur WDL to test this feature (copy-paste-edited from Thibault's [`docker_size_gcr.wdl`](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_size/docker_size_gcr.wdl)):; ```; apt-get install --assume-yes jq > /dev/null; NAME=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/name`; ZONE=`basename \`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/zone\``; PROJECT=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/project/project-id`; curl -s -H ""Authorization: Bearer `gcloud auth print-access-token`"" ""https://www.googleapis.com/compute/v1/projects/$PROJECT/zones/$ZONE/instances/$NAME?fields=cpuPlatform"" | jq -r '.cpuPlatform'; ```; Run on one of Jeff's legion GCE VMs this produces. ```; Intel Haswell; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656:736,Security,access,access-token,736,"The following could be used as the command body of a Centaur WDL to test this feature (copy-paste-edited from Thibault's [`docker_size_gcr.wdl`](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_size/docker_size_gcr.wdl)):; ```; apt-get install --assume-yes jq > /dev/null; NAME=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/name`; ZONE=`basename \`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/zone\``; PROJECT=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/project/project-id`; curl -s -H ""Authorization: Bearer `gcloud auth print-access-token`"" ""https://www.googleapis.com/compute/v1/projects/$PROJECT/zones/$ZONE/instances/$NAME?fields=cpuPlatform"" | jq -r '.cpuPlatform'; ```; Run on one of Jeff's legion GCE VMs this produces. ```; Intel Haswell; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656:68,Testability,test,test,68,"The following could be used as the command body of a Centaur WDL to test this feature (copy-paste-edited from Thibault's [`docker_size_gcr.wdl`](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_size/docker_size_gcr.wdl)):; ```; apt-get install --assume-yes jq > /dev/null; NAME=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/name`; ZONE=`basename \`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/instance/zone\``; PROJECT=`curl -s -H ""Metadata-Flavor: Google"" http://metadata.google.internal/computeMetadata/v1/project/project-id`; curl -s -H ""Authorization: Bearer `gcloud auth print-access-token`"" ""https://www.googleapis.com/compute/v1/projects/$PROJECT/zones/$ZONE/instances/$NAME?fields=cpuPlatform"" | jq -r '.cpuPlatform'; ```; Run on one of Jeff's legion GCE VMs this produces. ```; Intel Haswell; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-460339656
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349:48,Deployability,install,installing,48,@mcovarr is there a reason why your test WDL is installing `jq` in the command rather than picking a docker image which already has it installed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349:135,Deployability,install,installed,135,@mcovarr is there a reason why your test WDL is installing `jq` in the command rather than picking a docker image which already has it installed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349:36,Testability,test,test,36,@mcovarr is there a reason why your test WDL is installing `jq` in the command rather than picking a docker image which already has it installed?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461103349
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461842716:66,Testability,test,tests,66,@pshapiro4broad just want to be sure you'll be adding the Centaur tests?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-461842716
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227:99,Energy Efficiency,green,green,99,"> @pshapiro4broad just want to be sure you'll be adding the Centaur tests?. It turned out that we (green) didn't need this feature after all, and I've been a bit busy to run the required test. Maybe a red person could take this over, as I think it may be generally useful for other users?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227:68,Testability,test,tests,68,"> @pshapiro4broad just want to be sure you'll be adding the Centaur tests?. It turned out that we (green) didn't need this feature after all, and I've been a bit busy to run the required test. Maybe a red person could take this over, as I think it may be generally useful for other users?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227:187,Testability,test,test,187,"> @pshapiro4broad just want to be sure you'll be adding the Centaur tests?. It turned out that we (green) didn't need this feature after all, and I've been a bit busy to run the required test. Maybe a red person could take this over, as I think it may be generally useful for other users?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-465747227
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872:86,Testability,test,test,86,"@pshapiro4broad would you be able to provide (even just in theory) a WDL which could, test that this is working? Maybe with a short ""and then you'd want to check this value to make sure""piece of commentary?. If so, I bet we could wire the test into our testing framework on your behalf and merge this",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872:239,Testability,test,test,239,"@pshapiro4broad would you be able to provide (even just in theory) a WDL which could, test that this is working? Maybe with a short ""and then you'd want to check this value to make sure""piece of commentary?. If so, I bet we could wire the test into our testing framework on your behalf and merge this",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872:253,Testability,test,testing,253,"@pshapiro4broad would you be able to provide (even just in theory) a WDL which could, test that this is working? Maybe with a short ""and then you'd want to check this value to make sure""piece of commentary?. If so, I bet we could wire the test into our testing framework on your behalf and merge this",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469445872
https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469451365:115,Testability,test,test,115,"I've started working on this, the bit I pasted above a while back should hopefully be a good basis for the Centaur test.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4609#issuecomment-469451365
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460404199:0,Availability,Ping,Pinging,0,Pinging @chapmanb in case he has thoughts on what we could do here,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460404199
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610:501,Availability,down,download,501,"Adam and Jeff;; Thanks for this. I'm definitely agreed I don't want to break your tests every time we accidentally introduce a bug in bcbio. We have tagged versions of the Docker images (https://quay.io/repository/bcbio/bcbio-vc?tab=tags) so could pin to a specific CWL with a specific Docker tag. Data doesn't change as often in a back-incompatible way but you could also have a copy of that if it becomes an issue. We could generate CWL that ties to a specific Docker build, or just have your tests download the tagged version we've tested on. How aggressive is Cromwell at updating the local Docker version based on what's in the CWL? If it would leave a pre-downloaded and ready to go Docker alone, it seems like a pre-pull from a known tag and the pinned CWL should do most of what we need. Would that work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610:662,Availability,down,downloaded,662,"Adam and Jeff;; Thanks for this. I'm definitely agreed I don't want to break your tests every time we accidentally introduce a bug in bcbio. We have tagged versions of the Docker images (https://quay.io/repository/bcbio/bcbio-vc?tab=tags) so could pin to a specific CWL with a specific Docker tag. Data doesn't change as often in a back-incompatible way but you could also have a copy of that if it becomes an issue. We could generate CWL that ties to a specific Docker build, or just have your tests download the tagged version we've tested on. How aggressive is Cromwell at updating the local Docker version based on what's in the CWL? If it would leave a pre-downloaded and ready to go Docker alone, it seems like a pre-pull from a known tag and the pinned CWL should do most of what we need. Would that work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610:82,Testability,test,tests,82,"Adam and Jeff;; Thanks for this. I'm definitely agreed I don't want to break your tests every time we accidentally introduce a bug in bcbio. We have tagged versions of the Docker images (https://quay.io/repository/bcbio/bcbio-vc?tab=tags) so could pin to a specific CWL with a specific Docker tag. Data doesn't change as often in a back-incompatible way but you could also have a copy of that if it becomes an issue. We could generate CWL that ties to a specific Docker build, or just have your tests download the tagged version we've tested on. How aggressive is Cromwell at updating the local Docker version based on what's in the CWL? If it would leave a pre-downloaded and ready to go Docker alone, it seems like a pre-pull from a known tag and the pinned CWL should do most of what we need. Would that work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610:495,Testability,test,tests,495,"Adam and Jeff;; Thanks for this. I'm definitely agreed I don't want to break your tests every time we accidentally introduce a bug in bcbio. We have tagged versions of the Docker images (https://quay.io/repository/bcbio/bcbio-vc?tab=tags) so could pin to a specific CWL with a specific Docker tag. Data doesn't change as often in a back-incompatible way but you could also have a copy of that if it becomes an issue. We could generate CWL that ties to a specific Docker build, or just have your tests download the tagged version we've tested on. How aggressive is Cromwell at updating the local Docker version based on what's in the CWL? If it would leave a pre-downloaded and ready to go Docker alone, it seems like a pre-pull from a known tag and the pinned CWL should do most of what we need. Would that work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610:535,Testability,test,tested,535,"Adam and Jeff;; Thanks for this. I'm definitely agreed I don't want to break your tests every time we accidentally introduce a bug in bcbio. We have tagged versions of the Docker images (https://quay.io/repository/bcbio/bcbio-vc?tab=tags) so could pin to a specific CWL with a specific Docker tag. Data doesn't change as often in a back-incompatible way but you could also have a copy of that if it becomes an issue. We could generate CWL that ties to a specific Docker build, or just have your tests download the tagged version we've tested on. How aggressive is Cromwell at updating the local Docker version based on what's in the CWL? If it would leave a pre-downloaded and ready to go Docker alone, it seems like a pre-pull from a known tag and the pinned CWL should do most of what we need. Would that work?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-460720610
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936:65,Testability,test,tests,65,"To be clear @chapmanb, we never think of it as ""you breaking our tests"", but rather ""we should test differently so we don't have to bug Brad as much when things change""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936:95,Testability,test,test,95,"To be clear @chapmanb, we never think of it as ""you breaking our tests"", but rather ""we should test differently so we don't have to bug Brad as much when things change""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936
https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936:6,Usability,clear,clear,6,"To be clear @chapmanb, we never think of it as ""you breaking our tests"", but rather ""we should test differently so we don't have to bug Brad as much when things change""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613#issuecomment-461156936
https://github.com/broadinstitute/cromwell/pull/4615#issuecomment-461120477:113,Modifiability,config,configs,113,Thanks! . https://github.com/broadinstitute/firecloud-develop/blob/18ebf8ff504bd21618515e1d748d2d0f5fd38e32/base-configs/cromwell/cromwell.conf.ctmpl#L36'. This should similarly go into `firecloud-develop`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4615#issuecomment-461120477
https://github.com/broadinstitute/cromwell/pull/4615#issuecomment-461140902:66,Modifiability,config,config,66,Sorry for premature closing. I do think this should be in default config,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4615#issuecomment-461140902
https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286:37,Energy Efficiency,charge,charges,37,"@geoffjentry I understand re: egress charges. In my use case these aren't an issue, so a flag option would still help. Maybe, make egress cost a config option of a filesystem, and only reuse results if the egress cost would be under some user-specified value? You can also drop the requirement of specifying one engine/filesystem for all tasks. You could then return a cached result from any filesystem where it exists, without needing to copy it to a target filesystem. You could then also let workflow inputs point to files on different filesystems, and automatically choose the engine for each job based on where its inputs are.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286
https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286:145,Modifiability,config,config,145,"@geoffjentry I understand re: egress charges. In my use case these aren't an issue, so a flag option would still help. Maybe, make egress cost a config option of a filesystem, and only reuse results if the egress cost would be under some user-specified value? You can also drop the requirement of specifying one engine/filesystem for all tasks. You could then return a cached result from any filesystem where it exists, without needing to copy it to a target filesystem. You could then also let workflow inputs point to files on different filesystems, and automatically choose the engine for each job based on where its inputs are.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286
https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286:369,Performance,cache,cached,369,"@geoffjentry I understand re: egress charges. In my use case these aren't an issue, so a flag option would still help. Maybe, make egress cost a config option of a filesystem, and only reuse results if the egress cost would be under some user-specified value? You can also drop the requirement of specifying one engine/filesystem for all tasks. You could then return a cached result from any filesystem where it exists, without needing to copy it to a target filesystem. You could then also let workflow inputs point to files on different filesystems, and automatically choose the engine for each job based on where its inputs are.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4616#issuecomment-461576286
https://github.com/broadinstitute/cromwell/pull/4617#issuecomment-461526777:132,Deployability,release,release,132,"This is intended to be a very narrow change to move the ""does this workflow exist"" check from metadata to metadata summaries so the release can go forward. This is deliberately intended to follow existing naming conventions, coding patterns and API structure as much as possible. If anyone feels strongly that these things should be improved there can certainly be enhancement requests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4617#issuecomment-461526777
https://github.com/broadinstitute/cromwell/pull/4617#issuecomment-461526777:365,Modifiability,enhance,enhancement,365,"This is intended to be a very narrow change to move the ""does this workflow exist"" check from metadata to metadata summaries so the release can go forward. This is deliberately intended to follow existing naming conventions, coding patterns and API structure as much as possible. If anyone feels strongly that these things should be improved there can certainly be enhancement requests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4617#issuecomment-461526777
https://github.com/broadinstitute/cromwell/issues/4618#issuecomment-1518309526:99,Testability,test,test,99,Liquibase went to 4.8.0 in https://github.com/broadinstitute/cromwell/pull/6710 and we do have the test in place.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4618#issuecomment-1518309526
https://github.com/broadinstitute/cromwell/pull/4624#issuecomment-462491136:11,Availability,failure,failure,11,"I love the failure type but since you've done so much, would it be another load of work to use `sttp` + cats-effect backend vs the source of our Future woes, akka?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4624#issuecomment-462491136
https://github.com/broadinstitute/cromwell/pull/4624#issuecomment-462491136:75,Performance,load,load,75,"I love the failure type but since you've done so much, would it be another load of work to use `sttp` + cats-effect backend vs the source of our Future woes, akka?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4624#issuecomment-462491136
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-464196155:144,Testability,log,logged,144,"If you navigate [here](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team), do you see ""Ask a Question"" at the top-left when logged in?. ![screenshot-2019-2-15 ask the cromwell wdl team](https://user-images.githubusercontent.com/1087943/52883386-b9fff600-3138-11e9-8e2b-eef59693afbf.png). ---. I think the problem is that `write_json()` implicitly expects an object (i.e. map) and when you give it an array, it has no idea what to do with it. I would say this behavior is in contravention of the WDL spec, which leads off the `write_json()` section with ""Given something with any type, this writes the JSON equivalent to a file."". Your example should write a file with a JSON array in it, like; ```; [; ""/path/to/1.bam"",; ""/path/to/2.bam"",; ""/path/to/3.bam""; ]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-464196155
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465194780:46,Modifiability,plugin,plugins,46,"Hmm, I would try in a vanilla browser with no plugins",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465194780
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552:175,Modifiability,plug-in,plug-ins,175,"I also tried Firefox Quantum 65.0.1, with all extensions disabled. (Also tried with the latest Shockwave Flash, just in case.) Same result. I also tried IE9 with basically no plug-ins, and I cannot even login there. The ""Sign In"" button does nothing. Are you sure that my account gives me access to ask questions?. Any other ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552:289,Security,access,access,289,"I also tried Firefox Quantum 65.0.1, with all extensions disabled. (Also tried with the latest Shockwave Flash, just in case.) Same result. I also tried IE9 with basically no plug-ins, and I cannot even login there. The ""Sign In"" button does nothing. Are you sure that my account gives me access to ask questions?. Any other ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552:203,Testability,log,login,203,"I also tried Firefox Quantum 65.0.1, with all extensions disabled. (Also tried with the latest Shockwave Flash, just in case.) Same result. I also tried IE9 with basically no plug-ins, and I cannot even login there. The ""Sign In"" button does nothing. Are you sure that my account gives me access to ask questions?. Any other ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465215552
https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465393316:23,Usability,clear,clear,23,"@tmm211 And just to be clear, not asking you to solve the original issue, but rather the problem @pb-cdunn is having w/ the forum",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4625#issuecomment-465393316
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462380891:97,Availability,error,error,97,@wresch Looks like you are having DNS resolution issues. \. Can you resolve the endpoint per the error message?; `nslookup https://auth.docker.io/token`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462380891
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462380891:103,Integrability,message,message,103,@wresch Looks like you are having DNS resolution issues. \. Can you resolve the endpoint per the error message?; `nslookup https://auth.docker.io/token`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462380891
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738:269,Availability,avail,available,269,Thanks for the response @danbills - this is on a compute node which only has access to the outside network through an http(s)/ftp proxy so it can't do name resolution for outside addresses. Why does cromwell try to resolve that particular address? We don't have docker available and I tried with a config file that only defines a local and slurm backend and still get the same exceptions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738:298,Modifiability,config,config,298,Thanks for the response @danbills - this is on a compute node which only has access to the outside network through an http(s)/ftp proxy so it can't do name resolution for outside addresses. Why does cromwell try to resolve that particular address? We don't have docker available and I tried with a config file that only defines a local and slurm backend and still get the same exceptions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738:77,Security,access,access,77,Thanks for the response @danbills - this is on a compute node which only has access to the outside network through an http(s)/ftp proxy so it can't do name resolution for outside addresses. Why does cromwell try to resolve that particular address? We don't have docker available and I tried with a config file that only defines a local and slurm backend and still get the same exceptions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462393738
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697:140,Availability,ping,ping,140,"I reproduced the problem locally. The problem is our default health monitor `StandardHealthMonitorServiceActor` which periodically tries to ping Docker Hub. I'm not sure what changed between 36 and 37 that this now manifests when previously it did not. There is a `cromwell.services.healthmonitor.impl.noop.NoopHealthMonitorServiceActor` that one should be able to swap in to turn off health monitoring, but unfortunately there's a bug in the 37 version of this class that causes it to crash during initialization. As you've noticed the workflow still runs successfully albeit with a lot of noise, we'll try to come up with a more satisfactory resolution.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697:68,Energy Efficiency,monitor,monitor,68,"I reproduced the problem locally. The problem is our default health monitor `StandardHealthMonitorServiceActor` which periodically tries to ping Docker Hub. I'm not sure what changed between 36 and 37 that this now manifests when previously it did not. There is a `cromwell.services.healthmonitor.impl.noop.NoopHealthMonitorServiceActor` that one should be able to swap in to turn off health monitoring, but unfortunately there's a bug in the 37 version of this class that causes it to crash during initialization. As you've noticed the workflow still runs successfully albeit with a lot of noise, we'll try to come up with a more satisfactory resolution.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697
https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697:392,Energy Efficiency,monitor,monitoring,392,"I reproduced the problem locally. The problem is our default health monitor `StandardHealthMonitorServiceActor` which periodically tries to ping Docker Hub. I'm not sure what changed between 36 and 37 that this now manifests when previously it did not. There is a `cromwell.services.healthmonitor.impl.noop.NoopHealthMonitorServiceActor` that one should be able to swap in to turn off health monitoring, but unfortunately there's a bug in the 37 version of this class that causes it to crash during initialization. As you've noticed the workflow still runs successfully albeit with a lot of noise, we'll try to come up with a more satisfactory resolution.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626#issuecomment-462415697
https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-462450314:98,Modifiability,config,config,98,I'd vote 👍 on using noop as the default out-of-the-box option so long as:; - it's documented as a config change; - we do something sensible in centaur; - we make sure the specs are still working as expected,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-462450314
https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-469795137:150,Usability,usab,usable,150,@cjllanwarne [rebasing on this PR](https://github.com/broadinstitute/cromwell/pull/4631/files) so the `NoopHealthMonitorServiceActor` actually became usable.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-469795137
https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-469849765:61,Integrability,message,message,61,"@cjllanwarne you're good, thanks 🙂 The wording on the GitHub message made it sound like two reviews were missing but it was actually only one.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4632#issuecomment-469849765
https://github.com/broadinstitute/cromwell/pull/4633#issuecomment-486211090:26,Deployability,update,update,26,@cjllanwarne Just need to update the piece around private dockerhub support --otherwise approved 👍,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4633#issuecomment-486211090
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596:407,Availability,echo,echo,407,"Hey @vsoch, in our submit script, we're opting to pull and build our docker images on the head node as @TMiguelT suggested. If the build exists, singularity will ask to overwrite the existing build. Just wondering if there's an elegant way to skip the build if it exists (and it's up to date) or whether we should be forcing a rebuild every time. I could skip it like this, but it's not as friendly./; ```; echo 'n' | singularity build --sandbox $IMAGE docker://${docker}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596:438,Modifiability,sandbox,sandbox,438,"Hey @vsoch, in our submit script, we're opting to pull and build our docker images on the head node as @TMiguelT suggested. If the build exists, singularity will ask to overwrite the existing build. Just wondering if there's an elegant way to skip the build if it exists (and it's up to date) or whether we should be forcing a rebuild every time. I could skip it like this, but it's not as friendly./; ```; echo 'n' | singularity build --sandbox $IMAGE docker://${docker}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596:438,Testability,sandbox,sandbox,438,"Hey @vsoch, in our submit script, we're opting to pull and build our docker images on the head node as @TMiguelT suggested. If the build exists, singularity will ask to overwrite the existing build. Just wondering if there's an elegant way to skip the build if it exists (and it's up to date) or whether we should be forcing a rebuild every time. I could skip it like this, but it's not as friendly./; ```; echo 'n' | singularity build --sandbox $IMAGE docker://${docker}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463861596
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863078:28,Modifiability,sandbox,sandbox,28,How are you building with a sandbox without sudo?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863078
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863078:28,Testability,sandbox,sandbox,28,How are you building with a sandbox without sudo?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863078
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863223:63,Performance,cache,cache,63,"This would be a better use case for pull, which will check the cache first and not ask for the confirmation.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463863223
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252:315,Deployability,update,updated,315,"I'm confused. Sandbox mode doesn't/shouldn't require sudo. We included it because it requires the *least* permissions to use it. . As for `pull`, it seems to force rebuild the image every time, exactly the same as `build --force`. What we want ideally is a way to build the image if it doesn't exist or needs to be updated, but if neither is the case, then do nothing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252:14,Modifiability,Sandbox,Sandbox,14,"I'm confused. Sandbox mode doesn't/shouldn't require sudo. We included it because it requires the *least* permissions to use it. . As for `pull`, it seems to force rebuild the image every time, exactly the same as `build --force`. What we want ideally is a way to build the image if it doesn't exist or needs to be updated, but if neither is the case, then do nothing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252:14,Testability,Sandbox,Sandbox,14,"I'm confused. Sandbox mode doesn't/shouldn't require sudo. We included it because it requires the *least* permissions to use it. . As for `pull`, it seems to force rebuild the image every time, exactly the same as `build --force`. What we want ideally is a way to build the image if it doesn't exist or needs to be updated, but if neither is the case, then do nothing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463866252
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:232,Availability,down,download,232,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:386,Deployability,release,release,386,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:433,Deployability,release,releases,433,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:204,Modifiability,layers,layers,204,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:176,Performance,cache,cache,176,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477:667,Performance,cache,cached,667,"Yes that's correct, sorry I didn't see you are building from a docker uri. . I don't think there exists the exact functionality you want, but we are getting there. The current cache support is for docker layers, which will save you download time, but you still would rebuild from them each time. I think it would be worth the effort to ask for what you need. Take a look at the [latest release](https://github.com/sylabs/singularity/releases) that has some support for caching (for library images). Then I would open an issue and say something about it - you want the same caching but for docker pulled containers. This particular flow to pull (or build) and honor a cached image if it exists is very common and reasonable, and should be supported.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463867477
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463885163:83,Deployability,release,released,83,"Thanks, @vsoch, I will look into the new caching functionality once 3.1.0 is fully released, and I'll open an issue soon. The reason this matters is because if we run a scatter job in Cromwell where we have multiple jobs running the same image, they will all simultaneously try to rebuild the image file, which I imagine will catastrophically fail. But now that I think about it, if the image does need updating this will still cause it to fail. I might have to think about some kind of locking mechanism to use here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463885163
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463887263:176,Deployability,pipeline,pipeline,176,"I don't think the pull/build should be built in to the command that is run at scale - the image should be pulled /built once, and then the direct path passed into the script / pipeline that is run at scale.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463887263
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463890367:272,Deployability,update,updated,272,"You're right, it shouldn't. But because Cromwell only gives us one single hook to customise running containers, `submit-docker`, we have to ensure it can run at scale. Ideally Cromwell would have a `pull-docker` hook that's run each time a new image needs to be pulled or updated. But since that's not an option, I have to build the image separately for each job.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463890367
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463922311:23,Modifiability,config,config,23,"Okay, I've pushed some config changes so that each `singularity build` happens in its own working directory. And I've added `sbatch --wait`, because then if the job fails, Cromwell will know about it. I'm now happy for this to reviewed, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463922311
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:352,Deployability,install,install,352,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:705,Deployability,install,installable,705,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:327,Performance,cache,caches,327,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:508,Performance,concurren,concurrently,508,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:539,Performance,cache,cache,539,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:276,Testability,assert,assert,276,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232:935,Usability,feedback,feedback,935,"Hey @TMiguelT, I made a few small changes to udocker, added the notes we discussed and a next steps section to follow the general template of the other tutorials. I wanted to add a small section about the caching of udocker images but don't know udocker well enough to really assert this:. > #### Caching in udocker; > udocker caches images within the install or user directory, thus reducing the need to pull and build the docker containers at every stage. Clarification is required on whether udocker will concurrently write to the same cache directory for largely scattered workflows. So I've just left it out. I also think it might be worth saying more explicitly that Singularity is technically user-installable (just without `setuid`, as I didn't realise until our conversation. If you're happy with what's there now, I'll remove the WIP and put it up for review again. If there's anyone out there reading, we'd love to get your feedback or clarification on any points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464519232
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:328,Deployability,configurat,configuration,328,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:221,Modifiability,config,config,221,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:328,Modifiability,config,configuration,328,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:452,Modifiability,layers,layers,452,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:27,Performance,cache,caches,27,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:397,Performance,cache,cache,397,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267:431,Performance,cache,caches,431,"So the gist of how udocker caches things is that it uses a directory similar to Docker, which defaults to [`~/.udocker`](https://github.com/indigo-dc/udocker/blob/master/udocker.py#L137), but you can override that with a config file [described here](https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#9-configuration), to set a custom location, e.g. `reposdir = ""/path/to/cache""`. Within that directory it caches the different layers and images in different subdirectories. I'll write that up into the document.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464521267
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464537286:36,Deployability,install,installation,36,"@illusional, I've added Singularity installation docs, and udocker cache docs",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464537286
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464537286:67,Performance,cache,cache,67,"@illusional, I've added Singularity installation docs, and udocker cache docs",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464537286
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464973494:446,Safety,avoid,avoided,446,"Hmm, this still makes me very uncomfortable - if the PR is from your develop to develop, you shouldn't have those extra commits. You should not have merged master into your develop. To fix this, you can either start clean from a develop (not merged with master) or if you've tried that and had trouble, I'll offer to help you and open a separate PR. It's messy merges like this with force pushes that lead to a lot of headaches, and it should be avoided if possible. It's important to do this right. It's after 11pm here and I'm not in work mode, but I can help with this tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-464973494
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465204072:24,Availability,echo,echo,24,@illusional I wanted to echo the comments from @vsoch. Thanks to all of you who worked to get this going.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465204072
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465392789:25,Performance,Cache,Cache,25,I notice the Singularity Cache is now the second topic within Singularity. Do you mind if I put it back at the end? I don't think there's any need to confuse users with it immediately. @illusional,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465392789
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465407558:56,Availability,down,down,56,"@TMiguelT I've moved the singularity cache section back down. Hopefully this is all the comments actioned. Sorry @vsoch, I realised I've been resolving your comments as I actioned them, but I probably should've left them open as they're from your review. Also sorry for what was probably a lot of email spam over the past few hours.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465407558
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465407558:37,Performance,cache,cache,37,"@TMiguelT I've moved the singularity cache section back down. Hopefully this is all the comments actioned. Sorry @vsoch, I realised I've been resolving your comments as I actioned them, but I probably should've left them open as they're from your review. Also sorry for what was probably a lot of email spam over the past few hours.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-465407558
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:499,Availability,error,error,499,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:189,Deployability,install,install-linux,189,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:351,Deployability,configurat,configuration,351,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:459,Deployability,install,install,459,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:853,Deployability,install,install,853,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:333,Integrability,message,message,333,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:686,Integrability,depend,dependency,686,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:225,Modifiability,config,configure,225,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:351,Modifiability,config,configuration,351,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:1235,Testability,test,testing,1235,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:786,Usability,guid,guides,786,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702:802,Usability,guid,guide,802,"Hey @TMiguelT @vsoch, we noticed that on a system without `mksquashfs` in its path, the `singularity exec` from Dockerhub fails. This seems to be backed up here: http://singularity.lbl.gov/install-linux. > Note that when you configure, squashfs-tools is not required, however it is required for full functionality. You will see this message after the configuration:; > `mksquashfs from squash-tools is required for full functionality`; > If you choose not to install squashfs-tools, you will hit an error when you try a pull from Docker Hub, for example. I get slightly conflicting information from the Singularity 3 docs which just says: ; > Note that squashfs-tools is an image build dependency only and is not required for Singularity build and run commands.; (https://www.sylabs.io/guides/3.0/user-guide/quick_start.html?highlight=squashfs). We did install `squashfs` and it's in our `$PATH`, but it seems Singularity is only looking at:; - `/bin/mksquashfs`; - `/usr/bin/mksquashfs`; - `/sbin/mksquashfs`; - `/usr/sbin/mksquashfs`; - `/usr/local/bin/mksquashfs`; - `/usr/local/sbin/mksquashfs`. Any thoughts here, as you are almost always required to pull from docker hub (it's kind of the default). ___. I also noticed with some testing that in the udocker submit, if you exclude the `--rm` it will run a bit quicker. @danbills, am I able to make changes since the review?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468087702
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468090428:80,Deployability,install,installed,80,@illusional I'm sure it's true that squashfs is a build requirement. The admins installed it on our cluster worker nodes for that reason. So yes we should probably mention that in the Singularity installation section. Is that what you're asking?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468090428
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468090428:196,Deployability,install,installation,196,@illusional I'm sure it's true that squashfs is a build requirement. The admins installed it on our cluster worker nodes for that reason. So yes we should probably mention that in the Singularity installation section. Is that what you're asking?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468090428
https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468378046:156,Safety,safe,safe,156,@illusional I think that as long as @vsoch and @TMiguelT are :+1: on the current state that we're good to go. I'll wait to hear from them just to be on the safe side.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-468378046
https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468419113:207,Performance,scalab,scalable,207,"To give some context, as we work on the NHGRI AnVIL, it is of interest to produce workflows that utilize the PanCancer atlas. The representation of the atlas in BigQuery is excellent for learning both about scalable solutions and about cancer biology. With Cromwell+R we can protect the investigators from working with SQL directly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468419113
https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468419113:187,Usability,learn,learning,187,"To give some context, as we work on the NHGRI AnVIL, it is of interest to produce workflows that utilize the PanCancer atlas. The representation of the atlas in BigQuery is excellent for learning both about scalable solutions and about cancer biology. With Cromwell+R we can protect the investigators from working with SQL directly.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468419113
https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468446743:931,Availability,error,error,931,"in my view it is really quite important. so the sooner the better. there's a ton of stuff to work on, so its absence isn't a dealbreaker but; having it and making it easy for anvil users to take advantage of it, will; really; help the project. On Thu, Feb 28, 2019 at 4:25 PM Jeff Gentry <notifications@github.com>; wrote:. > @vjcitn <https://github.com/vjcitn> For the context of AnVIL, what's the; > preferred timeline for this sort of functionality?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468444538>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEaOwjOad-k6dtLtSVihKWltyAqGrF_Jks5vSEligaJpZM4a39vl>; > .; >. -- ; The information in this e-mail is intended only for the person to whom it ; is; addressed. If you believe this e-mail was sent to you in error and the ; e-mail; contains patient information, please contact the Partners Compliance ; HelpLine at; http://www.partners.org/complianceline ; <http://www.partners.org/complianceline> . If the e-mail was sent to you in ; error; but does not contain patient information, please contact the sender ; and properly; dispose of the e-mail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468446743
https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468446743:1158,Availability,error,error,1158,"in my view it is really quite important. so the sooner the better. there's a ton of stuff to work on, so its absence isn't a dealbreaker but; having it and making it easy for anvil users to take advantage of it, will; really; help the project. On Thu, Feb 28, 2019 at 4:25 PM Jeff Gentry <notifications@github.com>; wrote:. > @vjcitn <https://github.com/vjcitn> For the context of AnVIL, what's the; > preferred timeline for this sort of functionality?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468444538>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEaOwjOad-k6dtLtSVihKWltyAqGrF_Jks5vSEligaJpZM4a39vl>; > .; >. -- ; The information in this e-mail is intended only for the person to whom it ; is; addressed. If you believe this e-mail was sent to you in error and the ; e-mail; contains patient information, please contact the Partners Compliance ; HelpLine at; http://www.partners.org/complianceline ; <http://www.partners.org/complianceline> . If the e-mail was sent to you in ; error; but does not contain patient information, please contact the sender ; and properly; dispose of the e-mail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4638#issuecomment-468446743
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:339,Availability,error,error,339,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:347,Availability,Error,Error,347,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:27,Energy Efficiency,reduce,reduce,27,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:63,Energy Efficiency,Green,Green,63,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:38,Integrability,depend,dependency,38,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541:481,Safety,Timeout,Timeout,481,"other benefit is that we'd reduce our dependency on dockerhub. Green team is seeing issues that look like they're throttling us, namely a bunch of these:. ```; Execution failed: pulling image: docker pull: generic::unknown: retry budget exhausted (10 attempts): ; running [""docker"" ""pull"" ""google/cloud-sdk:slim""]: exit status 1 (standard error: ""Error response from ; daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection ; (Client.Timeout exceeded while awaiting headers)\n"") at ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4640#issuecomment-463034541
https://github.com/broadinstitute/cromwell/pull/4645#issuecomment-467548069:34,Testability,log,logging,34,Have you considered `debug` level logging?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4645#issuecomment-467548069
https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-465282009:42,Testability,test,tests,42,- [X] ~Waiting behind #4666 for the SLURM tests~,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-465282009
https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470346112:67,Modifiability,extend,extending,67,"@aednichols I would like to point out that just because; > someone extending this trait has to explicitly consider whether a newly-added state is terminal or not. ... that doesn't mean they'll necessarily get it right... . cf [[1]](https://github.com/broadinstitute/cromwell/pull/4654/commits/ff6790e7242dfd1e25eea2568d3bc42b649714f7), [[2]](https://github.com/broadinstitute/cromwell/pull/4654/commits/accfb5bc5d144d61e79b0e6058f4efa144ff424f) 😳",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470346112
https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287:76,Deployability,update,updated,76,Chris and Adam;; Thanks so much for this fix. I really appreciate having an updated release with this working plus all the goodness since release 36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287
https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287:84,Deployability,release,release,84,Chris and Adam;; Thanks so much for this fix. I really appreciate having an updated release with this working plus all the goodness since release 36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287
https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287:138,Deployability,release,release,138,Chris and Adam;; Thanks so much for this fix. I really appreciate having an updated release with this working plus all the goodness since release 36.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654#issuecomment-470983287
https://github.com/broadinstitute/cromwell/issues/4659#issuecomment-512006346:106,Performance,perform,perform,106,"I am getting this bug in Cromwell 44. Could not evaluate expression: ""--mem-per-cpu="" + memory_mb: Cannot perform operation: --mem-per-cpu= + WomLong(1024)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659#issuecomment-512006346
https://github.com/broadinstitute/cromwell/issues/4659#issuecomment-1030686093:59,Modifiability,config,configure,59,"still persist in cromwell 75.; Also in my case I'd like to configure docker memory usage and docker reqiers suffix ""g"" or ""m"" after the number, so the @DavyCats trick does not work here",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659#issuecomment-1030686093
https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464247842:204,Security,validat,validated,204,"@aednichols you probably misunderstood my issue that you closed. It was not about having a mixed map, but about Cromwell coercing well defined the types to Map[String, Any] at runtime while everything is validated by both Cromwell and womtool at compiletime.; I opened another issue, where the same problem emerges with the struct, where Cromwell tries to consider struct output as Map[String, Any] at runtime. https://github.com/broadinstitute/cromwell/issues/4663",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464247842
https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464248756:18,Modifiability,enhance,enhancement,18,"@antonkulaga this enhancement is intended as a general improvement, not a fix for any particular issue. Rest assured we will get to the bottom of your struct issue!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4661#issuecomment-464248756
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-464251330:338,Availability,error,error,338,"In the documentations to struct the syntax that is mentioned is:; ```; Person a = {""name"": ""John"",""age"": 30}; ```; So I expect that ; ```; QuantifiedRun quantified_run = {""run"": srr, ""folder"": quant_folder, ""quant"": quant, ""lib"": quant_lib}; ```; should be treated in a similar way. If in a development version you changed the syntax the error should be thrown at compiletime and it should be explained in the documentation",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-464251330
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-464255682:94,Usability,simpl,simplier,94,@aednichols kind-of: I did not have permission to reopen #4555 and I also decided to create a simplier workflow that shows the problem,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-464255682
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093:531,Availability,error,error,531,"Hello, I am new to WDL and have met the same problem recently. I defined a `struct` like this:; ```; struct Fastp {; File reportHtml; File reportJson; Array[File]+ fqs; }; ```; and try to return it as the output in a `task`:; ```; output {; Fastp out = {; ""reportHtml"": ""QC/fastp.html"",; ""reportJson"": ""QC/fastp.json"",; ""fqs"": if flag then [""QC/clean_1.fq.gz"",""QC/clean_2.fq.gz""] else [""QC/clean_1.fq.gz""]; }; }; ```; `womtool validate` was applied to check the language specification and everything went fine, but finally got the error when trying to run my workflow using Cromwell. Here is part of the error report:; ```; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomAnyType) with mixed types in map values: [WomString(QC/fastp.html), WomString(QC/fastp.json), [""QC/clean_1.fq.gz"", ""QC/clean_2.fq.gz""]]; ``` ; Any solution to this problem now?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093:604,Availability,error,error,604,"Hello, I am new to WDL and have met the same problem recently. I defined a `struct` like this:; ```; struct Fastp {; File reportHtml; File reportJson; Array[File]+ fqs; }; ```; and try to return it as the output in a `task`:; ```; output {; Fastp out = {; ""reportHtml"": ""QC/fastp.html"",; ""reportJson"": ""QC/fastp.json"",; ""fqs"": if flag then [""QC/clean_1.fq.gz"",""QC/clean_2.fq.gz""] else [""QC/clean_1.fq.gz""]; }; }; ```; `womtool validate` was applied to check the language specification and everything went fine, but finally got the error when trying to run my workflow using Cromwell. Here is part of the error report:; ```; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomAnyType) with mixed types in map values: [WomString(QC/fastp.html), WomString(QC/fastp.json), [""QC/clean_1.fq.gz"", ""QC/clean_2.fq.gz""]]; ``` ; Any solution to this problem now?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093:427,Security,validat,validate,427,"Hello, I am new to WDL and have met the same problem recently. I defined a `struct` like this:; ```; struct Fastp {; File reportHtml; File reportJson; Array[File]+ fqs; }; ```; and try to return it as the output in a `task`:; ```; output {; Fastp out = {; ""reportHtml"": ""QC/fastp.html"",; ""reportJson"": ""QC/fastp.json"",; ""fqs"": if flag then [""QC/clean_1.fq.gz"",""QC/clean_2.fq.gz""] else [""QC/clean_1.fq.gz""]; }; }; ```; `womtool validate` was applied to check the language specification and everything went fine, but finally got the error when trying to run my workflow using Cromwell. Here is part of the error report:; ```; java.lang.UnsupportedOperationException: Cannot construct WomMapType(WomStringType,WomAnyType) with mixed types in map values: [WomString(QC/fastp.html), WomString(QC/fastp.json), [""QC/clean_1.fq.gz"", ""QC/clean_2.fq.gz""]]; ``` ; Any solution to this problem now?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-885644093
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:758,Availability,echo,echo,758,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:991,Availability,error,error,991,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:1292,Safety,Abort,Aborting,1292,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:1334,Safety,Abort,Aborting,1334,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:1382,Safety,Abort,Aborted,1382,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:101,Testability,Test,Test,101,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:144,Testability,Test,Test,144,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:216,Testability,test,teste,216,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:1022,Usability,simpl,simple,1022,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304:1209,Usability,simpl,simply,1209,"Still experiencing this problem. It seems we cannot use `Array[File]` inside `struct`s for now. . ```Test.wdl; version development; ​; workflow Test {; input {; String file_name = ""file.txt""; String file_contents = ""teste""; }; ​; call WriteFile {; input:; file_name=file_name,; file_contents=file_contents; }; ​; Array[File] array_file = [WriteFile.output_file, WriteFile.output_file]; ​; MultiTypeStruct test_struct = {; ""file_name"" : file_name,; ""file"" : WriteFile.output_file,; ""array_file"" : array_file; }; ​; output {; MultiTypeStruct multi_type_struct_test = test_struct; }; }; ​; struct MultiTypeStruct {; String file_name; File file; Array[File] array_file; }; ​; task WriteFile {; input {; String file_name; String file_contents; }; ​; command <<<; echo -e """"""~{file_contents}"""""" > ~{file_name}; >>>; ​; runtime {; docker: ""gcr.io/google.com/cloudsdktool/cloud-sdk:330.0.0-alpine""; preemptible: 3; }; ​; output {; File output_file = ""~{file_name}""; }; }. ```. You can easily see an error happening when running a simple workflow like this. As long as you have an `Array[File]` inside a `struct`, it will keep on failing. In my case, I'm using `version development`, and the last task on the workflow simply gets stuck with status `Running` while the workflow itself moves to status `Aborting` and stays stuck permanently in `Aborting` (never actually moving its status to `Aborted`). Experienced this issue with Cromwell versions 63 and 74, while using GCP lifescience v2 backend.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4663#issuecomment-1017704304
https://github.com/broadinstitute/cromwell/pull/4666#issuecomment-465282209:40,Testability,test,tests,40,Will unblock #4654 by providing it with tests!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4666#issuecomment-465282209
https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-464891063:237,Testability,test,test,237,"@antonkulaga Thanks, let me know. It occurred to me that `parentWorkflowId` might not show up in the subworkflow's metadata (as opposed to calling metadata directly on that subworkflow's workflow id). But I haven't been in a position to test it myself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-464891063
https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-467456003:181,Security,expose,expose,181,There's an intention to add parentWorkflowId (or rootWorkflowId) to the metadata summary table which should allow us to query for it faster. I don't see any reason we couldn't also expose it in the `/query` result set too,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4667#issuecomment-467456003
https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476:158,Deployability,release,release,158,"I included some changes in #4961 that might work for this enhancement request. The changes in that PR publish ""workflowProcessingEvents"" for workflow pickup, release, and completion. The first two events types can be multi-valued since Cromwell can be restarted and possibly upgraded during the execution of a workflow. Sample metadata from a simple run:. ```; {; ""workflowName"": ""wf_hello"",; ""workflowProcessingEvents"": [; {; ""cromwellId"": ""cromid-4db4123"",; ""timestamp"": ""2019-05-13T15:00:22.152Z"",; ""cromwellVersion"": ""41-07606c8-SNAP"",; ""description"": ""Finished""; },; {; ""cromwellId"": ""cromid-4db4123"",; ""description"": ""PickedUp"",; ""timestamp"": ""2019-05-13T15:00:10.879Z"",; ""cromwellVersion"": ""41-07606c8-SNAP""; }; ],; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476
https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476:275,Deployability,upgrade,upgraded,275,"I included some changes in #4961 that might work for this enhancement request. The changes in that PR publish ""workflowProcessingEvents"" for workflow pickup, release, and completion. The first two events types can be multi-valued since Cromwell can be restarted and possibly upgraded during the execution of a workflow. Sample metadata from a simple run:. ```; {; ""workflowName"": ""wf_hello"",; ""workflowProcessingEvents"": [; {; ""cromwellId"": ""cromid-4db4123"",; ""timestamp"": ""2019-05-13T15:00:22.152Z"",; ""cromwellVersion"": ""41-07606c8-SNAP"",; ""description"": ""Finished""; },; {; ""cromwellId"": ""cromid-4db4123"",; ""description"": ""PickedUp"",; ""timestamp"": ""2019-05-13T15:00:10.879Z"",; ""cromwellVersion"": ""41-07606c8-SNAP""; }; ],; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476
https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476:58,Modifiability,enhance,enhancement,58,"I included some changes in #4961 that might work for this enhancement request. The changes in that PR publish ""workflowProcessingEvents"" for workflow pickup, release, and completion. The first two events types can be multi-valued since Cromwell can be restarted and possibly upgraded during the execution of a workflow. Sample metadata from a simple run:. ```; {; ""workflowName"": ""wf_hello"",; ""workflowProcessingEvents"": [; {; ""cromwellId"": ""cromid-4db4123"",; ""timestamp"": ""2019-05-13T15:00:22.152Z"",; ""cromwellVersion"": ""41-07606c8-SNAP"",; ""description"": ""Finished""; },; {; ""cromwellId"": ""cromid-4db4123"",; ""description"": ""PickedUp"",; ""timestamp"": ""2019-05-13T15:00:10.879Z"",; ""cromwellVersion"": ""41-07606c8-SNAP""; }; ],; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476
https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476:343,Usability,simpl,simple,343,"I included some changes in #4961 that might work for this enhancement request. The changes in that PR publish ""workflowProcessingEvents"" for workflow pickup, release, and completion. The first two events types can be multi-valued since Cromwell can be restarted and possibly upgraded during the execution of a workflow. Sample metadata from a simple run:. ```; {; ""workflowName"": ""wf_hello"",; ""workflowProcessingEvents"": [; {; ""cromwellId"": ""cromid-4db4123"",; ""timestamp"": ""2019-05-13T15:00:22.152Z"",; ""cromwellVersion"": ""41-07606c8-SNAP"",; ""description"": ""Finished""; },; {; ""cromwellId"": ""cromid-4db4123"",; ""description"": ""PickedUp"",; ""timestamp"": ""2019-05-13T15:00:10.879Z"",; ""cromwellVersion"": ""41-07606c8-SNAP""; }; ],; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4668#issuecomment-491862476
https://github.com/broadinstitute/cromwell/issues/4670#issuecomment-493539374:81,Deployability,release,releases,81,"I haven't run the workflow manually, but I don't see any commits in the last few releases which would have helped this. I think we should mark this as a bug (even if the ""fix"" just ends up being a test case to prove that it's fixed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4670#issuecomment-493539374
https://github.com/broadinstitute/cromwell/issues/4670#issuecomment-493539374:197,Testability,test,test,197,"I haven't run the workflow manually, but I don't see any commits in the last few releases which would have helped this. I think we should mark this as a bug (even if the ""fix"" just ends up being a test case to prove that it's fixed)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4670#issuecomment-493539374
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:472,Deployability,pipeline,pipelines,472,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:493,Deployability,Pipeline,PipelinesApiRequestManager,493,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:540,Deployability,Pipeline,PipelinesApiRequestHandler,540,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:1095,Deployability,pipeline,pipelines,1095,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:1116,Deployability,Pipeline,PipelinesApiRequestManager,1116,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:1163,Deployability,Pipeline,PipelinesApiRequestHandler,1163,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:29,Integrability,message,message,29,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:295,Safety,abort,abort,295,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:918,Safety,abort,abort,918,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:25,Testability,log,log,25,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:69,Testability,Test,TestJesApiQueryManager-,69,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:159,Testability,Test,TestJesApiQueryManager-,159,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:622,Testability,Test,TestJesApiQueryManager-,622,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:782,Testability,Test,TestJesApiQueryManager-,782,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147:1245,Testability,Test,TestJesApiQueryManager-,1245,"Sample of a possible new log message thread:; ```; [INFO] [...] [.../TestJesApiQueryManager-1262117937] Running with 1 PAPI request workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller1 has been removed and replaced by statusPoller2 in the pool of 1 workers; [WARN] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 terminated. 0 run creation requests, 5 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice. Exception details: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$$anonfun$1$$anon$1: PipelinesApiRequestHandler actor termination caught by manager; [INFO] [...] [.../TestJesApiQueryManager-1262117937] PAPI request worker statusPoller2 has been removed and replaced by statusPoller3 in the pool of 1 workers. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-479685147
https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-480294525:62,Availability,error,error,62,@mcovarr well the title of the pr **does** mention programmer error 😛,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4671#issuecomment-480294525
https://github.com/broadinstitute/cromwell/issues/4673#issuecomment-465849356:150,Security,hash,hash,150,"That's what I was thinking, yes. But that's a bit tricky because bash scripts don't really ""return"" anything. Perhaps each unique image (based on the hash) could be assigned its own directory within Cromwell, and that directory is set as the working directory for both `pull-docker` and `submit-docker`. Then, you can build the image into the CWD in `pull-docker`, and run it in `submit-docker` by just globbing for a `.sif` file (or whatever format it is)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4673#issuecomment-465849356
https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-468888510:24,Testability,log,logs,24,"@TMiguelT - Thanks! The logs should help me debug what's going here. I've seen this intermittently in the past, but it was difficult to catch.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-468888510
https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-470335668:50,Deployability,update,update,50,@TMiguelT - This should be resolved in the latest update to the CloudFormation templates at:; https://docs.opendata.aws/genomics-workflows. The use of a Custom AMI is now deprecated in favor of EC2 Launch Templates.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-470335668
https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-489183672:13,Availability,error,error,13,Got the same error in https://github.com/aws-samples/aws-refarch-wordpress,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-489183672
https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-506369596:88,Availability,error,error,88,@wleepang Could you share what change you made to fix the problem? I'm getting the same error on my own CloudFormation template.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4674#issuecomment-506369596
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466543684:31,Integrability,message,message,31,36. I also edited the original message,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466543684
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:92,Deployability,Pipeline,Pipelines,92,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:323,Deployability,release,released,323,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:453,Deployability,configurat,configuration,453,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:150,Integrability,depend,depending,150,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:433,Modifiability,config,configurable,433,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513:453,Modifiability,config,configuration,453,"Got it. . So in 36 you're a bit stuck in that it's hardcoded into the `v2alpha1` version of Pipelines API. You could use the `v1alpha2` PAPI backend, depending on if you're using PAPIv2 for a specific reason or just because it's newer (side note: Google would really prefer people to be using `v2alpha1`). As of 36.1 (just released today) that docker image is only pulled when running CWL (unclear if you're using CWL or WDL) and is configurable in the configuration file via `CWL.versions.VERSION.output-runtime-extractor.docker-image`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466545513
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466548089:86,Deployability,upgrade,upgrade,86,"I am using v2alpha1, and WDL. If I understand you correctly, does that mean that if I upgrade to 36.1, it should stop adding that action to the pipelines request?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466548089
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466548089:144,Deployability,pipeline,pipelines,144,"I am using v2alpha1, and WDL. If I understand you correctly, does that mean that if I upgrade to 36.1, it should stop adding that action to the pipelines request?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-466548089
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:48,Availability,error,error,48,"I did that and began encountering the following error:; ```; 2019-02-25 18:17:52,693 cromwell-system-akka.actor.default-dispatcher-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorF",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:134,Availability,ERROR,ERROR,134,"I did that and began encountering the following error:; ```; 2019-02-25 18:17:52,693 cromwell-system-akka.actor.default-dispatcher-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorF",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:2431,Availability,error,error,2431,".impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-3 ERROR - Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:2517,Availability,ERROR,ERROR,2517,"eConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-3 ERROR - Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused b",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:145,Deployability,configurat,configuration,145,"I did that and began encountering the following error:; ```; 2019-02-25 18:17:52,693 cromwell-system-akka.actor.default-dispatcher-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorF",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1114,Deployability,configurat,configuration,1114,er-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:145,Modifiability,config,configuration,145,"I did that and began encountering the following error:; ```; 2019-02-25 18:17:52,693 cromwell-system-akka.actor.default-dispatcher-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorF",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1079,Modifiability,config,config,1079,93 cromwell-system-akka.actor.default-dispatcher-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newA,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1086,Modifiability,Config,ConfigException,1086,er-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1114,Modifiability,config,configuration,1114,er-29 ERROR - No configuration setting found for key 'services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCe,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1179,Modifiability,config,config,1179,services'; akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorC,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1259,Modifiability,config,config,1259,cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried addi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1336,Modifiability,config,config,1336,tor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1407,Modifiability,config,config,1407,"r.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I r",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1478,Modifiability,config,config,1478,"eAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-syst",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1554,Modifiability,config,config,1554,".scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-3 ERROR - Class cromwell.services.womtool.i",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:5144,Performance,load,loadClass,5144, by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:51); 	... 24 common frames omitted; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:5214,Performance,load,loadClass,5214, by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:51); 	... 24 common frames omitted; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:5270,Performance,load,loadClass,5270, by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:264); 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:51); 	... 24 common frames omitted; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:3981,Security,Hash,HashMap,3981,.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4006,Security,Hash,HashMap,4006,orCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.servi,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4057,Security,Hash,HashMap,4057,Messages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4065,Security,Hash,HashTrieMap,4065,Messages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:4085,Security,Hash,HashMap,4085,cala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.RuntimeException: Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor for service Womtool cannot be found in the class path.; 	at cromwell.services.ServiceRegistryActor$.serviceProps(ServiceRegistryActor.scala:54); 	at cromwell.services.ServiceRegistryActor$.$anonfun$serviceNameToPropsMap$2(ServiceRegistryActor.scala:37); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); 	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:231); 	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:462); 	at scala.collection.TraversableLike.map(TraversableLike.scala:234); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:227); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:36); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; Caused by: java.lang.ClassNotFoundException: cromwell.services.womtool.impl.WomtoolServiceInCromwellActor; 	at java.net.URLClassLoader.fin,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1191,Usability,Simpl,SimpleConfig,1191,.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(Acto,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1218,Usability,Simpl,SimpleConfig,1218,zationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1271,Usability,Simpl,SimpleConfig,1271,e/ServiceRegistryActor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [referen,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1295,Usability,Simpl,SimpleConfig,1295,tor: exception during creation; 	at akka.actor.ActorInitializationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block],MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1348,Usability,Simpl,SimpleConfig,1348,lizationException$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/co,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1366,Usability,Simpl,SimpleConfig,1366,n$.apply(Actor.scala:193); 	at akka.actor.ActorCell.create(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/res,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1419,Usability,Simpl,SimpleConfig,1419,"ate(ActorCell.scala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet ano",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1437,Usability,Simpl,SimpleConfig,1437,"ala:669); 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . `",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1490,Usability,Simpl,SimpleConfig,1490,"l.scala:523); 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1513,Usability,Simpl,SimpleConfig,1513,"akka.actor.ActorCell.systemInvoke(ActorCell.scala:545); 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1566,Usability,Simpl,SimpleConfig,1566,"t akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-3 ERROR - Class cromwell.services.womtool.impl.WomtoolServ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881:1589,Usability,Simpl,SimpleConfig,1589,"ilbox.processAllSystemMessages(Mailbox.scala:283); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services'; 	at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156); 	at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188); 	at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268); 	at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41); 	at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35); 	at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63); 	at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65); 	at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25); 	at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87); 	at akka.actor.Props.newActor(Props.scala:212); 	at akka.actor.ActorCell.newActor(ActorCell.scala:624); 	at akka.actor.ActorCell.create(ActorCell.scala:650); 	... 9 common frames omitted; ```. I tried adding the [reference services block](https://github.com/broadinstitute/cromwell/blob/develop/core/src/main/resources/reference.conf#L480), but then I received yet another error: . ```; 2019-02-25 18:46:46,698 cromwell-system-akka.actor.default-dispatcher-3 ERROR - Class cromwell.services.womtool.impl.WomtoolServiceInCromwellActor",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467132881
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:103,Availability,error,error,103,"Additionally, in both the above trials, Cromwell still managed to start, but failed with the following error when starting a submission:. ```; 2019-02-25 18:47:23,071 cromwell-system-akka.actor.default-dispatcher-33 ERROR - Error during processing of request: 'Unknown factory null'. Completing with 500 Internal Server Error response. To change default exception handling behavior, provide a custom ExceptionHandler.; java.lang.IllegalStateException: Unknown factory null; 	at akka.http.impl.util.package$.actorSystem(package.scala:34); 	at akka.http.scaladsl.settings.SettingsCompanion.default(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.SettingsCompanion.default$(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scal",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:216,Availability,ERROR,ERROR,216,"Additionally, in both the above trials, Cromwell still managed to start, but failed with the following error when starting a submission:. ```; 2019-02-25 18:47:23,071 cromwell-system-akka.actor.default-dispatcher-33 ERROR - Error during processing of request: 'Unknown factory null'. Completing with 500 Internal Server Error response. To change default exception handling behavior, provide a custom ExceptionHandler.; java.lang.IllegalStateException: Unknown factory null; 	at akka.http.impl.util.package$.actorSystem(package.scala:34); 	at akka.http.scaladsl.settings.SettingsCompanion.default(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.SettingsCompanion.default$(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scal",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:224,Availability,Error,Error,224,"Additionally, in both the above trials, Cromwell still managed to start, but failed with the following error when starting a submission:. ```; 2019-02-25 18:47:23,071 cromwell-system-akka.actor.default-dispatcher-33 ERROR - Error during processing of request: 'Unknown factory null'. Completing with 500 Internal Server Error response. To change default exception handling behavior, provide a custom ExceptionHandler.; java.lang.IllegalStateException: Unknown factory null; 	at akka.http.impl.util.package$.actorSystem(package.scala:34); 	at akka.http.scaladsl.settings.SettingsCompanion.default(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.SettingsCompanion.default$(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scal",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:320,Availability,Error,Error,320,"Additionally, in both the above trials, Cromwell still managed to start, but failed with the following error when starting a submission:. ```; 2019-02-25 18:47:23,071 cromwell-system-akka.actor.default-dispatcher-33 ERROR - Error during processing of request: 'Unknown factory null'. Completing with 500 Internal Server Error response. To change default exception handling behavior, provide a custom ExceptionHandler.; java.lang.IllegalStateException: Unknown factory null; 	at akka.http.impl.util.package$.actorSystem(package.scala:34); 	at akka.http.scaladsl.settings.SettingsCompanion.default(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.SettingsCompanion.default$(SettingsCompanion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scal",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:1671,Integrability,Rout,RouteConcatenation,1671,Companion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anon,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:1690,Integrability,Rout,RouteWithConcatenation,1690,Companion.scala:20); 	at akka.http.scaladsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anon,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:1731,Integrability,Rout,RouteConcatenation,1731,adsl.settings.ParserSettings$.default(ParserSettings.scala:119); 	at cromwell.webservice.CromwellApiService.$anonfun$workflowRoutes$68(CromwellApiService.scala:233); 	at akka.http.scaladsl.server.Directive$.$anonfun$addByNameNullaryApply$2(Directive.scala:134); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2038,Integrability,Rout,RouteConcatenation,2038,mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenati,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2057,Integrability,Rout,RouteWithConcatenation,2057,mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenati,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2098,Integrability,Rout,RouteConcatenation,2098,66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.uti,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2158,Integrability,Rout,RouteConcatenation,2158,(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.uti,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2177,Integrability,Rout,RouteWithConcatenation,2177,(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.uti,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2218,Integrability,Rout,RouteConcatenation,2218,ttp.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResult$2(BasicDirectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(F,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2278,Integrability,Rout,RouteConcatenation,2278,ectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(F,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2297,Integrability,Rout,RouteWithConcatenation,2297,ectives.scala:66); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(F,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2338,Integrability,Rout,RouteConcatenation,2338,sl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scala,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2645,Integrability,Rout,RouteConcatenation,2645,rver.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.sca,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2664,Integrability,Rout,RouteWithConcatenation,2664,rver.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.sca,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2705,Integrability,Rout,RouteConcatenation,2705,enation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.di,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:2983,Integrability,Rout,RouteConcatenation,2983,6); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3002,Integrability,Rout,RouteWithConcatenation,3002,6); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); ,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3043,Integrability,Rout,RouteConcatenation,3043,Concatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$an,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3350,Integrability,Rout,RouteConcatenation,3350, akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpret,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3369,Integrability,Rout,RouteWithConcatenation,3369, akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpret,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3410,Integrability,Rout,RouteConcatenation,3410,rictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3470,Integrability,Rout,RouteConcatenation,3470,nsformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588); 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3489,Integrability,Rout,RouteWithConcatenation,3489,nsformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588); 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:3530,Integrability,Rout,RouteConcatenation,3530,45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRequestContext$2(BasicDirectives.scala:43); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588); 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:472); 	at ak,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:4034,Integrability,Rout,Route,4034,lde$2(RouteConcatenation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588); 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:472); 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:563); 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:745); 	at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:760); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at akka.stream.impl.fusing.ActorGraphInterpreter.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187:4065,Integrability,Rout,Route,4065,ation.scala:47); 	at akka.http.scaladsl.util.FastFuture$.strictTransform$1(FastFuture.scala:41); 	at akka.http.scaladsl.util.FastFuture$.transformWith$extension1(FastFuture.scala:45); 	at akka.http.scaladsl.util.FastFuture$.flatMap$extension(FastFuture.scala:26); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.RouteConcatenation$RouteWithConcatenation.$anonfun$$tilde$1(RouteConcatenation.scala:44); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$mapRouteResultWith$2(BasicDirectives.scala:72); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.directives.ExecutionDirectives.$anonfun$handleExceptions$2(ExecutionDirectives.scala:32); 	at akka.http.scaladsl.server.directives.BasicDirectives.$anonfun$textract$2(BasicDirectives.scala:159); 	at akka.http.scaladsl.server.Route$.$anonfun$asyncHandler$1(Route.scala:86); 	at akka.stream.impl.fusing.MapAsyncUnordered$$anon$26.onPush(Ops.scala:1303); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:519); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:411); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:588); 	at akka.stream.impl.fusing.GraphInterpreterShell$AsyncInput.execute(ActorGraphInterpreter.scala:472); 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:563); 	at akka.stream.impl.fusing.ActorGraphInterpreter.akka$stream$impl$fusing$ActorGraphInterpreter$$processEvent(ActorGraphInterpreter.scala:745); 	at akka.stream.impl.fusing.ActorGraphInterpreter$$anonfun$receive$1.applyOrElse(ActorGraphInterpreter.scala:760); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at akka.stream.impl.fusing.ActorGraphInterpreter.aroundReceive(Acto,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676#issuecomment-467133187
https://github.com/broadinstitute/cromwell/issues/4678#issuecomment-466792777:131,Availability,ping,pinging,131,"Hi - yes, I can confirm this. Cromwell has had WDL 1.0 support for not quite a year now. You're right that this should be updated (pinging @cjllanwarne )",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4678#issuecomment-466792777
https://github.com/broadinstitute/cromwell/issues/4678#issuecomment-466792777:122,Deployability,update,updated,122,"Hi - yes, I can confirm this. Cromwell has had WDL 1.0 support for not quite a year now. You're right that this should be updated (pinging @cjllanwarne )",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4678#issuecomment-466792777
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467576363:71,Deployability,Release,Releases,71,"Hi @zfrenchee, you can find the docker images for Cromwell 36.1 in our Releases tab [here](https://github.com/broadinstitute/cromwell/releases/tag/36.1). Is this the information you were looking for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467576363
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467576363:134,Deployability,release,releases,134,"Hi @zfrenchee, you can find the docker images for Cromwell 36.1 in our Releases tab [here](https://github.com/broadinstitute/cromwell/releases/tag/36.1). Is this the information you were looking for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467576363
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467577218:209,Modifiability,config,configure,209,"@salonishah11 Thanks for pointing me towards the docker containers, sorry I was unclear earlier. I'm looking for documentation on how to _run_ the docker containers -- any `docker -v` / `-e` / `-p` options to configure it. This topic warrants a page in the [docs](https://cromwell.readthedocs.io/en/stable/), I think, don't you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-467577218
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124:245,Availability,Error,Error,245,"@salonishah11 for example, I'm running a cromwell container in server mode, bound to port 8000: ; ```; docker run -p 8000:8000 cromwell server; ```; but when I try to ; ```; docker run cromwell submit --host 0.0.0.0:8000 ...; ```; I get: ; ```; Error: Option --host failed when given '0.0.0.0:8000'. no protocol: 0.0.0.0:8000; ```. Some simple docs would help here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124:303,Integrability,protocol,protocol,303,"@salonishah11 for example, I'm running a cromwell container in server mode, bound to port 8000: ; ```; docker run -p 8000:8000 cromwell server; ```; but when I try to ; ```; docker run cromwell submit --host 0.0.0.0:8000 ...; ```; I get: ; ```; Error: Option --host failed when given '0.0.0.0:8000'. no protocol: 0.0.0.0:8000; ```. Some simple docs would help here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124
https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124:337,Usability,simpl,simple,337,"@salonishah11 for example, I'm running a cromwell container in server mode, bound to port 8000: ; ```; docker run -p 8000:8000 cromwell server; ```; but when I try to ; ```; docker run cromwell submit --host 0.0.0.0:8000 ...; ```; I get: ; ```; Error: Option --host failed when given '0.0.0.0:8000'. no protocol: 0.0.0.0:8000; ```. Some simple docs would help here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4682#issuecomment-471224124
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:58,Availability,error,error,58,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:141,Availability,ping,ping,141,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:576,Deployability,configurat,configuration,576,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:64,Integrability,message,message,64,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:576,Modifiability,config,configuration,576,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411:37,Performance,response time,response time,37,"Hey @Xophmeister, sorry for the slow response time!. This error message is actually coming from our SFS (shared filesystem) backend (so I'll ping @kshakir). I'm not familiar with the `mounts` attribute in the SFS. However, I think the answer to your question is that none of the attributes asked for by the SFS backend are arrays, and so arrays are not a supported attribute type. . I actually could only find reference to the `mounts` attribute outside of the SFS backend in places like BCS and Google cloud. I wonder whether you just need to move this attribute out of your configuration file and into your WDL task itself?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685#issuecomment-481024411
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328:375,Availability,echo,echo,375,"Here is the wdl file used for the test:. ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous_task_out = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous_task_out = print_nach_nachman.out; }. output{; File out = print_nach_nachman_meuman.out; }; }. task print_nach{. String output_file = ""task1.out""; command{; echo ""nach"" > ${output_file}; }; output{; File out = output_file; }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""task2.out""; command{; echo ${sep=' ' previous_content} "" nachman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""three_task_sequence.out""; command{; echo ${sep=' ' previous_content} "" meuman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328:663,Availability,echo,echo,663,"Here is the wdl file used for the test:. ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous_task_out = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous_task_out = print_nach_nachman.out; }. output{; File out = print_nach_nachman_meuman.out; }; }. task print_nach{. String output_file = ""task1.out""; command{; echo ""nach"" > ${output_file}; }; output{; File out = output_file; }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""task2.out""; command{; echo ${sep=' ' previous_content} "" nachman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""three_task_sequence.out""; command{; echo ${sep=' ' previous_content} "" meuman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328:1002,Availability,echo,echo,1002,"Here is the wdl file used for the test:. ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous_task_out = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous_task_out = print_nach_nachman.out; }. output{; File out = print_nach_nachman_meuman.out; }; }. task print_nach{. String output_file = ""task1.out""; command{; echo ""nach"" > ${output_file}; }; output{; File out = output_file; }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""task2.out""; command{; echo ${sep=' ' previous_content} "" nachman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""three_task_sequence.out""; command{; echo ${sep=' ' previous_content} "" meuman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328:34,Testability,test,test,34,"Here is the wdl file used for the test:. ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous_task_out = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous_task_out = print_nach_nachman.out; }. output{; File out = print_nach_nachman_meuman.out; }; }. task print_nach{. String output_file = ""task1.out""; command{; echo ""nach"" > ${output_file}; }; output{; File out = output_file; }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""task2.out""; command{; echo ${sep=' ' previous_content} "" nachman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; File previous_task_out; Array[String] previous_content = read_lines(previous_task_out); String output_file = ""three_task_sequence.out""; command{; echo ${sep=' ' previous_content} "" meuman"" > ${output_file}; }; output{; File out = output_file; }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-468214328
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-484561317:40,Modifiability,config,config,40,"Hi @doron-st Can you post your Cromwell config & how you set up your batch environment, e.g. via the cloud formation launch templates?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-484561317
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-499598950:112,Modifiability,config,config,112,I'm having the same issue. I've used the CloudFormation template as is. Didn't make any changes in the Cromwell config.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-499598950
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500068947:214,Security,access,access,214,"This line in the stack trace indicates the root cause:. ```; at software.amazon.awssdk.services.s3.S3Client.listBuckets(S3Client.java:2184); ```. The permissions for the Cromwell server currently only provide full access to the S3 bucket specified in the CloudFormation template. Adding the `AmazonS3ReadOnlyAccess` managed policy to the server's instance profile fixes this, but I wonder if it can be more refined. Specifically, is there a case where a Cromwell server would need to read from more than one bucket?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500068947
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500810085:475,Security,access,access,475,"Yes there are! Like if your inputs are shared with other users and they; come from varying sources and you're not allowed to make copies. Something; like that is very common. On Fri, Jun 7, 2019 at 7:25 PM W. Lee Pang, PhD <notifications@github.com>; wrote:. > This line in the stack trace indicates the root cause:; >; > at software.amazon.awssdk.services.s3.S3Client.listBuckets(S3Client.java:2184); >; > The permissions for the Cromwell server currently only provide full access; > to the S3 bucket specified in the CloudFormation template. Adding the; > AmazonS3ReadOnlyAccess managed policy to the server's instance profile; > fixes this, but I wonder if it can be more refined. Specifically, is there; > a case where a Cromwell server would need to read from more than one bucket?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4686?email_source=notifications&email_token=ADR7XTOW5ARNYDZTLRZEEODPZLU6RA5CNFSM4G2ZBAQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXHHEUY#issuecomment-500068947>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ADR7XTOOSUHDDDUED4MXDEDPZLU6RANCNFSM4G2ZBAQQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-500810085
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084:128,Security,access,access,128,"Probably worth distinguishing the difference between the server instance and individual job instances. Each can get independent access permissions. I can see the need for job instances to be able to read from various input sources, including those not owned by the account. Does the server, i.e. the Cromwell process, need to read data across accounts as well? I was under the impression that it only needed to track status and logs for workflows and jobs submitted to it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084:428,Testability,log,logs,428,"Probably worth distinguishing the difference between the server instance and individual job instances. Each can get independent access permissions. I can see the need for job instances to be able to read from various input sources, including those not owned by the account. Does the server, i.e. the Cromwell process, need to read data across accounts as well? I was under the impression that it only needed to track status and logs for workflows and jobs submitted to it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-501247084
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-601996944:84,Deployability,release,released,84,Has anyone found a solution to this? I've experienced this issue since Cromwell was released for AWS and haven't found a good solution other than transferring all input files and references into the specific Cromwell S3 execution bucket.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-601996944
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-602899024:78,Security,access,access,78,The role granted to the EC2 that runs the Cromwell server would need to grant access to the bucket that you have specified in the outputs.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-602899024
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:396,Integrability,depend,depends,396,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:55,Security,access,access,55,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:177,Security,access,access,177,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:290,Security,access,access,290,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:652,Security,access,access,652,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894:124,Testability,test,test-data,124,"By default, the CloudFormation template will only give access to the bucket you specified at creation time as well as `gatk-test-data/*` and `broad-references/*`. To be able to access data in additional buckets you would need to grant `s3.*` to these resources through a policy that grants access to the bucket that you attach to `Cromwell-ServerStac-Ec2InstanceRole` (The exact name of the role depends on the name you gave the stack and some random characters cloud formation adds to prevent name collisions). In addition you need to add the same (or equivalent) policy to `GenomicsW-GenomicsEnvBatchInstance` role. This grants the batch worker EC2s access to the bucket. The policy would look something like:; ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:*""; ],; ""Resource"": [; ""arn:aws:s3:::my-bucket-name"",; ""arn:aws:s3:::my-bucket-name/*""; ],; ""Effect"": ""Allow"",; ""Sid"": ""S3BucketAllowAllObjectOps""; }; ]; }; ```. In the `GenomicsEnvBatchJobRole` you would also need to attach a more restricted policy similar to:. ```json; {; ""Version"": ""2012-10-17"",; ""Statement"": [; {; ""Action"": [; ""s3:Delete*"",; ""s3:PutBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Deny""; },; {; ""Action"": [; ""s3:ListBucket*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name"",; ""Effect"": ""Allow""; },; {; ""Action"": [; ""s3:*""; ],; ""Resource"": ""arn:aws:s3:::my-bucket-name/*"",; ""Effect"": ""Allow""; }; ]; } ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686#issuecomment-611697894
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514934007:54,Availability,error,error,54,"Hey, did you ever manage to get a workaround for this error?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514934007
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738:29,Deployability,deploy,deployment,29,"@geoffjentry yes. My current deployment is v42. If you have access to the GATK forums, i put more details in my post there: https://gatkforums.broadinstitute.org/wdl/discussion/24268/aws-batch-randomly-fails-when-running-multiple-workflows/p1?new=1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738:60,Security,access,access,60,"@geoffjentry yes. My current deployment is v42. If you have access to the GATK forums, i put more details in my post there: https://gatkforums.broadinstitute.org/wdl/discussion/24268/aws-batch-randomly-fails-when-running-multiple-workflows/p1?new=1",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-514937738
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-517178996:23,Availability,error,error,23,One up. I have similar error,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-517178996
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-522343642:29,Testability,log,logs,29,"@geoffjentry from inspecting logs and AWS Batch console, i think what is happening is that the jobs fail because Cromwell shutdowns the VMs earlier than expected. So one of shard hasn't finished and is unable to upload to S3, hence the problem here occurs. Anyways this is a hypothesis based on what I saw, hopefully is helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-522343642
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-582136461:74,Energy Efficiency,energy,energy,74,@alexwaldrop NB that I don't work there anymore and sadly haven't had the energy to actively contribute. Perhaps @aednichols can chime in,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-582136461
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:21,Availability,error,error,21,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:276,Availability,failure,failure,276,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:305,Availability,error,error,305,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:311,Integrability,message,message,311,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:373,Security,access,access,373,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:391,Testability,log,logged,391,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610:562,Testability,log,log,562,"I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-597868610
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:23,Availability,error,error,23,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:278,Availability,failure,failure,278,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:307,Availability,error,error,307,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:313,Integrability,message,message,313,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:375,Security,access,access,375,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:393,Testability,log,logged,393,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275:564,Testability,log,log,564,"> I am having the same error with the example ""Using Data on S3"" on https://docs.opendata.aws/genomics-workflows/orchestration/cromwell/cromwell-examples/ . I have changed the S3 bucket name in the .json file to my bucket name, but the run still failed. After reporting running failure, I have got the same error message. I am using cromwell-48. The S3 bucket has all public access, and I was logged in as the Admin in two terminal windows, one running the server and the other submitting the job. The previous two hello-world example were successful. There is no log file in the bucket and in the cromwell-execution, the only file create was the script. There is no rc or stderr or stdout created. @blindmouse Were you able to resolve your issue? I am encountering the same problem. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662080275
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662153411:121,Testability,log,log,121,"This can happen if the job fails meaning that an rc.txt file isn’t created.; It would be worth looking at the CloudWatch log for the batch job. On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu <notifications@github.com>; wrote:. > Is there any progress on this issue? I am the getting the following; > exception: IOException: Could not read from; > s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > Caused by: java.nio.file.NoSuchFileException: s3://; > s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662153411
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952:965,Integrability,message,message,965,"> This can happen if the job fails meaning that an rc.txt file isn’t created. It would be worth looking at the CloudWatch log for the batch job.; > […](#); > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu ***@***.***> wrote: Is there any progress on this issue? I am the getting the following exception: IOException: Could not read from s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt Caused by: java.nio.file.NoSuchFileException: s3:// s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <[#4687 (comment)](https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ> . Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952:122,Testability,log,log,122,"> This can happen if the job fails meaning that an rc.txt file isn’t created. It would be worth looking at the CloudWatch log for the batch job.; > […](#); > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu ***@***.***> wrote: Is there any progress on this issue? I am the getting the following exception: IOException: Could not read from s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt Caused by: java.nio.file.NoSuchFileException: s3:// s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <[#4687 (comment)](https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ> . Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952:936,Testability,log,logs,936,"> This can happen if the job fails meaning that an rc.txt file isn’t created. It would be worth looking at the CloudWatch log for the batch job.; > […](#); > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu ***@***.***> wrote: Is there any progress on this issue? I am the getting the following exception: IOException: Could not read from s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt Caused by: java.nio.file.NoSuchFileException: s3:// s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <[#4687 (comment)](https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ> . Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468:1326,Integrability,message,message,1326,"It may be that you’re running Cromwell 52 or later with an older AWS; CloudFormation built infrastructure. Can you share which build of Cromwell; you’re using and the build/ version/ origin of the CloudFormation template?. On Tue, Jul 21, 2020 at 8:18 PM Sri Paladugu <notifications@github.com>; wrote:. > This can happen if the job fails meaning that an rc.txt file isn’t; > created. It would be worth looking at the CloudWatch log for the batch job.; > … <#m_-7712250081708699723_>; > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu *@*.***> wrote: Is there any; > progress on this issue? I am the getting the following exception:; > IOException: Could not read from; > s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > Caused by: java.nio.file.NoSuchFileException: s3://; > s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > — You are receiving this because you are subscribed to this thread. Reply; > to this email directly, view it on GitHub <#4687 (comment); > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379>>,; > or unsubscribe; > https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ; > .; >; > Cloudwatch logs contained the following message: ""/bin/bash:; > /var/scratch/fetch_and_run.sh: Is a directory""; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6ENOHHXQP6VC5XUGZ5TR4YV5XANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468:429,Testability,log,log,429,"It may be that you’re running Cromwell 52 or later with an older AWS; CloudFormation built infrastructure. Can you share which build of Cromwell; you’re using and the build/ version/ origin of the CloudFormation template?. On Tue, Jul 21, 2020 at 8:18 PM Sri Paladugu <notifications@github.com>; wrote:. > This can happen if the job fails meaning that an rc.txt file isn’t; > created. It would be worth looking at the CloudWatch log for the batch job.; > … <#m_-7712250081708699723_>; > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu *@*.***> wrote: Is there any; > progress on this issue? I am the getting the following exception:; > IOException: Could not read from; > s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > Caused by: java.nio.file.NoSuchFileException: s3://; > s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > — You are receiving this because you are subscribed to this thread. Reply; > to this email directly, view it on GitHub <#4687 (comment); > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379>>,; > or unsubscribe; > https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ; > .; >; > Cloudwatch logs contained the following message: ""/bin/bash:; > /var/scratch/fetch_and_run.sh: Is a directory""; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6ENOHHXQP6VC5XUGZ5TR4YV5XANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468:1297,Testability,log,logs,1297,"It may be that you’re running Cromwell 52 or later with an older AWS; CloudFormation built infrastructure. Can you share which build of Cromwell; you’re using and the build/ version/ origin of the CloudFormation template?. On Tue, Jul 21, 2020 at 8:18 PM Sri Paladugu <notifications@github.com>; wrote:. > This can happen if the job fails meaning that an rc.txt file isn’t; > created. It would be worth looking at the CloudWatch log for the batch job.; > … <#m_-7712250081708699723_>; > On Tue, Jul 21, 2020 at 4:07 PM Sri Paladugu *@*.***> wrote: Is there any; > progress on this issue? I am the getting the following exception:; > IOException: Could not read from; > s3:///results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > Caused by: java.nio.file.NoSuchFileException: s3://; > s3.amazonaws.com/s3bucketname/results/ReadFile/5fec5c4a-2e3f-49ed-8f9e-6d9d2d759449/call-read_file/read_file-rc.txt; > — You are receiving this because you are subscribed to this thread. Reply; > to this email directly, view it on GitHub <#4687 (comment); > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662079379>>,; > or unsubscribe; > https://github.com/notifications/unsubscribe-auth/AF2E6EMJZ66Z5PIAEUX3IBLR4XYPZANCNFSM4G23FFUQ; > .; >; > Cloudwatch logs contained the following message: ""/bin/bash:; > /var/scratch/fetch_and_run.sh: Is a directory""; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-662170952>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6ENOHHXQP6VC5XUGZ5TR4YV5XANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-670978468
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-689558662:46,Availability,error,error,46,Hi @markjschreiber I'm also running into this error. I am using cromwell 53 with a custom cdk stack based on the CloudFormation infrastructure described here: https://docs.opendata.aws/genomics-workflows/. Are modifications needed for compatibility with newer versions of Cromwell? Are these documented somewhere?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-689558662
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691326074:238,Availability,error,error,238,"Attached is some documentation that works for v52 and should work for v53. On Wed, Sep 9, 2020 at 9:20 AM mderan-da <notifications@github.com> wrote:. > Hi @markjschreiber <https://github.com/markjschreiber> I'm also running; > into this error. I am using cromwell 53 with a custom cdk stack based on; > the CloudFormation infrastructure described here:; > https://docs.opendata.aws/genomics-workflows/; >; > Are modifications needed for compatibility with newer versions of; > Cromwell? Are these documented somewhere?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-689558662>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6EO6WEE4BYYPTX4HZ2LSE56JXANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691326074
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691723254:38,Availability,error,error,38,@markjschreiber running into the same error for both v52 and v53.1. I am using the same CloudFormation @mderan-da mentioned . Appreciate your newer documentation on this.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691723254
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-692083983:21,Availability,down,downloaded,21,"Documentation can be downloaded from here; https://cromwell-share-ad485.s3.us-east-2.amazonaws.com/InstallingGenomicsWorkflowCoreWithCromwel52.pdf. On Sun, Sep 13, 2020 at 4:48 PM Yaomin Xu <notifications@github.com> wrote:. > @markjschreiber <https://github.com/markjschreiber> running into the same; > error for both v52 and v53.1. I am using the same CloudFormation; > @mderan-da <https://github.com/mderan-da> mentioned . Appreciate your; > newer documentation on this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691723254>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6EKCM56WST3J6NO5CS3SFUVYLANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-692083983
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-692083983:304,Availability,error,error,304,"Documentation can be downloaded from here; https://cromwell-share-ad485.s3.us-east-2.amazonaws.com/InstallingGenomicsWorkflowCoreWithCromwel52.pdf. On Sun, Sep 13, 2020 at 4:48 PM Yaomin Xu <notifications@github.com> wrote:. > @markjschreiber <https://github.com/markjschreiber> running into the same; > error for both v52 and v53.1. I am using the same CloudFormation; > @mderan-da <https://github.com/mderan-da> mentioned . Appreciate your; > newer documentation on this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-691723254>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AF2E6EKCM56WST3J6NO5CS3SFUVYLANCNFSM4G23FFUQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-692083983
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269:126,Availability,error,error,126,"> Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory"". Also have this error. Anyone figure out what the issue is?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269:42,Integrability,message,message,42,"> Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory"". Also have this error. Anyone figure out what the issue is?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269:13,Testability,log,logs,13,"> Cloudwatch logs contained the following message: ""/bin/bash: /var/scratch/fetch_and_run.sh: Is a directory"". Also have this error. Anyone figure out what the issue is?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-727246269
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937:15,Availability,error,error,15,"Also have this error, using Cromwell 52, installed using this manual : . https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf. logs say : fetch_and_run.is is a directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937:41,Deployability,install,installed,41,"Also have this error, using Cromwell 52, installed using this manual : . https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf. logs say : fetch_and_run.is is a directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937:121,Deployability,Install,Installing,121,"Also have this error, using Cromwell 52, installed using this manual : . https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf. logs say : fetch_and_run.is is a directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937:177,Testability,log,logs,177,"Also have this error, using Cromwell 52, installed using this manual : . https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf. logs say : fetch_and_run.is is a directory.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747587937
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613:17,Availability,error,error,17,"> Also have this error, using Cromwell 52, installed using this manual :; > ; > https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf; > ; > logs say : fetch_and_run.is is a directory. Extra info : cloning job & resubmitting through aws console runs fine. so it seems to be a temporary issue",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613:43,Deployability,install,installed,43,"> Also have this error, using Cromwell 52, installed using this manual :; > ; > https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf; > ; > logs say : fetch_and_run.is is a directory. Extra info : cloning job & resubmitting through aws console runs fine. so it seems to be a temporary issue",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613:128,Deployability,Install,Installing,128,"> Also have this error, using Cromwell 52, installed using this manual :; > ; > https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf; > ; > logs say : fetch_and_run.is is a directory. Extra info : cloning job & resubmitting through aws console runs fine. so it seems to be a temporary issue",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613:190,Testability,log,logs,190,"> Also have this error, using Cromwell 52, installed using this manual :; > ; > https://aws-genomics-workflows.s3.amazonaws.com/Installing+the+Genomics+Workflow+Core+and+Cromwell.pdf; > ; > logs say : fetch_and_run.is is a directory. Extra info : cloning job & resubmitting through aws console runs fine. so it seems to be a temporary issue",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-747603613
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-840874050:118,Availability,error,error,118,"Hmmm, still stuck on this - any updates from your guys' end? I tried cloning and resubmitting, still getting the same error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-840874050
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-840874050:32,Deployability,update,updates,32,"Hmmm, still stuck on this - any updates from your guys' end? I tried cloning and resubmitting, still getting the same error.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-840874050
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-856677347:19,Availability,error,error,19,Still getting this error today.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-856677347
https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-1244579032:17,Availability,error,error,17,I'm getting this error almost certainly when I run workflows where more samples (e.g. 96) than usual are scattered.; Cromwell version: 60-6048d0e-SNAP. Is there a workaround to this?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687#issuecomment-1244579032
https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807:61,Availability,failure,failures,61,"Guys, you should update mysql connector! Most of my workflow failures were because of mysql connection loss, it is such a pain to have a pipeline running for >1 day and having stuff crashed because ""cromwell lost connection to mysql""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807
https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807:17,Deployability,update,update,17,"Guys, you should update mysql connector! Most of my workflow failures were because of mysql connection loss, it is such a pain to have a pipeline running for >1 day and having stuff crashed because ""cromwell lost connection to mysql""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807
https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807:137,Deployability,pipeline,pipeline,137,"Guys, you should update mysql connector! Most of my workflow failures were because of mysql connection loss, it is such a pain to have a pipeline running for >1 day and having stuff crashed because ""cromwell lost connection to mysql""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4690#issuecomment-468618807
https://github.com/broadinstitute/cromwell/issues/4692#issuecomment-468718231:58,Modifiability,coupling,coupling,58,This was done a while back and was intentional as we were coupling two unrelated concepts quite tightly. We were not aware of anyone taking advantage of that functionality so just removed it. It has since come up that there are people out there who **do** like having a mechanism to punch things through to the GCP VM and have discussed adding a new feature to handle that (e.g. a workflow option). Tagging @ruchim,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4692#issuecomment-468718231
https://github.com/broadinstitute/cromwell/pull/4693#issuecomment-468927503:137,Testability,test,tests,137,"Looks like this PR will either need to also add [this commit](https://github.com/broadinstitute/cromwell/pull/4669), or retry the PapiV2 tests around a dozen times until it gets just enough memory. I'm also fine if #4669 is submitted as a separate 37_hotfix-PR first.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4693#issuecomment-468927503
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470279447:176,Deployability,update,update,176,"hey @kshakir ! I'd be happy to make that change for you (the first one). For the second one, I've linked the example in the folder to the online docs, and I'd suggest that the update of the docs themselves be a separate PR. I've noticed with Cromwell (and other software, generally) that it's much cleaner / better to have smaller PRs that have scoped changes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470279447
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:511,Deployability,install,install-then-test,511,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:731,Deployability,install,install-and-configure,731,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:906,Deployability,install,installation,906,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:985,Deployability,Install,Installation,985,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:743,Modifiability,config,configure,743,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:524,Testability,test,test,524,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:1342,Testability,Test,Test,1342,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981:1455,Testability,test,testCentaurSlurm,1455,"Haven't used udocker yet myself, but I'm pretty sure `${docker_script}` should be used there also instead of `${script}`. As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Related side-note: I would love one day for our CI to also install-then-test udocker, [rootless docker](https://github.com/moby/moby/blob/fc01c2b481097a6057bec3cd1ab2d7b4488c50c4/docs/rootless.md), singularity, etc. If anyone comes across this and knows the magic spell to fully-install-and-configure any of these container tools, or other HPC like HTCondor, GridEngine, etc., (especially on Travis!), please drop a gist or a PR. For example, here's the installation others helped me scrape together for SLURM:; - [Cromwell SLURM CI Installation Script](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/test_slurm.inc.sh); - [Cromwell SLURM CI Conf](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/resources/slurm_application.conf) with commands to run/kill/check jobs; - [Cromwell SLURM CI Test Runner](https://github.com/broadinstitute/cromwell/blob/3c3a3f85ba1229738265b11c3573ccb538b719c2/src/ci/bin/testCentaurSlurm.sh)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470292981
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470293660:561,Usability,clear,clearly,561,"> As for HPC and docker, there are some renegades out there running nodes with docker. The very few I've come across are not on-prem, spin up private larger machines on cloud resources, add HPC+docker, and then run whatever scripts on top of that. This includes our CI... until we get one of the non-root LXC implementations going. Interesting! If it's a cloud setup, I don't know if we would call that HPC. When I say HPC I typically mean SLURM, SGE, etc., where there are many thousands of untrusted users. Putting Docker on those systems - no admin thinking clearly would do it. For a really small number of users that you absolutely trust? That could be a thing, haha. :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470293660
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470676678:138,Testability,test,tests,138,"Is the one failed run in travis related to these changes? It seems like a random TravisCI issue, but it might be my inexperience with the tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470676678
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470680968:23,Availability,failure,failure,23,"This is likely a bogus failure, I went ahead and restarted the job",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470680968
https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470681272:68,Testability,test,testing,68,"Poor TravisCI, I have had the same, and wound up switching a ton of testing suites over to CircleCI. I hope TravisCI survives after the major layoffs, now things aren't looking so great! :/ . You can do it Travis!!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4697#issuecomment-470681272
https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581:379,Deployability,update,update,379,"Hi,; ; I'm experiencing the same problem on AWS Batch. My workflow has 2 subworkflows. Even I don't change any part of my workflow/subworkflow, the caching only works for the first task in subworkflows. The subsequent tasks cannot be recognized by hashing. I guess this is because the subworkflow id is also involved in the task inputs, so it change hash. . Does anyone have any update or workaround for this problem? Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581
https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581:248,Security,hash,hashing,248,"Hi,; ; I'm experiencing the same problem on AWS Batch. My workflow has 2 subworkflows. Even I don't change any part of my workflow/subworkflow, the caching only works for the first task in subworkflows. The subsequent tasks cannot be recognized by hashing. I guess this is because the subworkflow id is also involved in the task inputs, so it change hash. . Does anyone have any update or workaround for this problem? Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581
https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581:350,Security,hash,hash,350,"Hi,; ; I'm experiencing the same problem on AWS Batch. My workflow has 2 subworkflows. Even I don't change any part of my workflow/subworkflow, the caching only works for the first task in subworkflows. The subsequent tasks cannot be recognized by hashing. I guess this is because the subworkflow id is also involved in the task inputs, so it change hash. . Does anyone have any update or workaround for this problem? Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4699#issuecomment-716072581
https://github.com/broadinstitute/cromwell/pull/4701#issuecomment-469719251:37,Availability,down,downgraded,37,@kshakir is this the library that we downgraded the last time we tried to upgrade all of our libraries?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4701#issuecomment-469719251
https://github.com/broadinstitute/cromwell/pull/4701#issuecomment-469719251:74,Deployability,upgrade,upgrade,74,@kshakir is this the library that we downgraded the last time we tried to upgrade all of our libraries?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4701#issuecomment-469719251
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405:151,Performance,perform,performance,151,"Looking at the actual SQL above . 1. If possible doing a ""SELECT 1"" (or any other constant) instead of ""SELECT *"" when dealing with EXISTS can be more performance. * requires pulling back all the data from the table for that row, whereas all you're doing is checking for existence. This can make a difference where the WHERE clause is completely satisfied by data within the index being used and the second seek back to the actual data does not need to happen . 2. My only concern is the performance of lots of EXISTS in MySQL. They should be fine, and if this was Oracle I wouldn't worry... but MySQL has proven to be a bit dumb about complex subqueries and don't know if EXISTS would fit into the same bucket. However, this will be proven out during testing... my guess is that if there is a problem it won't be subtle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405:488,Performance,perform,performance,488,"Looking at the actual SQL above . 1. If possible doing a ""SELECT 1"" (or any other constant) instead of ""SELECT *"" when dealing with EXISTS can be more performance. * requires pulling back all the data from the table for that row, whereas all you're doing is checking for existence. This can make a difference where the WHERE clause is completely satisfied by data within the index being used and the second seek back to the actual data does not need to happen . 2. My only concern is the performance of lots of EXISTS in MySQL. They should be fine, and if this was Oracle I wouldn't worry... but MySQL has proven to be a bit dumb about complex subqueries and don't know if EXISTS would fit into the same bucket. However, this will be proven out during testing... my guess is that if there is a problem it won't be subtle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405:752,Testability,test,testing,752,"Looking at the actual SQL above . 1. If possible doing a ""SELECT 1"" (or any other constant) instead of ""SELECT *"" when dealing with EXISTS can be more performance. * requires pulling back all the data from the table for that row, whereas all you're doing is checking for existence. This can make a difference where the WHERE clause is completely satisfied by data within the index being used and the second seek back to the actual data does not need to happen . 2. My only concern is the performance of lots of EXISTS in MySQL. They should be fine, and if this was Oracle I wouldn't worry... but MySQL has proven to be a bit dumb about complex subqueries and don't know if EXISTS would fit into the same bucket. However, this will be proven out during testing... my guess is that if there is a problem it won't be subtle.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469804405
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469889241:19,Deployability,update,updated,19,@mcovarr @kcibul I updated the examples above to reflect the SQL queries generated post PR feedback. Main changes:; - No `EXISTS` for the types of query that Job Manager 0.5.9 produces (labelsAnd and labelsOr).; - Because we now use `JOIN`s for both `LabelAND` and `LabelOR` queries.; - Using `1` instead of `*` for those sub-selects. Would appreciate any other thoughts,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469889241
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469889241:91,Usability,feedback,feedback,91,@mcovarr @kcibul I updated the examples above to reflect the SQL queries generated post PR feedback. Main changes:; - No `EXISTS` for the types of query that Job Manager 0.5.9 produces (labelsAnd and labelsOr).; - Because we now use `JOIN`s for both `LabelAND` and `LabelOR` queries.; - Using `1` instead of `*` for those sub-selects. Would appreciate any other thoughts,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469889241
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089:57,Performance,perform,performance,57,Looks good delta some final feedback incorporation and a performance test on alpha.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089:69,Testability,test,test,69,Looks good delta some final feedback incorporation and a performance test on alpha.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089:28,Usability,feedback,feedback,28,Looks good delta some final feedback incorporation and a performance test on alpha.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-469900089
https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-470343985:82,Deployability,patch,patch,82,I'm going to overrule `codecov/project` here since it appears to be a hiccup. The patch coverage is at around 77% (which is higher than the usual project overall average) so I'm pretty confident this doesn't represent an actual overall coverage reduction.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4702#issuecomment-470343985
https://github.com/broadinstitute/cromwell/pull/4706#issuecomment-470144771:49,Deployability,upgrade,upgrade,49,"You will likely need two `v37` confs. During the upgrade tests, new confs are needed to run against the cromwell-37 jar. Something like these should work:. #### local_37_application.conf; ```hocon; include ""local_application.conf""; database.db.driver = ""com.mysql.jdbc.Driver""; ```. #### papi_v2_37_application.conf; ```hocon; include ""papi_v2_application.conf""; database.db.driver = ""com.mysql.jdbc.Driver""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4706#issuecomment-470144771
https://github.com/broadinstitute/cromwell/pull/4706#issuecomment-470144771:57,Testability,test,tests,57,"You will likely need two `v37` confs. During the upgrade tests, new confs are needed to run against the cromwell-37 jar. Something like these should work:. #### local_37_application.conf; ```hocon; include ""local_application.conf""; database.db.driver = ""com.mysql.jdbc.Driver""; ```. #### papi_v2_37_application.conf; ```hocon; include ""papi_v2_application.conf""; database.db.driver = ""com.mysql.jdbc.Driver""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4706#issuecomment-470144771
https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900:67,Integrability,interface,interface,67,"That's actually pretty tough to do with the way Cromwell's backend interface is currently architected. We've run into this with HPC clusters as well. By the time something makes it to the backend interface it's already at the granularity of a single shard, and it's only on the **other** side of the backend interface that the code can be aware of the potential concept of an array job. It's certainly not an insurmountable problem (it's just code) but it'd be a fairly major architectural shift, and we know that there are users who have private backend implementations and thus we try not to change the interface as much as possible",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900
https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900:196,Integrability,interface,interface,196,"That's actually pretty tough to do with the way Cromwell's backend interface is currently architected. We've run into this with HPC clusters as well. By the time something makes it to the backend interface it's already at the granularity of a single shard, and it's only on the **other** side of the backend interface that the code can be aware of the potential concept of an array job. It's certainly not an insurmountable problem (it's just code) but it'd be a fairly major architectural shift, and we know that there are users who have private backend implementations and thus we try not to change the interface as much as possible",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900
https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900:308,Integrability,interface,interface,308,"That's actually pretty tough to do with the way Cromwell's backend interface is currently architected. We've run into this with HPC clusters as well. By the time something makes it to the backend interface it's already at the granularity of a single shard, and it's only on the **other** side of the backend interface that the code can be aware of the potential concept of an array job. It's certainly not an insurmountable problem (it's just code) but it'd be a fairly major architectural shift, and we know that there are users who have private backend implementations and thus we try not to change the interface as much as possible",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900
https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900:605,Integrability,interface,interface,605,"That's actually pretty tough to do with the way Cromwell's backend interface is currently architected. We've run into this with HPC clusters as well. By the time something makes it to the backend interface it's already at the granularity of a single shard, and it's only on the **other** side of the backend interface that the code can be aware of the potential concept of an array job. It's certainly not an insurmountable problem (it's just code) but it'd be a fairly major architectural shift, and we know that there are users who have private backend implementations and thus we try not to change the interface as much as possible",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4707#issuecomment-469889900
https://github.com/broadinstitute/cromwell/issues/4711#issuecomment-518199844:73,Performance,cache,cached-copy,73,"Hi @myazinn,. @rhpvorderman indeed solved this issue by implementing the cached-copy localization strategy. So no, this issue is no longer relevant.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4711#issuecomment-518199844
https://github.com/broadinstitute/cromwell/issues/4713#issuecomment-470603661:212,Deployability,release,release,212,"Hey @SHuang-Broad, yes you are right it should be pointing to 36.1. There was some conversation going on for forcing HomeBrew to recognize 36.1 as the newest version. But that has became unnecessary now as a new release should be out soon. You can look at the HomeBrew conversation [here](https://github.com/Homebrew/homebrew-core/pull/37175).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4713#issuecomment-470603661
https://github.com/broadinstitute/cromwell/issues/4722#issuecomment-474907876:28,Deployability,release,release,28,The fix will be in the next release of Cromwell. Thank you for reporting.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4722#issuecomment-474907876
https://github.com/broadinstitute/cromwell/issues/4723#issuecomment-475430588:37,Testability,log,log,37,Closing for now. Instead we chose to log this info via #4451,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4723#issuecomment-475430588
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407:256,Performance,cache,cache,256,"The `long_cmd` test is failing because the default MySQL packet size is too small for the gigantic metadata being generated, though I'm not sure if the problem is on the client or server or both. The capoeira tests complete successfully but get unexpected cache hits. I'm not sure why the CWL test is failing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407:15,Testability,test,test,15,"The `long_cmd` test is failing because the default MySQL packet size is too small for the gigantic metadata being generated, though I'm not sure if the problem is on the client or server or both. The capoeira tests complete successfully but get unexpected cache hits. I'm not sure why the CWL test is failing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407:209,Testability,test,tests,209,"The `long_cmd` test is failing because the default MySQL packet size is too small for the gigantic metadata being generated, though I'm not sure if the problem is on the client or server or both. The capoeira tests complete successfully but get unexpected cache hits. I'm not sure why the CWL test is failing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407:293,Testability,test,test,293,"The `long_cmd` test is failing because the default MySQL packet size is too small for the gigantic metadata being generated, though I'm not sure if the problem is on the client or server or both. The capoeira tests complete successfully but get unexpected cache hits. I'm not sure why the CWL test is failing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-471576407
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:149,Availability,ERROR,ERROR,149,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:223,Availability,Error,Error,223,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:3376,Availability,robust,robustExecuteOrRecover,3376,obExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad ho,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4366,Availability,Error,Error,4366,".withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4377,Availability,Error,Error,4377,".withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4971,Availability,error,error,4971,"n(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the reason why it is failing locally and not on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:3777,Energy Efficiency,Schedul,Scheduler,3777,ncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.bac,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:3799,Energy Efficiency,Schedul,Scheduler,3799,.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.St,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:570,Modifiability,config,config,570,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:647,Modifiability,Config,ConfigAsyncJobExecutionActor,647,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:718,Modifiability,config,config,718,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:784,Modifiability,Config,ConfigAsyncJobExecutionActor,784,"The `cwl_dynamic_initial_workdir` fails with below stack trace:; ```; 2019-03-13 12:29:04,388 cromwell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeS",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:1096,Modifiability,config,config,1096,ell-system-akka.dispatchers.backend-dispatcher-88 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsy,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:1164,Modifiability,Config,ConfigAsyncJobExecutionActor,1164,ConfigAsyncJobExecutionActor [UUID(c9194073)main:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:581); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.s,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:1506,Modifiability,config,config,1506,syncExecutionActor.scala:515); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:1633,Modifiability,Config,ConfigAsyncJobExecutionActor,1633,ionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:317); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.ba,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:1949,Modifiability,config,config,1949,mwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at crom,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:2015,Modifiability,Config,ConfigAsyncJobExecutionActor,2015,tents$(StandardAsyncExecutionActor.scala:316); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:2333,Modifiability,config,config,2333,5); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:2387,Modifiability,Config,ConfigAsyncJobExecutionActor,2387,nActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:2845,Modifiability,config,config,2845,Actor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvoca,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:2904,Modifiability,Config,ConfigAsyncJobExecutionActor,2904,a:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJo,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:3206,Modifiability,config,config,3206,dFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinP,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:3269,Modifiability,Config,ConfigAsyncJobExecutionActor,3269,bExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:644); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:644); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:959); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:951); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.r,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4607,Security,validat,validation,4607,"reTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder r",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4618,Security,Validat,Validation,4618,"ftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4629,Security,Validat,ValidationTry,4629,"ftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4661,Security,Validat,Validation,4661,"pport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4694,Security,validat,validation,4694,"imeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4705,Security,Validat,Validation,4705,"fun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder st",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4716,Security,Validat,ValidationTry,4716,"fun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder st",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4748,Security,Validat,Validation,4748,"pport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:4587,Testability,test,testdir,4587,".withRetry(Retry.scala:38); 	at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); 	at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); 	at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); 	at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:5178,Testability,test,testdir,5178,"n(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the reason why it is failing locally and not on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:5352,Testability,test,testdir,5352,"n(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the reason why it is failing locally and not on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:5644,Testability,test,testdir,5644,"n(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the reason why it is failing locally and not on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211:5659,Testability,test,test,5659,"n(Scheduler.scala:205); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Error evaluating ad hoc files:; <path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:579); 	... 35 common frames omitted; ```. The above stack trace was consuming the actual error:; `NoSuchFileException:<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution/centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir; `. Somewhere while resolving host to call root, instead of returning the path to inputs as `centaur/src/main/resources/standardTestCases/cwl_dynamic_initial_workdir/testdir`, it resolves the path by prefixing the call root context path, which is `<path_prefix>/cromwell/cromwell-executions/main/c9194073-c6ed-4c2a-97d6-fbc6a2314883/call-main/execution`. As a result, it tries to look for inputs inside the `execution` folder rather than inside `centaur/.../testdir`. This test passes in Travis and it might have different folder structure, which could be the reason why it is failing locally and not on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472514211
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:1025,Availability,down,down,1025,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:467,Deployability,install,install,467,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:109,Modifiability,config,configs,109,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:326,Modifiability,config,configs,326,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:948,Modifiability,config,configs,948,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:1086,Modifiability,config,configs,1086,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:1157,Modifiability,config,configs,1157,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:67,Performance,cache,cache,67,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:20,Testability,test,tests,20,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:300,Testability,test,tests,300,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:764,Testability,test,test,764,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:904,Testability,test,testCentaurLocal,904,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:979,Testability,test,tests,979,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580:1008,Testability,test,tests,1008,"Re:. > The capoeira tests complete successfully but get unexpected cache hits. Caching is also tweaked in CI configs. For example:. https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/src/ci/resources/local_provider_config.inc.conf#L6. Have you already tried the tests locally with the CI configs? For unicromtal, one can run the existing CI scripts with a bit of bootstrap:; - Setup vault; - Setup mysql locally (I'm using `brew install mysql`); - [Initialize a `travis` mysql user with granted permissions](https://dev.mysql.com/doc/refman/8.0/en/adding-users.html); - [Using the `travis` user create a `cromwell_test` schema](https://github.com/broadinstitute/cromwell/blob/279909b1f35c8305dcfc23ac8534dcb00ce09771/core/src/test/resources/application.conf#L24). From the cromwell source directory, with all of the above setup, one can try to run `src/ci/resources/testCentaurLocal.sh` and it will render the configs with vault and run the tests, including the restart tests that bring down/up cromwell. Also, if one just wants to ever use the CI configs with cromwell in IntelliJ, `sbt renderCiResources` will render configs into the folder `target/ci/resources`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580
https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-475245556:9,Testability,test,tests,9,"3 of the tests have been addressed in #4748, made this issue into a checklist",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-475245556
https://github.com/broadinstitute/cromwell/pull/4729#issuecomment-472014901:83,Testability,test,test,83,"Hi Ohad,. Thanks for the contrib. Looks like `WdlFileToWdlomSpec` is failing - the test output is a bit hard to parse, so here's the useful bit:; ```; should create the correct Element structure for task_with_metas2.wdl *** FAILED ***; No Element expectation defined for task_with_metas2 (WdlFileToWdlomSpec.scala:39); ```; You probably need to add a `""task_with_metas2"" -> FileElement(...)` tuple in `wdl.draft3.transforms.ast2wdlom.WdlFileToWdlomSpec`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4729#issuecomment-472014901
https://github.com/broadinstitute/cromwell/pull/4729#issuecomment-472847663:15,Testability,test,test,15,Thanks for the test fixes! We will get this reviewed,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4729#issuecomment-472847663
https://github.com/broadinstitute/cromwell/pull/4730#issuecomment-472146747:92,Availability,downtime,downtime,92,"Travis passed but Github is hanging getting the status back, possibly due to earlier github downtime (overheard in Slack)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4730#issuecomment-472146747
https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-484529709:21,Usability,learn,learned,21,"Brain dumping what I learned from Emil:; This localization code is in the [proxy](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/aws/src/main/resources/ecs-proxy/proxy).; Probably needs to use a force global flag as in the Java SDK. Looking forward, I also see an issue w/ call caching to files outside the compute region, as the [filesystem copy](https://github.com/broadinstitute/cromwell/blob/develop/filesystems/s3/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java) is not using the force global flag.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-484529709
https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699:339,Availability,error,error,339,"Hi, I this is might be a little late, but I am having this issue too when running using Batch. I configured my core environment on my own (without using the CF templates). I have a bucket that is located in `us-west-2` and the instance running Cromwell (v59), and the Job Queue are located in `us-east-2`. When I run a job, I get the same error that @illusional was getting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699
https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699:97,Modifiability,config,configured,97,"Hi, I this is might be a little late, but I am having this issue too when running using Batch. I configured my core environment on my own (without using the CF templates). I have a bucket that is located in `us-west-2` and the instance running Cromwell (v59), and the Job Queue are located in `us-east-2`. When I run a job, I get the same error that @illusional was getting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699
https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699:272,Performance,Queue,Queue,272,"Hi, I this is might be a little late, but I am having this issue too when running using Batch. I configured my core environment on my own (without using the CF templates). I have a bucket that is located in `us-west-2` and the instance running Cromwell (v59), and the Job Queue are located in `us-east-2`. When I run a job, I get the same error that @illusional was getting.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731#issuecomment-927177699
https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909:156,Performance,perform,performance,156,The endpoints which query the metadata table and would be affected by the removal of the mentioned indices are:; - metadata; - timing; - logs; - query. The performance of `/metadata` and `/timing` endpoints have been measured and put in the doc. The remaining 2 endpoints are not being called through FC and hence their performance doesn't need to be evaluated.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909
https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909:320,Performance,perform,performance,320,The endpoints which query the metadata table and would be affected by the removal of the mentioned indices are:; - metadata; - timing; - logs; - query. The performance of `/metadata` and `/timing` endpoints have been measured and put in the doc. The remaining 2 endpoints are not being called through FC and hence their performance doesn't need to be evaluated.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909
https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909:137,Testability,log,logs,137,The endpoints which query the metadata table and would be affected by the removal of the mentioned indices are:; - metadata; - timing; - logs; - query. The performance of `/metadata` and `/timing` endpoints have been measured and put in the doc. The remaining 2 endpoints are not being called through FC and hence their performance doesn't need to be evaluated.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4733#issuecomment-475366909
https://github.com/broadinstitute/cromwell/issues/4735#issuecomment-472114751:308,Testability,test,test,308,"I created [a branch](https://github.com/broadinstitute/cromwell/pull/4736) with this change just to see if anything obviously horrible happened with our CI. I haven't looked at the results yet, but a positive result here is a ""necessary but not sufficient"" for going forward since I don't think our existing test suite is likely to provide too much insight into the impact of removing these indexes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4735#issuecomment-472114751
https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472122237:15,Availability,downtime,downtime,15,is this a zero downtime migration?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472122237
https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472133864:47,Availability,downtime,downtime,47,"@mcovarr worth figuring out as any non-trivial downtime is going to be met with a giant ""no""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472133864
https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472141525:107,Availability,downtime,downtime,107,This is currently plan A for addressing the 10 TB database limit. Plan B would definitely have non-trivial downtime.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4736#issuecomment-472141525
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503160789:154,Testability,test,tests,154,"Hello!. I have recently started to work with the Cromwell project. Could you please clarify ""Acceptance criteria"" section? I would like to know which two tests should pass with non-default credentials. Also, could you please prompt where I can find a link to Jenkins?. Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503160789
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:916,Deployability,integrat,integrationTestCases,916,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1063,Deployability,integrat,integrationTestCases,1063,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:916,Integrability,integrat,integrationTestCases,916,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1063,Integrability,integrat,integrationTestCases,1063,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1211,Security,access,accessible,1211,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1284,Security,secur,security,1284,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:56,Testability,test,tests,56,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:166,Testability,test,tests,166,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:244,Testability,test,testCentaurAws,244,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:296,Testability,test,tests,296,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:332,Testability,test,test,332,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:441,Testability,test,testCentaurAws,441,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:478,Testability,test,tests,478,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:531,Testability,test,tests,531,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:682,Testability,test,test,682,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:807,Testability,test,test,807,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:957,Testability,test,test,957,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1101,Testability,test,test,1101,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1380,Testability,test,tests,1380,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164:1477,Testability,test,tests,1477,"Hi @AlekseiLitkovetc,. > I would like to know which two tests should pass with non-default credentials. Back in March when I filed the ticket we were only [including tests for four](https://github.com/broadinstitute/cromwell/blob/38/src/ci/bin/testCentaurAws.sh#L24-L27) of our dozens of Centaur tests. After the AWS hackathon, the test coverage expanded to only [exclude a few](https://github.com/broadinstitute/cromwell/blob/39/src/ci/bin/testCentaurAws.sh#L25-L53) remaining tests. So, the original minimum A/C was to see these tests passing with non-default creds:; - [hello](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/hello.test); - [long_cmd](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/standardTestCases/long_cmd.test); - [haplotypecaller.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/haplotypecaller.aws.test); - [singlesample.aws](https://github.com/broadinstitute/cromwell/blob/42/centaur/src/main/resources/integrationTestCases/singlesample.aws.test). > could you please prompt where I can find a link to Jenkins?. Our Jenkins servers are only internally accessible to Broad employees because of Jenkins continued problems with security. Perhaps one day we'll move off Travis to another public CI-as-a-Service that will run tests longer than 180 minutes, such as CircleCI or Google Cloud Build. Then we could migrate all tests to one place.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-503831164
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504048422:138,Testability,log,login,138,It's worth noting that this is not necessary to get a working Cromwell-on-AWS set up. It's only necessary if one wants to use the default login from the CLI,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504048422
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:671,Security,access,access,671,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:716,Security,access,access,716,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:371,Testability,test,tests,371,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:486,Testability,test,testing,486,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:633,Testability,test,testing,633,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413:791,Testability,test,testing,791,"@kshakir, thank you for your detailed explanation. If you do not mind, could you please shed some light on the one more thing.; I have a little bit messy with the definition of what the default credentials are.; Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed? In my point of view, it looks insecure to pass my keys and AWS environments for CI testing. This is why I think that I missed something. Also, in case if I suggest a fix for this task I will not be able to check the results of CI testing by myself cause I do not have access to the Jenkins. Is it possible to get access in read-only mode or I can communicate with someone who can provide testing results?. Thank you in advance for your answers!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-504776413
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:264,Deployability,configurat,configuration,264,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:336,Deployability,configurat,configuration,336,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:264,Modifiability,config,configuration,264,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:336,Modifiability,config,configuration,336,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:407,Modifiability,config,config,407,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:974,Modifiability,config,configured,974,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:294,Safety,detect,detected,294,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:161,Testability,test,tests,161,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:801,Testability,test,tests,801,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:553,Usability,guid,guide,553,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:748,Usability,guid,guide,748,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165:908,Usability,guid,guide,908,"> Does it mean that the credentials, which Travis and Jenkins use, are default credentials and the purpose of this task is to set other ones and check that four tests were successfully passed?. Using ""default credentials"" means that any one of a very long list of configuration setups are auto-detected by the AWS Java SDK. In each SDK-configuration case, the credentials are **not** read from the cromwell-config file and then the values passed on to the AWS SDK. Instead the SDK ""discovers"" them. https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default. This ticket is to instead wire in credentials to the SDK via [Explicitly Specifying Credentials](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-explicit). In the tests:; - Each of the ""[Default Credential Provider](https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/credentials.html#credentials-default)"" options would not be configured on the system; - The `java -Dconfig.file=..."" would contain the AWS key, secret and probably region; - When the various AWS SDK functions run, they each use the passed in credentials to run the commands for S3, Batch, etc.; - The jobs should still run to completion",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4740#issuecomment-505233165
https://github.com/broadinstitute/cromwell/issues/4741#issuecomment-472412608:834,Availability,down,down,834,"@Xophmeister Ultimately this is going to need changes to the WDL spec and thus a conversation over in the [OpenWDL group](www.openwdl.org), although your issue does start entering the murky grey area between WDL and Cromwell (which admittedly exists due to WDL's heritage as originally being a product of the Cromwell team). You're able to reference values in `runtime` because the WDL spec allows it. However, there's no notion in WDL of `default_runtime_attributes`, that's a purely Cromwell concept. Thus if Cromwell were to allow this, it'd encourage WDLs which would fail elsewhere. . My own $0.02 is that `runtime` is horribly broken and needs to be rebuilt from the ground up (again, over in OpenWDL, not here). Since history has shown that there's always some path to fixing `runtime` which **doesn't** require my burn it all down approach a good first step might be to suggest an official system of defaults over there. I'm going to close this issue as I don't believe there's anything reasonable we can do from the Cromwell side. If, given the context I provided above, you disagree (e.g. perhaps I misunderstood the ask) let me know and we might reopen it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4741#issuecomment-472412608
https://github.com/broadinstitute/cromwell/pull/4745#issuecomment-472882044:49,Availability,down,downloading,49,"Since I always build `womtool` myself instead of downloading, I did notice this problem but assumed there was some magic that made the version set correctly for release builds.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4745#issuecomment-472882044
https://github.com/broadinstitute/cromwell/pull/4745#issuecomment-472882044:161,Deployability,release,release,161,"Since I always build `womtool` myself instead of downloading, I did notice this problem but assumed there was some magic that made the version set correctly for release builds.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4745#issuecomment-472882044
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473119369:63,Testability,test,tests,63,"@kshakir huh, TIL. It currently passes **most** of the centaur tests, maybe I can square that away in a separate PR as we should be running as many as possible. What's weird is that `long_cmd` fails consistently for me but looks to be on the good list.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473119369
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:80,Modifiability,config,config,80,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:106,Modifiability,config,config,106,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:650,Modifiability,config,configs,650,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:250,Testability,test,test,250,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:456,Testability,test,test,456,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093:597,Testability,test,testCentaurAws,597,"> What's weird is that long_cmd fails consistently for me. Are you using the CI config files, or your own config file? `long_cmd` generates an _extremely_ long command line that approximates one of the longer gatk best practice commands. However the test line is so long that an [optional abbreviation](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/resources/build_application.inc.conf#L23) setting was added and enabled-in-CI so that the test could run. With [a bit of setup](https://github.com/broadinstitute/cromwell/issues/4725#issuecomment-472915580) one can run `src/ci/bin/testCentaurAws.sh` and it will attempt to use the CI configs locally.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123093
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123397:70,Availability,error,error,70,"@kshakir just a standard config file. I hadn't actually looked at the error yet, but will make a note to come back to this discussion :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123397
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123397:25,Modifiability,config,config,25,"@kshakir just a standard config file. I hadn't actually looked at the error yet, but will make a note to come back to this discussion :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473123397
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426:104,Modifiability,config,config,104,@geoffjentry I ran into the same problem with `long_cmd` when I made the same mistake of using a non-CI config during horicromtal testing. Some lessons learned [here](https://github.com/broadinstitute/cromwell/pull/4748/files).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426:130,Testability,test,testing,130,@geoffjentry I ran into the same problem with `long_cmd` when I made the same mistake of using a non-CI config during horicromtal testing. Some lessons learned [here](https://github.com/broadinstitute/cromwell/pull/4748/files).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426
https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426:152,Usability,learn,learned,152,@geoffjentry I ran into the same problem with `long_cmd` when I made the same mistake of using a non-CI config during horicromtal testing. Some lessons learned [here](https://github.com/broadinstitute/cromwell/pull/4748/files).,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4747#issuecomment-473341426
https://github.com/broadinstitute/cromwell/pull/4749#issuecomment-474016586:109,Testability,test,tests,109,"I think this might close #4354 and #4710, as well as fix the `bad_output_task` and `bad_file_string` centaur tests. Will need to double check when the new proxy is pushed",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4749#issuecomment-474016586
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:568,Availability,error,error,568,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:909,Availability,error,error,909,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:937,Availability,failure,failures,937,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:976,Safety,predict,predictable,976,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:49,Testability,test,test,49,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:238,Testability,test,test,238,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247:299,Usability,simpl,simplification,299,"Running the workflow; ```; version 1.0. workflow test {; input {; Array[File]? y = [""some/file/path.txt""]; }. output {; Array[File] x = select_first([y, []]); }; }; ```; on latest `develop` seems to work fine, producing outputs; ```; {; ""test.x"": [""some/file/path.txt""]; }; ```. Is this an accurate simplification of your problem case?. There is a good chance this bug is fixed in 37 onward as a result of https://github.com/broadinstitute/cromwell/pull/4324; >Fixed a regression in Cromwell 36 that could cause operations on empty arrays to fail with a spurious type error. I suspect your workflow got stuck after failing because the `WomArray` code [throws an exception](https://github.com/broadinstitute/cromwell/blob/develop/wom/src/main/scala/wom/values/WomArray.scala#L37) that screws up control flow. I believe this is a ""this should never happen"" case so we did not bother upgrading it to our fancier error handling that encodes failures in the type system to achieve predictable behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474440247
https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474470766:228,Deployability,upgrade,upgrade,228,"I was ultimately able to reproduce this on 36 by putting the value for `y` in the inputs JSON instead of as a default. The same scenario works fine on latest `develop`, so I am going to close this issue with the advice that you upgrade to 37.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755#issuecomment-474470766
https://github.com/broadinstitute/cromwell/issues/4756#issuecomment-474512847:0,Deployability,update,updated,0,updated,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4756#issuecomment-474512847
https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132:81,Deployability,update,updates,81,"> it's mostly a mystery what the summarizer is up to. 🤔 If we didn't want to log updates, maybe yet-another graphite metric to see summarization throughput?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132
https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132:145,Performance,throughput,throughput,145,"> it's mostly a mystery what the summarizer is up to. 🤔 If we didn't want to log updates, maybe yet-another graphite metric to see summarization throughput?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132
https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132:77,Testability,log,log,77,"> it's mostly a mystery what the summarizer is up to. 🤔 If we didn't want to log updates, maybe yet-another graphite metric to see summarization throughput?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4757#issuecomment-475105132
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-474911248:559,Availability,ERROR,ERROR,559,"Hi @geoffjentry, got an example of a fork in the liquibase scripts? One workaround that I'm already using in a couple of places is having a separate `changeSet` specific to postgres - for example `addAutoIncrement` does not really work the way it does in MySQL. But mostly I'm just enforcing the existing table/column name case conventions (Postgres wants to convert them all to lower-case). The main problem right now is the `IMPORTS_ZIP` column in `WORKFLOW_STORE_ENTRY` - the migrations are working but as soon as I try to run a workflow I get this:; ```; ERROR: column ""IMPORTS_ZIP"" is of type bytea but expression is of type bigint at character 335; ```; Typing this as a `Blob` in Slick appears to be the root of the problem, but I'll keep poking at it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-474911248
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616:1070,Deployability,update,update,1070,"> got an example of a fork in the liquibase scripts?. > One workaround that I'm already using in a couple of places is having a separate changeSet specific to postgres. See this link: http://www.liquibase.org/2009/03/what-effects-changeset-checksums.html. Those ""couple of places"" are likely the ""forks"" @geoffjentry was referring to. Additional changesets are fine, but ""adjusting the database migrations"" will add additional setup and test criteria regarding the MD5s. Here are two examples:. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/sync_not_null_constraints.xml#L20-L36. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/lengthen_wdl_value.xml#L5-L15. At minimum for the former changelog I suspect that fixes for Postgres (and [MariaDB](https://github.com/broadinstitute/cromwell/issues/4618) 🤔) will probably change the MD5s. As the link at the top says, there are workarounds to update/ignore the MD5s. But those workarounds will need to be implemented and CI tested-- along w/ [Postgres support](https://docs.travis-ci.com/user/database-setup/#postgresql).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616:240,Security,checksum,checksums,240,"> got an example of a fork in the liquibase scripts?. > One workaround that I'm already using in a couple of places is having a separate changeSet specific to postgres. See this link: http://www.liquibase.org/2009/03/what-effects-changeset-checksums.html. Those ""couple of places"" are likely the ""forks"" @geoffjentry was referring to. Additional changesets are fine, but ""adjusting the database migrations"" will add additional setup and test criteria regarding the MD5s. Here are two examples:. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/sync_not_null_constraints.xml#L20-L36. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/lengthen_wdl_value.xml#L5-L15. At minimum for the former changelog I suspect that fixes for Postgres (and [MariaDB](https://github.com/broadinstitute/cromwell/issues/4618) 🤔) will probably change the MD5s. As the link at the top says, there are workarounds to update/ignore the MD5s. But those workarounds will need to be implemented and CI tested-- along w/ [Postgres support](https://docs.travis-ci.com/user/database-setup/#postgresql).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616:437,Testability,test,test,437,"> got an example of a fork in the liquibase scripts?. > One workaround that I'm already using in a couple of places is having a separate changeSet specific to postgres. See this link: http://www.liquibase.org/2009/03/what-effects-changeset-checksums.html. Those ""couple of places"" are likely the ""forks"" @geoffjentry was referring to. Additional changesets are fine, but ""adjusting the database migrations"" will add additional setup and test criteria regarding the MD5s. Here are two examples:. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/sync_not_null_constraints.xml#L20-L36. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/lengthen_wdl_value.xml#L5-L15. At minimum for the former changelog I suspect that fixes for Postgres (and [MariaDB](https://github.com/broadinstitute/cromwell/issues/4618) 🤔) will probably change the MD5s. As the link at the top says, there are workarounds to update/ignore the MD5s. But those workarounds will need to be implemented and CI tested-- along w/ [Postgres support](https://docs.travis-ci.com/user/database-setup/#postgresql).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616:1151,Testability,test,tested,1151,"> got an example of a fork in the liquibase scripts?. > One workaround that I'm already using in a couple of places is having a separate changeSet specific to postgres. See this link: http://www.liquibase.org/2009/03/what-effects-changeset-checksums.html. Those ""couple of places"" are likely the ""forks"" @geoffjentry was referring to. Additional changesets are fine, but ""adjusting the database migrations"" will add additional setup and test criteria regarding the MD5s. Here are two examples:. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/sync_not_null_constraints.xml#L20-L36. https://github.com/broadinstitute/cromwell/blob/70cff69799f149191bdaec5d8878dd2a3d5202b7/database/migration/src/main/resources/changesets/lengthen_wdl_value.xml#L5-L15. At minimum for the former changelog I suspect that fixes for Postgres (and [MariaDB](https://github.com/broadinstitute/cromwell/issues/4618) 🤔) will probably change the MD5s. As the link at the top says, there are workarounds to update/ignore the MD5s. But those workarounds will need to be implemented and CI tested-- along w/ [Postgres support](https://docs.travis-ci.com/user/database-setup/#postgresql).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475014616
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:653,Availability,error,error,653,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:687,Deployability,update,updated,687,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:1423,Deployability,update,updated,1423,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:1584,Energy Efficiency,adapt,adapter,1584,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:1584,Integrability,adapter,adapter,1584,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156:1584,Modifiability,adapt,adapter,1584,"> I'm starting to wonder if it would be easier for me to just write out every CREATE statement to generate the current tables. I'd prefer to use liquibase syntax as much as possible, versus [custom crafted SQL](https://www.liquibase.org/documentation/changes/sql.html). > do you have a preference for 1) trying to make the current migrations work for Postgres too (without breaking the MD5s), or 2) make all existing migrations non-Postgres and add a single comprehensive Postgres-specific migration?. Of the two, I think it would be fantastic if we could do ""1)"". Minimum requirements are that existing MySQL users can startup cromwell w/o a liquibase error. Ultimately, if you can get updated changelogs that actually don't cause collisions with existing MD5s for those populated databases that's one avenue that might work. If not, and ""2)"" is uglier but doesn't break things for MySQL, then so be it. Side note: I suspect the existing Java/Scala changelogs can be a no-op / skip, assuming that anyone using Postgres will not need to migrate data for those specific changes. I believe we skipped those Java/Scala migrations for the in-memory HSQLDB instances. Also, you didn't ask, but in my dream world Cromwell would have changelogs that:; - Use liquibase syntax vs. sql as much as possible; - Work for a new database; - Work for all old/populated databases; - Work for HSQLDB + MySQL + PostgreSQL + MariaDB; - Can be updated to add other databases if/when our [Slick](http://slick.lightbend.com/doc/3.2.3/supported-databases.html) calls work or cromwell switches to another SQL adapter. To get to that last point I've wondered how one would best handle the liquibase MD5 issue in the future, either suppressing the warnings and / or resetting the MD5s as needed. **TL;DR Try 1), but as long as populated MySQL databases still startup with cromwell you're good!**",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-475371156
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:606,Availability,down,downstream,606,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:46,Deployability,update,update,46,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:289,Modifiability,refactor,refactoring,289,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:591,Modifiability,refactor,refactoring,591,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:411,Performance,load,loading,411,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:536,Security,access,accessed,536,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:1603,Testability,test,testing,1603,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402:1056,Usability,simpl,simply,1056,"Since it's been a month I thought I'd post an update. Main items:; - In general I'm having to make a lot more changes to the Scala code than I expected due to queries being written in a way that Postgres doesn't like. (This isn't a criticism, more of a heads-up.) Nothing functional, just refactoring.; - The way `Blob` is handled in Slick+Postgres turns out to be a massive pain. I'm not sure if Slick is lazy-loading these fields or I just don't understand how it works under the hood, but the workaround is that the blobs need to be accessed as part of a transaction, which involved some refactoring of downstream processing.; - Semi-related question: is there a reason why the entire contents of the `importsZip` need to be stored in the database? This quickly leads to an enormous METADATA_ENTRY table - possibly because I have call caching turned on, I haven't checked whether this is the cause yet.; - The auto-incremented fields that are `Option[Long]` in the data model can't be handled the same way in Postgres; I haven't decided whether this is simply different database behavior or a bug somewhere. Anyway I found a workaround for that too.; - I may have messed up and branched from `master` in my fork by mistake, and in any case I'm definitely out of sync with your `develop`. Do you have a preferred workflow to bring my branch up to date, i.e. to minimize the mess in the Git history? (Despite using Git daily I'm still not totally sure what ""best practice"" is.). At this point I can at least run a workflow using Postgres, minus call caching. I'm going to be focusing on completing and testing this in the next couple of weeks.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4759#issuecomment-486370402
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518659520:152,Availability,avail,available,152,Is this issue related to problem with deadlocks in `ServicesStoreSpec`?; If this task is still actual I'll appreciate more information about it (if any available).; @gemmalam @danbills,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518659520
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483:287,Performance,load,load,287,"Hi @likeanowl , thanks for your interest. I'm tempted to close this issue. I speculated that there could be contention. However, we have since moved to an isolated process for the summarizer, rendering this issue moot for us. . If you do work on this issue I would focus on developing a load test that can look at whether the thread pool suffers (is under heavy contenion) when under high metadata write load.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483:404,Performance,load,load,404,"Hi @likeanowl , thanks for your interest. I'm tempted to close this issue. I speculated that there could be contention. However, we have since moved to an isolated process for the summarizer, rendering this issue moot for us. . If you do work on this issue I would focus on developing a load test that can look at whether the thread pool suffers (is under heavy contenion) when under high metadata write load.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483:292,Testability,test,test,292,"Hi @likeanowl , thanks for your interest. I'm tempted to close this issue. I speculated that there could be contention. However, we have since moved to an isolated process for the summarizer, rendering this issue moot for us. . If you do work on this issue I would focus on developing a load test that can look at whether the thread pool suffers (is under heavy contenion) when under high metadata write load.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-518674483
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-522923560:192,Integrability,message,messages,192,@danbills Could you give more information about the test cases you see for this issue? I thought about using [gatling-akka](https://github.com/chatwork/gatling-akka) in order to send a lot of messages to `WriteMetadataActor` and `MetadataSummaryRefreshActor`.; Do you thing this approach is suitable for this problem?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-522923560
https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-522923560:52,Testability,test,test,52,@danbills Could you give more information about the test cases you see for this issue? I thought about using [gatling-akka](https://github.com/chatwork/gatling-akka) in order to send a lot of messages to `WriteMetadataActor` and `MetadataSummaryRefreshActor`.; Do you thing this approach is suitable for this problem?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4762#issuecomment-522923560
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-475637417:42,Safety,abort,abort,42,AC: Investigate the root cause of why the abort endpoint occasionally returns a 404 in production.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-475637417
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478633097:81,Deployability,update,updates,81,"Oh great! Is the root cause of that behavior known, why sometimes workflow store updates but not workflow metadata? Or is it just that the workflow metadata update fails, and we know why?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478633097
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478633097:157,Deployability,update,update,157,"Oh great! Is the root cause of that behavior known, why sometimes workflow store updates but not workflow metadata? Or is it just that the workflow metadata update fails, and we know why?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478633097
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478634137:72,Deployability,update,updates,72,"I don't know. I usually mentally bundle that into the general ""metadata updates get missed"" issue but that doesn't really answer the ""root cause"" question.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-478634137
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-482741999:147,Safety,abort,aborting,147,"@cjllanwarne that's a great point. This should be super test-able as well to see if its easy to recreate. I also wonder if we can see a ""spike"" of aborting workflow states after a restart in grafana -- not sure if that's actually feasible?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-482741999
https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-482741999:56,Testability,test,test-able,56,"@cjllanwarne that's a great point. This should be super test-able as well to see if its easy to recreate. I also wonder if we can see a ""spike"" of aborting workflow states after a restart in grafana -- not sure if that's actually feasible?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4767#issuecomment-482741999
https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497:921,Availability,failure,failures,921,"TOL and assuming the investigation requested above confirms it would be helpful:. The current blacklisting implementation asks ""did a read from this source bucket result in a 403?"" If the answer is no, Cromwell tries to copy from that source bucket at full blast. However if Cromwell's first attempts to read from that source bucket do in fact result in 403s, there can be a large number of failed copies before blacklisting kicks in. One possibility would be modifying the question to ""what is the status of this source bucket with respect to 403s?"" with valid responses of ""known good"", ""known bad"" and ""I don't know"". . For ""I don't know"" Cromwell could be more cautious in its handling of that source bucket and launch a single ""canary"" copy attempt. Based on the result of that canary attempt Cromwell could choose ""known good"" or ""known bad"" and blacklisting could proceed the same as it does today with fewer copy failures.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497
https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497:733,Deployability,canary,canary,733,"TOL and assuming the investigation requested above confirms it would be helpful:. The current blacklisting implementation asks ""did a read from this source bucket result in a 403?"" If the answer is no, Cromwell tries to copy from that source bucket at full blast. However if Cromwell's first attempts to read from that source bucket do in fact result in 403s, there can be a large number of failed copies before blacklisting kicks in. One possibility would be modifying the question to ""what is the status of this source bucket with respect to 403s?"" with valid responses of ""known good"", ""known bad"" and ""I don't know"". . For ""I don't know"" Cromwell could be more cautious in its handling of that source bucket and launch a single ""canary"" copy attempt. Based on the result of that canary attempt Cromwell could choose ""known good"" or ""known bad"" and blacklisting could proceed the same as it does today with fewer copy failures.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497
https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497:783,Deployability,canary,canary,783,"TOL and assuming the investigation requested above confirms it would be helpful:. The current blacklisting implementation asks ""did a read from this source bucket result in a 403?"" If the answer is no, Cromwell tries to copy from that source bucket at full blast. However if Cromwell's first attempts to read from that source bucket do in fact result in 403s, there can be a large number of failed copies before blacklisting kicks in. One possibility would be modifying the question to ""what is the status of this source bucket with respect to 403s?"" with valid responses of ""known good"", ""known bad"" and ""I don't know"". . For ""I don't know"" Cromwell could be more cautious in its handling of that source bucket and launch a single ""canary"" copy attempt. Based on the result of that canary attempt Cromwell could choose ""known good"" or ""known bad"" and blacklisting could proceed the same as it does today with fewer copy failures.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4768#issuecomment-475667497
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-476677441:99,Availability,failure,failure,99,"This is a regression-- we should have a centaur test case that goes through this scenario, so this failure is surprising and worth investigating.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-476677441
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-476677441:48,Testability,test,test,48,"This is a regression-- we should have a centaur test case that goes through this scenario, so this failure is surprising and worth investigating.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-476677441
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477128999:33,Availability,error,errors,33,My workflows are running without errors now.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477128999
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804:418,Availability,error,error,418,"Learned that a change in Pipelines API omitted the ""preemptible"" key from the operations metadata, and that change introduced a null pointer in the Cromwell code. . AC: As a way to address this, it would be great if we could modify the Cromwell code so that when its parsing operation metadata, that if certain keys are missing (such as Preemptible) -- we use the defaults where possible, else fail gracefully with an error that states which information couldn't be parsed, and that caused the workflow to fail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804:25,Deployability,Pipeline,Pipelines,25,"Learned that a change in Pipelines API omitted the ""preemptible"" key from the operations metadata, and that change introduced a null pointer in the Cromwell code. . AC: As a way to address this, it would be great if we could modify the Cromwell code so that when its parsing operation metadata, that if certain keys are missing (such as Preemptible) -- we use the defaults where possible, else fail gracefully with an error that states which information couldn't be parsed, and that caused the workflow to fail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804
https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804:0,Usability,Learn,Learned,0,"Learned that a change in Pipelines API omitted the ""preemptible"" key from the operations metadata, and that change introduced a null pointer in the Cromwell code. . AC: As a way to address this, it would be great if we could modify the Cromwell code so that when its parsing operation metadata, that if certain keys are missing (such as Preemptible) -- we use the defaults where possible, else fail gracefully with an error that states which information couldn't be parsed, and that caused the workflow to fail.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4772#issuecomment-477169804
https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-477174761:300,Integrability,Protocol,Protocol,300,"Sayeth Aaron,; >(1) The way the APIs (all Google Cloud APIs, in theory) work is that any *default* value is omitted. So there isn't really a list: any field that has the default value would be omitted. >(2) The default values are the 'zero' values for the primitive types. This is an artifact of the Protocol Buffer to JSON conversion: https://developers.google.com/protocol-buffers/docs/proto3#json",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-477174761
https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-477174761:366,Integrability,protocol,protocol-buffers,366,"Sayeth Aaron,; >(1) The way the APIs (all Google Cloud APIs, in theory) work is that any *default* value is omitted. So there isn't really a list: any field that has the default value would be omitted. >(2) The default values are the 'zero' values for the primitive types. This is an artifact of the Protocol Buffer to JSON conversion: https://developers.google.com/protocol-buffers/docs/proto3#json",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-477174761
https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-486406119:126,Availability,avail,available,126,"I assigned this to myself 12 (!) days ago but haven't started, I am taking this as an indication I am busy and should make it available for others to pick up",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4774#issuecomment-486406119
https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-477831107:52,Availability,avail,available,52,"Also is there any way to actually enumerate all the available settings? Probably this would be too many, and modifying some of them would break the system. Still it is nice to have, and I have tried searching for this 'inbuilt' defaults file in vain. I guess it is scattered across many java files.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-477831107
https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687:126,Availability,avail,available,126,"@EvanTheB `reference.conf` is the configuration file used by Cromwell.; > Also is there any way to actually enumerate all the available settings?. I am not sure how we can do that. But you are right, it might be a lot of effort to restructure/modify those files to be able to enumerate it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687
https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687:34,Deployability,configurat,configuration,34,"@EvanTheB `reference.conf` is the configuration file used by Cromwell.; > Also is there any way to actually enumerate all the available settings?. I am not sure how we can do that. But you are right, it might be a lot of effort to restructure/modify those files to be able to enumerate it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687
https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687:34,Modifiability,config,configuration,34,"@EvanTheB `reference.conf` is the configuration file used by Cromwell.; > Also is there any way to actually enumerate all the available settings?. I am not sure how we can do that. But you are right, it might be a lot of effort to restructure/modify those files to be able to enumerate it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776#issuecomment-478589687
https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579:512,Modifiability,config,config,512,"Hi, look at the [`database.db` stanza](https://github.com/broadinstitute/cromwell/blob/40a0608a629976aca75ddf7f7adafc0fbe8bb399/cromwell.examples.conf#L800):. You want to set the following:; ```; database.db {; numThreads =20; minThreads = 20; maxThreads =20; minConnections = 20; maxConnections = 20; }; ```. For reference and guidance on these nubmers, [look at the `forConfig` Docs for Slick](http://slick.lightbend.com/doc/3.2.3/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(path:String,config:com.typesafe.config.Config,driver:java.sql.Driver,classLoader:ClassLoader):JdbcBackend.this.Database).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579
https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579:532,Modifiability,config,config,532,"Hi, look at the [`database.db` stanza](https://github.com/broadinstitute/cromwell/blob/40a0608a629976aca75ddf7f7adafc0fbe8bb399/cromwell.examples.conf#L800):. You want to set the following:; ```; database.db {; numThreads =20; minThreads = 20; maxThreads =20; minConnections = 20; maxConnections = 20; }; ```. For reference and guidance on these nubmers, [look at the `forConfig` Docs for Slick](http://slick.lightbend.com/doc/3.2.3/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(path:String,config:com.typesafe.config.Config,driver:java.sql.Driver,classLoader:ClassLoader):JdbcBackend.this.Database).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579
https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579:539,Modifiability,Config,Config,539,"Hi, look at the [`database.db` stanza](https://github.com/broadinstitute/cromwell/blob/40a0608a629976aca75ddf7f7adafc0fbe8bb399/cromwell.examples.conf#L800):. You want to set the following:; ```; database.db {; numThreads =20; minThreads = 20; maxThreads =20; minConnections = 20; maxConnections = 20; }; ```. For reference and guidance on these nubmers, [look at the `forConfig` Docs for Slick](http://slick.lightbend.com/doc/3.2.3/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(path:String,config:com.typesafe.config.Config,driver:java.sql.Driver,classLoader:ClassLoader):JdbcBackend.this.Database).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579
https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579:328,Usability,guid,guidance,328,"Hi, look at the [`database.db` stanza](https://github.com/broadinstitute/cromwell/blob/40a0608a629976aca75ddf7f7adafc0fbe8bb399/cromwell.examples.conf#L800):. You want to set the following:; ```; database.db {; numThreads =20; minThreads = 20; maxThreads =20; minConnections = 20; maxConnections = 20; }; ```. For reference and guidance on these nubmers, [look at the `forConfig` Docs for Slick](http://slick.lightbend.com/doc/3.2.3/api/index.html#slick.jdbc.JdbcBackend$DatabaseFactoryDef@forConfig(path:String,config:com.typesafe.config.Config,driver:java.sql.Driver,classLoader:ClassLoader):JdbcBackend.this.Database).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4777#issuecomment-478074579
https://github.com/broadinstitute/cromwell/issues/4780#issuecomment-478984741:181,Deployability,configurat,configuration,181,Highly related to the [summarizer and worker Cromwell](https://github.com/broadinstitute/cromwell/issues/4781) issue and probably a better place to start since this is our existing configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4780#issuecomment-478984741
https://github.com/broadinstitute/cromwell/issues/4780#issuecomment-478984741:181,Modifiability,config,configuration,181,Highly related to the [summarizer and worker Cromwell](https://github.com/broadinstitute/cromwell/issues/4781) issue and probably a better place to start since this is our existing configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4780#issuecomment-478984741
https://github.com/broadinstitute/cromwell/pull/4789#issuecomment-479653436:212,Safety,safe,safe,212,"@cjllanwarne regarding merges to master, there indeed was a merge of the grammar change for call blocks. The new parser worked just fine without the associated Cromwell changes, which is proof that the bugfix is safe with respect to WDL implementations.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4789#issuecomment-479653436
https://github.com/broadinstitute/cromwell/pull/4789#issuecomment-479662249:72,Safety,sanity check,sanity check,72,A quick conflict resolve in IntellIJ took care of things very nicely. A sanity check is that the parser on this branch contains references to both `$call_brace_block` and `(?<!\\\\)`,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4789#issuecomment-479662249
https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479609606:45,Testability,test,test,45,Are we at a point where we can add a centaur test for call caching in AWS?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479609606
https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479618819:61,Testability,test,tests,61,@cjllanwarne did you not see the set of call caching centaur tests which were enabled by this PR?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479618819
https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479620382:84,Testability,test,test,84,"@cjllanwarne I admittedly didn't turn on the ones which would require a specialized test (i.e. involves S3) even though I believe they should now work. I was going to follow that up later on, mainly being lazy about getting the files in appropriate places",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4790#issuecomment-479620382
https://github.com/broadinstitute/cromwell/pull/4797#issuecomment-480071598:588,Modifiability,variab,variable,588,"@cjllanwarne @kshakir woah I didn't know about this! I've fixed the script per the spellcheck output and addressed its points below:. ```bash; docker_subbed=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); singularity_image=${cwd}/$docker_subbed.sif. if [ ! -f ""$singularity_image"" ]; then; singularity pull ""$singularity_image"" docker://${docker}; fi; ```. ![image](https://user-images.githubusercontent.com/22381693/55589465-01d7ec80-577c-11e9-8800-ddbcff440138.png). Addressing each point separately:; - [SC2001](https://github.com/koalaman/shellcheck/wiki/SC2001): I can't use the `${variable//search/replace}` syntax as Cromwell parses this expression and rejects the config as it would try to execute this when generating the block.; - [SC2154](https://github.com/koalaman/shellcheck/wiki/SC2154): `docker` and `cwd` are substituted by Cromwell.; - [SC2086](https://github.com/koalaman/shellcheck/wiki/SC2086): Similar to above, this is substituted into a string, so not needed at runtime. Which results in something like this:; ```bash; # Build the Docker image into a singularity image; docker_subbed=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< quay.io/biocontainers/cutadapt@sha256:8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24); singularity_image=/path/to/cromwell-executions/whole_genome_germline/47077714-9e90-49a6-91b6-902297b443ce/call-s1_alignsortedbam/shard-0/alignsortedbam/a8d7227b-20cf-4997-adf5-c1401d2eeb1f/call-cutadapt/$docker_subbed.sif. if [ ! -f ""$singularity_image"" ]; then; singularity pull ""$singularity_image"" docker://quay.io/biocontainers/cutadapt@sha256:8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24; fi; ```. Which leaves `$singularity_image` with the value ; ```; /path/to/cromwell-executions/my_wf/$exec_id/etc/cutadapt/quay.io_biocontainers_cutadapt_sha256_8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24.sif; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4797#issuecomment-480071598
https://github.com/broadinstitute/cromwell/pull/4797#issuecomment-480071598:673,Modifiability,config,config,673,"@cjllanwarne @kshakir woah I didn't know about this! I've fixed the script per the spellcheck output and addressed its points below:. ```bash; docker_subbed=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); singularity_image=${cwd}/$docker_subbed.sif. if [ ! -f ""$singularity_image"" ]; then; singularity pull ""$singularity_image"" docker://${docker}; fi; ```. ![image](https://user-images.githubusercontent.com/22381693/55589465-01d7ec80-577c-11e9-8800-ddbcff440138.png). Addressing each point separately:; - [SC2001](https://github.com/koalaman/shellcheck/wiki/SC2001): I can't use the `${variable//search/replace}` syntax as Cromwell parses this expression and rejects the config as it would try to execute this when generating the block.; - [SC2154](https://github.com/koalaman/shellcheck/wiki/SC2154): `docker` and `cwd` are substituted by Cromwell.; - [SC2086](https://github.com/koalaman/shellcheck/wiki/SC2086): Similar to above, this is substituted into a string, so not needed at runtime. Which results in something like this:; ```bash; # Build the Docker image into a singularity image; docker_subbed=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< quay.io/biocontainers/cutadapt@sha256:8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24); singularity_image=/path/to/cromwell-executions/whole_genome_germline/47077714-9e90-49a6-91b6-902297b443ce/call-s1_alignsortedbam/shard-0/alignsortedbam/a8d7227b-20cf-4997-adf5-c1401d2eeb1f/call-cutadapt/$docker_subbed.sif. if [ ! -f ""$singularity_image"" ]; then; singularity pull ""$singularity_image"" docker://quay.io/biocontainers/cutadapt@sha256:8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24; fi; ```. Which leaves `$singularity_image` with the value ; ```; /path/to/cromwell-executions/my_wf/$exec_id/etc/cutadapt/quay.io_biocontainers_cutadapt_sha256_8799129dfef6de4e0503e8f2c20acafdf261793cc392f312d84df8016bfeef24.sif; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4797#issuecomment-480071598
https://github.com/broadinstitute/cromwell/issues/4798#issuecomment-492413869:123,Deployability,deploy,deploy-horicromtal,123,"Filed https://broadinstitute.atlassian.net/browse/DSPTO-710. After a discussion with our devops representatives in channel deploy-horicromtal, I cut the autoscaling part for now because managed instance groups don't work in our env for reasons I don't fully understand (and can certainly be revisited later!)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4798#issuecomment-492413869
https://github.com/broadinstitute/cromwell/issues/4800#issuecomment-484262549:31,Deployability,upgrade,upgrade,31,"Sayeth @mcovarr: ; >The engine upgrade already has a horicromtal test, with some very recent bugfixes :wink:; so I think #4800 can be closed too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4800#issuecomment-484262549
https://github.com/broadinstitute/cromwell/issues/4800#issuecomment-484262549:65,Testability,test,test,65,"Sayeth @mcovarr: ; >The engine upgrade already has a horicromtal test, with some very recent bugfixes :wink:; so I think #4800 can be closed too",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4800#issuecomment-484262549
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597:33,Availability,error,error,33,"@kshakir helpfully notes:; >That error looks like JNI, that I suspect is jython related, thus is probably heterodon. Heterodon was slimmed down to remove everything NOT tested via mac and/or CI. So since we don’t have any :travis: / :jenkins: testing windows I would not expect heterodon to work. Good news (?): we still support shell invoking `cwltool`, but I have zero expectation for that to work on windows either... So this behavior is likely the result of a deliberate and helpful size optimization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597:139,Availability,down,down,139,"@kshakir helpfully notes:; >That error looks like JNI, that I suspect is jython related, thus is probably heterodon. Heterodon was slimmed down to remove everything NOT tested via mac and/or CI. So since we don’t have any :travis: / :jenkins: testing windows I would not expect heterodon to work. Good news (?): we still support shell invoking `cwltool`, but I have zero expectation for that to work on windows either... So this behavior is likely the result of a deliberate and helpful size optimization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597:492,Performance,optimiz,optimization,492,"@kshakir helpfully notes:; >That error looks like JNI, that I suspect is jython related, thus is probably heterodon. Heterodon was slimmed down to remove everything NOT tested via mac and/or CI. So since we don’t have any :travis: / :jenkins: testing windows I would not expect heterodon to work. Good news (?): we still support shell invoking `cwltool`, but I have zero expectation for that to work on windows either... So this behavior is likely the result of a deliberate and helpful size optimization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597:169,Testability,test,tested,169,"@kshakir helpfully notes:; >That error looks like JNI, that I suspect is jython related, thus is probably heterodon. Heterodon was slimmed down to remove everything NOT tested via mac and/or CI. So since we don’t have any :travis: / :jenkins: testing windows I would not expect heterodon to work. Good news (?): we still support shell invoking `cwltool`, but I have zero expectation for that to work on windows either... So this behavior is likely the result of a deliberate and helpful size optimization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597:243,Testability,test,testing,243,"@kshakir helpfully notes:; >That error looks like JNI, that I suspect is jython related, thus is probably heterodon. Heterodon was slimmed down to remove everything NOT tested via mac and/or CI. So since we don’t have any :travis: / :jenkins: testing windows I would not expect heterodon to work. Good news (?): we still support shell invoking `cwltool`, but I have zero expectation for that to work on windows either... So this behavior is likely the result of a deliberate and helpful size optimization.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480391597
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480395219:30,Performance,optimiz,optimization,30,"It seems likely that the size optimization was made independent of knowing how completely and utterly borked Cromwell becomes (unable to run WDLs!), so I still feel that a pass of PO input is valuable.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-480395219
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720:377,Availability,Error,Error,377,"Here is the size optimization that deletes untested jython files:. https://github.com/broadinstitute/heterodon/blob/b54010d4f1fe9395f854ab62e4b66c203bf3f45d/build.sh#L82-L84. If we come up with a CI regression case for Windows (x64?) then the appropriate files could be excluded from the filter and tested. Re: the borked Cromwell, we could catch-and-box the thrown `java.lang.Error` into a `java.lang.Exception` and Cromwell would handle this particular error more gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720:455,Availability,error,error,455,"Here is the size optimization that deletes untested jython files:. https://github.com/broadinstitute/heterodon/blob/b54010d4f1fe9395f854ab62e4b66c203bf3f45d/build.sh#L82-L84. If we come up with a CI regression case for Windows (x64?) then the appropriate files could be excluded from the filter and tested. Re: the borked Cromwell, we could catch-and-box the thrown `java.lang.Error` into a `java.lang.Exception` and Cromwell would handle this particular error more gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720:17,Performance,optimiz,optimization,17,"Here is the size optimization that deletes untested jython files:. https://github.com/broadinstitute/heterodon/blob/b54010d4f1fe9395f854ab62e4b66c203bf3f45d/build.sh#L82-L84. If we come up with a CI regression case for Windows (x64?) then the appropriate files could be excluded from the filter and tested. Re: the borked Cromwell, we could catch-and-box the thrown `java.lang.Error` into a `java.lang.Exception` and Cromwell would handle this particular error more gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720
https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720:299,Testability,test,tested,299,"Here is the size optimization that deletes untested jython files:. https://github.com/broadinstitute/heterodon/blob/b54010d4f1fe9395f854ab62e4b66c203bf3f45d/build.sh#L82-L84. If we come up with a CI regression case for Windows (x64?) then the appropriate files could be excluded from the filter and tested. Re: the borked Cromwell, we could catch-and-box the thrown `java.lang.Error` into a `java.lang.Exception` and Cromwell would handle this particular error more gracefully.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4802#issuecomment-481487720
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480345417:52,Deployability,install,install,52,"When you ran into this locally, was the DB a native install or running in Docker?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480345417
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480346756:7,Deployability,install,install,7,Native install,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480346756
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480398885:57,Usability,guid,guide,57,"Perhaps then this would work better in a troubleshooting guide than the ""getting yourself a MySQL database section""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480398885
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:33,Deployability,upgrade,upgrade,33,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:300,Security,password,password,300,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:364,Security,password,password,364,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:613,Security,validat,validated,613,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841
https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841:262,Testability,log,logs,262,"Assigning myself since the MySQL upgrade is the underlying cause. Here is the command sequence I use to create a new local DB for use by a fresh, totally default Cromwell checkout.; ```; docker run --name=mysql1 -p 3306:3306 -d mysql/mysql-server:latest; docker logs mysql1 # copy the auto generated password; docker exec -it mysql1 mysql -uroot -p # paste in the password from the previous stpe; ALTER USER 'root'@'localhost' IDENTIFIED BY '';; CREATE database cromwell_test;; CREATE USER 'root'@'%' IDENTIFIED BY '';; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;; FLUSH PRIVILEGES;; ```; I just validated it still works with recent versions, so it seems my theory about Docker using UTC is correct.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4803#issuecomment-480417841
https://github.com/broadinstitute/cromwell/pull/4804#issuecomment-480908247:60,Testability,test,test,60,"I noticed that the issue actually did inspire a conformance test, so I'm going to check out whether we can get credit for it now. https://github.com/common-workflow-language/common-workflow-language/pull/787",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4804#issuecomment-480908247
https://github.com/broadinstitute/cromwell/pull/4804#issuecomment-481005372:29,Testability,test,test,29,"Disappointingly, conformance test #135, the packed CWL one, is failing",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4804#issuecomment-481005372
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:12,Modifiability,config,config,12,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:502,Modifiability,rewrite,rewriteBatchedStatements,502,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:902,Modifiability,config,config,902,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:920,Modifiability,config,configure,920,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:1192,Modifiability,config,config,1192,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:191,Performance,cache,cache,191,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:312,Performance,cache,cache-results,312,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:1536,Performance,queue,queueArn,1536,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:1579,Performance,queue,queue,1579,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:186,Security,hash,hash-cache,186,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020:561,Security,password,password,561,"Here is the config file used for the above. ```; ﻿include required(classpath(""application"")). ""workflow_failure_mode"": ""ContinueWhilePossible"". webservice {; port = 2525; }. system.file-hash-cache=true. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; # driver = ""com.mysql.jdbc.Driver""; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://xxxxxx:xxxx/xxx?rewriteBatchedStatements=true&useSSL=false""; user = ""xxx""; password = ""xxx""; connectionTimeout = 120000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xx:role/xxx""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; }; engine {; filesystems {; s3 {; auth = ""assume-role-based-on-another""; }; }; }; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; // Base bucket for workflow executions; root = ""s3://xxx/cromwell-output""; // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""default""; // diff 2:; numSubmitAttempts = 1; // diff 3:; numCreateDefinitionAttempts = 1; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-west-2:xxx:job-queue/xxx""; }; filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }; }; }; }; }. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805#issuecomment-480408020
https://github.com/broadinstitute/cromwell/issues/4806#issuecomment-616204371:133,Deployability,pipeline,pipeline,133,Hello @salonishah11 @cjllanwarne . It is currently not possible to mention networks from different GCP project(not the project where pipeline is running). PAPIv2 is accepting networks from from another project as well if we mention the value as; projects/PROJECT_ID_DIFFERENT_FROM_PIPELINE/global/networks/NETWORK_NAME. I know it is not possible to mention whole network using labels in project. Any chance this can be included google backend?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4806#issuecomment-616204371
https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379:14,Availability,error,error,14,"Confirmed the error is improved in v39:. Looks similar to this. ; ```""message"": ""Task exceed_disk_size.simple_localize_and_fetch_size:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Please check the log file for more details: gs://ss_cromwell_bucket/cromwell-execution/exceed_disk_size/d142f233-f72a-40a6-9f84-8b8a2ead32e7/call-simple_localize_and_fetch_size/simple_localize_and_fetch_size.log.""```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379
https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379:201,Availability,error,error,201,"Confirmed the error is improved in v39:. Looks similar to this. ; ```""message"": ""Task exceed_disk_size.simple_localize_and_fetch_size:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Please check the log file for more details: gs://ss_cromwell_bucket/cromwell-execution/exceed_disk_size/d142f233-f72a-40a6-9f84-8b8a2ead32e7/call-simple_localize_and_fetch_size/simple_localize_and_fetch_size.log.""```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379
https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379:70,Integrability,message,message,70,"Confirmed the error is improved in v39:. Looks similar to this. ; ```""message"": ""Task exceed_disk_size.simple_localize_and_fetch_size:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Please check the log file for more details: gs://ss_cromwell_bucket/cromwell-execution/exceed_disk_size/d142f233-f72a-40a6-9f84-8b8a2ead32e7/call-simple_localize_and_fetch_size/simple_localize_and_fetch_size.log.""```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379
https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379:232,Testability,log,log,232,"Confirmed the error is improved in v39:. Looks similar to this. ; ```""message"": ""Task exceed_disk_size.simple_localize_and_fetch_size:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Please check the log file for more details: gs://ss_cromwell_bucket/cromwell-execution/exceed_disk_size/d142f233-f72a-40a6-9f84-8b8a2ead32e7/call-simple_localize_and_fetch_size/simple_localize_and_fetch_size.log.""```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379
https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379:423,Testability,log,log,423,"Confirmed the error is improved in v39:. Looks similar to this. ; ```""message"": ""Task exceed_disk_size.simple_localize_and_fetch_size:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Please check the log file for more details: gs://ss_cromwell_bucket/cromwell-execution/exceed_disk_size/d142f233-f72a-40a6-9f84-8b8a2ead32e7/call-simple_localize_and_fetch_size/simple_localize_and_fetch_size.log.""```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4809#issuecomment-480981379
https://github.com/broadinstitute/cromwell/pull/4811#issuecomment-481412176:12,Usability,clear,clearly,12,"@aednichols clearly, ; > it results from confusion between Latin cedere (“give up, yield”) and sedere (“to sit”). and not just ""oops, typo""... (cf: https://en.wiktionary.org/wiki/supercede#English)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4811#issuecomment-481412176
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286:67,Testability,test,tests,67,"@cjllanwarne Thanks for your extensive information on how to write tests. I would love to have written a test, but I could not find anything related in `engine/src/test` and I indeed have no experience with centaur. I will write a test right away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286:105,Testability,test,test,105,"@cjllanwarne Thanks for your extensive information on how to write tests. I would love to have written a test, but I could not find anything related in `engine/src/test` and I indeed have no experience with centaur. I will write a test right away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286:164,Testability,test,test,164,"@cjllanwarne Thanks for your extensive information on how to write tests. I would love to have written a test, but I could not find anything related in `engine/src/test` and I indeed have no experience with centaur. I will write a test right away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286:231,Testability,test,test,231,"@cjllanwarne Thanks for your extensive information on how to write tests. I would love to have written a test, but I could not find anything related in `engine/src/test` and I indeed have no experience with centaur. I will write a test right away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-481624286
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482021138:42,Availability,error,errors,42,"@mcovarr , @cjllanwarne . ~~Sorry for the errors still. I want to test locally of course, but that does not work for some reason:~~; EDIT: Nevermind. I found the documentation here: https://cromwell.readthedocs.io/en/stable/developers/Centaur/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482021138
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482021138:66,Testability,test,test,66,"@mcovarr , @cjllanwarne . ~~Sorry for the errors still. I want to test locally of course, but that does not work for some reason:~~; EDIT: Nevermind. I found the documentation here: https://cromwell.readthedocs.io/en/stable/developers/Centaur/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482021138
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914:51,Testability,test,test,51,"@cjllanwarne .The `relative_output_paths_colliding.test` will report a succeeded workflow, but cromwell will exit with non-zero status because of the copying. This means that `metadata {status: Failed}` is not entirely correct in this case. (Which makes the CI tests fail).; Is there a way to test the cromwell exit code in centaur?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914:261,Testability,test,tests,261,"@cjllanwarne .The `relative_output_paths_colliding.test` will report a succeeded workflow, but cromwell will exit with non-zero status because of the copying. This means that `metadata {status: Failed}` is not entirely correct in this case. (Which makes the CI tests fail).; Is there a way to test the cromwell exit code in centaur?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914:293,Testability,test,test,293,"@cjllanwarne .The `relative_output_paths_colliding.test` will report a succeeded workflow, but cromwell will exit with non-zero status because of the copying. This means that `metadata {status: Failed}` is not entirely correct in this case. (Which makes the CI tests fail).; Is there a way to test the cromwell exit code in centaur?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482033914
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482345386:198,Availability,failure,failure,198,"@rhpvorderman oh, I didn't notice your comment about the tests in my re-review. Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code. Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482345386
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482345386:57,Testability,test,tests,57,"@rhpvorderman oh, I didn't notice your comment about the tests in my re-review. Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code. Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482345386
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:121,Availability,failure,failure,121,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:551,Availability,failure,failure,551,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:681,Availability,error,error,681,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:825,Availability,error,error,825,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:687,Integrability,message,message,687,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:831,Integrability,message,message,831,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:361,Testability,test,tests,361,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:582,Testability,test,testing,582,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:630,Testability,test,tests,630,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:698,Testability,test,tested,698,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:755,Testability,test,test,755,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:941,Testability,test,tests,941,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:969,Testability,test,tested,969,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:1012,Testability,test,test,1012,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:1090,Testability,test,tested,1090,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876:1121,Testability,test,tests,1121,"> Hmm, that's an interesting problem - since centaur runs in server mode I don't think you'd see an exit code.; Does any failure data end up in Cromwell's metadata when this copy fails? If so, centaur can query for the metadata entry. @cjllanwarne I found the problem. I did not have a `final_workflow_outputs_dir` set in the options.json files for the centaur tests. If this path is not set `use_relative_output_paths` is of course not used... :man_facepalming: That is fixed now and it works as expected. Colliding outputs will return as a workflow failure. Since I got the local testing working I was able to add more advanced tests and make sure these are correct as well. The error message is tested when the outputs are colliding. In order for that test to work I had to make the output order of colliding paths in the error message deterministic. (Otherwise it would fail randomly). Also my colleague @DavyCats showed me some centaur tests were file outputs are tested. I used these as an example to also test for the outputs. ; All the behavior that this PR affects is now properly tested, which means that these tests should be able to discover regressions in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4815#issuecomment-482492876
https://github.com/broadinstitute/cromwell/issues/4818#issuecomment-481815773:73,Deployability,update,update,73,"Thanks for looking into it! Closing this spike as its complete, and will update the respective issue with the proposed solution.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4818#issuecomment-481815773
https://github.com/broadinstitute/cromwell/issues/4820#issuecomment-481837931:335,Usability,UX,UX,335,"The ""scatterAtxyz""s refer to implicit subworkflows that Cromwell creates to allow nested scatters (previously our only answer was ""write your own sub-workflow with the scatter in it). To find the call level data you'd go to the awkwardly-named subworkflow and expand it, just like any other subworkflow in a scatter. I agree there's a UX gap here - maybe our tooling can be smart and re-collapse the ""scatterAtxyz"" subworkflow into the same scope as the original workflow's calls?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4820#issuecomment-481837931
https://github.com/broadinstitute/cromwell/issues/4820#issuecomment-481838405:167,Usability,clear,clear,167,"I think it would be nice to be able to name a scatter. If I could `scatter (foo in bar) as baz { ... }` and have `baz` be what we see in metadata and timing, it would clear up a lot of confusion. Falling back to `line_char` would be ok if there's at least the option to specify a name.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4820#issuecomment-481838405
https://github.com/broadinstitute/cromwell/pull/4823#issuecomment-482727793:95,Availability,failure,failures,95,"Just in time for thumbs to come in, I'm realizing that I rather blindly added `55` to expected failures when in fact there is a chance I broke it. Investigating...",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4823#issuecomment-482727793
https://github.com/broadinstitute/cromwell/pull/4823#issuecomment-484288758:27,Deployability,update,update,27,Figured out that I need to update the contents of `gs://centaur-cwl-conformance` to match the latest commit,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4823#issuecomment-484288758
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-485466032:146,Availability,resilien,resilient,146,Are we ok to unilaterally make these changes? Are agora and rawls already building out functionality based on our existing behavior? Will they be resilient to us making these changes?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-485466032
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685:131,Availability,error,error,131,"Refinement update:. We are going to solve the first two points by adding a sort of `input_errors` map with input names as keys and error(s) as values. The absence of `errors` and presence of `input_errors` indicates the DA case where WDL is good and inputs bad. ~The last issue will split off into soliciting community feedback from non-workbench users and writing a nicer wrapper endpoint that's more compatible with curl (it is Adam's opinion, potentailly poorly supported, that this is hard right now)~ see https://github.com/broadinstitute/cromwell/issues/4892",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685:167,Availability,error,errors,167,"Refinement update:. We are going to solve the first two points by adding a sort of `input_errors` map with input names as keys and error(s) as values. The absence of `errors` and presence of `input_errors` indicates the DA case where WDL is good and inputs bad. ~The last issue will split off into soliciting community feedback from non-workbench users and writing a nicer wrapper endpoint that's more compatible with curl (it is Adam's opinion, potentailly poorly supported, that this is hard right now)~ see https://github.com/broadinstitute/cromwell/issues/4892",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685:11,Deployability,update,update,11,"Refinement update:. We are going to solve the first two points by adding a sort of `input_errors` map with input names as keys and error(s) as values. The absence of `errors` and presence of `input_errors` indicates the DA case where WDL is good and inputs bad. ~The last issue will split off into soliciting community feedback from non-workbench users and writing a nicer wrapper endpoint that's more compatible with curl (it is Adam's opinion, potentailly poorly supported, that this is hard right now)~ see https://github.com/broadinstitute/cromwell/issues/4892",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685:373,Integrability,wrap,wrapper,373,"Refinement update:. We are going to solve the first two points by adding a sort of `input_errors` map with input names as keys and error(s) as values. The absence of `errors` and presence of `input_errors` indicates the DA case where WDL is good and inputs bad. ~The last issue will split off into soliciting community feedback from non-workbench users and writing a nicer wrapper endpoint that's more compatible with curl (it is Adam's opinion, potentailly poorly supported, that this is hard right now)~ see https://github.com/broadinstitute/cromwell/issues/4892",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685
https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685:319,Usability,feedback,feedback,319,"Refinement update:. We are going to solve the first two points by adding a sort of `input_errors` map with input names as keys and error(s) as values. The absence of `errors` and presence of `input_errors` indicates the DA case where WDL is good and inputs bad. ~The last issue will split off into soliciting community feedback from non-workbench users and writing a nicer wrapper endpoint that's more compatible with curl (it is Adam's opinion, potentailly poorly supported, that this is hard right now)~ see https://github.com/broadinstitute/cromwell/issues/4892",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4824#issuecomment-486342685
https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-495405207:34,Deployability,update,updated,34,👍 👍 👍 ; Thanks so much! I've just updated my system with the latest Cromwell and this is perfect,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-495405207
https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533:1206,Availability,Error,Error,1206,"I need this ability to label Google VMs for resource tracking, but have been thus far unable to have a VM labelled correctly. The jobs submit and run, but the labels do not show up. . From the documentation here (https://cromwell.readthedocs.io/en/develop/wf_options/Google/), it's not clear where the google-specific options are added, so I tried the following: ; ```; {; ""default_runtime_attributes"":{; ""zones"":""us-east1-b"", ; ""google_labels"": {""custom-label"":""custom-value""}; }; }; ```; I submit (Cromwell v42) with:; ```; curl -X POST ""<CROMWELL URL>/api/workflows/v1"" \; -H ""accept: application/json"" \; -H ""Content-Type: multipart/form-data"" \; -F ""workflowSource=@main.wdl"" ; -F ""workflowInputs=@inputs.json"" \; -F ""workflowOptions=@options.json"" \; -F ""workflowType=WDL"" \; -F ""workflowTypeVersion=draft-2""; ```. That submits/runs fine, but when I check the VM that spins up, I only see the two labels of `cromwell-workflow-id` and `wdl-task-name`. If I change the options JSON to anything else, e.g.; ```; {; ""default_runtime_attributes"":{""zones"":""us-east1-b""},; ""google_labels"": {""custom-label"":""custom-value""}; }; ```; then it fails to submit, returning:; ```; {; ""status"": ""fail"",; ""message"": ""Error(s): Invalid workflow options provided: Unsupported key/value pair in WorkflowOptions: google_labels -> {\""custom-label\"":\""custom-value\""}""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533
https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533:1195,Integrability,message,message,1195,"I need this ability to label Google VMs for resource tracking, but have been thus far unable to have a VM labelled correctly. The jobs submit and run, but the labels do not show up. . From the documentation here (https://cromwell.readthedocs.io/en/develop/wf_options/Google/), it's not clear where the google-specific options are added, so I tried the following: ; ```; {; ""default_runtime_attributes"":{; ""zones"":""us-east1-b"", ; ""google_labels"": {""custom-label"":""custom-value""}; }; }; ```; I submit (Cromwell v42) with:; ```; curl -X POST ""<CROMWELL URL>/api/workflows/v1"" \; -H ""accept: application/json"" \; -H ""Content-Type: multipart/form-data"" \; -F ""workflowSource=@main.wdl"" ; -F ""workflowInputs=@inputs.json"" \; -F ""workflowOptions=@options.json"" \; -F ""workflowType=WDL"" \; -F ""workflowTypeVersion=draft-2""; ```. That submits/runs fine, but when I check the VM that spins up, I only see the two labels of `cromwell-workflow-id` and `wdl-task-name`. If I change the options JSON to anything else, e.g.; ```; {; ""default_runtime_attributes"":{""zones"":""us-east1-b""},; ""google_labels"": {""custom-label"":""custom-value""}; }; ```; then it fails to submit, returning:; ```; {; ""status"": ""fail"",; ""message"": ""Error(s): Invalid workflow options provided: Unsupported key/value pair in WorkflowOptions: google_labels -> {\""custom-label\"":\""custom-value\""}""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533
https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533:286,Usability,clear,clear,286,"I need this ability to label Google VMs for resource tracking, but have been thus far unable to have a VM labelled correctly. The jobs submit and run, but the labels do not show up. . From the documentation here (https://cromwell.readthedocs.io/en/develop/wf_options/Google/), it's not clear where the google-specific options are added, so I tried the following: ; ```; {; ""default_runtime_attributes"":{; ""zones"":""us-east1-b"", ; ""google_labels"": {""custom-label"":""custom-value""}; }; }; ```; I submit (Cromwell v42) with:; ```; curl -X POST ""<CROMWELL URL>/api/workflows/v1"" \; -H ""accept: application/json"" \; -H ""Content-Type: multipart/form-data"" \; -F ""workflowSource=@main.wdl"" ; -F ""workflowInputs=@inputs.json"" \; -F ""workflowOptions=@options.json"" \; -F ""workflowType=WDL"" \; -F ""workflowTypeVersion=draft-2""; ```. That submits/runs fine, but when I check the VM that spins up, I only see the two labels of `cromwell-workflow-id` and `wdl-task-name`. If I change the options JSON to anything else, e.g.; ```; {; ""default_runtime_attributes"":{""zones"":""us-east1-b""},; ""google_labels"": {""custom-label"":""custom-value""}; }; ```; then it fails to submit, returning:; ```; {; ""status"": ""fail"",; ""message"": ""Error(s): Invalid workflow options provided: Unsupported key/value pair in WorkflowOptions: google_labels -> {\""custom-label\"":\""custom-value\""}""; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4825#issuecomment-500586533
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:126,Modifiability,config,configured,126,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:7,Security,validat,validated,7,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:26,Testability,log,log,26,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:152,Testability,log,log-temporary,152,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:257,Testability,test,tested,257,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:689,Testability,log,logs,689,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:734,Testability,log,log-temporary,734,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:942,Testability,log,log,942,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1107,Testability,log,logs,1107,"does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1158,Testability,log,log,1158,"nal_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1259,Testability,log,logs,1259,"nal_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1310,Testability,log,log,1310,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1410,Testability,log,logs,1410,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1461,Testability,log,log,1461,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1561,Testability,log,logs,1561,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1612,Testability,log,log,1612,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1712,Testability,log,logs,1712,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1763,Testability,log,log,1763,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1863,Testability,log,logs,1863,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:1914,Testability,log,log,1914,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:2014,Testability,log,logs,2014,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:2065,Testability,log,log,2065,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:2166,Testability,log,logs,2166,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:2217,Testability,log,log,2217,"ow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.43bcbc56-3596-45b7-9f1d-c00dc36defd4.log; java 33951 cromwellbuild 40w REG 8,1 1340 533089 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.5b4c1033-3dfe-470c-bba4-5d31f2120948.log; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273:840,Usability,simpl,simple,840,"I have validated that the log file for each submitted workflow does not get closed when Cromwell is run in server mode and is configured with `workflow-log-temporary: false` and the workflow does not specify the `final_workflow_log_dir` option. I also have tested that Tony's fix above resolves the problem. While using a workflow options file is a workaround, it's not a general solution for debugging failed workflows submitted by users who did not include the options file to begin with. Even worse, the bug results in a file handle leak in Cromwell server. . Repro steps:. ```; # cromwell.conf; include required(classpath(""application"")); workflow-options {; # When true, per workflow logs will be deleted after copying; workflow-log-temporary: false; }; ```. Run: `java -Dconfig.file=cromwell.conf -jar cromwell.jar server` . Submit a simple Hello World .wdl file to /api/workflows (submit a couple times see the leak). We see that many log file handles remain unclosed:; `sudo lsof -p $(pidof java)`. ```; java 33951 cromwellbuild 33w REG 8,1 117 533080 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.11dbb9e7-10e3-48dc-b36f-0b7e35941ce3.log; java 33951 cromwellbuild 34w REG 8,1 1301 525688 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.0ed80fab-afd1-4783-9b27-409b75f0f2f7.log; java 33951 cromwellbuild 35w REG 8,1 117 533081 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.ef428f60-f8c3-4456-a3ea-bea63486881a.log; java 33951 cromwellbuild 36w REG 8,1 117 533085 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.4df4069e-0ef0-43ba-8bfb-37413d7ed229.log; java 33951 cromwellbuild 37w REG 8,1 117 533086 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.48e5c4ff-c067-465d-820b-2b41cb74ef31.log; java 33951 cromwellbuild 38w REG 8,1 117 533087 /home/cromwellbuild/cromwell/cromwell-workflow-logs/workflow.05bcd5a7-3924-4ba0-ab39-57bc09716abb.log; java 33951 cromwellbuild 39w REG 8,1 117 533088 /home/cromwellbuild/cromwell/cromw",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4826#issuecomment-499023273
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865:355,Security,hash,hash,355,"From the docs, emphasis mine:. >After a successful complete request, the parts no longer exist. Your complete multipart upload request must include the upload ID and a list of both part numbers and corresponding ETag values. Amazon S3 response includes an ETag that uniquely identifies the combined object data. **This ETag will not necessarily be an MD5 hash of the object data**. [Source](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html). Thinking out loud: Do we have to recreate the original multipart upload to get the same ETag deterministically? Or otherwise how can we get the combined ETag deterministically?. If not, we can use [UploadPartCopyRequest](http://aws-java-sdk-javadoc.s3-website-us-west-2.amazonaws.com/latest/software/amazon/awssdk/services/s3/model/UploadPartCopyRequest.html) to accomplish this [here](https://github.com/broadinstitute/cromwell/blob/b8aa5e1eee730dcd3edc2c8ff0cf0144127a3208/filesystems/s3/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java#L433). [Example multipart copy using old SDK](https://docs.aws.amazon.com/AmazonS3/latest/dev/CopyingObjctsUsingLLJavaMPUapi.html); [Migration guide from 1.1 to 2.0 (to interpret above in 2.0)](https://github.com/aws/aws-sdk-java-v2/blob/master/docs/LaunchChangelog.md#41-s3-changes)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865:1146,Usability,guid,guide,1146,"From the docs, emphasis mine:. >After a successful complete request, the parts no longer exist. Your complete multipart upload request must include the upload ID and a list of both part numbers and corresponding ETag values. Amazon S3 response includes an ETag that uniquely identifies the combined object data. **This ETag will not necessarily be an MD5 hash of the object data**. [Source](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html). Thinking out loud: Do we have to recreate the original multipart upload to get the same ETag deterministically? Or otherwise how can we get the combined ETag deterministically?. If not, we can use [UploadPartCopyRequest](http://aws-java-sdk-javadoc.s3-website-us-west-2.amazonaws.com/latest/software/amazon/awssdk/services/s3/model/UploadPartCopyRequest.html) to accomplish this [here](https://github.com/broadinstitute/cromwell/blob/b8aa5e1eee730dcd3edc2c8ff0cf0144127a3208/filesystems/s3/src/main/java/org/lerch/s3fs/S3FileSystemProvider.java#L433). [Example multipart copy using old SDK](https://docs.aws.amazon.com/AmazonS3/latest/dev/CopyingObjctsUsingLLJavaMPUapi.html); [Migration guide from 1.1 to 2.0 (to interpret above in 2.0)](https://github.com/aws/aws-sdk-java-v2/blob/master/docs/LaunchChangelog.md#41-s3-changes)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-483794865
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791:294,Testability,log,logic,294,"We've implemented a fix for the Cromwell-side of things to work w/ AWS CLI default settings for S3. These default settings are good for up to 83 GiB. The old limit was 5 GiB. . At 83 GiB the AWS CLI has to alter the default part size from 8 MiB to something larger and it's not clear what that logic is. ## What we want to do from here forward. The proxy should use larger part sizes all the time, ideally the largest part size of 5 GiB. Then w/ AWS limit of 10K parts we have a new limit of ~ 53 TiB. We attempted to alter the proxy to use this part size and set the threshold to 5 GB before using multipart and it broke the proxy. In order to find out what's happening we need to investigate proxy logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791:700,Testability,log,logs,700,"We've implemented a fix for the Cromwell-side of things to work w/ AWS CLI default settings for S3. These default settings are good for up to 83 GiB. The old limit was 5 GiB. . At 83 GiB the AWS CLI has to alter the default part size from 8 MiB to something larger and it's not clear what that logic is. ## What we want to do from here forward. The proxy should use larger part sizes all the time, ideally the largest part size of 5 GiB. Then w/ AWS limit of 10K parts we have a new limit of ~ 53 TiB. We attempted to alter the proxy to use this part size and set the threshold to 5 GB before using multipart and it broke the proxy. In order to find out what's happening we need to investigate proxy logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791:278,Usability,clear,clear,278,"We've implemented a fix for the Cromwell-side of things to work w/ AWS CLI default settings for S3. These default settings are good for up to 83 GiB. The old limit was 5 GiB. . At 83 GiB the AWS CLI has to alter the default part size from 8 MiB to something larger and it's not clear what that logic is. ## What we want to do from here forward. The proxy should use larger part sizes all the time, ideally the largest part size of 5 GiB. Then w/ AWS limit of 10K parts we have a new limit of ~ 53 TiB. We attempted to alter the proxy to use this part size and set the threshold to 5 GB before using multipart and it broke the proxy. In order to find out what's happening we need to investigate proxy logs.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-484685791
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-530844950:284,Usability,clear,clear,284,"I think two things here were premature: ; a) Me saying ""we've implemented"" as the branch was not merged.; b) Marking this ticket as ""Done"" . As this happened 6 months ago, I'm a little hazy on details but as I noted above the code we wrote ""broke the proxy,"" and apparently it wasn't clear why as I noted an investigation is in order. I will do my best to find that branch and surface it here.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-530844950
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241:87,Availability,error,error,87,"Hi is this implemented in the latest version of cromwell? ; I am getting the following error for files > 5G with the latest version . 2019-10-31 04:31:17,243 cromwell-system-akka.dispatchers.engine-dispatcher-32 WARN - 85d92e7d-3017-4e8d-adac-551ebcd50165-EngineJobExecutionActor-jgi_meta.bbcms:NA:1 [UUID(85d92e7d)]: Failed copying cache results for job BackendJobDescriptorKey_CommandCallNode_jgi_meta.bbcms:-1:1 (EnhancedCromwellIoException: [Attempted 1 time(s)] - S3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: 1272B7BFF87110E8)), invalidating cache entry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241:416,Modifiability,Enhance,EnhancedCromwellIoException,416,"Hi is this implemented in the latest version of cromwell? ; I am getting the following error for files > 5G with the latest version . 2019-10-31 04:31:17,243 cromwell-system-akka.dispatchers.engine-dispatcher-32 WARN - 85d92e7d-3017-4e8d-adac-551ebcd50165-EngineJobExecutionActor-jgi_meta.bbcms:NA:1 [UUID(85d92e7d)]: Failed copying cache results for job BackendJobDescriptorKey_CommandCallNode_jgi_meta.bbcms:-1:1 (EnhancedCromwellIoException: [Attempted 1 time(s)] - S3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: 1272B7BFF87110E8)), invalidating cache entry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241:333,Performance,cache,cache,333,"Hi is this implemented in the latest version of cromwell? ; I am getting the following error for files > 5G with the latest version . 2019-10-31 04:31:17,243 cromwell-system-akka.dispatchers.engine-dispatcher-32 WARN - 85d92e7d-3017-4e8d-adac-551ebcd50165-EngineJobExecutionActor-jgi_meta.bbcms:NA:1 [UUID(85d92e7d)]: Failed copying cache results for job BackendJobDescriptorKey_CommandCallNode_jgi_meta.bbcms:-1:1 (EnhancedCromwellIoException: [Attempted 1 time(s)] - S3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: 1272B7BFF87110E8)), invalidating cache entry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241:657,Performance,cache,cache,657,"Hi is this implemented in the latest version of cromwell? ; I am getting the following error for files > 5G with the latest version . 2019-10-31 04:31:17,243 cromwell-system-akka.dispatchers.engine-dispatcher-32 WARN - 85d92e7d-3017-4e8d-adac-551ebcd50165-EngineJobExecutionActor-jgi_meta.bbcms:NA:1 [UUID(85d92e7d)]: Failed copying cache results for job BackendJobDescriptorKey_CommandCallNode_jgi_meta.bbcms:-1:1 (EnhancedCromwellIoException: [Attempted 1 time(s)] - S3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: 1272B7BFF87110E8)), invalidating cache entry.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-548974241
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:189,Modifiability,Config,Configuring,189,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:249,Modifiability,config,configured,249,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:104,Performance,cache,cache,104,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:140,Security,hash,hash,140,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:281,Security,hash,hashing-strategy,281,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:468,Security,hash,hash,468,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:524,Security,hash,hash,524,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:697,Security,hash,hashed,697,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:743,Security,hash,hash,743,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065:857,Security,hash,hashing-strategy,857,"There hasn't unfortunately. This is sort of a desperate thought but maybe you can try to see if you can cache via file path instead of file hash (https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options). I don't know if its configured to work for AWS but ""hashing-strategy"" could be set to path -- though it may only ever work for the local filesystem and not S3. ```; # Possible values: file, path, path+modtime; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here.; # Default: file; hashing-strategy: ""file""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-581915065
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:37,Performance,cache,cacheCopy,37,"Cromwell-59 still has this problem. `cacheCopy` >= 5MB always has a different etag so it effectively disables call-caching due to different etag. ![image](https://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://gi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:773,Performance,cache,cacheCopy,773,"Cromwell-59 still has this problem. `cacheCopy` >= 5MB always has a different etag so it effectively disables call-caching due to different etag. ![image](https://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://gi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:400,Testability,test,test-copy-etag,400,"Cromwell-59 still has this problem. `cacheCopy` >= 5MB always has a different etag so it effectively disables call-caching due to different etag. ![image](https://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://gi",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:1022,Testability,test,test-copy-etag,1022,"ely disables call-caching due to different etag. ![image](https://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://github.com/broadinstitute/cromwell/issues/6327. This bug always fixes the duplication strategy as ",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:1266,Testability,test,test-copy-etag,1266,"tps://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://github.com/broadinstitute/cromwell/issues/6327. This bug always fixes the duplication strategy as `copy`. So call-caching always fails on AWS for files > 5MB.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075:1393,Testability,test,test-copy-etag,1393,"tps://user-images.githubusercontent.com/8625660/119712953-05280980-be16-11eb-8b0b-bdf057f7d2ca.png). So the original file's etag doesn't have `-` in etag (no multipart uploading).; ```; $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:26:37 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""0502111c7c676115303cca9931c2769b\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Tried to copy it to a temp location (mimicking `cacheCopy`).; ```; $ aws s3 cp s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz s3://encode-processing/test-copy-etag/; copy: s3://encode-processing/caper_out_v052521/atac/d249d56c-fcdb-4916-a830-2c191920d877/call-bam2ta/shard-0/glob-199637d3015dccbe277f621a18be9eb4/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz to s3://encode-processing/test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz. $ aws s3api head-object --bucket encode-processing --key test-copy-etag/ENCFF641SFZ.trim.srt.nodup.no_chrM_MT.tn5.tagAlign.gz; {; ""AcceptRanges"": ""bytes"",; ""LastModified"": ""Wed, 26 May 2021 18:27:41 GMT"",; ""ContentLength"": 164184869,; ""ETag"": ""\""a11d42b4abf4ef9d5de40183f25c520b-20\"""",; ""ContentType"": ""binary/octet-stream"",; ""ServerSideEncryption"": ""AES256"",; ""Metadata"": {}; }; ```. Got a different etag which matches with etag of the above snapshot. If `copy` method is used for `s3.caching.duplication-strategy` then call-caching is effectively disabled for all files > 5MB. . There is another bug in AWS backend's `s3.caching.duplication-strategy`.; https://github.com/broadinstitute/cromwell/issues/6327. This bug always fixes the duplication strategy as `copy`. So call-caching always fails on AWS for files > 5MB.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4828#issuecomment-849027075
https://github.com/broadinstitute/cromwell/issues/4829#issuecomment-488313577:76,Testability,Log,Log,76,Initial pass at implementation: write a function that returns this integer. Log it to Kibana every 10 minutes or some other interval. No alerts yet.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4829#issuecomment-488313577
https://github.com/broadinstitute/cromwell/pull/4830#issuecomment-482718058:24,Deployability,update,update,24,"We should probably also update the ""look like default"" commented out values in `examples.conf`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4830#issuecomment-482718058
https://github.com/broadinstitute/cromwell/pull/4831#issuecomment-482738687:74,Security,expose,exposed,74,Requesting reviews from:; - @kshakir because you created the values being exposed; - @rsasch to make sure adding new fields to `/query` won't play badly with Job Manager,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4831#issuecomment-482738687
https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483295408:107,Energy Efficiency,green,green,107,"This is a recent change which broke it if that's the case, which should be impossible as we only push when green",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483295408
https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483297075:235,Security,Encrypt,Encrypted,235,looks like we give a free pass on external contributors for at least some backends during CI:; ```; ********************************************************; ********************************************************; ** **; ** WARNING: Encrypted keys are unavailable. Exiting. **; ** **; ********************************************************; ********************************************************; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4833#issuecomment-483297075
https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757:158,Integrability,depend,dependent,158,"@kshakir I just made the following changes:. - SBT is now run on pushes, to make sure that the artifact publishing still happens. Since it's ~30 minutes, not dependent on external services, and less flaky than the other tests I still think this is an improvement over today; - I switched the syntax to `[force ci]`. See the most recent commit message and it triggering the tests to run.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757
https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757:343,Integrability,message,message,343,"@kshakir I just made the following changes:. - SBT is now run on pushes, to make sure that the artifact publishing still happens. Since it's ~30 minutes, not dependent on external services, and less flaky than the other tests I still think this is an improvement over today; - I switched the syntax to `[force ci]`. See the most recent commit message and it triggering the tests to run.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757
https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757:220,Testability,test,tests,220,"@kshakir I just made the following changes:. - SBT is now run on pushes, to make sure that the artifact publishing still happens. Since it's ~30 minutes, not dependent on external services, and less flaky than the other tests I still think this is an improvement over today; - I switched the syntax to `[force ci]`. See the most recent commit message and it triggering the tests to run.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757
https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757:373,Testability,test,tests,373,"@kshakir I just made the following changes:. - SBT is now run on pushes, to make sure that the artifact publishing still happens. Since it's ~30 minutes, not dependent on external services, and less flaky than the other tests I still think this is an improvement over today; - I switched the syntax to `[force ci]`. See the most recent commit message and it triggering the tests to run.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4839#issuecomment-485822757
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484146176:31,Testability,test,test,31,"If you’d like to submit such a test go for it 🙂. > On Apr 17, 2019, at 11:43 AM, Chris Llanwarne <notifications@github.com> wrote:; > ; > @cjllanwarne commented on this pull request.; > ; > Should we add the glob version of this test at the same time; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484146176
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484146176:229,Testability,test,test,229,"If you’d like to submit such a test go for it 🙂. > On Apr 17, 2019, at 11:43 AM, Chris Llanwarne <notifications@github.com> wrote:; > ; > @cjllanwarne commented on this pull request.; > ; > Should we add the glob version of this test at the same time; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484146176
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484174726:13,Deployability,update,updated,13,"@cjllanwarne updated the container image. I'm not inclined to add a glob test as I don't think it's really adding any value. As I said previously, if you'd like to add it knock yourself out",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484174726
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484174726:73,Testability,test,test,73,"@cjllanwarne updated the container image. I'm not inclined to add a glob test as I don't think it's really adding any value. As I said previously, if you'd like to add it knock yourself out",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484174726
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:205,Deployability,configurat,configuration,205,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:257,Deployability,configurat,configuration,257,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:205,Modifiability,config,configuration,205,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:257,Modifiability,config,configuration,257,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:76,Testability,test,testing,76,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:156,Testability,test,test,156,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925:330,Testability,test,tests,330,"TOL / pipe dream: inspired by the lovely system we have for CWL conformance testing, it would be nice to give Centaur distinct concepts for `-e` (exclude a test that is conceptually inappropriate for this configuration) and `-s` (really should work on this configuration but right now doesn't). Centaur could try to run ""shoulda"" tests with the sense of pass and fail reversed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484251925
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156:275,Performance,concurren,concurrent,275,"> I'm not inclined to add a glob test as I don't think it's really adding any value. The value which I think it would add is guaranteeing that the aliased task directories really are distinct. Eg this particular test case would pass if the tasks were ran in serial (cf. our ""concurrent job start limit"" option for AWS tests)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156:33,Testability,test,test,33,"> I'm not inclined to add a glob test as I don't think it's really adding any value. The value which I think it would add is guaranteeing that the aliased task directories really are distinct. Eg this particular test case would pass if the tasks were ran in serial (cf. our ""concurrent job start limit"" option for AWS tests)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156:212,Testability,test,test,212,"> I'm not inclined to add a glob test as I don't think it's really adding any value. The value which I think it would add is guaranteeing that the aliased task directories really are distinct. Eg this particular test case would pass if the tasks were ran in serial (cf. our ""concurrent job start limit"" option for AWS tests)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156:318,Testability,test,tests,318,"> I'm not inclined to add a glob test as I don't think it's really adding any value. The value which I think it would add is guaranteeing that the aliased task directories really are distinct. Eg this particular test case would pass if the tasks were ran in serial (cf. our ""concurrent job start limit"" option for AWS tests)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484259156
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484879049:37,Availability,reliab,reliably,37,As per hackathon - this test doesn't reliably fail in the intended circumstances. Closing in lieu of #4848,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484879049
https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484879049:24,Testability,test,test,24,As per hackathon - this test doesn't reliably fail in the intended circumstances. Closing in lieu of #4848,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4840#issuecomment-484879049
https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487338033:61,Performance,concurren,concurrent,61,"Currently, does cromwell support the situation where several concurrent cromwell instances share the same MySQL database? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487338033
https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487684113:410,Usability,clear,clear,410,"@gemmalam @danbills @mcovarr Sorry to bother you here, but I couldn't get a definite answer on the support forum ( https://gatkforums.broadinstitute.org/wdl/discussion/23421/multiple-cromwell-instances-sharing-the-same-database ). What is Cromwell's current level of support for multiple cromwell instances sharing the same MySQL database? From the forum, it seems that it works; but readthedocs don't make it clear, and the existence of the horicromtal label suggests that support for this is still being developed? Thanks for any info!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487684113
https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487684967:64,Performance,throughput,throughput,64,"Yes, it is still being developed and the first target is a high-throughput Cromwell that is used internally at Broad Institute. Once we get things working and suitable for end-users we will make it an official, documented feature.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4842#issuecomment-487684967
https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485017962:3,Testability,test,test,3,no test?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485017962
https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485050758:47,Testability,test,test,47,@mcovarr see #4848 - it's nontrivial to make a test for this (as in - we'll probably need to add a new mode to Centaur). We decided to punt for now during the hackathon.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485050758
https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485502251:21,Energy Efficiency,green,green,21,"Merging this as it's green and has no requested cleanups. @cjllanwarne I'm not deleting the branch, will leave that to you",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4853#issuecomment-485502251
https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782:304,Deployability,update,updated,304,"Pretty sure this was fixed by @delocalizer way back in #4109. However during my debugging of `globbingBehavior` for #4854, it seemed something was rotten in the state of `GenomicsHighPriorityQue-c1ed17c72de5fcb`. I still don't 100% know the setup for the AWS queues, but I think a) perhaps we just never updated ecs-proxy over in quay?, and/or b) maybe the ARN ""fixes"" in #4896/#4902 pulled in Conrad's fixes?. Either way #4958 stops excluding the tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782
https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782:259,Performance,queue,queues,259,"Pretty sure this was fixed by @delocalizer way back in #4109. However during my debugging of `globbingBehavior` for #4854, it seemed something was rotten in the state of `GenomicsHighPriorityQue-c1ed17c72de5fcb`. I still don't 100% know the setup for the AWS queues, but I think a) perhaps we just never updated ecs-proxy over in quay?, and/or b) maybe the ARN ""fixes"" in #4896/#4902 pulled in Conrad's fixes?. Either way #4958 stops excluding the tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782
https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782:448,Testability,test,tests,448,"Pretty sure this was fixed by @delocalizer way back in #4109. However during my debugging of `globbingBehavior` for #4854, it seemed something was rotten in the state of `GenomicsHighPriorityQue-c1ed17c72de5fcb`. I still don't 100% know the setup for the AWS queues, but I think a) perhaps we just never updated ecs-proxy over in quay?, and/or b) maybe the ARN ""fixes"" in #4896/#4902 pulled in Conrad's fixes?. Either way #4958 stops excluding the tests.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4855#issuecomment-491122782
https://github.com/broadinstitute/cromwell/pull/4858#issuecomment-485501748:50,Energy Efficiency,green,green,50,"Merging this for @aednichols as he's out, this is green, and there are no outstanding things described to clean up.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4858#issuecomment-485501748
https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256:67,Testability,test,test,67,"@gemmalam I think it is, except that it's hitting into a known bad test which was addressed after the branch was split off from develop. That test is now fixed but unfortunately we also need to address a bad PAPIv1 test. That also has a PR now so once either one of #4948 or #4949 merge and this PR gets rebased, I think we'll be good to merge it in.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256
https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256:142,Testability,test,test,142,"@gemmalam I think it is, except that it's hitting into a known bad test which was addressed after the branch was split off from develop. That test is now fixed but unfortunately we also need to address a bad PAPIv1 test. That also has a PR now so once either one of #4948 or #4949 merge and this PR gets rebased, I think we'll be good to merge it in.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256
https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256:215,Testability,test,test,215,"@gemmalam I think it is, except that it's hitting into a known bad test which was addressed after the branch was split off from develop. That test is now fixed but unfortunately we also need to address a bad PAPIv1 test. That also has a PR now so once either one of #4948 or #4949 merge and this PR gets rebased, I think we'll be good to merge it in.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4859#issuecomment-490574256
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485560062:7,Deployability,update,update,7,Can we update the test cases which now work? I suspect `custom_mount_point` at least could be re-enabled?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485560062
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485560062:18,Testability,test,test,18,Can we update the test cases which now work? I suspect `custom_mount_point` at least could be re-enabled?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485560062
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:335,Availability,error,error,335,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:350,Deployability,update,update,350,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:24,Security,validat,validate,24,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:361,Testability,test,test,361,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:501,Testability,test,testCentaurAws,501,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441:614,Testability,test,test,614,">This change appears to validate the format of the disk requirements but then do nothing with the actual values? Is that correct?. AWS has auto-sizing and auto-expanding disks, so the concept of specifying a disk size is not applicable in this universe. This PR lets Cromwell ignore everything after `local-disk` instead of issuing an error. >Can we update the test cases which now work? I suspect custom_mount_point at least could be re-enabled?. `custom_mount_point` is not on the excluded list in `testCentaurAws.sh`. Are you requesting new coverage by adding `awsbatch` to the backends for `custom_mount_point.test`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-485902441
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962:48,Testability,test,test,48,"oh, huh, it's specified as `papi`-only in the `.test` file:; ```; name: custom_mount_point; testFormat: workflowsuccess; backends: [Papi]; ```. We could either make an AWS version of this test, or, remove that backend requirement and use the `-e`s on the backends it won't work on",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962:92,Testability,test,testFormat,92,"oh, huh, it's specified as `papi`-only in the `.test` file:; ```; name: custom_mount_point; testFormat: workflowsuccess; backends: [Papi]; ```. We could either make an AWS version of this test, or, remove that backend requirement and use the `-e`s on the backends it won't work on",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962:188,Testability,test,test,188,"oh, huh, it's specified as `papi`-only in the `.test` file:; ```; name: custom_mount_point; testFormat: workflowsuccess; backends: [Papi]; ```. We could either make an AWS version of this test, or, remove that backend requirement and use the `-e`s on the backends it won't work on",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-486212962
https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-487476256:53,Testability,test,test,53,"So, where's this at? Is the only blocker the failing test?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4863#issuecomment-487476256
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-484928363:45,Deployability,update,update,45,"if #4865 has already merged before this one, update that table",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-484928363
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:910,Modifiability,config,config,910,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:229,Security,authoriz,authorization-token,229,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:272,Security,authoriz,authorizationData,272,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:292,Security,authoriz,authorizationToken,292,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910:326,Security,Authoriz,Authorization,326,"On hold for now. Using regular auth this appears to work manually but not in code. e.g. doing something like [this](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_auth):. ```; TOKEN=$(aws ecr get-authorization-token --output text --query 'authorizationData[].authorizationToken'); curl -i -H ""Authorization: Basic $TOKEN"" https://952500931424.dkr.ecr.us-east-1.amazonaws.com/v2/broadinstitute/cromwell/manfests/latest; ```. returns a blob of JSON containing all sorts of manifesty-looking data. However this doesn't seem to match up exactly with what the current code is doing: . * ~The current code sets `Bearer` auth, but that `curl` command works with `Basic` and not `Bearer`.~ Fixed, that was easy enough; * The current code expects to find the digest in the returned headers. However the digest is in the body and not the headers. It looks like having the `digest` in a `config` block is part of the spec so perhaps the existing code can actually parse and fall back on this if the digest isn't in the headers: https://docs.docker.com/registry/spec/manifest-v2-2/",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486798910
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486896880:12,Modifiability,config,config-parsing,12,"I have some config-parsing code that appears to work but is too gross to push, I'll see if I can clean it up.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486896880
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486926555:105,Availability,down,down,105,"@mcovarr - yes. Alteratively, you could use `DescribeImages` and supply an `ImageIds` argument to filter down the results by either `imageTag` or `imageDigest`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-486926555
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487068000:213,Testability,test,tests,213,"To attempt to accommodate ECR I changed Cromwell's Docker Registry V2 code to use the digest provided in the body of the response rather than the headers. Unfortunately this causes the Centaur ""docker image used"" tests on all other registries (Docker Hub, GCR and Quay) to fail. Tabling for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487068000
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234:298,Availability,down,downstream,298,"The comment in the keel PR asserts that the hashes returned in `Docker-Content-Digest` and within the body are the same, but in my limited testing on Docker Hub, Quay and GCR that did not seem to be the case. If the body value actually represents something other than the image digest it may cause downstream issues for Cromwell to treat as such. . Basically this issue needs more investigation. Since ECR support is apparently not as a high a priority as originally thought this issue has been deprioritized for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234:44,Security,hash,hashes,44,"The comment in the keel PR asserts that the hashes returned in `Docker-Content-Digest` and within the body are the same, but in my limited testing on Docker Hub, Quay and GCR that did not seem to be the case. If the body value actually represents something other than the image digest it may cause downstream issues for Cromwell to treat as such. . Basically this issue needs more investigation. Since ECR support is apparently not as a high a priority as originally thought this issue has been deprioritized for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234:27,Testability,assert,asserts,27,"The comment in the keel PR asserts that the hashes returned in `Docker-Content-Digest` and within the body are the same, but in my limited testing on Docker Hub, Quay and GCR that did not seem to be the case. If the body value actually represents something other than the image digest it may cause downstream issues for Cromwell to treat as such. . Basically this issue needs more investigation. Since ECR support is apparently not as a high a priority as originally thought this issue has been deprioritized for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234:139,Testability,test,testing,139,"The comment in the keel PR asserts that the hashes returned in `Docker-Content-Digest` and within the body are the same, but in my limited testing on Docker Hub, Quay and GCR that did not seem to be the case. If the body value actually represents something other than the image digest it may cause downstream issues for Cromwell to treat as such. . Basically this issue needs more investigation. Since ECR support is apparently not as a high a priority as originally thought this issue has been deprioritized for now.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487639234
https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487764851:73,Security,hash,hash,73,"I don't think it implies the header and body will **both** have the same hash for any given request. It sounds more like it will either be in the header or the body, hence they check one and then the other. Can you point me to a docker registry that doesn't follow this rule?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4864#issuecomment-487764851
https://github.com/broadinstitute/cromwell/pull/4865#issuecomment-485612460:23,Energy Efficiency,green,green,23,Merging as this is all green and there were no unresolved comments,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4865#issuecomment-485612460
https://github.com/broadinstitute/cromwell/pull/4872#issuecomment-485964920:236,Modifiability,inherit,inheritance,236,@kshakir I _think_ I've now got this generalized across all backends (I tested this with local and with PAPIv2). I'd definitely appreciate comments on whether I picked the right level of abstraction in the `XyzBackendJobExecutionActor` inheritance hierarchy to insert the change.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4872#issuecomment-485964920
https://github.com/broadinstitute/cromwell/pull/4872#issuecomment-485964920:72,Testability,test,tested,72,@kshakir I _think_ I've now got this generalized across all backends (I tested this with local and with PAPIv2). I'd definitely appreciate comments on whether I picked the right level of abstraction in the `XyzBackendJobExecutionActor` inheritance hierarchy to insert the change.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4872#issuecomment-485964920
https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-486795661:23,Security,hash,hash,23,"@ruchim turned on file hash caching, which solved the problem for us.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-486795661
https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-488065955:64,Deployability,update,update,64,@mwalker174 thanks for circling back to this and giving us this update!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4873#issuecomment-488065955
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172:187,Availability,alive,alive,187,"Hi @EvanTheB could you check something for me - you should be seeing a message like `Cromwell will watch for an rc file *and* double-check every {} seconds to make sure this job is still alive` when you start your job? (assuming `INFO` level logging is enabled). Then, with that background polling ongoing throughout the job run, if a full iteration of `exit-poll-timeout` has passed since the job stopped running, Cromwell will then mark the job as failed. If that gives you enough to put something more helpful into the docs that would be awesome! If not, I can maybe clarify a bit more? Otherwise we should hopefully be able to cycle round to improving this documentation _eventually_ (though unfortunately I can't make any stronger promises on an ETA than that!)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172:71,Integrability,message,message,71,"Hi @EvanTheB could you check something for me - you should be seeing a message like `Cromwell will watch for an rc file *and* double-check every {} seconds to make sure this job is still alive` when you start your job? (assuming `INFO` level logging is enabled). Then, with that background polling ongoing throughout the job run, if a full iteration of `exit-poll-timeout` has passed since the job stopped running, Cromwell will then mark the job as failed. If that gives you enough to put something more helpful into the docs that would be awesome! If not, I can maybe clarify a bit more? Otherwise we should hopefully be able to cycle round to improving this documentation _eventually_ (though unfortunately I can't make any stronger promises on an ETA than that!)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172:364,Safety,timeout,timeout,364,"Hi @EvanTheB could you check something for me - you should be seeing a message like `Cromwell will watch for an rc file *and* double-check every {} seconds to make sure this job is still alive` when you start your job? (assuming `INFO` level logging is enabled). Then, with that background polling ongoing throughout the job run, if a full iteration of `exit-poll-timeout` has passed since the job stopped running, Cromwell will then mark the job as failed. If that gives you enough to put something more helpful into the docs that would be awesome! If not, I can maybe clarify a bit more? Otherwise we should hopefully be able to cycle round to improving this documentation _eventually_ (though unfortunately I can't make any stronger promises on an ETA than that!)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172:242,Testability,log,logging,242,"Hi @EvanTheB could you check something for me - you should be seeing a message like `Cromwell will watch for an rc file *and* double-check every {} seconds to make sure this job is still alive` when you start your job? (assuming `INFO` level logging is enabled). Then, with that background polling ongoing throughout the job run, if a full iteration of `exit-poll-timeout` has passed since the job stopped running, Cromwell will then mark the job as failed. If that gives you enough to put something more helpful into the docs that would be awesome! If not, I can maybe clarify a bit more? Otherwise we should hopefully be able to cycle round to improving this documentation _eventually_ (though unfortunately I can't make any stronger promises on an ETA than that!)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-485806172
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:248,Availability,alive,alive,248,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:374,Deployability,configurat,configuration,374,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:418,Integrability,message,message,418,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:374,Modifiability,config,configuration,374,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:497,Safety,timeout,timeout,497,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:534,Safety,timeout,timeout-seconds,534,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:585,Safety,timeout,timeout,585,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965:462,Testability,log,logs,462,"Thanks @cjllanwarne , . > 2019-04-24 10:49:25,556 INFO - DispatchedConfigAsyncJobExecutionActor [UUID(917dfbca)JointGenotyping.ImportGenotypeGVCFs:7640:1]: Cromwell will watch for an rc file but will *not* double-check whether this job is actually alive (unless Cromwell restarts). So I guess I have not managed to enable polling after all! Edit: I found that I mispelt the configuration line, I wonder if there was a message telling me about misspelling in the logs. I had not heard of exit-poll-timeout, I assume you mean exit-code-timeout-seconds, or is this the `unrelated to this timeout`?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486025965
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911:33,Safety,timeout,timeout-seconds,33,"1. Oops, yes, I meant `exit-code-timeout-seconds`. ; 2. I think that the `unrelated to this timeout` side note is no longer accurate - the polling actually happens at the exact interval of the timeout now!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911:92,Safety,timeout,timeout,92,"1. Oops, yes, I meant `exit-code-timeout-seconds`. ; 2. I think that the `unrelated to this timeout` side note is no longer accurate - the polling actually happens at the exact interval of the timeout now!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911:193,Safety,timeout,timeout,193,"1. Oops, yes, I meant `exit-code-timeout-seconds`. ; 2. I think that the `unrelated to this timeout` side note is no longer accurate - the polling actually happens at the exact interval of the timeout now!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-486221911
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:58,Availability,alive,alive,58,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:195,Availability,alive,alive,195,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:244,Availability,alive,alive,244,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:358,Availability,down,down,358,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:408,Availability,alive,alive,408,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941:498,Safety,timeout,timeout-seconds,498,"I now notice that both checking for the RC and the 'check-alive' checks are controlled by this setting. This seems a bit strange as the rc checking is comparatively very cheap compared to 'check-alive'. Initially the point of not running check-alive all the time was that the cost was high compared to rc file checking. But now the solution has been to slow down rc checking to the speed of the costly check-alive! I am a bit muddled on this, so am not sure if I am getting it. . Without exit-code-timeout-seconds at what interval is the rc file checked for?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-488542941
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:216,Availability,down,down,216,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:315,Availability,alive,alive,315,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:397,Availability,alive,alive,397,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:139,Modifiability,config,configure,139,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:340,Modifiability,config,configurable,340,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707:377,Safety,timeout,timeout,377,"The regular status polling is totally separate from this option. . Regular polling backs off, so doesn't have a single ""interval"" value to configure or report (ie it starts off polling with short intervals but slows down as the job runs for longer and longer). That's true for all jobs across all backends. The `is-alive` check is a fixed (configurable) duration, and it's the timeout between `is-alive` returning false, and the job being considered failed, that are the same. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492253707
https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492495446:116,Testability,log,logs,116,"Ah I see thank you @cjllanwarne , I do not remember exactly where I got the idea that confused me, somewhere in the logs. But probably I was misunderstanding. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4877#issuecomment-492495446
https://github.com/broadinstitute/cromwell/pull/4878#issuecomment-486661322:28,Usability,feedback,feedback,28,Thanks @cjllanwarne for the feedback. I have moved the examples to the docs and referenced the docs in the changelog.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4878#issuecomment-486661322
https://github.com/broadinstitute/cromwell/pull/4878#issuecomment-488564412:86,Deployability,release,releases,86,@cjllanwarne thanks for merging! Can the changelog bits be retroactively added to the releases page so it is out there for everyone to see? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4878#issuecomment-488564412
https://github.com/broadinstitute/cromwell/pull/4881#issuecomment-485918090:97,Testability,test,testing,97,Ignoring codecov hiccup. See https://github.com/broadinstitute/cromwell/pull/4876 for proof that testing does indeed cover the diff,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4881#issuecomment-485918090
https://github.com/broadinstitute/cromwell/pull/4882#issuecomment-485915485:54,Testability,test,test,54,Closing this PR. @mcovarr is working on a fix for the test script,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4882#issuecomment-485915485
https://github.com/broadinstitute/cromwell/issues/4892#issuecomment-486346405:14,Integrability,wrap,wrapper,14,This could be wrapper endpoint or backwards-compatible changes to the existing one or both,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4892#issuecomment-486346405
https://github.com/broadinstitute/cromwell/pull/4893#issuecomment-487052380:18,Usability,simpl,simpler,18,@mcovarr now with simpler fix,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4893#issuecomment-487052380
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451:430,Safety,avoid,avoid,430,"@mcovarr @aednichols you both asked the same question from different directions... I'll try to answer both in one go:. * This *does not* alter how the class operates in production because it's a `None foreach { ... }`.; * I override the `None` in the spec so that I can guarantee the events land as a unit and aren't interrupted by the occasional flushing action. FWIW I did try to move *all* of this logic into the test class to avoid cluttering the main, but got tangled up trying to override the FSM actions with a `receive` in the test class and it ended up not working as I'd hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451:401,Testability,log,logic,401,"@mcovarr @aednichols you both asked the same question from different directions... I'll try to answer both in one go:. * This *does not* alter how the class operates in production because it's a `None foreach { ... }`.; * I override the `None` in the spec so that I can guarantee the events land as a unit and aren't interrupted by the occasional flushing action. FWIW I did try to move *all* of this logic into the test class to avoid cluttering the main, but got tangled up trying to override the FSM actions with a `receive` in the test class and it ended up not working as I'd hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451:416,Testability,test,test,416,"@mcovarr @aednichols you both asked the same question from different directions... I'll try to answer both in one go:. * This *does not* alter how the class operates in production because it's a `None foreach { ... }`.; * I override the `None` in the spec so that I can guarantee the events land as a unit and aren't interrupted by the occasional flushing action. FWIW I did try to move *all* of this logic into the test class to avoid cluttering the main, but got tangled up trying to override the FSM actions with a `receive` in the test class and it ended up not working as I'd hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451:535,Testability,test,test,535,"@mcovarr @aednichols you both asked the same question from different directions... I'll try to answer both in one go:. * This *does not* alter how the class operates in production because it's a `None foreach { ... }`.; * I override the `None` in the spec so that I can guarantee the events land as a unit and aren't interrupted by the occasional flushing action. FWIW I did try to move *all* of this logic into the test class to avoid cluttering the main, but got tangled up trying to override the FSM actions with a `receive` in the test class and it ended up not working as I'd hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486854451
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:211,Availability,down,downside,211,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:144,Integrability,message,messages,144,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:198,Integrability,message,message,198,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:40,Testability,test,tests,40,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:96,Testability,test,tests,96,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038:241,Testability,test,tests,241,"FWIW 2: it's also possible to ""fix"" the tests by pushing the flush interval back to ~2s for the tests - thus reducing the chance that the probe messages are sent at the same time as a regular flush message. The downside to that was that the tests were taking 20 seconds each, which didn't feel great (and even though unlikely, there was still a small chance of an accident happening)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4898#issuecomment-486855038
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-487106360:134,Usability,feedback,feedback,134,Thank you for the PR! The Cromwell team is unfortunately a bit slammed this week but we hope to get back to you with more substantial feedback next week. 🙂,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-487106360
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:708,Integrability,synchroniz,synchronized,708,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:75,Performance,perform,performance,75,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:114,Performance,cache,cached-copy,114,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:745,Performance,race condition,race conditions,745,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:897,Performance,cache,cached-copy,897,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:1162,Performance,cache,cache,1162,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:1242,Performance,perform,performance,1242,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703:1098,Usability,clear,clear,1098,"@aednichols . I implemented the changes. The lock should have a negligible performance impact. It only locks when cached-copy strategy is used, threads which use other strategies are not blocked by this. (This was already true before the changes). A dictionary is used to keep track which files are being copied within the process. Filesystem lock files are too slow for this because during scatters cromwell creates a lot of threads that need exactly the same file at the same time. . A lock file is now used so other cromwell processes know the file is being copied. The chances of two processes needing the same file at exactly the same time is negligible, so lock files are fast enough here. Due to the `synchronized` lock, there can not be race conditions where more than one thread modifies the dictionary and/or creates the lock file at the same time. (The lock is absolutely necessary for cached-copy to work). The amount of time spent in the lock per thread is negligible. . I implemented a waitOnCopy function which lets a thread wait for the locks in the dictionary on the filesystem to clear. This structure allows a lot of paths to be copied to the cache at the same time. So the copying is still multithreaded, maintaining high performance. Are these changes satisfactory?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488295703
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313:95,Availability,avail,available,95,"Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313:15,Deployability,update,update,15,"Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313:63,Usability,feedback,feedback,63,"Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488296313
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488310510:128,Usability,feedback,feedback,128,"@gemmalam Could you remove the ""back with originator"" label? This PR has already returned from the originator. I am waiting for feedback. So if this stays with ""back with originator"" we will be in waiting on eachother deadlock :slightly_smiling_face: .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-488310510
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140:97,Availability,avail,available,97,"> Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available. @aednichols could you give an indication when the feedback will be coming?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140:17,Deployability,update,update,17,"> Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available. @aednichols could you give an indication when the feedback will be coming?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140:65,Usability,feedback,feedback,65,"> Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available. @aednichols could you give an indication when the feedback will be coming?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140:158,Usability,feedback,feedback,158,"> Thanks for the update! We will assign reviewers to give proper feedback, as soon as someone is available. @aednichols could you give an indication when the feedback will be coming?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-495676140
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225:269,Energy Efficiency,adapt,adapt,269,"I can understand. This solution is not ideal. On the upside: it is only activated for those who willingly put ""cached-copy"" in their configs. The rest of the cromwell users are **not** affected by the lock mechanism. By default this does **not** affect anyone. I could adapt this PR and plaster the words: `WARNING: EXPERIMENTAL` all over it if that helps. EDIT: While I mention it ""is not ideal"", the only situation where the locks might not be effective is when using multiple cromwell processes, that do use the same execution folder. Does this happen often in practice? Is this even a supported use case?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225:133,Modifiability,config,configs,133,"I can understand. This solution is not ideal. On the upside: it is only activated for those who willingly put ""cached-copy"" in their configs. The rest of the cromwell users are **not** affected by the lock mechanism. By default this does **not** affect anyone. I could adapt this PR and plaster the words: `WARNING: EXPERIMENTAL` all over it if that helps. EDIT: While I mention it ""is not ideal"", the only situation where the locks might not be effective is when using multiple cromwell processes, that do use the same execution folder. Does this happen often in practice? Is this even a supported use case?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225:269,Modifiability,adapt,adapt,269,"I can understand. This solution is not ideal. On the upside: it is only activated for those who willingly put ""cached-copy"" in their configs. The rest of the cromwell users are **not** affected by the lock mechanism. By default this does **not** affect anyone. I could adapt this PR and plaster the words: `WARNING: EXPERIMENTAL` all over it if that helps. EDIT: While I mention it ""is not ideal"", the only situation where the locks might not be effective is when using multiple cromwell processes, that do use the same execution folder. Does this happen often in practice? Is this even a supported use case?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225:111,Performance,cache,cached-copy,111,"I can understand. This solution is not ideal. On the upside: it is only activated for those who willingly put ""cached-copy"" in their configs. The rest of the cromwell users are **not** affected by the lock mechanism. By default this does **not** affect anyone. I could adapt this PR and plaster the words: `WARNING: EXPERIMENTAL` all over it if that helps. EDIT: While I mention it ""is not ideal"", the only situation where the locks might not be effective is when using multiple cromwell processes, that do use the same execution folder. Does this happen often in practice? Is this even a supported use case?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498211225
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498644488:254,Deployability,integrat,integrated,254,"Also. File locks are not that good. But locking via the database would be ideal for horicromtal. If I get some pointers I can implement a database lock. This will require an extra table or something, so I need some pointers on how this should be ideally integrated in cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498644488
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498644488:254,Integrability,integrat,integrated,254,"Also. File locks are not that good. But locking via the database would be ideal for horicromtal. If I get some pointers I can implement a database lock. This will require an extra table or something, so I need some pointers on how this should be ideally integrated in cromwell.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-498644488
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:394,Deployability,patch,patched,394,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:461,Deployability,release,releases,461,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:482,Deployability,patch,patches,482,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:812,Deployability,pipeline,pipeline,812,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:343,Modifiability,config,config,343,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142:316,Performance,cache,cached-copy,316,"> There's quite a bit of debate internally about this PR. Some team members remain deeply uncomfortable with how locking is handled, but it would take us a lot of time to research and recommend a better solution. If I may reiterate: by default this does not break anything for anyone. The locking only happens when `cached-copy` is set in the config consciously by the user. I maintain [my own patched jar for cromwell](https://github.com/rhpvorderman/cromwell/releases/tag/41-LUMC-patches), because this is taking very long already. We are running this in production and not experiencing problems. (There are only problems when the maximum number of hardlinks is reached, then cromwell defaults to copying again. It does not break anything, but it will use a lot of space on the filesystem and it will slowdown pipeline runs. I am working on a fix for that as well.)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504046142
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504301482:189,Deployability,update,updated,189,"@aednichols and @mcovarr Thank you very much for the reviews. @aednichols Thank you very much for keeping me informed about the status of this PR, it is much appreciated. The code has been updated to reflect the comments. I also merged the latest branch of develop in and updated the changelog.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504301482
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504301482:272,Deployability,update,updated,272,"@aednichols and @mcovarr Thank you very much for the reviews. @aednichols Thank you very much for keeping me informed about the status of this PR, it is much appreciated. The code has been updated to reflect the comments. I also merged the latest branch of develop in and updated the changelog.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504301482
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:4,Availability,error,errors,4,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:265,Availability,failure,failures,265,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:330,Integrability,message,message,330,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:519,Integrability,message,message,519,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:797,Integrability,message,messages,797,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:18,Testability,test,testing,18,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:111,Testability,test,test,111,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:763,Testability,Assert,AssertionError,763,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:879,Testability,test,testkit,879,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:909,Testability,Test,TestEventListener,909,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:1505,Testability,Test,TestSuite,1505,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:1527,Testability,Test,TestSuite,1527,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:1573,Testability,Test,TestSuite,1573,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025:1596,Testability,Test,TestSuite,1596,"Two errors on the testing:; ```; - should successfully run curl *** FAILED *** (1 minute, 37 seconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: bb88b541-3f1a-490c-9121-7685b4ab54b3). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Job curl_wf.newsgrab:NA:1 exited with return code 6 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""; }; ],; ""message"" : ""Workflow failed""; }; ]; ```. ```; info] PubSubMetadataServiceActorSpec:; [info] A PubSubMetadataActor with a subscription should ; [info] - should create the requested subscription *** FAILED *** (17 milliseconds); [info] java.lang.AssertionError: received 1 excess messages on InfoFilter(None,Left(Creating subscription baz),true); [info] at akka.testkit.EventFilter.intercept(TestEventListener.scala:116); [info] at cromwell.services.metadata.impl.pubsub.PubSubMetadataServiceActorSpec.$anonfun$new$9(PubSubMetadataServiceActorSpec.scala:40); [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); [info] at org.scalatest.Transformer.apply(Transformer.scala:22); [info] at org.scalatest.Transformer.apply(Transformer.scala:20); [info] at org.scalatest.WordSpecLike$$anon$1.apply(WordSpecLike.scala:1078); [info] at org.scalatest.TestSuite.withFixture(TestSuite.scala:196); [info] at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195); ```; I don't see how these are caused by this PR. I would gladly fix them if I would know how.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504347025
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803:10,Availability,failure,failures,10,"Those two failures are probably unrelated test flakiness (the curl exit 6 is a ""Couldn't resolve host"" error). I've restarted the two builds, hopefully the errors will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803:103,Availability,error,error,103,"Those two failures are probably unrelated test flakiness (the curl exit 6 is a ""Couldn't resolve host"" error). I've restarted the two builds, hopefully the errors will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803:156,Availability,error,errors,156,"Those two failures are probably unrelated test flakiness (the curl exit 6 is a ""Couldn't resolve host"" error). I've restarted the two builds, hopefully the errors will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803:42,Testability,test,test,42,"Those two failures are probably unrelated test flakiness (the curl exit 6 is a ""Couldn't resolve host"" error). I've restarted the two builds, hopefully the errors will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-504405803
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:271,Integrability,message,message,271,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:688,Integrability,depend,depend,688,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:503,Performance,cache,cached-copy,503,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:467,Security,hash,hashing-strategy,467,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924:265,Testability,log,log,265,"Hey @rhpvorderman, I've started to use this for our workflows and seems to be working well! Props for this change :). I've got a small suggestion (not enough to raise an issue, and only if you're already making other changes), it would be awesome if Cromwell could log a message to say that it's copying files. I watch for that because then I know the task is starting properly. . Unrelated to that, I was wondering what hurdles might have to be overcome to devise a hashing-strategy based on your new `cached-copy` (that's not File / md5). You've mentioned [before](https://github.com/broadinstitute/cromwell/issues/2620#issuecomment-482565332) that this might be possible as it doesn't depend on the final path.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507916924
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:582,Availability,ping,ping,582,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:188,Integrability,message,message,188,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:379,Integrability,message,message,379,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:433,Performance,cache,cached-copy,433,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:172,Testability,log,login,172,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522:426,Testability,test,tested,426,"@illusional ; I am happy you like this change. I have checked your other post in #4945 and your use case is similar to ours. We use a SGE cluster and run cromwell from the login node. The message is really easy to implement. But I am not sure what would be the right way to tackle this. I would like some consistency with the other localization methods, and I don't know if they message when a file is being copied. I haven't tested cached-copy in conjunction with call-caching and path+modtime yet. If I find issues with it I will create a new issue on the cromwell issue tracker, ping you, and see if I can fix it in a PR. We rely heavily on the path+modtime strategy as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-507966522
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:697,Modifiability,Config,Configuring,697,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:527,Performance,cache,cache-strategies,527,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:769,Security,hash,hash,769,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:928,Security,hash,hash,928,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219:70,Testability,log,log,70,"Ooop, I might have misspoke. I thought the copy strategy did actually log that it was copying, but I realised that what I was seeing was that the `hard link` had failed, and knew that it was copying based on that:. > `WARN - Localization via hard link has failed: /path/to/destination.file -> /path/to/original.file: Invalid cross-device link`. I think it still might be useful, but I realise there's actually no precedent here. ---. Oh, so the path+modtime sort of just works? I was under the impression it wouldn't for those cache-strategies. I don't know if it wouldn't try, or would never succeed because I never tried, but here's what the [docs say](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options):. > - ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; > - ""path+modtime"" will compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. Thanks for the reply!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-508309219
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-568303076:128,Performance,cache,cached-hardlink,128,"Hey @rhpvorderman, just wanted to check in and say this has been working great!. I was thinking about adding a new one, called ""cached-hardlink"" or so, but instead of always copying, it would try to hard-link it first. We have the use case where often our bigger sequence data is on the same disk, but some reference files are not. My plan was to just follow your pattern, but use a modified `localizePathViaCachedCopy` (like `localizePathViaHardlink`). Do you have any advice if I were to give it a crack over the EOY break?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-568303076
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-571456289:103,Performance,cache,cached-copy,103,"@illusional You can set the priorities for localization like this; ```; localization: [; ""hard-link"", ""cached-copy"", ""copy""; ]; ```; In that case it will try to hard-link first. It works on our setup. > Hey @rhpvorderman, just wanted to check in and say this has been working great!. Thanks for letting us know. In our institute it is also working great. We have had zero crashes, deadlocks etc. related to this code. So we are also quite happy with it. I am very glad it is useful to others as well.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-571456289
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-638049145:81,Availability,Ping,Pinging,81,Thanks for the heads up. We haven't gotten around to move our cluster to 51 yet. Pinging @DavyCats so he is also aware.; We will investigate the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-638049145
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645255220:70,Modifiability,config,config,70,"Haha yeah I was just about to say I think it's working with a revised config change. I PRd a doc change, but it's only in the [develop docs](https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645255220
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645255220:184,Modifiability,Config,Configuring,184,"Haha yeah I was just about to say I think it's working with a revised config change. I PRd a doc change, but it's only in the [develop docs](https://cromwell.readthedocs.io/en/develop/Configuring/#local-filesystem-options).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645255220
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645263460:65,Deployability,install,installation,65,"Good work! For me the problem was caused because I use the conda installation of cromwell and I made a typo in the `_JAVA_OPTIONS` environment variable, so it was running locally instead of on the cluster :man_facepalming: . Still I managed to find the issue because of your issue :smile: .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645263460
https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645263460:143,Modifiability,variab,variable,143,"Good work! For me the problem was caused because I use the conda installation of cromwell and I made a typo in the `_JAVA_OPTIONS` environment variable, so it was running locally instead of on the cluster :man_facepalming: . Still I managed to find the issue because of your issue :smile: .",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900#issuecomment-645263460
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:686,Performance,concurren,concurrent,686,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:803,Performance,concurren,concurrent,803,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:912,Performance,concurren,concurrent,912,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:1204,Performance,concurren,concurrent,1204, recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:189,Security,hash,hashing,189,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:296,Security,hash,hashing,296,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:511,Security,hash,hashCode,511,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:720,Security,hash,hash,720,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855:62,Testability,log,logs,62,Something looks like it's got an infinite recursion (from SBT logs):; ```; [0m[[0m[31merror[0m] [0m[0mjava.lang.StackOverflowError[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3.productHash(MurmurHash3.scala:64)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.util.hashing.MurmurHash3$.productHash(MurmurHash3.scala:211)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.ScalaRunTime$._hashCode(ScalaRunTime.scala:145)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.Tuple2.hashCode(Tuple2.scala:19)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.runtime.Statics.anyHash(Statics.java:115)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap$MangledHashing.hash(TrieMap.scala:984)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.computeHash(TrieMap.scala:829)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.get(TrieMap.scala:844)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.MapLike.contains$(MapLike.scala:150)[0m; [0m[[0m[31merror[0m] [0m[0m	at scala.collection.concurrent.TrieMap.contains(TrieMap.scala:631)[0m; [0m[[0m[31merror[0m] [0m[0m	at scoverage.Invoker$.invoked(Invoker.scala:34)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:44)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloudNioFileSystemProvider.scala:48)[0m; [0m[[0m[31merror[0m] [0m[0m	at cloud.nio.impl.drs.DrsCloudNioFileSystemProvider.getHost(DrsCloud,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4903#issuecomment-487021855
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488569744:127,Usability,clear,clearer,127,One of my former colleagues (ffinfo) added this feature because we needed it on our HPC. With your documentation it looks much clearer. Thanks a lot!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488569744
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488880044:131,Performance,load,load,131,@rhpvorderman which backend are you using? I assume a SGE-like system. Do you have trouble with the qstat -j requests causing high load? Have you already implemented a similar system to the linked script?. The problem with just increasing this value is that it also slows checking for the rc file.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488880044
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546:558,Availability,alive,alive,558,@EvanTheB We use SGE. The problem is our configuration. SGE checks on VMEM instead of actual memory used. This means that a lot of java tools will exceed the memory limits and be killed by the scheduler. In that case there is no RC file. That is why qstat -j should be checked as well. > The problem with just increasing this value is that it also slows checking for the rc file. Maybe we can do this in a more elegant way. I will have a look at your script and also at the cromwell code. It should be trivial to decouple the RC file checking from the check-alive checking. Maybe my colleague @DavyCats has some suggestions as well? Also I know that @cpavanrun uses a similar backend and makes use of this feature. Maybe he also has some suggestions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546:41,Deployability,configurat,configuration,41,@EvanTheB We use SGE. The problem is our configuration. SGE checks on VMEM instead of actual memory used. This means that a lot of java tools will exceed the memory limits and be killed by the scheduler. In that case there is no RC file. That is why qstat -j should be checked as well. > The problem with just increasing this value is that it also slows checking for the rc file. Maybe we can do this in a more elegant way. I will have a look at your script and also at the cromwell code. It should be trivial to decouple the RC file checking from the check-alive checking. Maybe my colleague @DavyCats has some suggestions as well? Also I know that @cpavanrun uses a similar backend and makes use of this feature. Maybe he also has some suggestions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546:193,Energy Efficiency,schedul,scheduler,193,@EvanTheB We use SGE. The problem is our configuration. SGE checks on VMEM instead of actual memory used. This means that a lot of java tools will exceed the memory limits and be killed by the scheduler. In that case there is no RC file. That is why qstat -j should be checked as well. > The problem with just increasing this value is that it also slows checking for the rc file. Maybe we can do this in a more elegant way. I will have a look at your script and also at the cromwell code. It should be trivial to decouple the RC file checking from the check-alive checking. Maybe my colleague @DavyCats has some suggestions as well? Also I know that @cpavanrun uses a similar backend and makes use of this feature. Maybe he also has some suggestions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546:41,Modifiability,config,configuration,41,@EvanTheB We use SGE. The problem is our configuration. SGE checks on VMEM instead of actual memory used. This means that a lot of java tools will exceed the memory limits and be killed by the scheduler. In that case there is no RC file. That is why qstat -j should be checked as well. > The problem with just increasing this value is that it also slows checking for the rc file. Maybe we can do this in a more elegant way. I will have a look at your script and also at the cromwell code. It should be trivial to decouple the RC file checking from the check-alive checking. Maybe my colleague @DavyCats has some suggestions as well? Also I know that @cpavanrun uses a similar backend and makes use of this feature. Maybe he also has some suggestions.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488991546
https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488996990:118,Availability,down,down,118,Huh. Did not realise the return-code file checking rate is also bound by the exit-code-checking poll rate. That slows down the development cycle somewhat; we have it set pretty long (~120 minutes) to prevent overloading the queque systems.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4905#issuecomment-488996990
https://github.com/broadinstitute/cromwell/issues/4906#issuecomment-487203496:42,Testability,test,test-data,42,Units used by GCS:; ```5.17 MiB gs://gatk-test-data/wgs_fastq/NA12878_20k/H06HDADXX130110.1.ATCACGAT.20k_reads_1.fastq```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4906#issuecomment-487203496
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:792,Availability,redundant,redundant,792,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:95,Performance,queue,queues,95,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:485,Performance,queue,queue,485,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:501,Performance,queue,queue,501,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:735,Performance,queue,queue,735,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:986,Performance,queue,queue,986,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:1026,Performance,queue,queue,1026,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:1131,Performance,queue,queue,1131,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:1184,Performance,queue,queue,1184,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:689,Safety,sanity check,sanity check,689,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:792,Safety,redund,redundant,792,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810:924,Safety,abort,aborting,924,"The cause and effect:. - An assumption in the token dispenser actor (that none of the internal queues were ever empty) turned out to not always be true; - As a result, not infrequently an attempted `dequeue` would cause the `JobExecutionTokenDispenserActor` to crash and be restarted - zeroing out all known token dispensations *and* all known actors waiting for tokens.; - The overall consequence of this was that jobs would submit their request for exeution tokens and be added to a queue. But that queue was lost when the `JobExecutionTokenDispenserActor` was restarted and therefore the jobs would sit forever waiting for a token which was never sent to them. The fix:; - First, add a sanity check before calling `dequeue`. If the queue is empty, don't do it. But hopefully will now be a redundant check thanks to:; - Second, one situation was identified which would lead to this state when token-requesting-actors were aborting before a token was dispensed. If that left the token queue for that hog group empty then the queue was not being correctly removed from the `JobExecutionTokenDispenserActor` - thus leaving an empty queue behind and triggering the ""dequeue on an empty queue"" bug.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4908#issuecomment-488345810
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:1004,Integrability,message,messages,1004,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:127,Performance,queue,queue,127,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:500,Performance,queue,queue,500,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:827,Performance,queue,queues,827,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:1054,Performance,queue,queues,1054,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:102,Testability,log,logs,102,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667:1000,Testability,log,log,1000,"Good news? This would also band-aid the jobs-never-running problem reported last week. From the token logs: . 6:22 PM :; ```; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 3367; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 3947,; ""atLimit"" : true; },; ...; ```. At 6:26 PM the `JobExecutionTokenDispenserActor` crashed with a stack trace similar to the one in this PR description. 6:27 PM:. ```; ""tokenTypes"" : [; ""queue"" : {; ""groupsNeedingTokens"" : [; {; ""hogGroup"" : ""porcine-project"",; ""size"" : 5; }; ],; ...; ""poolState"" : {; ""hogGroups"" : [; {; ""hogGroup"" : ""porcine-project"",; ""used"" : 16,; ""atLimit"" : false; }; ],; ...; ```. So the crash of the `JobExecutionTokenDispenserActor` not only lost the token assignments, but also the hog queues. The loss of token assignments leads to the fairly harmless condition of Cromwell handing out more tokens than it actually should (though emitting thousands of scary log messages in the process). But the loss of the hog queues means that the 3367 jobs that needed tokens at 6:22 PM would never receive them.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488007667
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964:96,Availability,error,error,96,@mcovarr that was indeed my theory. I'm trying to create a test case to actually reproduce this error to make sure my fix doesn't have some other weird downstream problems (eg getting 10 lines later then throw some other exception wouldn't be a great outcome),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964:152,Availability,down,downstream,152,@mcovarr that was indeed my theory. I'm trying to create a test case to actually reproduce this error to make sure my fix doesn't have some other weird downstream problems (eg getting 10 lines later then throw some other exception wouldn't be a great outcome),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964
https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964:59,Testability,test,test,59,@mcovarr that was indeed my theory. I'm trying to create a test case to actually reproduce this error to make sure my fix doesn't have some other weird downstream problems (eg getting 10 lines later then throw some other exception wouldn't be a great outcome),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909#issuecomment-488082964
https://github.com/broadinstitute/cromwell/issues/4912#issuecomment-488707414:50,Security,hash,hash,50,"P.S. the current docs advise including the sha256 hash in the docker runtime spec:; https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#image-versions; Which makes sense, but unfortunately right now it seems to disable caching (at least with the Local backend).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4912#issuecomment-488707414
https://github.com/broadinstitute/cromwell/issues/4913#issuecomment-487420609:22,Modifiability,config,config,22,"Hi @carbocation - the config files are in [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md) which is a JSON superset. thus JSON is valid, but other forms are as well",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4913#issuecomment-487420609
https://github.com/broadinstitute/cromwell/issues/4913#issuecomment-487420609:79,Modifiability,config,config,79,"Hi @carbocation - the config files are in [HOCON](https://github.com/lightbend/config/blob/master/HOCON.md) which is a JSON superset. thus JSON is valid, but other forms are as well",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4913#issuecomment-487420609
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027:153,Testability,log,log,153,"@cjllanwarne While I can see the instances that Cromwell has spawned, those instances are not named or labeled in a way that would let me identify which log file to look at. This is unlike, say, dsub, which labels each machine in a way that makes it easy to tell which specific task and chunk it belongs to. So, while I can see those machines sitting there idling, I can't easily go look and tell what's in their logfiles. For that same reason, I can't really answer your questions as well as I'd like to be able to.; 1. To the best of my knowledge, jobs don't fail during this process (aside from the usual preemptible instance terminations), but I can't go from google compute instance => log file.; 1. I do believe that *at least some* of the jobs become created in duplicate. I believe this because (for example), in a job where I scattered into 2,400 chunks, I saw over 3,500 live VMs running. (There is no additional scattering or other reason for the number of machines to be more than 2,400 in that particular circumstance.). If Cromwell added a label to these machines in the way that dsub does, I think I could do a much better job answering your questions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027:413,Testability,log,logfiles,413,"@cjllanwarne While I can see the instances that Cromwell has spawned, those instances are not named or labeled in a way that would let me identify which log file to look at. This is unlike, say, dsub, which labels each machine in a way that makes it easy to tell which specific task and chunk it belongs to. So, while I can see those machines sitting there idling, I can't easily go look and tell what's in their logfiles. For that same reason, I can't really answer your questions as well as I'd like to be able to.; 1. To the best of my knowledge, jobs don't fail during this process (aside from the usual preemptible instance terminations), but I can't go from google compute instance => log file.; 1. I do believe that *at least some* of the jobs become created in duplicate. I believe this because (for example), in a job where I scattered into 2,400 chunks, I saw over 3,500 live VMs running. (There is no additional scattering or other reason for the number of machines to be more than 2,400 in that particular circumstance.). If Cromwell added a label to these machines in the way that dsub does, I think I could do a much better job answering your questions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027:691,Testability,log,log,691,"@cjllanwarne While I can see the instances that Cromwell has spawned, those instances are not named or labeled in a way that would let me identify which log file to look at. This is unlike, say, dsub, which labels each machine in a way that makes it easy to tell which specific task and chunk it belongs to. So, while I can see those machines sitting there idling, I can't easily go look and tell what's in their logfiles. For that same reason, I can't really answer your questions as well as I'd like to be able to.; 1. To the best of my knowledge, jobs don't fail during this process (aside from the usual preemptible instance terminations), but I can't go from google compute instance => log file.; 1. I do believe that *at least some* of the jobs become created in duplicate. I believe this because (for example), in a job where I scattered into 2,400 chunks, I saw over 3,500 live VMs running. (There is no additional scattering or other reason for the number of machines to be more than 2,400 in that particular circumstance.). If Cromwell added a label to these machines in the way that dsub does, I think I could do a much better job answering your questions.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488421027
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019:383,Availability,error,errors,383,Thanks @carbocation - based on what you're saying it sounds like those run creation requests are in fact succeeding but just taking longer than Cromwell's request timeout to respond. For whoever picks up this ticket: I believe that wiring through an option to increase [timeouts on the requests to Google](https://developers.google.com/api-client-library/java/google-api-java-client/errors) (and make the value configurable) is hopefully sufficient for fixing this error.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019:465,Availability,error,error,465,Thanks @carbocation - based on what you're saying it sounds like those run creation requests are in fact succeeding but just taking longer than Cromwell's request timeout to respond. For whoever picks up this ticket: I believe that wiring through an option to increase [timeouts on the requests to Google](https://developers.google.com/api-client-library/java/google-api-java-client/errors) (and make the value configurable) is hopefully sufficient for fixing this error.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019:411,Modifiability,config,configurable,411,Thanks @carbocation - based on what you're saying it sounds like those run creation requests are in fact succeeding but just taking longer than Cromwell's request timeout to respond. For whoever picks up this ticket: I believe that wiring through an option to increase [timeouts on the requests to Google](https://developers.google.com/api-client-library/java/google-api-java-client/errors) (and make the value configurable) is hopefully sufficient for fixing this error.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019:163,Safety,timeout,timeout,163,Thanks @carbocation - based on what you're saying it sounds like those run creation requests are in fact succeeding but just taking longer than Cromwell's request timeout to respond. For whoever picks up this ticket: I believe that wiring through an option to increase [timeouts on the requests to Google](https://developers.google.com/api-client-library/java/google-api-java-client/errors) (and make the value configurable) is hopefully sufficient for fixing this error.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019
https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019:270,Safety,timeout,timeouts,270,Thanks @carbocation - based on what you're saying it sounds like those run creation requests are in fact succeeding but just taking longer than Cromwell's request timeout to respond. For whoever picks up this ticket: I believe that wiring through an option to increase [timeouts on the requests to Google](https://developers.google.com/api-client-library/java/google-api-java-client/errors) (and make the value configurable) is hopefully sufficient for fixing this error.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914#issuecomment-488437019
https://github.com/broadinstitute/cromwell/issues/4916#issuecomment-494544562:490,Availability,error,error,490,"I don't know what's going on with the labels. Ruchi, Gemma and I discussed this when I was Acting Delivery Czar for a day in your absence. It definitely was in the sprint at one point. A/C: at a minimum emulate the exception above and confirm that a running WorkflowActor does not crash and hang forever without making progress. Some very nice-to-haves would be understanding what actually is going on here; could we be failing faster with conspicuous broken credentials? Also de-scary any error messages a la the other `OneForOneStrategy` tickets as appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4916#issuecomment-494544562
https://github.com/broadinstitute/cromwell/issues/4916#issuecomment-494544562:496,Integrability,message,messages,496,"I don't know what's going on with the labels. Ruchi, Gemma and I discussed this when I was Acting Delivery Czar for a day in your absence. It definitely was in the sprint at one point. A/C: at a minimum emulate the exception above and confirm that a running WorkflowActor does not crash and hang forever without making progress. Some very nice-to-haves would be understanding what actually is going on here; could we be failing faster with conspicuous broken credentials? Also de-scary any error messages a la the other `OneForOneStrategy` tickets as appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4916#issuecomment-494544562
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-490175339:21,Deployability,Pipeline,Pipelines,21,AC: Confirm that the Pipelines API Request Worker can handle a 502 -- it should be retried.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-490175339
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544:5,Availability,Error,Error,5,```; Error 502 (Server Error)!!1; ```; I find this level of excitement about a server error deeply distrubing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544:23,Availability,Error,Error,23,```; Error 502 (Server Error)!!1; ```; I find this level of excitement about a server error deeply distrubing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544:86,Availability,error,error,86,```; Error 502 (Server Error)!!1; ```; I find this level of excitement about a server error deeply distrubing,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492860544
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:171,Availability,error,error,171,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:48,Deployability,Pipeline,PipelinesApiRequestWorker,48,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:398,Deployability,pipeline,pipelines,398,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:419,Deployability,Pipeline,PipelinesApiRequestWorker,419,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:454,Deployability,Pipeline,PipelinesApiRequestWorker,454,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:191,Integrability,interface,interface,191,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137:42,Testability,mock,mock,42,@mcovarr would you be content if I made a mock `PipelinesApiRequestWorker` that always crashes and check that the manager handles it?. I'm also thinking about introducing error types at this interface in the stack so that explosions in Google code don't percolate into Cromwell; ```; at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); ```,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4917#issuecomment-492863137
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-487949926:137,Deployability,configurat,configuration,137,"This is an amazing contribution!. I wonder whether it would be possible to make a single “create all the tables at once, in their latest configuration” migration for Postgres, given that no Cromwell instantiated prior to Postgres support could possibly have a database that needs migrating.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-487949926
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-487949926:137,Modifiability,config,configuration,137,"This is an amazing contribution!. I wonder whether it would be possible to make a single “create all the tables at once, in their latest configuration” migration for Postgres, given that no Cromwell instantiated prior to Postgres support could possibly have a database that needs migrating.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-487949926
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488093257:32,Deployability,patch,patch,32,"I have no idea why the ""codecov/patch"" test is failing, or how to fix it - the ""details"" link isn't very helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488093257
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488093257:39,Testability,test,test,39,"I have no idea why the ""codecov/patch"" test is failing, or how to fix it - the ""details"" link isn't very helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488093257
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488300367:88,Integrability,wrap,wrap,88,"@natechols -- Thanks again for this amazing contribution! We're at a point of trying to wrap up reviews for some urgent changes. Our plan is to come back to this PR in 2 weeks to do a more thorough review. Sorry about the delay, but hoping to get back to this soon.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488300367
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109:465,Deployability,release,releases,465,"@ruchim That's fine, this isn't blocking me right now, as long as I have something to tell my boss. However if someone has time to suggest what tests I should add for Postgresql, I can try to have those added by the time you're ready to review the entire mess. (Or should it just be everything you're testing for MySQL? This seems easy enough to add but I'm nervous about bloating your travis-ci runtimes.). Just out of curiosity, what is the timeline for Cromwell releases this year? I am fine using my fork for now but eventually we want to be able to use the official jarfile.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109:144,Testability,test,tests,144,"@ruchim That's fine, this isn't blocking me right now, as long as I have something to tell my boss. However if someone has time to suggest what tests I should add for Postgresql, I can try to have those added by the time you're ready to review the entire mess. (Or should it just be everything you're testing for MySQL? This seems easy enough to add but I'm nervous about bloating your travis-ci runtimes.). Just out of curiosity, what is the timeline for Cromwell releases this year? I am fine using my fork for now but eventually we want to be able to use the official jarfile.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109:301,Testability,test,testing,301,"@ruchim That's fine, this isn't blocking me right now, as long as I have something to tell my boss. However if someone has time to suggest what tests I should add for Postgresql, I can try to have those added by the time you're ready to review the entire mess. (Or should it just be everything you're testing for MySQL? This seems easy enough to add but I'm nervous about bloating your travis-ci runtimes.). Just out of curiosity, what is the timeline for Cromwell releases this year? I am fine using my fork for now but eventually we want to be able to use the official jarfile.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488330109
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799:91,Deployability,release,release,91,@natechols we are currently releasing every 3 weeks and next week is when we are aiming to release 41. We'll make sure to circle back to this PR and work with you on what to test when we have more time. The goal would be to get this released in 42 if all goes well!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799:233,Deployability,release,released,233,@natechols we are currently releasing every 3 weeks and next week is when we are aiming to release 41. We'll make sure to circle back to this PR and work with you on what to test when we have more time. The goal would be to get this released in 42 if all goes well!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799:174,Testability,test,test,174,@natechols we are currently releasing every 3 weeks and next week is when we are aiming to release 41. We'll make sure to circle back to this PR and work with you on what to test when we have more time. The goal would be to get this released in 42 if all goes well!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-488378799
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-499651256:145,Deployability,release,release,145,"@gemmalam Just wanted to check up on this since it's been a month - will it be reviewed as part of the current sprint, and hopefully included in release 43?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-499651256
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-499873031:40,Testability,test,testing,40,Hi @natechols! We are working on adding testing for this support. You can check out the PR https://github.com/broadinstitute/cromwell/pull/5018. Completing the reviewing and approval of this PR did carry over from our last sprint to this one. We are currently in our first week of a three week sprint.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-499873031
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1114,Availability,rollback,rollbackException,1114,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1231,Availability,error,error,1231,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1352,Availability,error,error,1352,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1114,Deployability,rollback,rollbackException,1114,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:162,Integrability,message,messages,162,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1358,Integrability,message,message,1358,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1061,Modifiability,Config,Config,1061,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1069,Modifiability,extend,extend,1069,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:893,Performance,concurren,concurrent,893,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:929,Performance,concurren,concurrent,929,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:692,Testability,Log,LoggerFactory,692,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606:1440,Testability,test,test,1440,"> There is one I'm having trouble googling a fix for. I can't figure out how to shut off PostgreSQL exceptions printing possibly sensitive row contents via their messages. I wouldn't be surprised if this is baked into the JDBC layer. We could try something like this:; ```; diff --git a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; index 5d28cf1..5b0e227 100644; --- a/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; +++ b/database/sql/src/main/scala/cromwell/database/slick/SlickDatabase.scala; @@ -11,6 +11,7 @@ import net.ceedubs.ficus.Ficus._; import org.slf4j.LoggerFactory; import slick.basic.DatabaseConfig; import slick.jdbc.{JdbcCapabilities, JdbcProfile, TransactionIsolation}; +import org.postgresql.util.{PSQLException, ServerErrorMessage}. import scala.concurrent.duration._; import scala.concurrent.{Await, ExecutionContext, Future}; @@ -199,6 +200,8 @@ abstract class SlickDatabase(override val originalDatabaseConfig: Config) extend; case _ => /* keep going */; }; throw rollbackException; + case pe: PSQLException =>; + throw new PSQLException(new ServerErrorMessage(s""Oh no, a postgres error occurred! ${pe.getMessage}"")); }; }(actionExecutionContext); }; ```; only with some on-the-fly modification of the error message instead of my dummy string. This compiles for me, but I'm not sure how to test it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504487606
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160:470,Deployability,integrat,integration,470,"Ah, oh well, thanks for the second set of eyes. https://github.com/broadinstitute/cromwell/commit/2682c001d99823098e655acd1dd7a3062a68f495 has your change implemented with some ~nasty~ reflection that hopefully the rest of the DSP-Batcher's will accept, and the test re-enabled. CI running here to see if it breaks anything:; https://travis-ci.com/broadinstitute/cromwell/builds/116462548. Assuming this works, I think the changes will pass all of our existing unit and integration tests!. We can get two others to review. I should abstain due to our collaboration on the code. 😉",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160:470,Integrability,integrat,integration,470,"Ah, oh well, thanks for the second set of eyes. https://github.com/broadinstitute/cromwell/commit/2682c001d99823098e655acd1dd7a3062a68f495 has your change implemented with some ~nasty~ reflection that hopefully the rest of the DSP-Batcher's will accept, and the test re-enabled. CI running here to see if it breaks anything:; https://travis-ci.com/broadinstitute/cromwell/builds/116462548. Assuming this works, I think the changes will pass all of our existing unit and integration tests!. We can get two others to review. I should abstain due to our collaboration on the code. 😉",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160:262,Testability,test,test,262,"Ah, oh well, thanks for the second set of eyes. https://github.com/broadinstitute/cromwell/commit/2682c001d99823098e655acd1dd7a3062a68f495 has your change implemented with some ~nasty~ reflection that hopefully the rest of the DSP-Batcher's will accept, and the test re-enabled. CI running here to see if it breaks anything:; https://travis-ci.com/broadinstitute/cromwell/builds/116462548. Assuming this works, I think the changes will pass all of our existing unit and integration tests!. We can get two others to review. I should abstain due to our collaboration on the code. 😉",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160:482,Testability,test,tests,482,"Ah, oh well, thanks for the second set of eyes. https://github.com/broadinstitute/cromwell/commit/2682c001d99823098e655acd1dd7a3062a68f495 has your change implemented with some ~nasty~ reflection that hopefully the rest of the DSP-Batcher's will accept, and the test re-enabled. CI running here to see if it breaks anything:; https://travis-ci.com/broadinstitute/cromwell/builds/116462548. Assuming this works, I think the changes will pass all of our existing unit and integration tests!. We can get two others to review. I should abstain due to our collaboration on the code. 😉",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504500160
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504501245:43,Testability,test,tests,43,Should I merge 2682c00 with this if the CI tests pass?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504501245
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504555440:45,Testability,test,tests,45,> Should I merge 2682c00 with this if the CI tests pass?. Yes plz.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504555440
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501:494,Integrability,message,message,494,"Tests continue to run well. I forgot about documentation though, both a short blurb in the `/CHANGELOG.md`, and that linking over to as much documentation as needed under `/docs`. Not sure if you've used MkDocs before, but [the live docs are hosted here](https://cromwell.readthedocs.io/en/stable/search.html?q=mysql), and the docs can be tested locally by running `mkdocs serve` from the cromwell root directory and then browsing to http://localhost:8000. If you run into any issues drop us a message here. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501:0,Testability,Test,Tests,0,"Tests continue to run well. I forgot about documentation though, both a short blurb in the `/CHANGELOG.md`, and that linking over to as much documentation as needed under `/docs`. Not sure if you've used MkDocs before, but [the live docs are hosted here](https://cromwell.readthedocs.io/en/stable/search.html?q=mysql), and the docs can be tested locally by running `mkdocs serve` from the cromwell root directory and then browsing to http://localhost:8000. If you run into any issues drop us a message here. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501:339,Testability,test,tested,339,"Tests continue to run well. I forgot about documentation though, both a short blurb in the `/CHANGELOG.md`, and that linking over to as much documentation as needed under `/docs`. Not sure if you've used MkDocs before, but [the live docs are hosted here](https://cromwell.readthedocs.io/en/stable/search.html?q=mysql), and the docs can be tested locally by running `mkdocs serve` from the cromwell root directory and then browsing to http://localhost:8000. If you run into any issues drop us a message here. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-504575501
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505530181:132,Integrability,message,message,132,"@natechols Do you mind making the last change requested above, then git-squashing everything into a one commit with a single commit message? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505530181
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505582077:33,Availability,failure,failure,33,I don't understand the Travis CI failure - is this unrelated? Is there a way for me to re-run the test?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505582077
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505582077:98,Testability,test,test,98,I don't understand the Travis CI failure - is this unrelated? Is there a way for me to re-run the test?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505582077
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193:29,Availability,error,error,29,"It's a dependency resolution error, which seems surprising. I cleared Travis cache and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193:7,Integrability,depend,dependency,7,"It's a dependency resolution error, which seems surprising. I cleared Travis cache and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193:77,Performance,cache,cache,77,"It's a dependency resolution error, which seems surprising. I cleared Travis cache and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193
https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193:62,Usability,clear,cleared,62,"It's a dependency resolution error, which seems surprising. I cleared Travis cache and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919#issuecomment-505586193
https://github.com/broadinstitute/cromwell/pull/4922#issuecomment-488566852:227,Performance,cache,cached-copy,227,"Speaking as an external contributor: I like this contributing guide. It is short and to the point. Great work!. One question: what if I as an external contributor am interested in maintaining some of the code? For instance the cached-copy localization (#4900 ) is a small self-contained piece of code. Our institute will use that all the time. So I don't mind to fix the bugs in that part of the code. Since WDL is a bigger community than broad, it would be nice if some (self-contained) parts of the code can be maintained by the community as well. A good example would be code for backends that broad doesn't use (as much). EDIT: #4919 would be another great example of code contributed and possibly maintained by the community.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4922#issuecomment-488566852
https://github.com/broadinstitute/cromwell/pull/4922#issuecomment-488566852:62,Usability,guid,guide,62,"Speaking as an external contributor: I like this contributing guide. It is short and to the point. Great work!. One question: what if I as an external contributor am interested in maintaining some of the code? For instance the cached-copy localization (#4900 ) is a small self-contained piece of code. Our institute will use that all the time. So I don't mind to fix the bugs in that part of the code. Since WDL is a bigger community than broad, it would be nice if some (self-contained) parts of the code can be maintained by the community as well. A good example would be code for backends that broad doesn't use (as much). EDIT: #4919 would be another great example of code contributed and possibly maintained by the community.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4922#issuecomment-488566852
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:67,Availability,error,error,67,"@cjllanwarne that wdl does look right. I was able to reproduce the error successfully using a similar wdl in Papiv2 backend:; ```; task random_words {. String dollar = ""$""; command <<<; cat << 'EOF' > random.txt; This should fail. ${dollar}{Hello} blah blah; EOF; >>>. runtime {; docker: ""ubuntu:latest""; }. output {; String text = read_string(""random.txt""); }; }. workflow read_random_words {; call random_words. output {; String random_text = random_words.text; }; }; ```. The error thrown by Cromwell is:; ```; ERROR - WorkflowManagerActor Workflow a8de1168-8b70-4d54-83f6-aa41adc8f87e failed (during ExecutingWorkflowState): java.lang.RuntimeException: Failed to evaluate 'read_random_words.random_text' (reason 1 of 1): Evaluating random_words.text failed: key not found: random_words; 	at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:29); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$7(WorkflowExecutionActor.scala:523); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$2(list.scala:66); 	at cats.Eval$.advance(Eval.scala:271); 	at cats.Eval$.loop$1(Eval.scala:350); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:479,Availability,error,error,479,"@cjllanwarne that wdl does look right. I was able to reproduce the error successfully using a similar wdl in Papiv2 backend:; ```; task random_words {. String dollar = ""$""; command <<<; cat << 'EOF' > random.txt; This should fail. ${dollar}{Hello} blah blah; EOF; >>>. runtime {; docker: ""ubuntu:latest""; }. output {; String text = read_string(""random.txt""); }; }. workflow read_random_words {; call random_words. output {; String random_text = random_words.text; }; }; ```. The error thrown by Cromwell is:; ```; ERROR - WorkflowManagerActor Workflow a8de1168-8b70-4d54-83f6-aa41adc8f87e failed (during ExecutingWorkflowState): java.lang.RuntimeException: Failed to evaluate 'read_random_words.random_text' (reason 1 of 1): Evaluating random_words.text failed: key not found: random_words; 	at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:29); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$7(WorkflowExecutionActor.scala:523); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$2(list.scala:66); 	at cats.Eval$.advance(Eval.scala:271); 	at cats.Eval$.loop$1(Eval.scala:350); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:514,Availability,ERROR,ERROR,514,"@cjllanwarne that wdl does look right. I was able to reproduce the error successfully using a similar wdl in Papiv2 backend:; ```; task random_words {. String dollar = ""$""; command <<<; cat << 'EOF' > random.txt; This should fail. ${dollar}{Hello} blah blah; EOF; >>>. runtime {; docker: ""ubuntu:latest""; }. output {; String text = read_string(""random.txt""); }; }. workflow read_random_words {; call random_words. output {; String random_text = random_words.text; }; }; ```. The error thrown by Cromwell is:; ```; ERROR - WorkflowManagerActor Workflow a8de1168-8b70-4d54-83f6-aa41adc8f87e failed (during ExecutingWorkflowState): java.lang.RuntimeException: Failed to evaluate 'read_random_words.random_text' (reason 1 of 1): Evaluating random_words.text failed: key not found: random_words; 	at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:29); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$7(WorkflowExecutionActor.scala:523); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:74); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:64); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$2(list.scala:66); 	at cats.Eval$.advance(Eval.scala:271); 	at cats.Eval$.loop$1(Eval.scala:350); 	at cats.Eval$.cats$Eval$$evaluate(Eval.scala:368); 	at cats.Eval$Defer.value(Eval.scala:257); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:2436,Testability,Log,LoggingFSM,2436,ances$$anon$1.traverse(list.scala:73); 	at cats.instances.ListInstances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:188); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:186); 	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:168); 	at akka.actor.FSM.processEvent(FSM.scala:687); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:820); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:802); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:678); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:2516,Testability,Log,LoggingFSM,2516,stances$$anon$1.traverse(list.scala:12); 	at cats.Traverse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:188); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:186); 	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:168); 	at akka.actor.FSM.processEvent(FSM.scala:687); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:820); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:802); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:678); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at a,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242:2571,Testability,Log,LoggingFSM,2571,rse$Ops.traverse(Traverse.scala:19); 	at cats.Traverse$Ops.traverse$(Traverse.scala:19); 	at cats.Traverse$ToTraverseOps$$anon$3.traverse(Traverse.scala:19); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.cromwell$engine$workflow$lifecycle$execution$WorkflowExecutionActor$$startRunnableNodes(WorkflowExecutionActor.scala:517); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:188); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor$$anonfun$5.applyOrElse(WorkflowExecutionActor.scala:186); 	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:168); 	at akka.actor.FSM.processEvent(FSM.scala:687); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.LoggingFSM.processEvent(FSM.scala:820); 	at akka.actor.LoggingFSM.processEvent$(FSM.scala:802); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processEvent(WorkflowExecutionActor.scala:51); 	at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:678); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:51); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.d,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4928#issuecomment-488786242
https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055:22,Modifiability,plugin,plugin,22,Argh. The [shellcheck plugin](https://plugins.jetbrains.com/plugin/10195-shellcheck) is not highlighting all warnings as I expected. 🤦‍♂. Will clean up the warnings using the brew'ed shellcheck.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055
https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055:38,Modifiability,plugin,plugins,38,Argh. The [shellcheck plugin](https://plugins.jetbrains.com/plugin/10195-shellcheck) is not highlighting all warnings as I expected. 🤦‍♂. Will clean up the warnings using the brew'ed shellcheck.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055
https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055:60,Modifiability,plugin,plugin,60,Argh. The [shellcheck plugin](https://plugins.jetbrains.com/plugin/10195-shellcheck) is not highlighting all warnings as I expected. 🤦‍♂. Will clean up the warnings using the brew'ed shellcheck.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4930#issuecomment-490131055
https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489150608:14,Deployability,Pipeline,Pipelines,14,"Are you using Pipelines API v1?. We are tracking a possible PAPI GPU issue that is limited to v1. If you are able to use the v2 backend instead, I would recommend that as a workaround (v2 is better in other ways too!).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489150608
https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959:132,Availability,avail,available,132,The official word from Google is that the OS installed on Pipelines API v1 workers has aged enough that driver support is no longer available. The best I can do on behalf of Cromwell is recommend switching to v2; if you have any further questions feel free to reopen!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959
https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959:45,Deployability,install,installed,45,The official word from Google is that the OS installed on Pipelines API v1 workers has aged enough that driver support is no longer available. The best I can do on behalf of Cromwell is recommend switching to v2; if you have any further questions feel free to reopen!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959
https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959:58,Deployability,Pipeline,Pipelines,58,The official word from Google is that the OS installed on Pipelines API v1 workers has aged enough that driver support is no longer available. The best I can do on behalf of Cromwell is recommend switching to v2; if you have any further questions feel free to reopen!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935#issuecomment-489215959
https://github.com/broadinstitute/cromwell/pull/4937#issuecomment-489165255:61,Deployability,update,updated,61,"For those who are curious yet lazy, here's a link to see the updated formatting [in-place](https://github.com/broadinstitute/cromwell/blob/aednichols-patch-1/CONTRIBUTING.md)!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4937#issuecomment-489165255
https://github.com/broadinstitute/cromwell/pull/4937#issuecomment-489165255:150,Deployability,patch,patch-,150,"For those who are curious yet lazy, here's a link to see the updated formatting [in-place](https://github.com/broadinstitute/cromwell/blob/aednichols-patch-1/CONTRIBUTING.md)!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4937#issuecomment-489165255
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117:152,Availability,reliab,reliable,152,"@cjllanwarne, here is the PR. This is only for workflow definitions, and only for line numbers. I found that it is, as you were saying, hard to extract reliable information from Hermes for column numbers. I *would* like to get the entire extent in the source file covered by an AST. It was slow slog to updates the tests to correctly check line numbers. Let's start with this change, and see how it goes. . Thank you,; Ohad.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117:303,Deployability,update,updates,303,"@cjllanwarne, here is the PR. This is only for workflow definitions, and only for line numbers. I found that it is, as you were saying, hard to extract reliable information from Hermes for column numbers. I *would* like to get the entire extent in the source file covered by an AST. It was slow slog to updates the tests to correctly check line numbers. Let's start with this change, and see how it goes. . Thank you,; Ohad.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117:315,Testability,test,tests,315,"@cjllanwarne, here is the PR. This is only for workflow definitions, and only for line numbers. I found that it is, as you were saying, hard to extract reliable information from Hermes for column numbers. I *would* like to get the entire extent in the source file covered by an AST. It was slow slog to updates the tests to correctly check line numbers. Let's start with this change, and see how it goes. . Thank you,; Ohad.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-489182117
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112:76,Availability,failure,failure,76,If you rebase onto the tip of `develop` you should be able to fix that test failure. We had to do some fixes to those docker tests thanks to some changes in Travis,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112:71,Testability,test,test,71,If you rebase onto the tip of `develop` you should be able to fix that test failure. We had to do some fixes to those docker tests thanks to some changes in Travis,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112
https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112:125,Testability,test,tests,125,If you rebase onto the tip of `develop` you should be able to fix that test failure. We had to do some fixes to those docker tests thanks to some changes in Travis,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4938#issuecomment-490123112
https://github.com/broadinstitute/cromwell/pull/4940#issuecomment-491383867:25,Deployability,release,release,25,Might or might not block release. We'll await Adam's verdict on Monday morning,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4940#issuecomment-491383867
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477:472,Deployability,release,release,472,"@helgridly @davidangb for context, our understanding is that the absolute worst case here is, ""Cromwell might make a change, meaning that Rawls/Agora won't validate something that Cromwell could run - if only it were to be submitted"". Or alternatively, ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". Given the slow rate of change in the WDL draft-2 libraries recently, and the (very significant) pain in updating Rawls and Agora every release, that feels like a reasonable position for a few months while we await the switchover to womtool-as-a-service. Are we missing something?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477:156,Security,validat,validate,156,"@helgridly @davidangb for context, our understanding is that the absolute worst case here is, ""Cromwell might make a change, meaning that Rawls/Agora won't validate something that Cromwell could run - if only it were to be submitted"". Or alternatively, ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". Given the slow rate of change in the WDL draft-2 libraries recently, and the (very significant) pain in updating Rawls and Agora every release, that feels like a reasonable position for a few months while we await the switchover to womtool-as-a-service. Are we missing something?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489665477
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429:26,Safety,avoid,avoid,26,"I'm really just trying to avoid ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". I think the process is reasonable as long as there are some safeguards against this, and if you tell me that the current test approach covers that, fine with me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429:176,Safety,safe,safeguards,176,"I'm really just trying to avoid ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". I think the process is reasonable as long as there are some safeguards against this, and if you tell me that the current test approach covers that, fine with me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429:237,Testability,test,test,237,"I'm really just trying to avoid ""Cromwell will regress and no longer succeed a workflow that Rawls thinks is fine"". I think the process is reasonable as long as there are some safeguards against this, and if you tell me that the current test approach covers that, fine with me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-489691429
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490096475:95,Deployability,upgrade,upgrades,95,"@davidangb I think that's fair. How about us saying that we'll continue to run the rawls/agora upgrades, but only if changes are made to the WDL draft 2 libraries. Otherwise we'll leave them at their current version?. In effect that probably means we won't be changing anything in the draft-2 libraries for the next few weeks... but it's good to have a fall back in case an urgent fix is needed (we didn't have anything planned in any case, which is why we didn't mind this freeze in the first place).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490096475
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490124790:132,Deployability,deploy,deploy,132,Do we want to keep this? (from Checklist for FC to accept Cromwell doc); ```; Run long-running submissions immediately before a dev deploy and observe that they pass after the new Cromwell version picks them up and completes them.; ```; This was added after the Cromwell 34 release meltdown. There were some changes in it that caused all the running submissions to fail.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490124790
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490124790:274,Deployability,release,release,274,Do we want to keep this? (from Checklist for FC to accept Cromwell doc); ```; Run long-running submissions immediately before a dev deploy and observe that they pass after the new Cromwell version picks them up and completes them.; ```; This was added after the Cromwell 34 release meltdown. There were some changes in it that caused all the running submissions to fail.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490124790
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490140739:36,Deployability,upgrade,upgrade,36,@salonishah11 I believe we now have upgrade tests in our CI which would catch that. @mcovarr @kshakir does that sound right?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490140739
https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490140739:44,Testability,test,tests,44,@salonishah11 I believe we now have upgrade tests in our CI which would catch that. @mcovarr @kshakir does that sound right?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4941#issuecomment-490140739
https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-490067240:56,Deployability,release,release,56,"Thank you. Looking forward to kicking the tires on this release.; What would be the default value of the driverVersion? It doesn't look like its a required attribute (??), so why not let GCP pick the stable one?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-490067240
https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334:190,Deployability,install,installed,190,"@sharmaashish that's a great point. I _suspect_ (but haven't checked this) that if we don't specify any driver version then the VM we receive will spin up with a GPU attached, but no driver installed. So it's not ""required"" in that sense, but if you want to use GPUs then perhaps it is... I think it would be appropriate to open an issue to ""Update the default Nvidia GPU version in PAPIv2"" with this suggestion (or maybe re-open this issue one with an updated title and description - I'll leave that up to you). I'll also say that since you've already identified the line in the code and the change you want to make, we always appreciate PRs from motivated contributors!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334
https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334:342,Deployability,Update,Update,342,"@sharmaashish that's a great point. I _suspect_ (but haven't checked this) that if we don't specify any driver version then the VM we receive will spin up with a GPU attached, but no driver installed. So it's not ""required"" in that sense, but if you want to use GPUs then perhaps it is... I think it would be appropriate to open an issue to ""Update the default Nvidia GPU version in PAPIv2"" with this suggestion (or maybe re-open this issue one with an updated title and description - I'll leave that up to you). I'll also say that since you've already identified the line in the code and the change you want to make, we always appreciate PRs from motivated contributors!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334
https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334:453,Deployability,update,updated,453,"@sharmaashish that's a great point. I _suspect_ (but haven't checked this) that if we don't specify any driver version then the VM we receive will spin up with a GPU attached, but no driver installed. So it's not ""required"" in that sense, but if you want to use GPUs then perhaps it is... I think it would be appropriate to open an issue to ""Update the default Nvidia GPU version in PAPIv2"" with this suggestion (or maybe re-open this issue one with an updated title and description - I'll leave that up to you). I'll also say that since you've already identified the line in the code and the change you want to make, we always appreciate PRs from motivated contributors!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4942#issuecomment-492702334
https://github.com/broadinstitute/cromwell/pull/4943#issuecomment-493122445:315,Energy Efficiency,schedul,schedule,315,"Thanks for your contribution!. I realize we didn't give much of an explanation for the ""hold"" label - we describe our process for external contributors here: https://github.com/broadinstitute/cromwell/blob/develop/CONTRIBUTING.md. In a nutshell, reviewing PRs is time-intensive and we have to work it into our team schedule alongside everything else.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4943#issuecomment-493122445
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774:288,Energy Efficiency,drain,drain,288,"I've worked out what happened, but I don't know if I can resolve this next problem. . I had call-caching turned on for SFS, and this was MD5 hash was being calculated by Cromwell on the login node, however for 2x 100GB BAM files at each step this was (obviously in retrospect) a resource drain. This was only applicable to backends that use the Local Filesystem (GCS and S3 file systems probably use their blob / object id). If you come across this issue, you might have a couple of solutions:; - Turn off call-caching, might not matter to you.; - If you're not using containers, you might be able to get away with the [path+modtime caching strategy](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options), requires you to use the [`soft-link` copying strategy](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem).; - If you **are** using containers, you're out of luck unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774:693,Modifiability,Config,Configuring,693,"I've worked out what happened, but I don't know if I can resolve this next problem. . I had call-caching turned on for SFS, and this was MD5 hash was being calculated by Cromwell on the login node, however for 2x 100GB BAM files at each step this was (obviously in retrospect) a resource drain. This was only applicable to backends that use the Local Filesystem (GCS and S3 file systems probably use their blob / object id). If you come across this issue, you might have a couple of solutions:; - Turn off call-caching, might not matter to you.; - If you're not using containers, you might be able to get away with the [path+modtime caching strategy](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options), requires you to use the [`soft-link` copying strategy](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem).; - If you **are** using containers, you're out of luck unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774:141,Security,hash,hash,141,"I've worked out what happened, but I don't know if I can resolve this next problem. . I had call-caching turned on for SFS, and this was MD5 hash was being calculated by Cromwell on the login node, however for 2x 100GB BAM files at each step this was (obviously in retrospect) a resource drain. This was only applicable to backends that use the Local Filesystem (GCS and S3 file systems probably use their blob / object id). If you come across this issue, you might have a couple of solutions:; - Turn off call-caching, might not matter to you.; - If you're not using containers, you might be able to get away with the [path+modtime caching strategy](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options), requires you to use the [`soft-link` copying strategy](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem).; - If you **are** using containers, you're out of luck unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774:186,Testability,log,login,186,"I've worked out what happened, but I don't know if I can resolve this next problem. . I had call-caching turned on for SFS, and this was MD5 hash was being calculated by Cromwell on the login node, however for 2x 100GB BAM files at each step this was (obviously in retrospect) a resource drain. This was only applicable to backends that use the Local Filesystem (GCS and S3 file systems probably use their blob / object id). If you come across this issue, you might have a couple of solutions:; - Turn off call-caching, might not matter to you.; - If you're not using containers, you might be able to get away with the [path+modtime caching strategy](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options), requires you to use the [`soft-link` copying strategy](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem).; - If you **are** using containers, you're out of luck unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507482774
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507792585:26,Performance,cache,cached-copy,26,"re containers, would the `cached-copy` localization strategy in #4900 help you?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507792585
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507871439:155,Performance,cache,cached-copy,155,"Yeah I've been following that! I'm excited to try it soon, and I think it'll knock out a good chunk of CPU when it's copying files between disks, but the `cached-copy` strategy hard links files, which means it's not eligible for any other call-caching strategy except File.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-507871439
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-508219639:328,Deployability,pipeline,pipeline,328,"As someone who is having a somewhat similar issue, what did you do to fix the resource management problem? I'm seeing a lot of processes spawned, and memory usage growing out of control. I have a system with a 6-core CPU and 32 GB of RAM, running Linux Mint, and I'm trying to run the processing-for-variant-discovery-gatk4.wdl pipeline (with some interest in running other GATK pipelines as well)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-508219639
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-508219639:379,Deployability,pipeline,pipelines,379,"As someone who is having a somewhat similar issue, what did you do to fix the resource management problem? I'm seeing a lot of processes spawned, and memory usage growing out of control. I have a system with a 6-core CPU and 32 GB of RAM, running Linux Mint, and I'm trying to run the processing-for-variant-discovery-gatk4.wdl pipeline (with some interest in running other GATK pipelines as well)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-508219639
https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-572796376:79,Energy Efficiency,reduce,reduce,79,"Hey @bkohrn, just checking up on old threads:. - running a MySQL database will reduce the memory usage of Cromwell for larger workflows.; - ie: memory(mySQL + cromwell) < memory(cromwell w/ NO MySQL); - CPU can be mitigated by turning off call-caching, or at least the ""File"" strategy for call-caching.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945#issuecomment-572796376
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:256,Availability,down,downloads,256,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:548,Availability,echo,echo,548,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:662,Availability,echo,echo,662,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:137,Modifiability,portab,portable,137,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:166,Safety,timeout,timeout,166,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:177,Safety,timeout,timeout,177,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:279,Safety,timeout,timeout,279,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:346,Safety,timeout,timeout-invocation,346,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:419,Safety,timeout,timeout,419,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:451,Safety,timeout,timeout,451,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717:651,Safety,timeout,timeout,651,"Side note for those **only** looking to put time limits on commands, and **not** looking for a workaround for cloud bugs-- here's a more-portable time limit option: `timeout`. `timeout` differs slightly in each distro. Example docs:; - https://busybox.net/downloads/BusyBox.html#timeout; - https://www.gnu.org/software/coreutils/manual/html_node/timeout-invocation.html; - https://manpages.debian.org/stretch/coreutils/timeout.1.en.html. The command `timeout` will most likely be unable to help for ""stuck"" cloud jobs. For example, if the command `echo hello world` actually exits but for some unknown reason the cloud VM sticks around forever, then `timeout 5s echo hello world` will likely have the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4946#issuecomment-490059717
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:1082,Deployability,pipeline,pipelines,1082,ing [#4947](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=desc) into [develop](https://codecov.io/gh/broadinstitute/cromwell/commit/26085f5833cee3c9091d391102d5d0885a2b7d71?src=pr&el=desc) will **increase** coverage by `2.22%`.; > The diff coverage is `84.61%`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/graphs/tree.svg?width=650&token=DJALPpnS9I&height=150&src=pr)](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## develop #4947 +/- ##; ===========================================; + Coverage 62.61% 64.84% +2.22% ; ===========================================; Files 1015 1015 ; Lines 25904 25914 +10 ; Branches 811 829 +18 ; ===========================================; + Hits 16221 16804 +583 ; + Misses 9683 9110 -573; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=tree) | Coverage Δ | |; |---|---|---|; | [.../google/pipelines/v2alpha1/api/ActionBuilder.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvZ29vZ2xlL3BpcGVsaW5lcy92MmFscGhhMS9zcmMvbWFpbi9zY2FsYS9jcm9td2VsbC9iYWNrZW5kL2dvb2dsZS9waXBlbGluZXMvdjJhbHBoYTEvYXBpL0FjdGlvbkJ1aWxkZXIuc2NhbGE=) | `82.4% <84.61%> (+20.5%)` | :arrow_up: |; | [.../scala/cromiam/webservice/EngineRouteSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-Q3JvbUlBTS9zcmMvbWFpbi9zY2FsYS9jcm9taWFtL3dlYnNlcnZpY2UvRW5naW5lUm91dGVTdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...expression/renaming/BinaryOperatorEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvbmV3LWJhc2Uvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmFzZS93ZGxvbTJ3b20vZXhwcmVzc2lvbi9yZW5hbWluZy9CaW5hcnlPcGVyYXRvckV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...l/services/womtool/models/WomTypeJsonSupport.scala](https://code,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:4534,Deployability,update,update,4534,"titute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvbWV0YWRhdGEvbWV0YWRhdGEuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | ... and [645 more](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=footer). Last update [26085f5...01c37f1](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:4433,Energy Efficiency,Power,Powered,4433,"titute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvbWV0YWRhdGEvbWV0YWRhdGEuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | ... and [645 more](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=footer). Last update [26085f5...01c37f1](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:2333,Modifiability,config,config,2333,vYXBpL0FjdGlvbkJ1aWxkZXIuc2NhbGE=) | `82.4% <84.61%> (+20.5%)` | :arrow_up: |; | [.../scala/cromiam/webservice/EngineRouteSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-Q3JvbUlBTS9zcmMvbWFpbi9zY2FsYS9jcm9taWFtL3dlYnNlcnZpY2UvRW5naW5lUm91dGVTdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...expression/renaming/BinaryOperatorEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvbmV3LWJhc2Uvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmFzZS93ZGxvbTJ3b20vZXhwcmVzc2lvbi9yZW5hbWluZy9CaW5hcnlPcGVyYXRvckV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...l/services/womtool/models/WomTypeJsonSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvd29tdG9vbC9tb2RlbHMvV29tVHlwZUpzb25TdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...end/impl/sfs/config/CpuDeclarationValidation.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvc2ZzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9zZnMvY29uZmlnL0NwdURlY2xhcmF0aW9uVmFsaWRhdGlvbi5zY2FsYQ==) | `0% <0%> (-100%)` | :arrow_down: |; | [...aft2/src/main/scala/wdl/draft2/model/package.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyY,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:2925,Security,validat,validate,2925,XhwcmVzc2lvbi9yZW5hbWluZy9CaW5hcnlPcGVyYXRvckV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...l/services/womtool/models/WomTypeJsonSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvd29tdG9vbC9tb2RlbHMvV29tVHlwZUpzb25TdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...end/impl/sfs/config/CpuDeclarationValidation.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvc2ZzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9zZnMvY29uZmlnL0NwdURlY2xhcmF0aW9uVmFsaWRhdGlvbi5zY2FsYQ==) | `0% <0%> (-100%)` | :arrow_down: |; | [...aft2/src/main/scala/wdl/draft2/model/package.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21ha,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:2934,Security,Validat,Validate,2934,XhwcmVzc2lvbi9yZW5hbWluZy9CaW5hcnlPcGVyYXRvckV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...l/services/womtool/models/WomTypeJsonSupport.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvd29tdG9vbC9tb2RlbHMvV29tVHlwZUpzb25TdXBwb3J0LnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...end/impl/sfs/config/CpuDeclarationValidation.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvc2ZzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9zZnMvY29uZmlnL0NwdURlY2xhcmF0aW9uVmFsaWRhdGlvbi5zY2FsYQ==) | `0% <0%> (-100%)` | :arrow_down: |; | [...aft2/src/main/scala/wdl/draft2/model/package.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21ha,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620:4296,Usability,learn,learn,4296,"titute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL21vZGVsL2RyYWZ0Mi9zcmMvbWFpbi9zY2FsYS93ZGwvZHJhZnQyL21vZGVsL3BhY2thZ2Uuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...ool/src/main/scala/womtool/validate/Validate.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d29tdG9vbC9zcmMvbWFpbi9zY2FsYS93b210b29sL3ZhbGlkYXRlL1ZhbGlkYXRlLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...king/expression/files/BiscayneFileEvaluators.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-d2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvc3JjL21haW4vc2NhbGEvd2RsL3RyYW5zZm9ybXMvYmlzY2F5bmUvbGlua2luZy9leHByZXNzaW9uL2ZpbGVzL0Jpc2NheW5lRmlsZUV2YWx1YXRvcnMuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/backend/impl/bcs/BcsDocker.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c3VwcG9ydGVkQmFja2VuZHMvYmNzL3NyYy9tYWluL3NjYWxhL2Nyb213ZWxsL2JhY2tlbmQvaW1wbC9iY3MvQmNzRG9ja2VyLnNjYWxh) | `0% <0%> (-100%)` | :arrow_down: |; | [...in/scala/cromwell/services/metadata/metadata.scala](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree#diff-c2VydmljZXMvc3JjL21haW4vc2NhbGEvY3JvbXdlbGwvc2VydmljZXMvbWV0YWRhdGEvbWV0YWRhdGEuc2NhbGE=) | `0% <0%> (-100%)` | :arrow_down: |; | ... and [645 more](https://codecov.io/gh/broadinstitute/cromwell/pull/4947/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=footer). Last update [26085f5...01c37f1](https://codecov.io/gh/broadinstitute/cromwell/pull/4947?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4947#issuecomment-491028620
https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116:111,Availability,ERROR,ERROR,111,"I spoke too soon, seeing a lot of `23:47:24.836 [centaur-acting-like-a-system-akka.actor.default-dispatcher-9] ERROR centaur.api.CentaurCromwellClient$ - Submitting invalid_inputs_json_object returned 400 Bad Request`. . Maybe only log as an error (and retry...) if the return code is not 4xx?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116
https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116:242,Availability,error,error,242,"I spoke too soon, seeing a lot of `23:47:24.836 [centaur-acting-like-a-system-akka.actor.default-dispatcher-9] ERROR centaur.api.CentaurCromwellClient$ - Submitting invalid_inputs_json_object returned 400 Bad Request`. . Maybe only log as an error (and retry...) if the return code is not 4xx?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116
https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116:232,Testability,log,log,232,"I spoke too soon, seeing a lot of `23:47:24.836 [centaur-acting-like-a-system-akka.actor.default-dispatcher-9] ERROR centaur.api.CentaurCromwellClient$ - Submitting invalid_inputs_json_object returned 400 Bad Request`. . Maybe only log as an error (and retry...) if the return code is not 4xx?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359116
https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359665:39,Testability,log,log,39,"Cool, I'll switch the `4XX` series to `log.info()`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4956#issuecomment-491359665
https://github.com/broadinstitute/cromwell/issues/4963#issuecomment-491859810:310,Integrability,message,message,310,"Hi @Bek - thanks to eagle eyed colleague @cjllanwarne - you're using the interpolation if/else syntax outside of a `task` `command` block, however you can instead use `if true_or_false then ""Foo"" else ""Bar""`. Also note that there's another issue lurking. In your `call` block you need to add `input:`, `input: message = var`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4963#issuecomment-491859810
https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819:172,Testability,test,tested,172,"@DavyCats Nice workflow.; I have modified it slightly. It will now always fail. Unless call-caching is incorrect. An absolute path should be chosen for outputDir. ~~I have tested this with cromwell-41 and it fails at first. But succeeds when the second time when call-caching is enabled.~~. EDIT: Using this test workflow I found something really weird.; EDIT2: Nevermind, this does not work as a good test.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819
https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819:308,Testability,test,test,308,"@DavyCats Nice workflow.; I have modified it slightly. It will now always fail. Unless call-caching is incorrect. An absolute path should be chosen for outputDir. ~~I have tested this with cromwell-41 and it fails at first. But succeeds when the second time when call-caching is enabled.~~. EDIT: Using this test workflow I found something really weird.; EDIT2: Nevermind, this does not work as a good test.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819
https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819:402,Testability,test,test,402,"@DavyCats Nice workflow.; I have modified it slightly. It will now always fail. Unless call-caching is incorrect. An absolute path should be chosen for outputDir. ~~I have tested this with cromwell-41 and it fails at first. But succeeds when the second time when call-caching is enabled.~~. EDIT: Using this test workflow I found something really weird.; EDIT2: Nevermind, this does not work as a good test.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-496500819
https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498156531:28,Security,access,access,28,@gemmalam Could you give me access to view this issue? email: davycats.dc@gmail.com,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498156531
https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498294904:80,Security,access,access,80,@DavyCats I sent you an invitation! Let me know if you run into any issues with access,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4965#issuecomment-498294904
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358:429,Deployability,pipeline,pipelines-api-workflow-options,429,"Hey @indraniel -- this isn't yet supported --but the plan is to add it eventually. For now, it may be helpful to add something like an rsync at the top of your task, to see what logs are being produced by your task, or if things have gone quiet. It's also possible to add a monitoring script to run in the background that includes info about cpu/memory usage ; https://cromwell.readthedocs.io/en/stable/wf_options/Google/#google-pipelines-api-workflow-options (see ""monitoring_script"")",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358:274,Energy Efficiency,monitor,monitoring,274,"Hey @indraniel -- this isn't yet supported --but the plan is to add it eventually. For now, it may be helpful to add something like an rsync at the top of your task, to see what logs are being produced by your task, or if things have gone quiet. It's also possible to add a monitoring script to run in the background that includes info about cpu/memory usage ; https://cromwell.readthedocs.io/en/stable/wf_options/Google/#google-pipelines-api-workflow-options (see ""monitoring_script"")",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358:178,Testability,log,logs,178,"Hey @indraniel -- this isn't yet supported --but the plan is to add it eventually. For now, it may be helpful to add something like an rsync at the top of your task, to see what logs are being produced by your task, or if things have gone quiet. It's also possible to add a monitoring script to run in the background that includes info about cpu/memory usage ; https://cromwell.readthedocs.io/en/stable/wf_options/Google/#google-pipelines-api-workflow-options (see ""monitoring_script"")",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-491980358
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:222,Deployability,pipeline,pipeline,222,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:288,Deployability,pipeline,pipelines,288,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:646,Deployability,pipeline,pipelines-tools,646,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:708,Deployability,pipeline,pipelines,708,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:826,Deployability,pipeline,pipelines-tools,826,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979:888,Deployability,pipeline,pipelines,888,"For later when we want to begin implementing this feature:. The [Papi docs](https://cloud.google.com/genomics/docs/how-tos/migration#accessing_the_containers) recommend adding an action that looks like this:. ```json; {; ""pipeline"": {; ""actions"": [; {; ""imageUri"": ""gcr.io/cloud-genomics-pipelines/tools"",; ""entrypoint"": ""ssh-server"",; ""flags"": [; ""RUN_IN_BACKGROUND""; ],; ""portMappings"": {; ""22"": 22; }; }; ]; }; }; ```. via: https://groups.google.com/forum/#!topic/google-genomics-discuss/1nkIxKrqBk0. Permalinks versions of the floating-""master""-links in that thread:; - [""Handling of the command line flag""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L402-L404); - [""Container (""action"") added""](https://github.com/googlegenomics/pipelines-tools/blob/749315a73e6c3bd5277351e32a365f42198db1ae/pipelines/internal/commands/run/run.go#L759-L766)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-492863979
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-494561050:431,Energy Efficiency,monitor,monitoringAction,431,"Followed up with @ruchim via email and we poked around the codebase this afternoon and think we have a good idea on how to add this functionality. First though we wanted to run the general plan by you guys and had a couple of questions. . It seems like the place to staple this in would be as an additional `Action` in `GenomicsFactory` (as was alluded to above). We weren't sure if it made sense to staple it in as an additional `monitoringAction` or `userAction` as they are both handled slightly differently than this would be. Neither fits perfectly, but it seems like it could potentially be made to work in either place. . Another alternative (maybe the cleanest one?) would be to just introduce a `remoteAccessAction` or similar helper that builds up an action just for this purpose. We wouldn't want to change the default behavior and/or have this `ssh` server always running, so it seems to make sense to make it configurable. We figured the PAPI section of the conf file would be a reasonable place to add this new option. Does that generally sound in line with how you guys would approach this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-494561050
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-494561050:922,Modifiability,config,configurable,922,"Followed up with @ruchim via email and we poked around the codebase this afternoon and think we have a good idea on how to add this functionality. First though we wanted to run the general plan by you guys and had a couple of questions. . It seems like the place to staple this in would be as an additional `Action` in `GenomicsFactory` (as was alluded to above). We weren't sure if it made sense to staple it in as an additional `monitoringAction` or `userAction` as they are both handled slightly differently than this would be. Neither fits perfectly, but it seems like it could potentially be made to work in either place. . Another alternative (maybe the cleanest one?) would be to just introduce a `remoteAccessAction` or similar helper that builds up an action just for this purpose. We wouldn't want to change the default behavior and/or have this `ssh` server always running, so it seems to make sense to make it configurable. We figured the PAPI section of the conf file would be a reasonable place to add this new option. Does that generally sound in line with how you guys would approach this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-494561050
https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-497762266:91,Testability,log,logged,91,Whatever was done seems to have worked. I clicked the second invitation link while already logged in and I can now see the JIRA issues in question. Thanks all!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4966#issuecomment-497762266
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:199,Availability,error,error,199,"> I have tried Float memory_gb = 1.0 as the runtime attribute and ${""-l mem="" + memory_gb + ""GB""} as the submit string but this fails with qsub: Illegal attribute or resource value Resource_List.mem error. `Int memory = 1` is the equivalent of `Int memory_b = 1` and is generating values in **bytes**. A WDL specifying gigs of memory will therefore generate very large values, with 4GB generating the string `-l mem=4294967296""GB""`. If you navigate within the cromwell-executions directory and find the `submit*` files that contain the generated qsub command, you should see something like that. `cd` to the directory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; St",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:726,Availability,error,error,726,"> I have tried Float memory_gb = 1.0 as the runtime attribute and ${""-l mem="" + memory_gb + ""GB""} as the submit string but this fails with qsub: Illegal attribute or resource value Resource_List.mem error. `Int memory = 1` is the equivalent of `Int memory_b = 1` and is generating values in **bytes**. A WDL specifying gigs of memory will therefore generate very large values, with 4GB generating the string `-l mem=4294967296""GB""`. If you navigate within the cromwell-executions directory and find the `submit*` files that contain the generated qsub command, you should see something like that. `cd` to the directory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; St",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:1698,Availability,down,down,1698,"irectory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; String env_start=""${""; String env_end=""}""; # other variables here; """""". submit = """"""; qsub \; -P ${env_start}PROJECT:-raijin_project_id${env_end} \; ...; """"""; ```. > jobfs is a parameter used to control scratch space local to the execution node. Currently it is being passed as a string. Unfortunately you cannot define a parameter as rich as `memory`. For custom attributes one only has the choice of `Float`, `Int`, or `String`. If you don't like `String`, you could use a `Float` and have the WDL use `runtime { jobfs_gb: 4.0 }`, or just `runtime { jobfs: 4.0 }` and tell everyone to always using gigabytes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:832,Modifiability,config,config,832,"> I have tried Float memory_gb = 1.0 as the runtime attribute and ${""-l mem="" + memory_gb + ""GB""} as the submit string but this fails with qsub: Illegal attribute or resource value Resource_List.mem error. `Int memory = 1` is the equivalent of `Int memory_b = 1` and is generating values in **bytes**. A WDL specifying gigs of memory will therefore generate very large values, with 4GB generating the string `-l mem=4294967296""GB""`. If you navigate within the cromwell-executions directory and find the `submit*` files that contain the generated qsub command, you should see something like that. `cd` to the directory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; St",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:1572,Modifiability,variab,variable,1572,"omething like that. `cd` to the directory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; String env_start=""${""; String env_end=""}""; # other variables here; """""". submit = """"""; qsub \; -P ${env_start}PROJECT:-raijin_project_id${env_end} \; ...; """"""; ```. > jobfs is a parameter used to control scratch space local to the execution node. Currently it is being passed as a string. Unfortunately you cannot define a parameter as rich as `memory`. For custom attributes one only has the choice of `Float`, `Int`, or `String`. If you don't like `String`, you could use a `Float` and have the WDL use `runtime { jobfs_gb: 4.0 }`, or just `runtime { jobfs: 4.0 }` and tell ev",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:1637,Modifiability,variab,variables,1637,"irectory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; String env_start=""${""; String env_end=""}""; # other variables here; """""". submit = """"""; qsub \; -P ${env_start}PROJECT:-raijin_project_id${env_end} \; ...; """"""; ```. > jobfs is a parameter used to control scratch space local to the execution node. Currently it is being passed as a string. Unfortunately you cannot define a parameter as rich as `memory`. For custom attributes one only has the choice of `Float`, `Int`, or `String`. If you don't like `String`, you could use a `Float` and have the WDL use `runtime { jobfs_gb: 4.0 }`, or just `runtime { jobfs: 4.0 }` and tell everyone to always using gigabytes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:1842,Modifiability,variab,variable,1842,"irectory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; String env_start=""${""; String env_end=""}""; # other variables here; """""". submit = """"""; qsub \; -P ${env_start}PROJECT:-raijin_project_id${env_end} \; ...; """"""; ```. > jobfs is a parameter used to control scratch space local to the execution node. Currently it is being passed as a string. Unfortunately you cannot define a parameter as rich as `memory`. For custom attributes one only has the choice of `Float`, `Int`, or `String`. If you don't like `String`, you could use a `Float` and have the WDL use `runtime { jobfs_gb: 4.0 }`, or just `runtime { jobfs: 4.0 }` and tell everyone to always using gigabytes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439:2050,Modifiability,variab,variables,2050,"irectory, take the generated qsub command and try it on your cluster. Hopefully you get the same ""Illegal attribute"" error. Play around with the command until you get the correct syntax. From there we can get your Cromwell config setup such it transforms the `memory` attribute into a valid syntax. Some possible examples:. | Example qsub usage | Runtime Attribute | Description |; |------------------------|------------------------|-------------------------------------------------------------------------------------------------|; | `qsub -l mem=4.0GB …` | `Float memory_gb = 1` | decimal values allowed, units are two characters uppercase |; | `qsub -l mem=4g …` | `Int memory_gb = 1` | integer values only, no decimals, and units must be one character lowercase |; | `qsub -l mem=4000mb …` | `Int memory_mb = 1000` | integer values only, and it turns out gigabytes aren't even allowed as a unit, so use megabytes |. > I would like to use $PROJECT environment variable as the default value for raijin_project_id. Environment variables won't work within HOCON, but can be passed through down into the generated submit files. It will take a bit of escaping to get past WDL-draft2, as both POSIX and WDL-draft2 both use `${...}` for variable names. To escape past WDL-draft2, create two new runtime attributes and then use them in your submit. Example:; ```HOCON; runtime-attributes = """"""; String env_start=""${""; String env_end=""}""; # other variables here; """""". submit = """"""; qsub \; -P ${env_start}PROJECT:-raijin_project_id${env_end} \; ...; """"""; ```. > jobfs is a parameter used to control scratch space local to the execution node. Currently it is being passed as a string. Unfortunately you cannot define a parameter as rich as `memory`. For custom attributes one only has the choice of `Float`, `Int`, or `String`. If you don't like `String`, you could use a `Float` and have the WDL use `runtime { jobfs_gb: 4.0 }`, or just `runtime { jobfs: 4.0 }` and tell everyone to always using gigabytes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-492892439
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-2105600521:146,Deployability,configurat,configuration,146,"Hi！; I am glad to see this issue, and I have also tried using PBS as the backend to run it. But I'm not very good at it.; Can you show me how the configuration file for cromwell is defined when using PBS as the backend?; Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-2105600521
https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-2105600521:146,Modifiability,config,configuration,146,"Hi！; I am glad to see this issue, and I have also tried using PBS as the backend to run it. But I'm not very good at it.; Can you show me how the configuration file for cromwell is defined when using PBS as the backend?; Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967#issuecomment-2105600521
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492444503:24,Availability,error,error,24,"I just encountered this error, as well. I narrowed it down to this commit. https://github.com/broadinstitute/cromwell/commit/448067fd72fc1bde89c0e4291d8790a65ff5968f",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492444503
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492444503:54,Availability,down,down,54,"I just encountered this error, as well. I narrowed it down to this commit. https://github.com/broadinstitute/cromwell/commit/448067fd72fc1bde89c0e4291d8790a65ff5968f",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492444503
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492445214:8,Testability,test,test,8,"Example test case:. `wf.cwl`:; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0. class: Workflow. inputs:; - id: astring; type: string. outputs:; - id: afile; type: File; outputSource: touch/output. steps:; - id: touch; run: cwl/touch.cwl; in:; - id: input; source: astring; out:; - id: output; ```. in `cwl/touch.cwl`:; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0. requirements:; - class: DockerRequirement; dockerPull: ubuntu:bionic-20180426. class: CommandLineTool. inputs:; - id: input; type: string; inputBinding:; position: 0. outputs:; - id: output; type: File; outputBinding:; glob: $(inputs.input); ; baseCommand: [touch]; ```; then zip the dir:; ```; zip -r cwl.zip cwl; ```; test input `wf.json`:; ```; {; ""astring"": ""hello""; }; ```. example run cmd:; ```; java -Dconfig.file=/mnt/scratch/cromwell.examples.conf -jar /mnt/scratch/cromwell-37-6447dd6-SNAP.jar run wf.cwl -i wf.json --imports cwl.zip -t CWL; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492445214
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492445214:691,Testability,test,test,691,"Example test case:. `wf.cwl`:; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0. class: Workflow. inputs:; - id: astring; type: string. outputs:; - id: afile; type: File; outputSource: touch/output. steps:; - id: touch; run: cwl/touch.cwl; in:; - id: input; source: astring; out:; - id: output; ```. in `cwl/touch.cwl`:; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0. requirements:; - class: DockerRequirement; dockerPull: ubuntu:bionic-20180426. class: CommandLineTool. inputs:; - id: input; type: string; inputBinding:; position: 0. outputs:; - id: output; type: File; outputBinding:; glob: $(inputs.input); ; baseCommand: [touch]; ```; then zip the dir:; ```; zip -r cwl.zip cwl; ```; test input `wf.json`:; ```; {; ""astring"": ""hello""; }; ```. example run cmd:; ```; java -Dconfig.file=/mnt/scratch/cromwell.examples.conf -jar /mnt/scratch/cromwell-37-6447dd6-SNAP.jar run wf.cwl -i wf.json --imports cwl.zip -t CWL; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-492445214
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137:110,Availability,error,error,110,"I have encountered the same problem, either local mode or server mode. version : comwell41; wdl: version 1. - error info: . ```; ""submission"": ""2019-06-28T08:36:56.384Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/imports_workflow_63e53e21-b200-46b2-9653-db79983d6c1d_3805297415647673436.zip4786068963842572955/bcftools-task/bcftoolsView.wdl""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ```. - my wdl header. ```; version 1.0. import ""bcftools-task/bcftoolsView.wdl"" as select; import ""beagle-task/prephasing.wdl"" as prephasing. ```. - unzip -v impute_human_beagle_v1.zip. ```; Archive: impute_human_beagle_v1.zip; Length Method Size Cmpr Date Time CRC-32 Name; -------- ------ ------- ---- ---------- ----- -------- ----; 655 Defl:N 319 51% 06-28-2019 15:52 d52896d1 bcftools-task/bcftoolsView.wdl; 694 Defl:N 384 45% 06-28-2019 14:24 552eeedb beagle-task/prephasing.wdl; -------- ------- --- -------; 1349 703 48% 2 files; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137:194,Availability,failure,failures,194,"I have encountered the same problem, either local mode or server mode. version : comwell41; wdl: version 1. - error info: . ```; ""submission"": ""2019-06-28T08:36:56.384Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/imports_workflow_63e53e21-b200-46b2-9653-db79983d6c1d_3805297415647673436.zip4786068963842572955/bcftools-task/bcftoolsView.wdl""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ```. - my wdl header. ```; version 1.0. import ""bcftools-task/bcftoolsView.wdl"" as select; import ""beagle-task/prephasing.wdl"" as prephasing. ```. - unzip -v impute_human_beagle_v1.zip. ```; Archive: impute_human_beagle_v1.zip; Length Method Size Cmpr Date Time CRC-32 Name; -------- ------ ------- ---- ---------- ----- -------- ----; 655 Defl:N 319 51% 06-28-2019 15:52 d52896d1 bcftools-task/bcftoolsView.wdl; 694 Defl:N 384 45% 06-28-2019 14:24 552eeedb beagle-task/prephasing.wdl; -------- ------- --- -------; 1349 703 48% 2 files; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137:247,Integrability,message,message,247,"I have encountered the same problem, either local mode or server mode. version : comwell41; wdl: version 1. - error info: . ```; ""submission"": ""2019-06-28T08:36:56.384Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/imports_workflow_63e53e21-b200-46b2-9653-db79983d6c1d_3805297415647673436.zip4786068963842572955/bcftools-task/bcftoolsView.wdl""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ```. - my wdl header. ```; version 1.0. import ""bcftools-task/bcftoolsView.wdl"" as select; import ""beagle-task/prephasing.wdl"" as prephasing. ```. - unzip -v impute_human_beagle_v1.zip. ```; Archive: impute_human_beagle_v1.zip; Length Method Size Cmpr Date Time CRC-32 Name; -------- ------ ------- ---- ---------- ----- -------- ----; 655 Defl:N 319 51% 06-28-2019 15:52 d52896d1 bcftools-task/bcftoolsView.wdl; 694 Defl:N 384 45% 06-28-2019 14:24 552eeedb beagle-task/prephasing.wdl; -------- ------- --- -------; 1349 703 48% 2 files; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137:401,Integrability,message,message,401,"I have encountered the same problem, either local mode or server mode. version : comwell41; wdl: version 1. - error info: . ```; ""submission"": ""2019-06-28T08:36:56.384Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""/tmp/imports_workflow_63e53e21-b200-46b2-9653-db79983d6c1d_3805297415647673436.zip4786068963842572955/bcftools-task/bcftoolsView.wdl""; }; ],; ""message"": ""Workflow input processing failed""; }; ],; ```. - my wdl header. ```; version 1.0. import ""bcftools-task/bcftoolsView.wdl"" as select; import ""beagle-task/prephasing.wdl"" as prephasing. ```. - unzip -v impute_human_beagle_v1.zip. ```; Archive: impute_human_beagle_v1.zip; Length Method Size Cmpr Date Time CRC-32 Name; -------- ------ ------- ---- ---------- ----- -------- ----; 655 Defl:N 319 51% 06-28-2019 15:52 d52896d1 bcftools-task/bcftoolsView.wdl; 694 Defl:N 384 45% 06-28-2019 14:24 552eeedb beagle-task/prephasing.wdl; -------- ------- --- -------; 1349 703 48% 2 files; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-506658137
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519025813:684,Availability,echo,echo,684,"Hi @notestaff and @huangzhibo -; I'm currently investigating this issue and trying to reproduce the problem.; Since I'm not familiar with WDL, I took workflow examples from [here](https://cromwell.readthedocs.io/en/stable/SubWorkflows/) and put `sub_wdl.wdl` in a subdirectory.; Therefore, the `main.wdl` looks like ; ```; import ""sub_dir/sub_wdl.wdl"" as sub. workflow main_workflow {; call sub.hello_and_goodbye { input: hello_and_goodbye_input = ""sub world"" }; # call myTask { input: hello_and_goodbye.hello_output }; output {; String main_output = hello_and_goodbye.hello_output; }; }; ```; The body of `sub_wdl.wdl` wasn't changed; ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String salutation = read_string(stdout()); }; }; task goodbye {; String addressee; command {; echo ""Goodbye ${addressee}!""; }; output {; String salutation = read_string(stdout()); }; }; workflow hello_and_goodbye {; String hello_and_goodbye_input; call hello {input: addressee = hello_and_goodbye_input }; call goodbye {input: addressee = hello_and_goodbye_input }; output {; String hello_output = hello.salutation; String goodbye_output = goodbye.salutation; }; }; ```; I put `sub_wdl.wdl` into a subdirectory; ```; mkdir sub_dir; mv sub_wdl.wdl sub_dir/sub_wdl.wdl; ```; zipped this subdirectory; ```; zip -r sub_dir.zip sub_dir/; ```; and ran a workflow with the following commad; ```; java -jar /home/path/to/cromwell/cromwell.jar run /home/path/to/files/main.wdl --imports /home/path/to/files/sub_dir.zip; ```; The workflow succeeded without any problem.; Maybe my workflow is not reproducing this issue because I'm doing something wrong. I tried to run this workflow using Cromwell 41 and 45. Workflows succeeded in both cases. Can you tell me what should be changed in order to reproduce your problem?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519025813
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519025813:819,Availability,echo,echo,819,"Hi @notestaff and @huangzhibo -; I'm currently investigating this issue and trying to reproduce the problem.; Since I'm not familiar with WDL, I took workflow examples from [here](https://cromwell.readthedocs.io/en/stable/SubWorkflows/) and put `sub_wdl.wdl` in a subdirectory.; Therefore, the `main.wdl` looks like ; ```; import ""sub_dir/sub_wdl.wdl"" as sub. workflow main_workflow {; call sub.hello_and_goodbye { input: hello_and_goodbye_input = ""sub world"" }; # call myTask { input: hello_and_goodbye.hello_output }; output {; String main_output = hello_and_goodbye.hello_output; }; }; ```; The body of `sub_wdl.wdl` wasn't changed; ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String salutation = read_string(stdout()); }; }; task goodbye {; String addressee; command {; echo ""Goodbye ${addressee}!""; }; output {; String salutation = read_string(stdout()); }; }; workflow hello_and_goodbye {; String hello_and_goodbye_input; call hello {input: addressee = hello_and_goodbye_input }; call goodbye {input: addressee = hello_and_goodbye_input }; output {; String hello_output = hello.salutation; String goodbye_output = goodbye.salutation; }; }; ```; I put `sub_wdl.wdl` into a subdirectory; ```; mkdir sub_dir; mv sub_wdl.wdl sub_dir/sub_wdl.wdl; ```; zipped this subdirectory; ```; zip -r sub_dir.zip sub_dir/; ```; and ran a workflow with the following commad; ```; java -jar /home/path/to/cromwell/cromwell.jar run /home/path/to/files/main.wdl --imports /home/path/to/files/sub_dir.zip; ```; The workflow succeeded without any problem.; Maybe my workflow is not reproducing this issue because I'm doing something wrong. I tried to run this workflow using Cromwell 41 and 45. Workflows succeeded in both cases. Can you tell me what should be changed in order to reproduce your problem?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519025813
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519931357:211,Availability,error,error,211,"Hi @myazinn, I have had trouble doing the same thing with cromwell 44 for CWL. I cannot import tools.zip to run workflows. . `java -jar ~/bin/cromwell-44.jar run echo_cat_wf.cwl -i in.yml -p tools.zip` gives me error:. ```; Workflow input processing failed:; Invalid workflow reference: echo_cat_wf.cwl; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519931357
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519947699:44,Availability,error,error,44,"Hi @drkennetz ; Thank you for the info. The error you get and the usage scenario are very similar to issue #5085. I'm not sure, but I think that your problem has the same reason.; I already made a PR #5104 that should fix this. ; Although I'm not sure that Cromwell’s team will accept it, you can try to use it. If you know how to assemble a project in a .jar file from source code, then do it from the branch of this PR and run your workflow. I think it should run normally.; Alternatively, you can try to run Cromwell (the one that you have) in a server mode and submit your workflow using REST API or Swagger (it provides nice GUI).; If you'll make any of this, let me know if that helped. If it didn't help, please give me some examples of what you're running so I can reproduce it.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519947699
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519981728:238,Availability,echo,echo,238,"@huangzhibo Hi huangzhibo, this makes no difference for me (for cwl). I only contain tools called by the workflow in my zipped directory and it still does not recognize this as a valid workflow.; Example:; ```; ./echo_cat_wf.cwl; ./tools/echo.cwl; ./tools/cat.cwl. zip -r tools.zip tools; ```; then run:. `java -jar cromwell-44.jar run -i in.yml -p tools.zip --type cwl echo_cat_wf.cwl`; Gives me error.; Thanks,; Dennis",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519981728
https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519981728:397,Availability,error,error,397,"@huangzhibo Hi huangzhibo, this makes no difference for me (for cwl). I only contain tools called by the workflow in my zipped directory and it still does not recognize this as a valid workflow.; Example:; ```; ./echo_cat_wf.cwl; ./tools/echo.cwl; ./tools/cat.cwl. zip -r tools.zip tools; ```; then run:. `java -jar cromwell-44.jar run -i in.yml -p tools.zip --type cwl echo_cat_wf.cwl`; Gives me error.; Thanks,; Dennis",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4969#issuecomment-519981728
https://github.com/broadinstitute/cromwell/pull/4970#issuecomment-492716170:0,Testability,Test,Tests,0,Tests passed. This PR is no longer needed,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4970#issuecomment-492716170
https://github.com/broadinstitute/cromwell/pull/4972#issuecomment-492804573:23,Availability,failure,failures,23,I've been getting some failures on an unrelated workflow in the jenkins test. Looking to see if this change somehow caused a regression or if we're just in for a world of hurt once our nightly kicks off tonight,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4972#issuecomment-492804573
https://github.com/broadinstitute/cromwell/pull/4972#issuecomment-492804573:72,Testability,test,test,72,I've been getting some failures on an unrelated workflow in the jenkins test. Looking to see if this change somehow caused a regression or if we're just in for a world of hurt once our nightly kicks off tonight,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4972#issuecomment-492804573
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146:54,Modifiability,config,config,54,"More info on this--there is no region in the cromwell config file, and us-west-2 is specified in ~/.aws/config. Also us-east does not occur in any of the WDLs or json files. So I believe cromwell is _supposed_ to use whatever's set in ~/.aws/config. . Here's an example of where the metadata says the region is us-east-1:. ```; ""runtimeAttributes"": {; ""failOnStderr"": ""false"",; ""queueArn"": ""arn:aws:batch:us-west-2:xxx:job-queue/cromwell-1999"",; ""disks"": ""local-disk /cromwell_root"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""quay.io/fhcrc-microbiome/picard:2.20.1"",; ""maxRetries"": ""1"",; ""cpu"": ""4"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-east-1a"",; ""memoryMin"": ""2 GB"",; ""memory"": ""4 GB""; },; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146:104,Modifiability,config,config,104,"More info on this--there is no region in the cromwell config file, and us-west-2 is specified in ~/.aws/config. Also us-east does not occur in any of the WDLs or json files. So I believe cromwell is _supposed_ to use whatever's set in ~/.aws/config. . Here's an example of where the metadata says the region is us-east-1:. ```; ""runtimeAttributes"": {; ""failOnStderr"": ""false"",; ""queueArn"": ""arn:aws:batch:us-west-2:xxx:job-queue/cromwell-1999"",; ""disks"": ""local-disk /cromwell_root"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""quay.io/fhcrc-microbiome/picard:2.20.1"",; ""maxRetries"": ""1"",; ""cpu"": ""4"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-east-1a"",; ""memoryMin"": ""2 GB"",; ""memory"": ""4 GB""; },; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146:242,Modifiability,config,config,242,"More info on this--there is no region in the cromwell config file, and us-west-2 is specified in ~/.aws/config. Also us-east does not occur in any of the WDLs or json files. So I believe cromwell is _supposed_ to use whatever's set in ~/.aws/config. . Here's an example of where the metadata says the region is us-east-1:. ```; ""runtimeAttributes"": {; ""failOnStderr"": ""false"",; ""queueArn"": ""arn:aws:batch:us-west-2:xxx:job-queue/cromwell-1999"",; ""disks"": ""local-disk /cromwell_root"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""quay.io/fhcrc-microbiome/picard:2.20.1"",; ""maxRetries"": ""1"",; ""cpu"": ""4"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-east-1a"",; ""memoryMin"": ""2 GB"",; ""memory"": ""4 GB""; },; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146:379,Performance,queue,queueArn,379,"More info on this--there is no region in the cromwell config file, and us-west-2 is specified in ~/.aws/config. Also us-east does not occur in any of the WDLs or json files. So I believe cromwell is _supposed_ to use whatever's set in ~/.aws/config. . Here's an example of where the metadata says the region is us-east-1:. ```; ""runtimeAttributes"": {; ""failOnStderr"": ""false"",; ""queueArn"": ""arn:aws:batch:us-west-2:xxx:job-queue/cromwell-1999"",; ""disks"": ""local-disk /cromwell_root"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""quay.io/fhcrc-microbiome/picard:2.20.1"",; ""maxRetries"": ""1"",; ""cpu"": ""4"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-east-1a"",; ""memoryMin"": ""2 GB"",; ""memory"": ""4 GB""; },; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146:423,Performance,queue,queue,423,"More info on this--there is no region in the cromwell config file, and us-west-2 is specified in ~/.aws/config. Also us-east does not occur in any of the WDLs or json files. So I believe cromwell is _supposed_ to use whatever's set in ~/.aws/config. . Here's an example of where the metadata says the region is us-east-1:. ```; ""runtimeAttributes"": {; ""failOnStderr"": ""false"",; ""queueArn"": ""arn:aws:batch:us-west-2:xxx:job-queue/cromwell-1999"",; ""disks"": ""local-disk /cromwell_root"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""quay.io/fhcrc-microbiome/picard:2.20.1"",; ""maxRetries"": ""1"",; ""cpu"": ""4"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zones"": ""us-east-1a"",; ""memoryMin"": ""2 GB"",; ""memory"": ""4 GB""; },; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-492893146
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493251791:230,Modifiability,config,config,230,"So if I understood correctly, I believe the issue is you need to specify `zones` properly in your `runtime` block. The default value is `us-east-1a` which tracks with what you're seeing. Cromwell does not (AFAICT) look at `~/.aws/config` for anything",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493251791
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033:254,Modifiability,config,config,254,"I got my first aws.conf from somewhere, don't remember exactly, but I think it was from the AWS team, possibly from some version of their cloudformation template, and it had this in it:. ```; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; ```. If that''s correct, it means that cromwell _should_ be looking in `~/.aws/config`, but maybe it's not correct. Or it is but Cromwell is not picking up the region somehow. So `zones` is supposed to go in the WDL? Something like this?. ```; runtime {; docker: ""ubuntu:latest""; zones: ""us-west-2""; }; ```. ?. Is there an example documented somewhere?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033:272,Modifiability,config,configure,272,"I got my first aws.conf from somewhere, don't remember exactly, but I think it was from the AWS team, possibly from some version of their cloudformation template, and it had this in it:. ```; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; ```. If that''s correct, it means that cromwell _should_ be looking in `~/.aws/config`, but maybe it's not correct. Or it is but Cromwell is not picking up the region somehow. So `zones` is supposed to go in the WDL? Something like this?. ```; runtime {; docker: ""ubuntu:latest""; zones: ""us-west-2""; }; ```. ?. Is there an example documented somewhere?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033:401,Modifiability,config,config,401,"I got my first aws.conf from somewhere, don't remember exactly, but I think it was from the AWS team, possibly from some version of their cloudformation template, and it had this in it:. ```; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configure command,; # // or us-east-1 by default; ```. If that''s correct, it means that cromwell _should_ be looking in `~/.aws/config`, but maybe it's not correct. Or it is but Cromwell is not picking up the region somehow. So `zones` is supposed to go in the WDL? Something like this?. ```; runtime {; docker: ""ubuntu:latest""; zones: ""us-west-2""; }; ```. ?. Is there an example documented somewhere?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493264033
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493265705:169,Modifiability,config,config,169,"@dtenenba It's possible the cloudformation templates do some magic to pull the value (@wleepang ?) . There are a couple of places you can specify this:. - Your cromwell config file(s): The field `backend.providers.YOURBATCHBACKENDNAME.config.default-runtime-attributes`; - The workflow options JSON file, field name `default-runtime-attributes`; - The `zones` field as you suggested above. You can see an example [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#zones)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493265705
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493265705:235,Modifiability,config,config,235,"@dtenenba It's possible the cloudformation templates do some magic to pull the value (@wleepang ?) . There are a couple of places you can specify this:. - Your cromwell config file(s): The field `backend.providers.YOURBATCHBACKENDNAME.config.default-runtime-attributes`; - The workflow options JSON file, field name `default-runtime-attributes`; - The `zones` field as you suggested above. You can see an example [here](https://cromwell.readthedocs.io/en/develop/RuntimeAttributes/#zones)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493265705
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493266406:125,Availability,avail,availability,125,"Thanks. That seems kind of googly, not sure if it maps to AWS concepts. Would I put a region in there (like us-west-2) or an availability zone, such as us-west-2a? I thought that AZ's were governed by the VPC used by the compute environment and thus could not be influenced by anything in aws.conf, a WDL, or workflow options....",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493266406
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281:275,Deployability,configurat,configuration,275,"Actually the more I'm digging into this I take it all back. For now. The `zones` field in the Cromwell code doesn't seem to be actually used anywhere except for tests. . Thining about it now I have a recollection that this was part of the cloud formation setup for the batch configuration. I'll need to dig into this unless @wleepang swoops in with some wizardly knowledge. BTW, it could be (and would make sense) that `~/.aws/conf` file is getting picked up via one of the Amazon libraries Cromwell is using. But I see no evidence that it's being directly used by Cromwell itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281:275,Modifiability,config,configuration,275,"Actually the more I'm digging into this I take it all back. For now. The `zones` field in the Cromwell code doesn't seem to be actually used anywhere except for tests. . Thining about it now I have a recollection that this was part of the cloud formation setup for the batch configuration. I'll need to dig into this unless @wleepang swoops in with some wizardly knowledge. BTW, it could be (and would make sense) that `~/.aws/conf` file is getting picked up via one of the Amazon libraries Cromwell is using. But I see no evidence that it's being directly used by Cromwell itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281:161,Testability,test,tests,161,"Actually the more I'm digging into this I take it all back. For now. The `zones` field in the Cromwell code doesn't seem to be actually used anywhere except for tests. . Thining about it now I have a recollection that this was part of the cloud formation setup for the batch configuration. I'll need to dig into this unless @wleepang swoops in with some wizardly knowledge. BTW, it could be (and would make sense) that `~/.aws/conf` file is getting picked up via one of the Amazon libraries Cromwell is using. But I see no evidence that it's being directly used by Cromwell itself.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493269281
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493270266:172,Modifiability,config,config,172,"I am pretty sure at least the `~/.aws/credentials` file is picked up by some amazon library, otherwise no AWS calls would work. Typically AWS libraries pick up the `~/.aws/config` file too. Here's how you find out what the region is in python, no idea how to do it in Scala. ```python; import boto3; session = boto3.session.Session(); print(session.region_name); ```; This ends up matching what's in `~/.aws/config`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493270266
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493270266:408,Modifiability,config,config,408,"I am pretty sure at least the `~/.aws/credentials` file is picked up by some amazon library, otherwise no AWS calls would work. Typically AWS libraries pick up the `~/.aws/config` file too. Here's how you find out what the region is in python, no idea how to do it in Scala. ```python; import boto3; session = boto3.session.Session(); print(session.region_name); ```; This ends up matching what's in `~/.aws/config`.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493270266
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493272139:152,Modifiability,config,config,152,"Aha ... I think I found what you need (**NB** I'm not in a position to actually test these theories right now, YMMV and all that). In your **Cromwell** config, look at the field `aws.region`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493272139
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493272139:80,Testability,test,test,80,"Aha ... I think I found what you need (**NB** I'm not in a position to actually test these theories right now, YMMV and all that). In your **Cromwell** config, look at the field `aws.region`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493272139
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493273965:90,Modifiability,config,config,90,"Yeah, that's what I""m thinking. Sorry I should have picked up on that when you posted the config block earlier but I was getting confused between the various config file types. Also my mind still tries to think in terms of `zone` and not `region` in terms of Cromwell settings :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493273965
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493273965:158,Modifiability,config,config,158,"Yeah, that's what I""m thinking. Sorry I should have picked up on that when you posted the config block earlier but I was getting confused between the various config file types. Also my mind still tries to think in terms of `zone` and not `region` in terms of Cromwell settings :)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493273965
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493306888:134,Modifiability,config,config,134,"@dtenenba , @geoffjentry - the `aws.region` in the `cromwell.conf` file needs to be set. Ideally, it should use settings from `~/.aws/config` for ""default"", but that is not the case. It will pick up the default credentials though. From a CloudFormation standpoint, when creating a Cromwell server, the region is set in the config using a pseudo parameter. See [this line](https://github.com/aws-samples/aws-genomics-workflows/blob/0c119b14131468f9fd8007332ba74e3319bf3d2d/src/templates/cromwell/cromwell-server.template.yaml#L281). This well be whatever region you launched the template in. For AZs, those are effectively defined when the Batch Compute Environment is created (they are the subnets you specify, which should match up to AZs you created with the associated VPC.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493306888
https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493306888:323,Modifiability,config,config,323,"@dtenenba , @geoffjentry - the `aws.region` in the `cromwell.conf` file needs to be set. Ideally, it should use settings from `~/.aws/config` for ""default"", but that is not the case. It will pick up the default credentials though. From a CloudFormation standpoint, when creating a Cromwell server, the region is set in the config using a pseudo parameter. See [this line](https://github.com/aws-samples/aws-genomics-workflows/blob/0c119b14131468f9fd8007332ba74e3319bf3d2d/src/templates/cromwell/cromwell-server.template.yaml#L281). This well be whatever region you launched the template in. For AZs, those are effectively defined when the Batch Compute Environment is created (they are the subnets you specify, which should match up to AZs you created with the associated VPC.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4974#issuecomment-493306888
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493515502:36,Availability,failure,failure,36,"I don't understand the travis build failure, it looks to be something unrelated to my changes.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493515502
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960:210,Performance,cache,cache,210,"Are you positive? I'm seeing a `Compilation failed` near the end. If `compile` alone doesn't surface the issue, try `test:compile`. There is a very small chance this is caused by caching - or rather inadequate cache invalidation - so I cleared Travis's cache on this build and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960:253,Performance,cache,cache,253,"Are you positive? I'm seeing a `Compilation failed` near the end. If `compile` alone doesn't surface the issue, try `test:compile`. There is a very small chance this is caused by caching - or rather inadequate cache invalidation - so I cleared Travis's cache on this build and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960:117,Testability,test,test,117,"Are you positive? I'm seeing a `Compilation failed` near the end. If `compile` alone doesn't surface the issue, try `test:compile`. There is a very small chance this is caused by caching - or rather inadequate cache invalidation - so I cleared Travis's cache on this build and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960:236,Usability,clear,cleared,236,"Are you positive? I'm seeing a `Compilation failed` near the end. If `compile` alone doesn't surface the issue, try `test:compile`. There is a very small chance this is caused by caching - or rather inadequate cache invalidation - so I cleared Travis's cache on this build and restarted.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493606960
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722:170,Availability,error,error,170,"This PR is a continuation of PR https://github.com/broadinstitute/cromwell/pull/4938. The idea is to propagate line numbers to the WOM structures, so you could report an error to the user with correct source locations. . In dxWDL, I need this also to recover the original ordering of the source code. The WOM structure is a partially sorted graph. For example, in a program like: . ```wdl; workflow foo {; call A; call B; }; ```. you don't know what came first, `A` or `B`, because they are unordered.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722:251,Availability,recover,recover,251,"This PR is a continuation of PR https://github.com/broadinstitute/cromwell/pull/4938. The idea is to propagate line numbers to the WOM structures, so you could report an error to the user with correct source locations. . In dxWDL, I need this also to recover the original ordering of the source code. The WOM structure is a partially sorted graph. For example, in a program like: . ```wdl; workflow foo {; call A; call B; }; ```. you don't know what came first, `A` or `B`, because they are unordered.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722:251,Safety,recover,recover,251,"This PR is a continuation of PR https://github.com/broadinstitute/cromwell/pull/4938. The idea is to propagate line numbers to the WOM structures, so you could report an error to the user with correct source locations. . In dxWDL, I need this also to recover the original ordering of the source code. The WOM structure is a partially sorted graph. For example, in a program like: . ```wdl; workflow foo {; call A; call B; }; ```. you don't know what came first, `A` or `B`, because they are unordered.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493627722
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493629183:69,Availability,error,error,69,"The output was very verbose, so I didn't find the actual compilation error. I think I fixed it now. We'll see if the tests pass this time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493629183
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493629183:117,Testability,test,tests,117,"The output was very verbose, so I didn't find the actual compilation error. I think I fixed it now. We'll see if the tests pass this time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-493629183
https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-497016193:19,Availability,error,error,19,Trying to fix a CI error by merging with the main development branch.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4977#issuecomment-497016193
https://github.com/broadinstitute/cromwell/issues/4979#issuecomment-494152187:56,Security,secur,security,56,"""This is not deemed to be a critical issue (yet) from a security perspective"". however. ""we should make sure to clear this up when we get a chance""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979#issuecomment-494152187
https://github.com/broadinstitute/cromwell/issues/4979#issuecomment-494152187:112,Usability,clear,clear,112,"""This is not deemed to be a critical issue (yet) from a security perspective"". however. ""we should make sure to clear this up when we get a chance""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979#issuecomment-494152187
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493524242:250,Availability,echo,echo,250,"Failing workflow:. ```wdl; version 1.0. workflow foo {; call bar; output {; Array[File] baz = bar.baz; }; }. task bar {; input {; Array[Array[String]]? baz ; }; command <<<; x=~{ if defined(baz) then write_tsv(baz) else '' }; if [[ -z ""$x"" ]]; then; echo ""no file""; else; cp $x output.tsv; fi; >>>; output {; Array[File] baz = glob(""*.tsv""); }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493524242
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493524324:224,Availability,echo,echo,224,"Working workflow:. ```wdl; workflow foo {; call bar; output {; Array[File] baz = bar.baz; }; }. task bar {; Array[Array[String]]? baz; command <<<; x=${ if defined(baz) then write_tsv(baz) else '' }; if [[ -z ""$x"" ]]; then; echo ""no file""; else; cp $x output.tsv; fi; >>>; output {; Array[File] baz = glob(""*.tsv""); }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493524324
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493532384:29,Testability,log,logic,29,"hey @jdidion, the expression logic got tidied up a lot for our 1.0 support, and it appears that something which was evidently a useful ""bug"" in our draft-2 support got ""fixed"" for 1.0. If you look over in the spec, the [`write_tsv` function](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#file-write_tsvarrayarraystring) requires a `Array[Array[String]]` argument (whereas you are passing in a `Array[Array[String]]?`). That's why Cromwell is no longer accepting the workflow. I would suggest making a PR over in openWDL to explicitly allow `write_tsv` to accept optional inputs. In the meantime, you might be able to do something like this to work around this for now:. ```wdl; input {; Array[Array[String]]? baz ; }; baz_if_defined = select_first([baz, []]). command {; x=~{ if defined(baz) then write_tsv(definitely_baz) else '' }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-493532384
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-496240424:86,Performance,perform,performed,86,"@cjllanwarne -- my understanding is that the read/write functions can't be optionally performed in the command, since the write and read involve file functions --which tend to happen upstream of the command being initiated?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-496240424
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071:50,Availability,error,error,50,@gemmalam I tried to create an account but got an error saying I don't have access,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071:76,Security,access,access,76,@gemmalam I tried to create an account but got an error saying I don't have access,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-498771071
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-499936542:110,Availability,error,error,110,@jdidion I talked to a site admin and this setting should be updated. Please let me know if you run into this error again and I will add you manually and continue to communicate with our site admin about this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-499936542
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-499936542:61,Deployability,update,updated,61,@jdidion I talked to a site admin and this setting should be updated. Please let me know if you run into this error again and I will add you manually and continue to communicate with our site admin about this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-499936542
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309:44,Deployability,update,updated,44,Thanks. Do you know what email address they updated? I still cannot access the project containing that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309:68,Security,access,access,68,Thanks. Do you know what email address they updated? I still cannot access the project containing that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-509710309
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927:139,Security,access,access,139,@jdidion I didn't receive an email address from you so I didn't manually add you. You should be able to sign up with a gmail account. Full access sometimes is delayed so you may need to try and log in again later.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927:194,Testability,log,log,194,@jdidion I didn't receive an email address from you so I didn't manually add you. You should be able to sign up with a gmail account. Full access sometimes is delayed so you may need to try and log in again later.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510059927
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510060577:66,Security,access,access,66,I signed up with my gmail account awhile ago but still don't have access. It is XXX@gmail.com.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510060577
https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510062459:65,Security,access,access,65,@jdidion I've added you. Let me know if you still need help with access.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981#issuecomment-510062459
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435:787,Availability,echo,echo,787,"running into the same issue as well. `java -Dconfig.file=cromwell-aws.conf -jar cromwell-42.jar run file_copy_test.wdl --options cromwell-options.json`. Tried with V40,41,42 and same issues.. Quick test script hacked together from other scripts:; `file_copy_test.wdl`; ```; workflow WGS_BAM_to_GVCF {; 	String input_file = ""s3://bucket/file"". 	# Merge per-interval GVCFs; 	call MergeGVCFs {; 		input:; 			input_file = input_file; 	 }. 	# Outputs that will be retained when execution is complete; 	output {; 		File output_vcf = MergeGVCFs.output_vcf; 	}; }. #### TASKS ####. # Merge GVCFs generated per-interval for the same sample; task MergeGVCFs {; 	File input_file; String output_file_name = ""output.txt"". 	Int machine_mem_gb = 2; 	Int command_mem_gb = machine_mem_gb - 1. command {; echo ${input_file} > ${output_file_name}; }. 	runtime {; 		docker: ""ubuntu""; memory: ""${machine_mem_gb}G""; cpu: 1; 	}. 	output {; 		File output_vcf = ""${output_file_name}""; 	}; }; ```. `cromwell_options.json`; ```; {; ""final_workflow_outputs_dir"":""s3://3-bucket"",; ""use_relative_output_paths"":true,; ""final_workflow_log_dir"":""s3://s3-bucket/wf_logs""; }; ```. error:; ```; [2019-06-15 19:50:15,63] [error] WorkflowManagerActor Workflow c9dd69e1-121e-45bc-911f-92d6bb6a2074 failed (during FinalizingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/WGS_BAM_to_GVCF/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; Caused by: java.lang.IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; 	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:216); 	at org.lerch.s3fs.S3FileSystemProvider.copy(S3FileSystemProvider.java:420); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:663); 	at cromwell.core.path.BetterFileMeth",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435:1146,Availability,error,error,1146,"rom other scripts:; `file_copy_test.wdl`; ```; workflow WGS_BAM_to_GVCF {; 	String input_file = ""s3://bucket/file"". 	# Merge per-interval GVCFs; 	call MergeGVCFs {; 		input:; 			input_file = input_file; 	 }. 	# Outputs that will be retained when execution is complete; 	output {; 		File output_vcf = MergeGVCFs.output_vcf; 	}; }. #### TASKS ####. # Merge GVCFs generated per-interval for the same sample; task MergeGVCFs {; 	File input_file; String output_file_name = ""output.txt"". 	Int machine_mem_gb = 2; 	Int command_mem_gb = machine_mem_gb - 1. command {; echo ${input_file} > ${output_file_name}; }. 	runtime {; 		docker: ""ubuntu""; memory: ""${machine_mem_gb}G""; cpu: 1; 	}. 	output {; 		File output_vcf = ""${output_file_name}""; 	}; }; ```. `cromwell_options.json`; ```; {; ""final_workflow_outputs_dir"":""s3://3-bucket"",; ""use_relative_output_paths"":true,; ""final_workflow_log_dir"":""s3://s3-bucket/wf_logs""; }; ```. error:; ```; [2019-06-15 19:50:15,63] [error] WorkflowManagerActor Workflow c9dd69e1-121e-45bc-911f-92d6bb6a2074 failed (during FinalizingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/WGS_BAM_to_GVCF/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; Caused by: java.lang.IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; 	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:216); 	at org.lerch.s3fs.S3FileSystemProvider.copy(S3FileSystemProvider.java:420); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:663); 	at cromwell.core.path.BetterFileMethods.copyTo(BetterFileMethods.scala:425); 	at cromwell.core.path.BetterFileMethods.copyTo$(BetterFileMethods.scala:424); 	at cromwell.filesystems.s3.S3Path.copyTo(S3PathBuilder.scala:160); 	at cromwell.engine.io.nio.NioFlow.$an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435:1185,Availability,error,error,1185,"rom other scripts:; `file_copy_test.wdl`; ```; workflow WGS_BAM_to_GVCF {; 	String input_file = ""s3://bucket/file"". 	# Merge per-interval GVCFs; 	call MergeGVCFs {; 		input:; 			input_file = input_file; 	 }. 	# Outputs that will be retained when execution is complete; 	output {; 		File output_vcf = MergeGVCFs.output_vcf; 	}; }. #### TASKS ####. # Merge GVCFs generated per-interval for the same sample; task MergeGVCFs {; 	File input_file; String output_file_name = ""output.txt"". 	Int machine_mem_gb = 2; 	Int command_mem_gb = machine_mem_gb - 1. command {; echo ${input_file} > ${output_file_name}; }. 	runtime {; 		docker: ""ubuntu""; memory: ""${machine_mem_gb}G""; cpu: 1; 	}. 	output {; 		File output_vcf = ""${output_file_name}""; 	}; }; ```. `cromwell_options.json`; ```; {; ""final_workflow_outputs_dir"":""s3://3-bucket"",; ""use_relative_output_paths"":true,; ""final_workflow_log_dir"":""s3://s3-bucket/wf_logs""; }; ```. error:; ```; [2019-06-15 19:50:15,63] [error] WorkflowManagerActor Workflow c9dd69e1-121e-45bc-911f-92d6bb6a2074 failed (during FinalizingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/WGS_BAM_to_GVCF/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; Caused by: java.lang.IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; 	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:216); 	at org.lerch.s3fs.S3FileSystemProvider.copy(S3FileSystemProvider.java:420); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:663); 	at cromwell.core.path.BetterFileMethods.copyTo(BetterFileMethods.scala:425); 	at cromwell.core.path.BetterFileMethods.copyTo$(BetterFileMethods.scala:424); 	at cromwell.filesystems.s3.S3Path.copyTo(S3PathBuilder.scala:160); 	at cromwell.engine.io.nio.NioFlow.$an",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435:1330,Modifiability,Enhance,EnhancedCromwellIoException,1330,"	 }. 	# Outputs that will be retained when execution is complete; 	output {; 		File output_vcf = MergeGVCFs.output_vcf; 	}; }. #### TASKS ####. # Merge GVCFs generated per-interval for the same sample; task MergeGVCFs {; 	File input_file; String output_file_name = ""output.txt"". 	Int machine_mem_gb = 2; 	Int command_mem_gb = machine_mem_gb - 1. command {; echo ${input_file} > ${output_file_name}; }. 	runtime {; 		docker: ""ubuntu""; memory: ""${machine_mem_gb}G""; cpu: 1; 	}. 	output {; 		File output_vcf = ""${output_file_name}""; 	}; }; ```. `cromwell_options.json`; ```; {; ""final_workflow_outputs_dir"":""s3://3-bucket"",; ""use_relative_output_paths"":true,; ""final_workflow_log_dir"":""s3://s3-bucket/wf_logs""; }; ```. error:; ```; [2019-06-15 19:50:15,63] [error] WorkflowManagerActor Workflow c9dd69e1-121e-45bc-911f-92d6bb6a2074 failed (during FinalizingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/WGS_BAM_to_GVCF/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; Caused by: java.lang.IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; 	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:216); 	at org.lerch.s3fs.S3FileSystemProvider.copy(S3FileSystemProvider.java:420); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:663); 	at cromwell.core.path.BetterFileMethods.copyTo(BetterFileMethods.scala:425); 	at cromwell.core.path.BetterFileMethods.copyTo$(BetterFileMethods.scala:424); 	at cromwell.filesystems.s3.S3Path.copyTo(S3PathBuilder.scala:160); 	at cromwell.engine.io.nio.NioFlow.$anonfun$copy$1(NioFlow.scala:84); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:87);",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435:198,Testability,test,test,198,"running into the same issue as well. `java -Dconfig.file=cromwell-aws.conf -jar cromwell-42.jar run file_copy_test.wdl --options cromwell-options.json`. Tried with V40,41,42 and same issues.. Quick test script hacked together from other scripts:; `file_copy_test.wdl`; ```; workflow WGS_BAM_to_GVCF {; 	String input_file = ""s3://bucket/file"". 	# Merge per-interval GVCFs; 	call MergeGVCFs {; 		input:; 			input_file = input_file; 	 }. 	# Outputs that will be retained when execution is complete; 	output {; 		File output_vcf = MergeGVCFs.output_vcf; 	}; }. #### TASKS ####. # Merge GVCFs generated per-interval for the same sample; task MergeGVCFs {; 	File input_file; String output_file_name = ""output.txt"". 	Int machine_mem_gb = 2; 	Int command_mem_gb = machine_mem_gb - 1. command {; echo ${input_file} > ${output_file_name}; }. 	runtime {; 		docker: ""ubuntu""; memory: ""${machine_mem_gb}G""; cpu: 1; 	}. 	output {; 		File output_vcf = ""${output_file_name}""; 	}; }; ```. `cromwell_options.json`; ```; {; ""final_workflow_outputs_dir"":""s3://3-bucket"",; ""use_relative_output_paths"":true,; ""final_workflow_log_dir"":""s3://s3-bucket/wf_logs""; }; ```. error:; ```; [2019-06-15 19:50:15,63] [error] WorkflowManagerActor Workflow c9dd69e1-121e-45bc-911f-92d6bb6a2074 failed (during FinalizingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/WGS_BAM_to_GVCF/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; Caused by: java.lang.IllegalArgumentException: copying directories is not yet supported: s3://s3bucket/c9dd69e1-121e-45bc-911f-92d6bb6a2074/call-MergeGVCFs/output.txt; 	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:216); 	at org.lerch.s3fs.S3FileSystemProvider.copy(S3FileSystemProvider.java:420); 	at java.nio.file.Files.copy(Files.java:1274); 	at better.files.File.copyTo(File.scala:663); 	at cromwell.core.path.BetterFileMeth",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-502394435
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516545076:97,Availability,error,error,97,Did you try the test WDL and json provided by robthompsonweb? Any of my workflows have this same error and they all have essentially that same basic structure.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516545076
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516545076:16,Testability,test,test,16,Did you try the test WDL and json provided by robthompsonweb? Any of my workflows have this same error and they all have essentially that same basic structure.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516545076
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516827202:172,Testability,log,logs,172,"@robthompsonweb as i understand, you expect the output.txt to be a file(not a directory) located at ""s3://3-bucket/WGS_BAM_to_GVCF/workflow/call-MergeGVCFs/output.txt/ and logs at s3://s3-bucket/wf_logs. Am i right?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-516827202
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:166,Deployability,integrat,integration,166,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:316,Deployability,integrat,integration,316,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:166,Integrability,integrat,integration,166,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:316,Integrability,integrat,integration,316,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:57,Performance,perform,performed,57,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:74,Testability,test,testing,74,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:178,Testability,test,test,178,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385:328,Testability,test,test,328,"We are ready to submit PR with fix for this issue and we performed manual testing on several backends (AWS, GCP, Local), but there are some troubles with creation of integration test for that: in particular, we didn't find the way to pass cromwell options to cromwell running in server mode. Is this possible and is integration test required for this issue? @wleepang",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519482385
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519615534:57,Testability,test,test,57,"@TimurKustov You just need to specify it in the [centaur test description](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_alpine.test#L8) of , with a pointer to where the option file lives",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519615534
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519615534:190,Testability,test,test,190,"@TimurKustov You just need to specify it in the [centaur test description](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/docker_alpine.test#L8) of , with a pointer to where the option file lives",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519615534
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519841408:71,Testability,test,test,71,"@geoffjentry Could you also please help with another question about `*.test` files: is it possible to run multiple separate workflows (wdl or cwl) in one test? Not importing as sub-workflows, but as a completely independent workflows?; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519841408
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519841408:154,Testability,test,test,154,"@geoffjentry Could you also please help with another question about `*.test` files: is it possible to run multiple separate workflows (wdl or cwl) in one test? Not importing as sub-workflows, but as a completely independent workflows?; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-519841408
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075:46,Deployability,integrat,integration,46,"@geoffjentry ; I trying to write some kind of integration test for my fix of this task and me with @TimurKustov came to idea of executing two workflows sequential in order to get outputs, results and call logs copied after execution of the first workflow and assure that they are exist and correctly placed by running second workflow, which would check these files locations and existence.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075:46,Integrability,integrat,integration,46,"@geoffjentry ; I trying to write some kind of integration test for my fix of this task and me with @TimurKustov came to idea of executing two workflows sequential in order to get outputs, results and call logs copied after execution of the first workflow and assure that they are exist and correctly placed by running second workflow, which would check these files locations and existence.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075:58,Testability,test,test,58,"@geoffjentry ; I trying to write some kind of integration test for my fix of this task and me with @TimurKustov came to idea of executing two workflows sequential in order to get outputs, results and call logs copied after execution of the first workflow and assure that they are exist and correctly placed by running second workflow, which would check these files locations and existence.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075:205,Testability,log,logs,205,"@geoffjentry ; I trying to write some kind of integration test for my fix of this task and me with @TimurKustov came to idea of executing two workflows sequential in order to get outputs, results and call logs copied after execution of the first workflow and assure that they are exist and correctly placed by running second workflow, which would check these files locations and existence.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-520024075
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-522934849:29,Deployability,update,updates,29,@wleepang @geoffjentry ; Any updates about PR #5110 ? :smile:,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-522934849
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967:96,Deployability,integrat,integration,96,"@likeanowl - Took a look at the PR. Overall, looks good, but had a couple questions. Do the new integration tests you mention cover the points I brought up - i.e. mostly around default credentials use and default region config?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967:96,Integrability,integrat,integration,96,"@likeanowl - Took a look at the PR. Overall, looks good, but had a couple questions. Do the new integration tests you mention cover the points I brought up - i.e. mostly around default credentials use and default region config?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967:220,Modifiability,config,config,220,"@likeanowl - Took a look at the PR. Overall, looks good, but had a couple questions. Do the new integration tests you mention cover the points I brought up - i.e. mostly around default credentials use and default region config?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967:108,Testability,test,tests,108,"@likeanowl - Took a look at the PR. Overall, looks good, but had a couple questions. Do the new integration tests you mention cover the points I brought up - i.e. mostly around default credentials use and default region config?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-523568967
https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-530285103:21,Availability,error,error,21,"I'm getting the same error when using; ```; output {; Array[File] files = glob(""*.txt""); }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4982#issuecomment-530285103
https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632:94,Deployability,release,release,94,Is this the sort of scheme you mean? ie considering the operation as idempotent if you ask to release twice? ; * `releaseHold` on a held workflow => 201; * `releaseHold` on a running workflow => 200,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632
https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632:114,Deployability,release,releaseHold,114,Is this the sort of scheme you mean? ie considering the operation as idempotent if you ask to release twice? ; * `releaseHold` on a held workflow => 201; * `releaseHold` on a running workflow => 200,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632
https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632:157,Deployability,release,releaseHold,157,Is this the sort of scheme you mean? ie considering the operation as idempotent if you ask to release twice? ; * `releaseHold` on a held workflow => 201; * `releaseHold` on a running workflow => 200,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494025632
https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494904639:173,Availability,error,errors,173,"@cjllanwarne yes. This won't protect us from returning 40x for workflows that are not in the store that may have legitimately gone terminal, but at least this won't produce errors for workflows that are obviously OK.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4983#issuecomment-494904639
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732:283,Availability,failure,failures,283,"> Looks very promising! 😄; > ; > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > ; > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788. Thanks for your review!; In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732:302,Availability,avail,available,302,"> Looks very promising! 😄; > ; > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > ; > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788. Thanks for your review!; In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732:278,Testability,test,test,278,"> Looks very promising! 😄; > ; > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > ; > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788. Thanks for your review!; In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732:293,Testability,log,logs,293,"> Looks very promising! 😄; > ; > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > ; > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788. Thanks for your review!; In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732:640,Testability,test,test,640,"> Looks very promising! 😄; > ; > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > ; > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788. Thanks for your review!; In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-497553732
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:281,Availability,failure,failures,281,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:300,Availability,avail,available,300,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:276,Testability,test,test,276,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:291,Testability,log,logs,291,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:646,Testability,test,test,646,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308:917,Testability,test,test,917,"> > Looks very promising! 😄; > > I would ask that all commented out code be removed in the final version of the PR (if it's part of work-in-progress that's totally fine).; > > I applied these changes to a branch in the Cromwell repo and ran our Centaur CI. There were several test failures, logs are available here: https://travis-ci.com/broadinstitute/cromwell/jobs/202934788; > ; > Thanks for your review!; > In this PR, BCS started to use the runtime `docker` which only supports AlibabaCloud Container Registry, so in the failed cases, docker image `ubuntu:latest` from dockerhub is not supported. In order to fix it, we need to provide your test account in us-east-1 region a new ECS image which contains a local `ubuntu:latest` docker image, and next week will be ok. We have provided a new custom ECS image with local `ubuntu:latest` docker image(`src/ci/bin/test_bcs.inc.sh`). Please run Centaur CI for a new test. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-499071308
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:325,Availability,failure,failures,325,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:490,Deployability,update,updated,490,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:73,Testability,test,tests,73,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:171,Testability,test,testCentaurBcs,171,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:220,Testability,test,tests,220,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:272,Testability,test,test,272,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469:363,Testability,test,tests,363,"FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied. Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512249469
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:3718,Availability,failure,failures,3718,"econds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail during execution failures.terminal_status (2 minutes, 55 seconds); - should fail during execution import_passwd (5 seconds, 348 milliseconds); - should fail during execution import_passwd_url (5 seconds, 610 milliseconds); - should fail during execution invalid_return_code (45 seconds, 607 milliseconds); - should fail during execution invalid_runtime_attributes (15 seconds, 637 milliseconds); - should fail during execution invalid_wdl (10 seconds, 626 milliseconds); - should fail during execution invalid_workflow_url (6 seconds,",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:21770,Availability,recover,recover,21770,ully run google_labels_good !!! IGNORED !!!; - should successfully run google_labels_sub !!! IGNORED !!!; - should successfully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:21893,Availability,recover,recover,21893,ully run google_labels_good !!! IGNORED !!!; - should successfully run google_labels_sub !!! IGNORED !!!; - should successfully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:21906,Availability,failure,failures,21906,ully run google_labels_good !!! IGNORED !!!; - should successfully run google_labels_sub !!! IGNORED !!!; - should successfully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:247,Performance,cache,cache,247,"log | grep should | sort; done; - should Fail the first run and NOT call cache the second run of dont_cache_to_failed_jobs *** FAILED *** (5 minutes, 37 seconds); - should call cache the second run of cwl_cache_between_workflows *** FAILED *** (2 minutes, 56 seconds); - should fail during execution bad_file_string *** FAILED *** (2 minutes, 44 seconds); - should fail during execution bad_output_task *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - shou",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:351,Performance,cache,cache,351,"log | grep should | sort; done; - should Fail the first run and NOT call cache the second run of dont_cache_to_failed_jobs *** FAILED *** (5 minutes, 37 seconds); - should call cache the second run of cwl_cache_between_workflows *** FAILED *** (2 minutes, 56 seconds); - should fail during execution bad_file_string *** FAILED *** (2 minutes, 44 seconds); - should fail during execution bad_output_task *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - shou",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2448,Performance,cache,cache,2448," *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2799,Performance,cache,cache,2799,"econds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail during execution failures.terminal_status (2 minutes, 55 seconds); - should fail during execution import_passwd (5 seconds, 348 milliseconds); - should fail during execution import_passwd_url (5 seconds, 610 milliseconds); - should fail during execution invalid_return_code (45 seconds, 607 milliseconds); - should fail during execution invalid_runtime_attributes (15 seconds, 637 milliseconds); - should fail during execution invalid_wdl (10 seconds, 626 milliseconds); - should fail during execution invalid_workflow_url (6 seconds,",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2823,Performance,cache,cacheBetweenWF,2823,"econds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail during execution failures.terminal_status (2 minutes, 55 seconds); - should fail during execution import_passwd (5 seconds, 348 milliseconds); - should fail during execution import_passwd_url (5 seconds, 610 milliseconds); - should fail during execution invalid_return_code (45 seconds, 607 milliseconds); - should fail during execution invalid_runtime_attributes (15 seconds, 637 milliseconds); - should fail during execution invalid_wdl (10 seconds, 626 milliseconds); - should fail during execution invalid_workflow_url (6 seconds,",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2877,Performance,cache,cache,2877,"econds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail during execution failures.terminal_status (2 minutes, 55 seconds); - should fail during execution import_passwd (5 seconds, 348 milliseconds); - should fail during execution import_passwd_url (5 seconds, 610 milliseconds); - should fail during execution invalid_return_code (45 seconds, 607 milliseconds); - should fail during execution invalid_runtime_attributes (15 seconds, 637 milliseconds); - should fail during execution invalid_wdl (10 seconds, 626 milliseconds); - should fail during execution invalid_workflow_url (6 seconds,",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2971,Performance,cache,cache,2971,"econds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail during execution failures.terminal_status (2 minutes, 55 seconds); - should fail during execution import_passwd (5 seconds, 348 milliseconds); - should fail during execution import_passwd_url (5 seconds, 610 milliseconds); - should fail during execution invalid_return_code (45 seconds, 607 milliseconds); - should fail during execution invalid_runtime_attributes (15 seconds, 637 milliseconds); - should fail during execution invalid_wdl (10 seconds, 626 milliseconds); - should fail during execution invalid_workflow_url (6 seconds,",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:5897,Performance,cache,cacheWithinWF,5897,"file (20 seconds, 134 milliseconds); - should fail to submit invalid_inputs_json (20 seconds, 144 milliseconds); - should fail to submit invalid_inputs_json_object (20 seconds, 163 milliseconds); - should fail to submit invalid_labels (20 seconds, 144 milliseconds); - should fail to submit invalid_options_json (20 seconds, 152 milliseconds); - should fail to submit invalid_workflow_url_length (20 seconds, 112 milliseconds); - should fail to submit workflow_url_with_no_protocol (20 seconds, 517 milliseconds); - should successfully run aliased_subworkflows (2 minutes, 45 seconds); - should successfully run array_io (3 minutes, 46 seconds); - should successfully run array_literal_locations (1 minute, 25 seconds); - should successfully run arrays_scatters_ifs (46 seconds, 201 milliseconds); - should successfully run biscayne_as_map_et_al (15 seconds, 807 milliseconds); - should successfully run biscayne_http_relative_imports (47 seconds, 636 milliseconds); - should successfully run cacheWithinWF (2 minutes, 37 seconds); - should successfully run complex_types_files (3 minutes, 10 seconds); - should successfully run composedenginefunctions (57 seconds, 606 milliseconds); - should successfully run continue_on_return_code (1 minute, 36 seconds); - should successfully run cwl_glob_sort (56 seconds, 873 milliseconds); - should successfully run cwl_glob_sort_with_workflow_url (1 minute, 46 seconds); - should successfully run cwl_import_type (1 minute, 36 seconds); - should successfully run cwl_input_binding_expression (57 seconds, 548 milliseconds); - should successfully run cwl_optionals (56 seconds, 805 milliseconds); - should successfully run cwl_prefix_for_array (1 minute, 5 seconds); - should successfully run cwl_scatter_wf1 (2 minutes, 15 seconds); - should successfully run declarations (2 minutes, 35 seconds); - should successfully run declarations_as_nodes (4 minutes, 6 seconds); - should successfully run declarations_in_ifs (1 minute, 15 seconds); - should successful",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16306,Performance,cache,cache,16306,"low_var_refs (1 minute, 46 seconds); - should successfully run subdirectory (1 minute, 16 seconds); - should successfully run subworkflows_in_ifs (1 minute, 47 seconds); - should successfully run taskless_engine_functions (16 seconds, 277 milliseconds); - should successfully run test_file_outputs_from_input (45 seconds, 789 milliseconds); - should successfully run three_step__subwf_cwl (2 minutes, 33 seconds); - should successfully run tmp_dir (1 minute, 6 seconds); - should successfully run valid_labels (37 seconds, 78 milliseconds); - should successfully run variable_scoping (38 seconds, 77 milliseconds); - should successfully run wdl_empty_glob (46 seconds, 965 milliseconds); - should successfully run wdl_function_locations (1 minute, 37 seconds); - should successfully run workflow_engine_functions (21 seconds, 482 milliseconds); - should successfully run workflow_output_declarations (46 seconds, 853 milliseconds); - should successfully run workflow_type_and_version_wdl (40 seconds, 392 milliseconds); - should successfully run workflow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16406,Performance,cache,cache,16406,"low_var_refs (1 minute, 46 seconds); - should successfully run subdirectory (1 minute, 16 seconds); - should successfully run subworkflows_in_ifs (1 minute, 47 seconds); - should successfully run taskless_engine_functions (16 seconds, 277 milliseconds); - should successfully run test_file_outputs_from_input (45 seconds, 789 milliseconds); - should successfully run three_step__subwf_cwl (2 minutes, 33 seconds); - should successfully run tmp_dir (1 minute, 6 seconds); - should successfully run valid_labels (37 seconds, 78 milliseconds); - should successfully run variable_scoping (38 seconds, 77 milliseconds); - should successfully run wdl_empty_glob (46 seconds, 965 milliseconds); - should successfully run wdl_function_locations (1 minute, 37 seconds); - should successfully run workflow_engine_functions (21 seconds, 482 milliseconds); - should successfully run workflow_output_declarations (46 seconds, 853 milliseconds); - should successfully run workflow_type_and_version_wdl (40 seconds, 392 milliseconds); - should successfully run workflow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16720,Performance,cache,cache,16720,,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16795,Performance,cache,cache,16795,,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16890,Performance,cache,cache,16890,,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16958,Performance,cache,cache,16958,,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2525,Safety,abort,abort,2525," *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2571,Safety,abort,abort,2571," *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2630,Safety,abort,abort,2630,"** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2655,Safety,abort,abort,2655,"** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execut",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2711,Safety,abort,abort,2711,"3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:2736,Safety,abort,abort,2736,"3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - should successfully run non_root_default_user *** FAILED *** (3 minutes, 20 seconds); - should successfully run relative_output_paths *** FAILED *** (2 minutes, 42 seconds); - should successfully run space *** FAILED *** (4 minutes, 18 seconds); - should successfully run standard_output_paths_colliding_prevented *** FAILED *** (3 minutes, 1 second); - should successfully run three_step_cwl *** FAILED *** (5 minutes, 29 seconds); - should NOT call cache the second run of readFromCacheFalse (3 minutes, 21 seconds); - should abort a workflow immediately after submission abort.instant_abort (5 seconds, 52 milliseconds); - should abort a workflow mid run abort.scheduled_abort (2 minutes, 20 seconds); - should abort a workflow mid run abort.sub_workflow_abort (3 minutes, 2 seconds); - should call cache the second run of cacheBetweenWF (2 minutes, 55 seconds); - should call cache the second run of call_cache_hit_prefixes_no_hint (1 minute, 40 seconds); - should call cache the second run of floating_tags (3 minutes, 25 seconds); - should fail during execution bad_docker_name (35 seconds, 238 milliseconds); - should fail during execution bad_workflow_failure_mode (5 seconds, 920 milliseconds); - should fail during execution chainfail (42 seconds, 454 milliseconds); - should fail during execution cont_while_possible (3 minutes, 57 seconds); - should fail during execution cont_while_possible_scatter (2 minutes, 27 seconds); - should fail during execution draft3_read_file_limits (3 minutes, 26 seconds); - should fail during execution empty_filename (16 seconds, 333 milliseconds); - should fail during execution failing_continue_on_return_code (55 seconds, 180 milliseconds); - should fail d",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16517,Safety,abort,abort,16517,"low_var_refs (1 minute, 46 seconds); - should successfully run subdirectory (1 minute, 16 seconds); - should successfully run subworkflows_in_ifs (1 minute, 47 seconds); - should successfully run taskless_engine_functions (16 seconds, 277 milliseconds); - should successfully run test_file_outputs_from_input (45 seconds, 789 milliseconds); - should successfully run three_step__subwf_cwl (2 minutes, 33 seconds); - should successfully run tmp_dir (1 minute, 6 seconds); - should successfully run valid_labels (37 seconds, 78 milliseconds); - should successfully run variable_scoping (38 seconds, 77 milliseconds); - should successfully run wdl_empty_glob (46 seconds, 965 milliseconds); - should successfully run wdl_function_locations (1 minute, 37 seconds); - should successfully run workflow_engine_functions (21 seconds, 482 milliseconds); - should successfully run workflow_output_declarations (46 seconds, 853 milliseconds); - should successfully run workflow_type_and_version_wdl (40 seconds, 392 milliseconds); - should successfully run workflow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16566,Safety,abort,abort,16566,"low_var_refs (1 minute, 46 seconds); - should successfully run subdirectory (1 minute, 16 seconds); - should successfully run subworkflows_in_ifs (1 minute, 47 seconds); - should successfully run taskless_engine_functions (16 seconds, 277 milliseconds); - should successfully run test_file_outputs_from_input (45 seconds, 789 milliseconds); - should successfully run three_step__subwf_cwl (2 minutes, 33 seconds); - should successfully run tmp_dir (1 minute, 6 seconds); - should successfully run valid_labels (37 seconds, 78 milliseconds); - should successfully run variable_scoping (38 seconds, 77 milliseconds); - should successfully run wdl_empty_glob (46 seconds, 965 milliseconds); - should successfully run wdl_function_locations (1 minute, 37 seconds); - should successfully run workflow_engine_functions (21 seconds, 482 milliseconds); - should successfully run workflow_output_declarations (46 seconds, 853 milliseconds); - should successfully run workflow_type_and_version_wdl (40 seconds, 392 milliseconds); - should successfully run workflow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16616,Safety,abort,abort,16616,"flow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.restart_abort_jes !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.restart_abort_tes !!! IGNORED !!!; - should call cache the second run of backendWithNoDocker !!! IGNORED !!!; - should call cache the second run of call_cache_hit_prefixes_empty_hint_papi !!! IGNORED !!!; - should call cache the second run of fofn_caching !!! IGNORED !!!; - should call cache the third run of call_cache_hit_prefixes_two_roots_empty_hint_cache_hit_papi !!! IGNORED !!!; - should fail during execution circular_dependencies !!! IGNORED !!!; - should fail during execution google_labels_bad !!! IGNORED !!!; - should fail during execution gpu_on_papi_invalid !!! IGNORED !!!; - should fail during execution localize_file_larger_than_disk_space !!! IGNORED !!!; - should fail during execution missing_input_failure_papiv1 !!! IGNORED !!!; - should fail during execution missing_input_failure_papiv2 !!! IGNORED !!!; - should fail during execution papi_fail_on_bad_attrs !!! IGNORED !!!; - should fail during execution refresh_token_failu",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:16665,Safety,abort,abort,16665,"flow_url_biscayne_sub_wfs (35 seconds, 322 milliseconds); - should successfully run workflow_url_http_relative_imports (35 seconds, 718 milliseconds); - should successfully run workflow_url_square (15 seconds, 152 milliseconds); - should successfully run workflow_url_sub_workflow_hello_world (53 seconds, 160 milliseconds); - should successfully run workflowenginefunctions (45 seconds, 630 milliseconds); - should successfully run writeToCache (1 minute, 15 seconds); - should successfully run write_lines (1 minute, 55 seconds); - should successfully run write_lines_files (3 minutes, 5 seconds); - should successfully run write_tsv (56 seconds, 21 milliseconds); - should NOT call cache the second run of call_cache_hit_prefixes_empty_hint_local !!! IGNORED !!!; - should NOT call cache the second run of call_cache_hit_prefixes_two_roots_empty_hint_cache_miss_papi !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.restart_abort_jes !!! IGNORED !!!; - should abort a workflow mid run and restart immediately abort.restart_abort_tes !!! IGNORED !!!; - should call cache the second run of backendWithNoDocker !!! IGNORED !!!; - should call cache the second run of call_cache_hit_prefixes_empty_hint_papi !!! IGNORED !!!; - should call cache the second run of fofn_caching !!! IGNORED !!!; - should call cache the third run of call_cache_hit_prefixes_two_roots_empty_hint_cache_hit_papi !!! IGNORED !!!; - should fail during execution circular_dependencies !!! IGNORED !!!; - should fail during execution google_labels_bad !!! IGNORED !!!; - should fail during execution gpu_on_papi_invalid !!! IGNORED !!!; - should fail during execution localize_file_larger_than_disk_space !!! IGNORED !!!; - should fail during execution missing_input_failure_papiv1 !!! IGNORED !!!; - should fail during execution missing_input_failure_papiv2 !!! IGNORED !!!; - should fail during execution papi_fail_on_bad_attrs !!! IGNORED !!!; - should fail during execution refresh_token_failu",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:21770,Safety,recover,recover,21770,ully run google_labels_good !!! IGNORED !!!; - should successfully run google_labels_sub !!! IGNORED !!!; - should successfully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:21893,Safety,recover,recover,21893,ully run google_labels_good !!! IGNORED !!!; - should successfully run google_labels_sub !!! IGNORED !!!; - should successfully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:43,Testability,test,testCentaurBcs,43,"FYI results of running a97f39d `src/ci/bin/testCentaurBcs.sh` without `-i` entries on my laptop:. ```shell; $ for color in 31m 32m 33m; do grep $color target/ci/logs/centaur.log | grep should | sort; done; - should Fail the first run and NOT call cache the second run of dont_cache_to_failed_jobs *** FAILED *** (5 minutes, 37 seconds); - should call cache the second run of cwl_cache_between_workflows *** FAILED *** (2 minutes, 56 seconds); - should fail during execution bad_file_string *** FAILED *** (2 minutes, 44 seconds); - should fail during execution bad_output_task *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - shou",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:161,Testability,log,logs,161,"FYI results of running a97f39d `src/ci/bin/testCentaurBcs.sh` without `-i` entries on my laptop:. ```shell; $ for color in 31m 32m 33m; do grep $color target/ci/logs/centaur.log | grep should | sort; done; - should Fail the first run and NOT call cache the second run of dont_cache_to_failed_jobs *** FAILED *** (5 minutes, 37 seconds); - should call cache the second run of cwl_cache_between_workflows *** FAILED *** (2 minutes, 56 seconds); - should fail during execution bad_file_string *** FAILED *** (2 minutes, 44 seconds); - should fail during execution bad_output_task *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - shou",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:174,Testability,log,log,174,"log | grep should | sort; done; - should Fail the first run and NOT call cache the second run of dont_cache_to_failed_jobs *** FAILED *** (5 minutes, 37 seconds); - should call cache the second run of cwl_cache_between_workflows *** FAILED *** (2 minutes, 56 seconds); - should fail during execution bad_file_string *** FAILED *** (2 minutes, 44 seconds); - should fail during execution bad_output_task *** FAILED *** (3 minutes, 18 seconds); - should fail during execution relative_output_paths_colliding *** FAILED *** (3 minutes, 27 seconds); - should successfully run curl *** FAILED *** (8 minutes, 38 seconds); - should successfully run cwl_cache_within_workflow *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_import_type_packed *** FAILED *** (3 minutes, 43 seconds); - should successfully run cwl_interpolated_strings *** FAILED *** (2 minutes, 49 seconds); - should successfully run cwl_relative_imports_url *** FAILED *** (3 minutes, 37 seconds); - should successfully run cwl_relative_imports_zip *** FAILED *** (2 minutes, 52 seconds); - should successfully run docker_hash_dockerhub *** FAILED *** (5 minutes, 18 seconds); - should successfully run docker_hash_gcr *** FAILED *** (5 minutes, 31 seconds); - should successfully run docker_hash_quay *** FAILED *** (4 minutes, 31 seconds); - should successfully run hello *** FAILED *** (2 minutes, 54 seconds); - should successfully run hello_yaml *** FAILED *** (2 minutes, 47 seconds); - should successfully run inline_file *** FAILED *** (3 minutes, 4 seconds); - should successfully run inline_file_custom_entryname *** FAILED *** (3 minutes, 9 seconds); - should successfully run iwdr_input_string *** FAILED *** (3 minutes, 10 seconds); - should successfully run iwdr_input_string_function *** FAILED *** (2 minutes, 59 seconds); - shou",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132:22029,Testability,test,tests,22029,fully run gpu_cuda_image !!! IGNORED !!!; - should successfully run gpu_on_papi_valid !!! IGNORED !!!; - should successfully run http_inputs !!! IGNORED !!!; - should successfully run http_inputs_cwl !!! IGNORED !!!; - should successfully run input_expressions !!! IGNORED !!!; - should successfully run input_from_bucket_with_requester_pays !!! IGNORED !!!; - should successfully run inter_scatter_dependencies !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes !!! IGNORED !!!; - should successfully run invalidate_bad_caches_jes_no_copy !!! IGNORED !!!; - should successfully run jes_labels !!! IGNORED !!!; - should successfully run length_slurm_no_docker !!! IGNORED !!!; - should successfully run local_gcs !!! IGNORED !!!; - should successfully run monitoring_log !!! IGNORED !!!; - should successfully run monitoring_log_papiv1 !!! IGNORED !!!; - should successfully run papi_cpu_platform !!! IGNORED !!!; - should successfully run papi_v2_log !!! IGNORED !!!; - should successfully run papiv1_streams !!! IGNORED !!!; - should successfully run prepare_scatter_gather_papi !!! IGNORED !!!; - should successfully run refresh_token !!! IGNORED !!!; - should successfully run refresh_token_sub_workflow !!! IGNORED !!!; - should successfully run requester_pays_engine_functions !!! IGNORED !!!; - should successfully run requester_pays_localization !!! IGNORED !!!; - should successfully run super_massive_array_output !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv1 !!! IGNORED !!!; - should successfully run workbench_health_monitor_check_papiv2 !!! IGNORED !!!; - should successfully run workflow_type_and_version_cwl !!! IGNORED !!!; - should survive a Cromwell restart and recover jobs restart_jes_with_recover !!! IGNORED !!!; - should survive a Cromwell restart when a workflow was failing and recover jobs failures.restart_while_failing_jes !!! IGNORED !!!; $ ; ```. **TL;DR This PR ran 187 of 209 (non-ignored) standard centaur tests**,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512361132
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:327,Availability,failure,failures,327,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:499,Deployability,update,updated,499,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:75,Testability,test,tests,75,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:173,Testability,test,testCentaurBcs,173,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:222,Testability,test,tests,222,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:274,Testability,test,test,274,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275:365,Testability,test,tests,365,"> FYI out of curiosity I'm going to also run the full suite of our centaur tests ([removing the `-i includes`](https://github.com/broadinstitute/cromwell/blob/44/src/ci/bin/testCentaurBcs.sh#L19-L20)) to see if additional tests pass with our credentials. If you can see our test results on the Alibaba servers you may see some failures, but as long as the existing tests pass I'll be satisfied.; > ; > Separately, an entry should be added to the CHANGELOG.md with a short line pointing users to the updated documentation. ([Example](https://github.com/broadinstitute/cromwell/blob/44/CHANGELOG.md#stackdriver-instrumentation)) I've been holding off suggesting this change because that file changes _a lot_ and is subject to frequent merge conflicts. Now that this PR is close enough to merging I think it's time. Done.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4992#issuecomment-512635275
https://github.com/broadinstitute/cromwell/pull/4993#issuecomment-495400504:9,Testability,test,tested,9,@mcovarr tested manually and it does appear to make it through,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4993#issuecomment-495400504
https://github.com/broadinstitute/cromwell/pull/4995#issuecomment-495620362:343,Integrability,message,message,343,"I think this is great! I would like @ruchim to take a look and see what she thinks about turning off issue creation after a certain date. Also, if we should close out all of the existing tickets after that date. Jira is open for folks to join and look at our board so this shouldn't be too big of a pain, but I don't know how we would get the message out to everyone.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4995#issuecomment-495620362
https://github.com/broadinstitute/cromwell/pull/4996#issuecomment-495644563:83,Testability,test,testing,83,@gdlex4015 or @andy7i - could you confirm that it's cool for us to do our own perf testing (and that this process is the right one)?,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4996#issuecomment-495644563
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475:42,Deployability,integrat,integrates,42,"Hi @azzaea,. The AWS backend for Cromwell integrates with AWS Batch for job scheduling and execution. As such it pretty much only uses tasks that use Docker containers. My understanding is that Cromwell can be configured with multiple backends (e.g. AWS and FilesystemLocal) and that tasks can be parameterized via inputs to the workflow to choose which backend it runs on.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475:76,Energy Efficiency,schedul,scheduling,76,"Hi @azzaea,. The AWS backend for Cromwell integrates with AWS Batch for job scheduling and execution. As such it pretty much only uses tasks that use Docker containers. My understanding is that Cromwell can be configured with multiple backends (e.g. AWS and FilesystemLocal) and that tasks can be parameterized via inputs to the workflow to choose which backend it runs on.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475:42,Integrability,integrat,integrates,42,"Hi @azzaea,. The AWS backend for Cromwell integrates with AWS Batch for job scheduling and execution. As such it pretty much only uses tasks that use Docker containers. My understanding is that Cromwell can be configured with multiple backends (e.g. AWS and FilesystemLocal) and that tasks can be parameterized via inputs to the workflow to choose which backend it runs on.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475:210,Modifiability,config,configured,210,"Hi @azzaea,. The AWS backend for Cromwell integrates with AWS Batch for job scheduling and execution. As such it pretty much only uses tasks that use Docker containers. My understanding is that Cromwell can be configured with multiple backends (e.g. AWS and FilesystemLocal) and that tasks can be parameterized via inputs to the workflow to choose which backend it runs on.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475:297,Modifiability,parameteriz,parameterized,297,"Hi @azzaea,. The AWS backend for Cromwell integrates with AWS Batch for job scheduling and execution. As such it pretty much only uses tasks that use Docker containers. My understanding is that Cromwell can be configured with multiple backends (e.g. AWS and FilesystemLocal) and that tasks can be parameterized via inputs to the workflow to choose which backend it runs on.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502847475
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:306,Deployability,pipeline,pipeline,306,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:571,Deployability,pipeline,pipeline,571,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:756,Deployability,configurat,configuration,756,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:756,Modifiability,config,configuration,756,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:129,Performance,load,load,129,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:423,Performance,load,load,423,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782:796,Performance,load,load,796,"Hi @wleepang . Yes, you are right. The problem I have is particularly when using a slurm backend, as I don't find an easy way to load environment modules except to actually modify the individual command section of each task definition in my workflow. This is inconvenient because when I'm running the same pipeline on AWS batch, there are no environment modules, so my tasks fail unless I explicitly remove all the `module load <module name>` from the command part of each task. I would like to switch back and forth between cloud and cluster without having to touch the pipeline script (i.e. individual tasks) itself. Put differently, can I specify a runtime attribute called `module` much like the `docker` attribute, and then somehow modify the backend configuration settings to have cromwell load this module? . Did I explain myself better this time?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-502902782
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:335,Integrability,inject,inject,335,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:381,Integrability,wrap,wrap,381,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:208,Modifiability,config,config,208,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:355,Performance,load,load,355,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382:335,Security,inject,inject,335,"I'll largely defer to @cjllanwarne, @mcovarr, or @danbills on the specifics, but it seems that you could specify the runtime attribute you need and how to interpret it by customizing the SLURM backend in the config:. https://cromwell.readthedocs.io/en/stable/backends/SLURM/. If I'm reading the docs correctly, it might be possible to inject your `module load` command into the `--wrap` argument.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-505658382
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902:320,Availability,error,error,320,"I ran into a related issue while running the ENCODE HiC pipeline via Caper on SLURM. I opened an issue there too. On our HPC I need to `module load cuda/11.7` to use the `nvcc` binary. I tried `--wrap='module load cuda/11.7'` but while this gets passed to the `sbatch` command it returns a script argument not permitted error, possibly because `module` isn't a binary but a bash function? Are there any other options for using Caper/Cromwell with the `module` system?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902:56,Deployability,pipeline,pipeline,56,"I ran into a related issue while running the ENCODE HiC pipeline via Caper on SLURM. I opened an issue there too. On our HPC I need to `module load cuda/11.7` to use the `nvcc` binary. I tried `--wrap='module load cuda/11.7'` but while this gets passed to the `sbatch` command it returns a script argument not permitted error, possibly because `module` isn't a binary but a bash function? Are there any other options for using Caper/Cromwell with the `module` system?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902:196,Integrability,wrap,wrap,196,"I ran into a related issue while running the ENCODE HiC pipeline via Caper on SLURM. I opened an issue there too. On our HPC I need to `module load cuda/11.7` to use the `nvcc` binary. I tried `--wrap='module load cuda/11.7'` but while this gets passed to the `sbatch` command it returns a script argument not permitted error, possibly because `module` isn't a binary but a bash function? Are there any other options for using Caper/Cromwell with the `module` system?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902:143,Performance,load,load,143,"I ran into a related issue while running the ENCODE HiC pipeline via Caper on SLURM. I opened an issue there too. On our HPC I need to `module load cuda/11.7` to use the `nvcc` binary. I tried `--wrap='module load cuda/11.7'` but while this gets passed to the `sbatch` command it returns a script argument not permitted error, possibly because `module` isn't a binary but a bash function? Are there any other options for using Caper/Cromwell with the `module` system?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902
https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902:209,Performance,load,load,209,"I ran into a related issue while running the ENCODE HiC pipeline via Caper on SLURM. I opened an issue there too. On our HPC I need to `module load cuda/11.7` to use the `nvcc` binary. I tried `--wrap='module load cuda/11.7'` but while this gets passed to the `sbatch` command it returns a script argument not permitted error, possibly because `module` isn't a binary but a bash function? Are there any other options for using Caper/Cromwell with the `module` system?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997#issuecomment-1430297902
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-495660263:16,Testability,test,testing,16,"I did some more testing. The same workflow, but now with the command `exit 1` is properly retried by cromwell 39. ; Also, the code in https://github.com/broadinstitute/cromwell/pull/4654/files looks sound, it must be elsewhere. Somewhere in the code it decides that ""externally killed"" jobs should not be retried but other failed jobs can be retried.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-495660263
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-495707094:150,Testability,test,test,150,"Hey @rhpvorderman - given your experiences, it sounds like this would be a valid change. A PR would be a great idea if you can see what to do and can test that it's working. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-495707094
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:480,Integrability,depend,depended,480,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:97,Modifiability,refactor,refactoring,97,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:163,Modifiability,refactor,refactoring,163,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:376,Modifiability,refactor,refactored,376,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:730,Modifiability,refactor,refactored,730,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:649,Safety,abort,aborted,649,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589:917,Safety,timeout,timeout-seconds,917,"@cjllanwarne I pointed to the wrong line of code, sorry for that. I have identified the bug. The refactoring produced **better** code. The code written before the refactoring created a rc file with exit code `9`(Which was probably a mistake as the comments above the code said that 137 was chosen, for kill -9). `137` for SIGKILL would have been the better value. The current refactored code uses SIGTERM (`143`). This looks nicer, but unfortunately the functionality of the code depended on the choice for `9`. . If cromwell gets SIGINT (`130`) , SIGKILL (`137`) or SIGTERM(`143`) as exit codes for a job, it assumes that cromwell was the one that aborted them and the jobs should NOT be retried. This makes perfect sense. . The refactored code now returns a return code(`143`) that makes cromwell believe that the job should not be retried. My solution would be to write a non-sensical return code in the case exit-timeout-seconds is used. I am working on a pr now. EDIT: This change indeed fixes the problem. PR coming.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998#issuecomment-496236589
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497167230:207,Availability,error,error,207,"Not sure what was going on there but that seems to have been a transient problem. I created a branch in our repo with your changes and it failed the same way for me once, but I restarted it and got past the error. You can see the progress of the builds here: https://travis-ci.com/broadinstitute/cromwell/builds/113681945",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497167230
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233:177,Availability,failure,failures,177,"The following tests failed in the `centaurPAPIv2` run in our CI (this doesn't run for external contributors for credentials reasons). This build does have issues with transient failures at times, but these failures all appear to be label-related:. * jes_labels; * google_labels_bad; * google_labels_sub; * google_labels_good",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233:206,Availability,failure,failures,206,"The following tests failed in the `centaurPAPIv2` run in our CI (this doesn't run for external contributors for credentials reasons). This build does have issues with transient failures at times, but these failures all appear to be label-related:. * jes_labels; * google_labels_bad; * google_labels_sub; * google_labels_good",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233:14,Testability,test,tests,14,"The following tests failed in the `centaurPAPIv2` run in our CI (this doesn't run for external contributors for credentials reasons). This build does have issues with transient failures at times, but these failures all appear to be label-related:. * jes_labels; * google_labels_bad; * google_labels_sub; * google_labels_good",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497256233
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:341,Integrability,wrap,wrapper,341,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:469,Integrability,wrap,wrapper,469,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:59,Testability,test,tests,59,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:170,Testability,test,tests,170,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:662,Testability,test,test,662,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:788,Testability,test,test,788,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:825,Testability,test,test,825,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:959,Testability,test,test,959,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:997,Testability,test,test,997,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:1172,Testability,log,log,1172,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100:1339,Testability,test,test,1339,"I believe I've found the issues with the jes and bad label tests, but I can't figure out why the other two failed. As far as I can tell, the relevant files for these two tests are. * [google_labels.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/google_labels.wdl); * [wrapper.wdl](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/wrapper.wdl); * [good_options.json](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels/good_options.json); * [google_labels_good.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_good.test); * [google_labels_subworkflows.test](https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/standardTestCases/google_labels_subworkflows.test). It seems like the subworkflows test is just calling the good labels wdl as a subworkflow to check that it still passes, so I'm just going to assume that they are both failing for the same issue. The travis log, or at least the parts that I checked, don't contain much information besides the fact that the workflow failed. I'm not really sure how to approach debugging the test",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497359100
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497376396:191,Testability,test,testOnly,191,"If you want to reproduce locally you can run a Cromwell server and then follow the instructions in `Centaur.md`. To run `google_labels_good` it would be something like . ```; sbt ""centaur/it:testOnly * -- -n google_labels_good""; ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497376396
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203:13,Deployability,update,updates,13,I pushed the updates that I think might fix the JES and bad label test cases. Still working on getting the sbt tests set up locally,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203:66,Testability,test,test,66,I pushed the updates that I think might fix the JES and bad label test cases. Still working on getting the sbt tests set up locally,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203:111,Testability,test,tests,111,I pushed the updates that I think might fix the JES and bad label test cases. Still working on getting the sbt tests set up locally,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-497390203
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-501727926:34,Deployability,update,update,34,"No worries, but thank you for the update! We're on our current sprint and assuming we have some time leftover, we'll come back to it, otherwise it's been allotted towards the upcoming sprint. Thanks! @gemmalam",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-501727926
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-505541479:63,Testability,test,tests,63,"Hi @agraubert - we're not likely to have the cycles to fix the tests ourselves in the near future, and it sounds like you don't either. In light of that, I'm going to close the PR - but you should absolutely feel free to reopen in the future. We'd be very happy to merge this contribution if it arrives with tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-505541479
https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-505541479:308,Testability,test,tests,308,"Hi @agraubert - we're not likely to have the cycles to fix the tests ourselves in the near future, and it sounds like you don't either. In light of that, I'm going to close the PR - but you should absolutely feel free to reopen in the future. We'd be very happy to merge this contribution if it arrives with tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5000#issuecomment-505541479
https://github.com/broadinstitute/cromwell/issues/5001#issuecomment-495744779:182,Availability,mask,mask,182,"Thanks. What's strange is that many other analyses _were_ being run successfully at the time. If the PAPI retry mechanism is somewhat deficient, maybe it makes sense for Cromwell to mask that by resubmitting the analysis? E.g. there could be a config setting for the number of times to retry analyses that fail for transient-looking reasons.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5001#issuecomment-495744779
https://github.com/broadinstitute/cromwell/issues/5001#issuecomment-495744779:244,Modifiability,config,config,244,"Thanks. What's strange is that many other analyses _were_ being run successfully at the time. If the PAPI retry mechanism is somewhat deficient, maybe it makes sense for Cromwell to mask that by resubmitting the analysis? E.g. there could be a config setting for the number of times to retry analyses that fail for transient-looking reasons.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5001#issuecomment-495744779
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749:96,Modifiability,config,configure,96,"In order to fix the coverage I am willing to write tests. But I need some explanation on how to configure the cromwell that is used by centaur, so I can set `exit-code-timeout-seconds`. Can somebody give me that? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749:168,Safety,timeout,timeout-seconds,168,"In order to fix the coverage I am willing to write tests. But I need some explanation on how to configure the cromwell that is used by centaur, so I can set `exit-code-timeout-seconds`. Can somebody give me that? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749:51,Testability,test,tests,51,"In order to fix the coverage I am willing to write tests. But I need some explanation on how to configure the cromwell that is used by centaur, so I can set `exit-code-timeout-seconds`. Can somebody give me that? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496377749
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496824583:206,Usability,clear,clear,206,@cjllanwarne Thanks for your great suggestions.; The change has been brought back to one line of code. And 7 lines of comments to explain why that line is the way it is... Hopefully the last line will make clear why `79` is an appropriate exit code for this use case.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-496824583
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-497485334:84,Testability,test,tests,84,This now looks good to me. I'll make a clone of this branch in our repo so that our tests can run on it (it's a permissions thing that means only internal PRs can run the full suite of CI... 🤷‍♂),MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-497485334
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-498234074:59,Testability,test,tests,59,> I'll make a clone of this branch in our repo so that our tests can run on it (it's a permissions thing that means only internal PRs can run the full suite of CI... man_shrugging). Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-498234074
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084:20,Testability,test,test,20,"> We don't actively test the cluster backend retries, which I think adequately explains why the codecov for this diff is 0. > In other words, the tests don't cover this code because we never use it, but if it works for you then +1 from me. Thanks a lot @cjllanwarne ! I have thought about setting up tests in the cromwell test suite, but it is not very easy (if it all possible) to do this in an automated fashion.; We regularly test our workflows on the cluster, so any issues with Cromwell are bound to come up quickly. ; Thanks again for reviewing and merging!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084:146,Testability,test,tests,146,"> We don't actively test the cluster backend retries, which I think adequately explains why the codecov for this diff is 0. > In other words, the tests don't cover this code because we never use it, but if it works for you then +1 from me. Thanks a lot @cjllanwarne ! I have thought about setting up tests in the cromwell test suite, but it is not very easy (if it all possible) to do this in an automated fashion.; We regularly test our workflows on the cluster, so any issues with Cromwell are bound to come up quickly. ; Thanks again for reviewing and merging!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084:300,Testability,test,tests,300,"> We don't actively test the cluster backend retries, which I think adequately explains why the codecov for this diff is 0. > In other words, the tests don't cover this code because we never use it, but if it works for you then +1 from me. Thanks a lot @cjllanwarne ! I have thought about setting up tests in the cromwell test suite, but it is not very easy (if it all possible) to do this in an automated fashion.; We regularly test our workflows on the cluster, so any issues with Cromwell are bound to come up quickly. ; Thanks again for reviewing and merging!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084:322,Testability,test,test,322,"> We don't actively test the cluster backend retries, which I think adequately explains why the codecov for this diff is 0. > In other words, the tests don't cover this code because we never use it, but if it works for you then +1 from me. Thanks a lot @cjllanwarne ! I have thought about setting up tests in the cromwell test suite, but it is not very easy (if it all possible) to do this in an automated fashion.; We regularly test our workflows on the cluster, so any issues with Cromwell are bound to come up quickly. ; Thanks again for reviewing and merging!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084
https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084:429,Testability,test,test,429,"> We don't actively test the cluster backend retries, which I think adequately explains why the codecov for this diff is 0. > In other words, the tests don't cover this code because we never use it, but if it works for you then +1 from me. Thanks a lot @cjllanwarne ! I have thought about setting up tests in the cromwell test suite, but it is not very easy (if it all possible) to do this in an automated fashion.; We regularly test our workflows on the cluster, so any issues with Cromwell are bound to come up quickly. ; Thanks again for reviewing and merging!",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003#issuecomment-499366084
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496508131:145,Deployability,Pipeline,Pipeline,145,"Based on the example you shared, would you mind listing what is actually produced inside of the call directory? ; ```s3://s4-pbg-hc/HC_Dev_Run_5/Pipeline/RSM278260-6_8plex/pipeline_workflow/3997371c-9513-4386-a579-a72639c6e960/call-Haplotypecaller/shard-0/hc.Haplotypecaller/755021ae-948b-47f9-94a8-66b486bda47d/call-HC_GVCF/shard-6/```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496508131
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496509163:288,Security,integrity,integrity,288,"There is no directory for shard-6. That's why the workflow agent can't read the RC file. The time-stamps for the files referenced in the job parameter json, however, reflect the time that the job was re-executed. This is probably the most troubling aspect for us as it suggests that data integrity for previous samples cannot be guaranteed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-496509163
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-498498798:325,Deployability,release,release,325,We noticed something similar where it would re-use previous job definitions and do the tasks but fail to write back to the RC file (b/c it was looking for the wrong location which didn't exist). If you can get any info from AWS about what job definition is being used here that might give you another clue. We were using non-release branches though (aws hackathon and then now the develop branch from about a week ago after the polling pull request was merged) so I can't say much else. Maybe test on 42??,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-498498798
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-498498798:493,Testability,test,test,493,We noticed something similar where it would re-use previous job definitions and do the tasks but fail to write back to the RC file (b/c it was looking for the wrong location which didn't exist). If you can get any info from AWS about what job definition is being used here that might give you another clue. We were using non-release branches though (aws hackathon and then now the develop branch from about a week ago after the polling pull request was merged) so I can't say much else. Maybe test on 42??,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-498498798
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451:233,Deployability,integrat,integration,233,"I'm wondering if this is related to cromwell creating new job definitions for **every** new call, versus using parameter substitution to modify the inputs for a single job definition? There may be some sort of backend issue with the integration to the AWS APIs that and old job definition is being called incorrectly instead of yet another new definition being created with the correct inputs? . This would track with the workflow log saying that the job definition already exists and then re-using a job that has inputs for a completely different sample.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451:233,Integrability,integrat,integration,233,"I'm wondering if this is related to cromwell creating new job definitions for **every** new call, versus using parameter substitution to modify the inputs for a single job definition? There may be some sort of backend issue with the integration to the AWS APIs that and old job definition is being called incorrectly instead of yet another new definition being created with the correct inputs? . This would track with the workflow log saying that the job definition already exists and then re-using a job that has inputs for a completely different sample.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451:431,Testability,log,log,431,"I'm wondering if this is related to cromwell creating new job definitions for **every** new call, versus using parameter substitution to modify the inputs for a single job definition? There may be some sort of backend issue with the integration to the AWS APIs that and old job definition is being called incorrectly instead of yet another new definition being created with the correct inputs? . This would track with the workflow log saying that the job definition already exists and then re-using a job that has inputs for a completely different sample.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-501250451
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-502888987:26,Performance,concurren,concurrent,26,"@mcnelsonsema4 - how many concurrent jobs are in the scatter, and are you running multiple workflows with the same WDLs, but different inputs, at the same time?. Cromwell creates a new job definition revision with every job submission. This is because of the way task paths are handled via container volumes and mount points.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-502888987
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-504128934:171,Integrability,depend,depending,171,"@wleepang , We're scattering by chromosome for any step using a scatter, so 25 concurrent jobs/sample. The number of simultaneous samples run at a time varies from 1-100+ depending on needs, and we're using multiple workflows, but some sub-wdls are shared between the larger workflows. And I'm not sure I really understand why a new job definition must be made for every call. I presume you're submitting jobs using a submit_job() API call where you can specify container overrides and set unique mount points versus having them pre-established in a job definition and calling that without any modification? . Scala is not my language so how those calls are being made and how the determination of whether or not a job definition already exists (regardless of it being correct in light of this bug) is not something I can easily determine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-504128934
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-504128934:79,Performance,concurren,concurrent,79,"@wleepang , We're scattering by chromosome for any step using a scatter, so 25 concurrent jobs/sample. The number of simultaneous samples run at a time varies from 1-100+ depending on needs, and we're using multiple workflows, but some sub-wdls are shared between the larger workflows. And I'm not sure I really understand why a new job definition must be made for every call. I presume you're submitting jobs using a submit_job() API call where you can specify container overrides and set unique mount points versus having them pre-established in a job definition and calling that without any modification? . Scala is not my language so how those calls are being made and how the determination of whether or not a job definition already exists (regardless of it being correct in light of this bug) is not something I can easily determine.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-504128934
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-505665761:874,Availability,error,error,874,"@mcnelsonsema4 - the `SubmitJob` API does not support overriding volumes and mount points to the container. These are set in the Job Definition referenced by `SubmitJob`. The host path for the volume uses the UUID that Cromwell generates for the task to isolate localized inputs and any outputs generated. Since the UUID is regenerated for each task execution, a new Job Definition revision is created with the corresponding new host path for the volume. The API call for creating new Job Definitions and revisions isn't intended for a high volume of requests. The [code involved](https://github.com/broadinstitute/cromwell/blob/90154ed22b2a78dfbb1c5342a8f0d39164aaeac8/supportedBackends/aws/src/main/scala/cromwell/backend/impl/aws/AwsBatchJob.scala#L201-L218) seems to keep retrying the request to the API. It's possible an API response is returned that isn't caught as a error and allowing the use of the ""most recent"" revision, which was a revision submitted by another task by the same name that ran earlier. @cjllanwarne, @mcovarr, @danbills - any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-505665761
https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-505995959:390,Modifiability,variab,variables,390,Deregistering a job definition is probably not recommended since it will likely have similar constraints as the current method of creating a job def for each task call. Reducing the number of job definitions that need to be created would be better long term. That would require changing how task specific paths on the host instance are created - e.g. using a combination of job environment variables and additional commands to container overrides.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004#issuecomment-505995959
https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-499991087:181,Security,access,accessing,181,"Hello @haaskyle, we are currently using Jira for our backlog. I have moved your ticket to https://broadworkbench.atlassian.net/browse/BA-5695. Please let me know if you have issues accessing it. You will need to create a Jira account. The priority of this ticket will be reviewed.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-499991087
https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-1421492972:204,Safety,risk,risky,204,It's not likely this will be worked on as the dev team has no experience with proxies nor one to test against. Can you have your corporate IT allowlist Docker? It seems like it would be a popular and non-risky request.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-1421492972
https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-1421492972:97,Testability,test,test,97,It's not likely this will be worked on as the dev team has no experience with proxies nor one to test against. Can you have your corporate IT allowlist Docker? It seems like it would be a popular and non-risky request.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5006#issuecomment-1421492972
https://github.com/broadinstitute/cromwell/pull/5008#issuecomment-498620276:187,Testability,test,tests,187,"It now fails on `- should successfully run gpu_cuda_image *** FAILED *** (41 minutes, 36 seconds)`. This is probably not caused by this code change. I don't see what I can do to make the tests pass unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5008#issuecomment-498620276
https://github.com/broadinstitute/cromwell/pull/5014#issuecomment-498276705:33,Availability,failure,failure,33,"ah I get it now, I see the build failure on your other PR :+1:",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5014#issuecomment-498276705
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634:511,Availability,down,down,511,"This seems to be interestingly connected with the spec change https://github.com/openwdl/wdl/pull/315 (so cc @patmagee). As that PR is currently written, we would be fine to do the scheme like this, because the `memory` section says ""you can provide as much memory as you want, as long as it's over this amount"", but it feels like we're in danger of writing non-portable WDLs like this because the incentive is to write a small value first and rely on the doubling to catch you if necessary. FWIW I'd rather go down the route of:; - `memory` is treated as the ""guaranteed to work"" ceiling amount; - We could start by having a much lower `memory_to_try_first` attribute representing the first value to try; - If the task fails, we can then double it from the low baseline, until either the task succeeds or we reach the `memory` ceiling, and at that point we don't try any further. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634:520,Integrability,rout,route,520,"This seems to be interestingly connected with the spec change https://github.com/openwdl/wdl/pull/315 (so cc @patmagee). As that PR is currently written, we would be fine to do the scheme like this, because the `memory` section says ""you can provide as much memory as you want, as long as it's over this amount"", but it feels like we're in danger of writing non-portable WDLs like this because the incentive is to write a small value first and rely on the doubling to catch you if necessary. FWIW I'd rather go down the route of:; - `memory` is treated as the ""guaranteed to work"" ceiling amount; - We could start by having a much lower `memory_to_try_first` attribute representing the first value to try; - If the task fails, we can then double it from the low baseline, until either the task succeeds or we reach the `memory` ceiling, and at that point we don't try any further. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634:362,Modifiability,portab,portable,362,"This seems to be interestingly connected with the spec change https://github.com/openwdl/wdl/pull/315 (so cc @patmagee). As that PR is currently written, we would be fine to do the scheme like this, because the `memory` section says ""you can provide as much memory as you want, as long as it's over this amount"", but it feels like we're in danger of writing non-portable WDLs like this because the incentive is to write a small value first and rely on the doubling to catch you if necessary. FWIW I'd rather go down the route of:; - `memory` is treated as the ""guaranteed to work"" ceiling amount; - We could start by having a much lower `memory_to_try_first` attribute representing the first value to try; - If the task fails, we can then double it from the low baseline, until either the task succeeds or we reach the `memory` ceiling, and at that point we don't try any further. Does that make sense?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499235634
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499246858:142,Availability,failure,failure,142,"Maybe I'm being melodramatic. Probably if something needs 128GB of memory then something has gone wrong or we need a new method. It's worth a failure to go take a look. Yeah, I could be on board with two parameters like the Java xmx/xms.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499246858
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499248766:211,Usability,clear,clear,211,"I guess what we call these attributes doesn't really matter so much as, we have to accept one of these worlds:; * The spec defines a maximum memory value, above which Cromwell will never go; * The spec makes it clear that memory increasing will sometimes be required to complete tasks when they specify ""average"" `memory` attributes; * Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499248766
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511:143,Energy Efficiency,schedul,scheduler,143,"> May I get a review on the design, but not the scala?. Wow thanks for adding this. This is exactly what we need on our cluster. Sometimes the scheduler aggressively kills jobs based on VMEM (instead of actual mem). So retrying with upping the memory requirements is a nice way to circumvent this annoying issue. (Instead of using insane memory requirements to make sure it passes in 99% of the cases). As for the design. I would add; 1. A number of attempts configurable parameter in the config. A sane default would be 1. Meaning that this feature will not be used by default, for reasons elaborated on later.; 2. A factor with which the memory is increased on each attempt. So if the factor is 1.5 > Attempt 1 will be 1.5^0 = 1 times the memory, Attempt 2 1.5^1 = 1.5, Attempt 3 = 1.5^2 = 2.25. A sane default here would be 2 I guess. As for @cjllanwarne's concerns:. > The spec defines a maximum memory value, above which Cromwell will never go; ; I think the spec just states the value that should be given to whatever backend. But semantics aside, I guess that means the same as saying it is the maximum. > Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines. This is a very good reason to not enable this feature by default. But since there are very good reasons for having this feature, having it as a configurable option will be very very nice. Let the user decide how they want to treat their memory requirements. That is the most user-friendly way to do. This is why I think a sane default for the number of attempts should be 1 (i.e. no retries).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511:459,Modifiability,config,configurable,459,"> May I get a review on the design, but not the scala?. Wow thanks for adding this. This is exactly what we need on our cluster. Sometimes the scheduler aggressively kills jobs based on VMEM (instead of actual mem). So retrying with upping the memory requirements is a nice way to circumvent this annoying issue. (Instead of using insane memory requirements to make sure it passes in 99% of the cases). As for the design. I would add; 1. A number of attempts configurable parameter in the config. A sane default would be 1. Meaning that this feature will not be used by default, for reasons elaborated on later.; 2. A factor with which the memory is increased on each attempt. So if the factor is 1.5 > Attempt 1 will be 1.5^0 = 1 times the memory, Attempt 2 1.5^1 = 1.5, Attempt 3 = 1.5^2 = 2.25. A sane default here would be 2 I guess. As for @cjllanwarne's concerns:. > The spec defines a maximum memory value, above which Cromwell will never go; ; I think the spec just states the value that should be given to whatever backend. But semantics aside, I guess that means the same as saying it is the maximum. > Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines. This is a very good reason to not enable this feature by default. But since there are very good reasons for having this feature, having it as a configurable option will be very very nice. Let the user decide how they want to treat their memory requirements. That is the most user-friendly way to do. This is why I think a sane default for the number of attempts should be 1 (i.e. no retries).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511:489,Modifiability,config,config,489,"> May I get a review on the design, but not the scala?. Wow thanks for adding this. This is exactly what we need on our cluster. Sometimes the scheduler aggressively kills jobs based on VMEM (instead of actual mem). So retrying with upping the memory requirements is a nice way to circumvent this annoying issue. (Instead of using insane memory requirements to make sure it passes in 99% of the cases). As for the design. I would add; 1. A number of attempts configurable parameter in the config. A sane default would be 1. Meaning that this feature will not be used by default, for reasons elaborated on later.; 2. A factor with which the memory is increased on each attempt. So if the factor is 1.5 > Attempt 1 will be 1.5^0 = 1 times the memory, Attempt 2 1.5^1 = 1.5, Attempt 3 = 1.5^2 = 2.25. A sane default here would be 2 I guess. As for @cjllanwarne's concerns:. > The spec defines a maximum memory value, above which Cromwell will never go; ; I think the spec just states the value that should be given to whatever backend. But semantics aside, I guess that means the same as saying it is the maximum. > Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines. This is a very good reason to not enable this feature by default. But since there are very good reasons for having this feature, having it as a configurable option will be very very nice. Let the user decide how they want to treat their memory requirements. That is the most user-friendly way to do. This is why I think a sane default for the number of attempts should be 1 (i.e. no retries).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511:1451,Modifiability,config,configurable,1451,"> May I get a review on the design, but not the scala?. Wow thanks for adding this. This is exactly what we need on our cluster. Sometimes the scheduler aggressively kills jobs based on VMEM (instead of actual mem). So retrying with upping the memory requirements is a nice way to circumvent this annoying issue. (Instead of using insane memory requirements to make sure it passes in 99% of the cases). As for the design. I would add; 1. A number of attempts configurable parameter in the config. A sane default would be 1. Meaning that this feature will not be used by default, for reasons elaborated on later.; 2. A factor with which the memory is increased on each attempt. So if the factor is 1.5 > Attempt 1 will be 1.5^0 = 1 times the memory, Attempt 2 1.5^1 = 1.5, Attempt 3 = 1.5^2 = 2.25. A sane default here would be 2 I guess. As for @cjllanwarne's concerns:. > The spec defines a maximum memory value, above which Cromwell will never go; ; I think the spec just states the value that should be given to whatever backend. But semantics aside, I guess that means the same as saying it is the maximum. > Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines. This is a very good reason to not enable this feature by default. But since there are very good reasons for having this feature, having it as a configurable option will be very very nice. Let the user decide how they want to treat their memory requirements. That is the most user-friendly way to do. This is why I think a sane default for the number of attempts should be 1 (i.e. no retries).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511:1582,Usability,user-friendly,user-friendly,1582,"> May I get a review on the design, but not the scala?. Wow thanks for adding this. This is exactly what we need on our cluster. Sometimes the scheduler aggressively kills jobs based on VMEM (instead of actual mem). So retrying with upping the memory requirements is a nice way to circumvent this annoying issue. (Instead of using insane memory requirements to make sure it passes in 99% of the cases). As for the design. I would add; 1. A number of attempts configurable parameter in the config. A sane default would be 1. Meaning that this feature will not be used by default, for reasons elaborated on later.; 2. A factor with which the memory is increased on each attempt. So if the factor is 1.5 > Attempt 1 will be 1.5^0 = 1 times the memory, Attempt 2 1.5^1 = 1.5, Attempt 3 = 1.5^2 = 2.25. A sane default here would be 2 I guess. As for @cjllanwarne's concerns:. > The spec defines a maximum memory value, above which Cromwell will never go; ; I think the spec just states the value that should be given to whatever backend. But semantics aside, I guess that means the same as saying it is the maximum. > Cromwell will be able to run WDLs which will not run anywhere else... and thus we would have to be very strict in policing our ""best practices"" WDL to makes sure it can be run on other engines. This is a very good reason to not enable this feature by default. But since there are very good reasons for having this feature, having it as a configurable option will be very very nice. Let the user decide how they want to treat their memory requirements. That is the most user-friendly way to do. This is why I think a sane default for the number of attempts should be 1 (i.e. no retries).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499374511
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499549114:174,Integrability,Depend,Depending,174,"The opinions from other engine developers in the WDL spec makes it sound like they're quite relaxed about this doubling scheme, so IMO it's fine to go ahead with this as-is. Depending on whether I get my way or not, we might or might not see a spec change in WDL 2.0 with a maximum memory ~requirement~ `runtime` attribute, above which Cromwell should not go, but that would be a bridge for us to cross in the future. TL;DR: 👍",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499549114
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499549114:380,Integrability,bridg,bridge,380,"The opinions from other engine developers in the WDL spec makes it sound like they're quite relaxed about this doubling scheme, so IMO it's fine to go ahead with this as-is. Depending on whether I get my way or not, we might or might not see a spec change in WDL 2.0 with a maximum memory ~requirement~ `runtime` attribute, above which Cromwell should not go, but that would be a bridge for us to cross in the future. TL;DR: 👍",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-499549114
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-500442583:23,Usability,feedback,feedback,23,Closing as I have some feedback to make changes!,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-500442583
https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-515629279:465,Safety,predict,predict,465,"It would be a really nice to have feature indeed!. In addition to what was said above, we're also planning to work on runtime metrics reporting at DSP hackathon with @mohawkTrail and @rexwangcc . In the future, the ""automatic retry"" feature could enable us to collect runtime statistics much more easily (in a fully automated fashion). From this, we could then build accurate models on how much resources are actually needed, for a given set of inputs (so we could predict the amount of resources for future workflows, instead of relying on guesswork or retries). Without this feature, we have to either overshoot the amount of resources uniformly for all tasks (and then collect how much they actually need), or somehow retry this in a ""ladder"" fashion using an automated script that does a ""parameter sweep"" that we then pass to our workflow as inputs (or directly edit using something like MiniWDL perhaps?).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5017#issuecomment-515629279
https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862:259,Availability,recover,recover,259,"My ""test"" right now is the following code in a Scala worksheet:; ```; import scala.concurrent.{ExecutionContext, Future}. implicit val ec = ExecutionContext.global. val x = Future(throw new Exception(""hello world"")). val y = x.map(_ => println(""wasd""))(ec); .recover { case a: Throwable => println(""Exception was: "" + a.getMessage) }(ec); ```; which prints; ```; Exception was: hello world; ```; I'm working on figuring out how construct this in situ in a way that meaningfully tests something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862
https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862:83,Performance,concurren,concurrent,83,"My ""test"" right now is the following code in a Scala worksheet:; ```; import scala.concurrent.{ExecutionContext, Future}. implicit val ec = ExecutionContext.global. val x = Future(throw new Exception(""hello world"")). val y = x.map(_ => println(""wasd""))(ec); .recover { case a: Throwable => println(""Exception was: "" + a.getMessage) }(ec); ```; which prints; ```; Exception was: hello world; ```; I'm working on figuring out how construct this in situ in a way that meaningfully tests something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862
https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862:259,Safety,recover,recover,259,"My ""test"" right now is the following code in a Scala worksheet:; ```; import scala.concurrent.{ExecutionContext, Future}. implicit val ec = ExecutionContext.global. val x = Future(throw new Exception(""hello world"")). val y = x.map(_ => println(""wasd""))(ec); .recover { case a: Throwable => println(""Exception was: "" + a.getMessage) }(ec); ```; which prints; ```; Exception was: hello world; ```; I'm working on figuring out how construct this in situ in a way that meaningfully tests something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862
https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862:4,Testability,test,test,4,"My ""test"" right now is the following code in a Scala worksheet:; ```; import scala.concurrent.{ExecutionContext, Future}. implicit val ec = ExecutionContext.global. val x = Future(throw new Exception(""hello world"")). val y = x.map(_ => println(""wasd""))(ec); .recover { case a: Throwable => println(""Exception was: "" + a.getMessage) }(ec); ```; which prints; ```; Exception was: hello world; ```; I'm working on figuring out how construct this in situ in a way that meaningfully tests something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862
https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862:478,Testability,test,tests,478,"My ""test"" right now is the following code in a Scala worksheet:; ```; import scala.concurrent.{ExecutionContext, Future}. implicit val ec = ExecutionContext.global. val x = Future(throw new Exception(""hello world"")). val y = x.map(_ => println(""wasd""))(ec); .recover { case a: Throwable => println(""Exception was: "" + a.getMessage) }(ec); ```; which prints; ```; Exception was: hello world; ```; I'm working on figuring out how construct this in situ in a way that meaningfully tests something.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5022#issuecomment-501411862
https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501050669:155,Modifiability,config,config,155,"@mcovarr Yeah, I discussed with @ruchim - we're skipping that for now, but agreed that it'd be a nice idea in general (tho i'd say `workflow_options`, not config)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501050669
https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501312553:63,Energy Efficiency,Green,Green,63,"Hello Jeff—would you mind testing if this would break Terra or Green team prod? Meaning, if the SAs don’t have BQ scope before being sent to Cromwell, and then Cromwell adds the BQ scope—does the task fail to run?. <sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501312553
https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501312553:26,Testability,test,testing,26,"Hello Jeff—would you mind testing if this would break Terra or Green team prod? Meaning, if the SAs don’t have BQ scope before being sent to Cromwell, and then Cromwell adds the BQ scope—does the task fail to run?. <sub>Sent with <a href=""http://githawk.com"">GitHawk</a></sub>",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-501312553
https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465:128,Security,access,access,128,"@mcovarr @ruchim I confirmed that this is fine. The underlying PAPI job will fail as expected (since it does not have rights to access BQ) but nothing blows up in a weird way. . Steps:. 1. Make a minimally permissioned SA and try running. This succeeds as the default compute service account has editor access. However, nothing blew up when setting the BQ scope. Sorta success.; 2. Use that minimally permissioned SA as the `google_compute_service_account` - the PAPI job fails as expected, but nothing else untoward happened. Great success.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465
https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465:303,Security,access,access,303,"@mcovarr @ruchim I confirmed that this is fine. The underlying PAPI job will fail as expected (since it does not have rights to access BQ) but nothing blows up in a weird way. . Steps:. 1. Make a minimally permissioned SA and try running. This succeeds as the default compute service account has editor access. However, nothing blew up when setting the BQ scope. Sorta success.; 2. Use that minimally permissioned SA as the `google_compute_service_account` - the PAPI job fails as expected, but nothing else untoward happened. Great success.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5023#issuecomment-503668465
https://github.com/broadinstitute/cromwell/pull/5026#issuecomment-501851960:112,Testability,log,logic,112,@aednichols @kshakir requesting re-reviews because I had to make a more substantial change to the interpolation logic.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5026#issuecomment-501851960
https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777:15,Testability,test,test,15,">do you have a test for the network and auth specified, but no subnetwork?. @cjllanwarne do you mean a centaur test? Or unit test?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777
https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777:111,Testability,test,test,111,">do you have a test for the network and auth specified, but no subnetwork?. @cjllanwarne do you mean a centaur test? Or unit test?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777
https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777:125,Testability,test,test,125,">do you have a test for the network and auth specified, but no subnetwork?. @cjllanwarne do you mean a centaur test? Or unit test?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504094777
https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504540935:15,Testability,test,test,15,">do you have a test for the network and auth specified, but no subnetwork. Talked offline. The unit test for this is already added.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504540935
https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504540935:100,Testability,test,test,100,">do you have a test for the network and auth specified, but no subnetwork. Talked offline. The unit test for this is already added.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5027#issuecomment-504540935
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502094173:199,Energy Efficiency,Green,Green,199,"Hey Denis -- I'll pose the same question as I did in another open [PR](https://github.com/broadinstitute/cromwell/pull/5023). Would you mind testing if this change is going to break for Terra and/or Green team prod? Meaning, if the user service Accounts don’t have BQ permission before setting those scopes in Cromwell, does the task fail to run?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502094173
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502094173:141,Testability,test,testing,141,"Hey Denis -- I'll pose the same question as I did in another open [PR](https://github.com/broadinstitute/cromwell/pull/5023). Would you mind testing if this change is going to break for Terra and/or Green team prod? Meaning, if the user service Accounts don’t have BQ permission before setting those scopes in Cromwell, does the task fail to run?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502094173
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502138379:60,Usability,clear,clear,60,"@ruchim I'll keep the convo here so it's centralized. To be clear, you're asking about making sure what happens if the SA does not have the appropriate role attached to their permissions? If not, I don't understand the question (specifically the use of ""scope"" in this context)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502138379
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502198188:238,Security,access,access,238,"What behavior would be desired, in this case? One required behavior would be that the workflow should still run (I presume). Anything else? @geoffjentry @ruchim . Is this the same as if the user specifies a table to which they don't have access?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502198188
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502204552:62,Energy Efficiency,monitor,monitoring,62,"I'm curious - did we need to ensure that SAs had support for `monitoring.write` when you all added that in #4562? My bet is that this would have the same behavior, although perhaps not as that scope seems to be a little hidden",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502204552
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348:275,Deployability,update,updateData,275,"@ruchim I think @geoffjentry is spot on - adding a scope by itself won't change existing behavior. It's only when the user sets `monitoring_image` to `quay.io/broadinstitute/cromwell-monitor-bigquery`, _then_ it will fail if the SA for the task doesn't have `bigquery.tables.updateData` permission on the monitoring dataset. So existing users on Terra won't be affected, unless we start routinely adding that option to all workflows and don't adjust the IAM permissions on pets.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348:183,Energy Efficiency,monitor,monitor-bigquery,183,"@ruchim I think @geoffjentry is spot on - adding a scope by itself won't change existing behavior. It's only when the user sets `monitoring_image` to `quay.io/broadinstitute/cromwell-monitor-bigquery`, _then_ it will fail if the SA for the task doesn't have `bigquery.tables.updateData` permission on the monitoring dataset. So existing users on Terra won't be affected, unless we start routinely adding that option to all workflows and don't adjust the IAM permissions on pets.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348:305,Energy Efficiency,monitor,monitoring,305,"@ruchim I think @geoffjentry is spot on - adding a scope by itself won't change existing behavior. It's only when the user sets `monitoring_image` to `quay.io/broadinstitute/cromwell-monitor-bigquery`, _then_ it will fail if the SA for the task doesn't have `bigquery.tables.updateData` permission on the monitoring dataset. So existing users on Terra won't be affected, unless we start routinely adding that option to all workflows and don't adjust the IAM permissions on pets.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348:387,Integrability,rout,routinely,387,"@ruchim I think @geoffjentry is spot on - adding a scope by itself won't change existing behavior. It's only when the user sets `monitoring_image` to `quay.io/broadinstitute/cromwell-monitor-bigquery`, _then_ it will fail if the SA for the task doesn't have `bigquery.tables.updateData` permission on the monitoring dataset. So existing users on Terra won't be affected, unless we start routinely adding that option to all workflows and don't adjust the IAM permissions on pets.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502242348
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:632,Availability,failure,failure,632,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:472,Safety,risk,risk,472,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:505,Safety,risk,risk,505,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:615,Security,validat,validate,615,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296:347,Testability,test,testing,347,@dinvlad In my PR (#5023) the intention was to allow users to be able to interact with BQ from inside their WDL commands. With that in mind I believe what you're suggesting is that nothing untoward would happen unless they did this and their service account didn't have the corresponding permission set. Is that correct?. I still think it's worth testing to be sure but since it looks like we've added scopes before w/o issue I'm less fearful .... but IMO there's still a risk and we should make sure the risk is 0. Denis - it's on my list to poke at this but if you all don't want to wait for me and would like to validate success/failure please feel free to do so,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502247296
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:68,Energy Efficiency,monitor,monitoring,68,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:183,Energy Efficiency,monitor,monitoringConfig,183,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:1069,Energy Efficiency,Monitor,Monitoring,1069,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:1477,Energy Efficiency,monitor,monitoringConfig,1477,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:224,Modifiability,config,config,224,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:325,Modifiability,variab,variables,325,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:386,Modifiability,variab,variable,386,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:722,Modifiability,variab,variables,722,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:787,Modifiability,config,config,787,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:522,Security,access,access,522,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400:611,Security,access,accessing,611,"Re this PR, I'm re-working it to pass all of the task call-specific monitoring info (workflow name/id, task call name/index/attempt, `inputs`, `disks`, and the opaque image-specific `monitoringConfig` string) through a JSON config file on GCS (thanks @kshakir for the idea!). This way, we no longer have to use environmental variables, and can pass much more data than can be held in a variable (looking at you, `inputs`!). That still has a potential problem of running against the API quota for GCS, but since we already access multiple files from that execution bucket inside the task, the assumption is that accessing one extra file won't hurt. However, I'm unsure if we should just get rid of all of the environmental variables in favor of one that points to the GCS URL of the JSON config, or should we keep them (and thus duplicate information) for backwards compatibility. AFAIK, hardly anyone used this feature yet, especially given that the current ""official"" `monitoring_image` has been essentially broken, because Google decided to start failing Stackdriver Monitoring requests if they are submitted more than 1/minute, for a given time series. We should fix the `monitoring_image` separately (or replace it with the BigQuery version), but the question remains whether we still want to keep those env vars around for that previous use case (for anyone who might've been using a custom `monitoring_image` already). Alternatively, we could pass only the `inputs` and `monitoringConfig` through a JSON blob on GCS, and continue with the rest as-is via env vars (but that's messy, IMO).",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-502266400
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-505654233:341,Energy Efficiency,monitor,monitoring,341,"@aednichols this PR is currently blocked, as I have a few questions I’m hoping to resolve with your team’s help, once you have time. The PR Jeff merged is very welcome, but it only solves a tiny portion of this one. As such, I’ve reverted the scope commit from it, so its only concern now is being able to pass additional information to the monitoring task. If you’d prefer the questions to be raised here instead, please let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-505654233
https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-528065027:145,Energy Efficiency,monitor,monitor-bq,145,"Closing, since we've implemented Cromwell metadata export via a Cloud Function. For details, see https://github.com/broadinstitute/cromwell-task-monitor-bq#metadata-upload",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028#issuecomment-528065027
https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501755712:491,Modifiability,plugin,plugin,491,"I think this is a really cool idea! It feels somewhat above the scope of Cromwell itself (since it's calling Cromwell rather than part of it) but as part of the [openWDL](https://github.com/openwdl/wdl) ecosystem I think it's an awesome thing to have. I suggest getting in touch with @mlin and @dinvlad for the following reasons:. > What do you think? I am excited to implement the full solution, it should not take more than a few hours. * I mention @dinvlad because he's been working on a plugin for VS Code with a WDL debugging option for WDL files. It could be that there's a fair amount of crossover you could take advantage of. > Can I use this parser? https://github.com/TMiguelT/WdlParserPackaging. * @mlin has a much friendlier WDL parsing library over at [miniWDL](https://github.com/chanzuckerberg/miniwdl/). I suspect you'll have a much better time using that parser API.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501755712
https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501826170:230,Availability,failure,failures,230,"Additionally, @rexwangcc has been working on https://cromwell-tools.readthedocs.io, which at least partially seems to implement what you proposed. We're also planning to move other functionality, like parsing of metadata.json for failures, into it over time, to be used together with `miniWDL` for WDL debugging support.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501826170
https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278:37,Integrability,wrap,wrapper,37,"@prihoda . miniwdl has a [little CLI wrapper](https://github.com/chanzuckerberg/miniwdl#miniwdl-cromwell) to make it nicer to launch cromwell locally. It doesn't do the the shebang script which is a neat idea, however, it does implement versions of (i) parsing the task/workflow inputs to expose them as command-line arguments, and (ii) parsing the outputs to organize them more nicely after they come out. [Here is a link](https://github.com/chanzuckerberg/miniwdl/blob/b7f399b56ad2f01ed9867e6105c036a251c4ae73/WDL/CLI.py#L289) to the CLI entrypoint for this where you can see how all this happens. I'd be happy to work with you on merging & fleshing out the ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278
https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278:289,Security,expose,expose,289,"@prihoda . miniwdl has a [little CLI wrapper](https://github.com/chanzuckerberg/miniwdl#miniwdl-cromwell) to make it nicer to launch cromwell locally. It doesn't do the the shebang script which is a neat idea, however, it does implement versions of (i) parsing the task/workflow inputs to expose them as command-line arguments, and (ii) parsing the outputs to organize them more nicely after they come out. [Here is a link](https://github.com/chanzuckerberg/miniwdl/blob/b7f399b56ad2f01ed9867e6105c036a251c4ae73/WDL/CLI.py#L289) to the CLI entrypoint for this where you can see how all this happens. I'd be happy to work with you on merging & fleshing out the ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5029#issuecomment-501874278
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-501879498:19,Integrability,message,messaged,19,@lbergelson I just messaged our system administrators. I believe someone keeps changing a setting. It shouldn’t matter if you are on the internal WiFi. I’m sorry for the inconvenience this is causing.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-501879498
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502078996:78,Security,access,access,78,@lbergelson the issue has been fixed. Let me know if you still aren’t able to access our backlog.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502078996
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980:6,Security,access,access,6,"I can access it now. It's really gross to have to sign into a private jira in order to see bug reports from an open source project though. If we have to use JIRA for some reason, is there a way to at least make it publicly visible without a login?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980:241,Testability,log,login,241,"I can access it now. It's really gross to have to sign into a private jira in order to see bug reports from an open source project though. If we have to use JIRA for some reason, is there a way to at least make it publicly visible without a login?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502154980
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:208,Availability,error,error,208,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:827,Modifiability,SANDBOX,SANDBOX,827,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:109,Security,access,access,109,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:74,Testability,log,logged,74,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:827,Testability,SANDBOX,SANDBOX,827,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778:903,Usability,UX,UX,903,"It would be nice to have some more documentation about this. When I first logged in this morning, I couldn't access the board, so I tried creating an account and that also failed initially for an _unexpected error, please try again later_ sort of thing. . Also, what board do we create Cromwell issues under? My best guess is `Jira Support` and that's where I created my issue: [Cromwell (server) loses ability to poll some workflows](https://broadworkbench.atlassian.net/browse/JS-34), but all of the other issues aren't really Cromwell related. A ""query"" field might also be useful. . These are the boards currently on Jira:; - `Batch Analysis`; - `Cloud Accounts`; - `Data-repo`; - `DevOps`; - `DSP-ELT Backlog`; - `Interactive Analysis`; - `Jira Support`; - `New Project`; - `PERF`; - `PRODUCTION`; - `QA`; - `SAND-NG`; - `SANDBOX`; - `SUPPORT`; - `TERRA ROADMAP`; - `TerraUI`; - `User Metrics`; - `UX`",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-502892778
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028:141,Integrability,message,message,141,"@gemmalam - I am trying to access the JIRA tickets for cromwell. I followed the link in the README and created an account, but I'm getting a message ""<my_email_address> doesn't have access to Jira on broadworkbench.atlassian.net.""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028:27,Security,access,access,27,"@gemmalam - I am trying to access the JIRA tickets for cromwell. I followed the link in the README and created an account, but I'm getting a message ""<my_email_address> doesn't have access to Jira on broadworkbench.atlassian.net.""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028:182,Security,access,access,182,"@gemmalam - I am trying to access the JIRA tickets for cromwell. I followed the link in the README and created an account, but I'm getting a message ""<my_email_address> doesn't have access to Jira on broadworkbench.atlassian.net.""",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1095862028
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097067077:87,Security,access,access,87,"@wholtz unfortunately, I no longer work a the Broad Institute and cannot help you gain access to the cromwell Jira project. @aednichols should be able to help or connect you with someone who can.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097067077
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783:58,Modifiability,config,configured,58,"We have not consistently been able to keep the JIRA board configured for the partial public access we need. The JIRA instance is shared by many groups and has to meet a lot of compliance needs, and the Cromwell access seems to get lost in the shuffle. I think it's more likely that we will remove the link to JIRA and suggest sticking to Github issues.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783:92,Security,access,access,92,"We have not consistently been able to keep the JIRA board configured for the partial public access we need. The JIRA instance is shared by many groups and has to meet a lot of compliance needs, and the Cromwell access seems to get lost in the shuffle. I think it's more likely that we will remove the link to JIRA and suggest sticking to Github issues.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783
https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783:211,Security,access,access,211,"We have not consistently been able to keep the JIRA board configured for the partial public access we need. The JIRA instance is shared by many groups and has to meet a lot of compliance needs, and the Cromwell access seems to get lost in the shuffle. I think it's more likely that we will remove the link to JIRA and suggest sticking to Github issues.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5031#issuecomment-1097501783
https://github.com/broadinstitute/cromwell/pull/5032#issuecomment-502847254:11,Modifiability,refactor,refactor,11,~~Going to refactor this a little~~ EDIT: no I'm not,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5032#issuecomment-502847254
https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574:213,Modifiability,inherit,inheritance,213,"@mcovarr indeed. I think our centaur tests were set up to assume certain limits, and by changing the defaults I've upset the tests. I _think_ I just need to work out where to re-set those centaur defaults but the inheritance hierarchy for those files is kind of opaque to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574
https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574:37,Testability,test,tests,37,"@mcovarr indeed. I think our centaur tests were set up to assume certain limits, and by changing the defaults I've upset the tests. I _think_ I just need to work out where to re-set those centaur defaults but the inheritance hierarchy for those files is kind of opaque to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574
https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574:125,Testability,test,tests,125,"@mcovarr indeed. I think our centaur tests were set up to assume certain limits, and by changing the defaults I've upset the tests. I _think_ I just need to work out where to re-set those centaur defaults but the inheritance hierarchy for those files is kind of opaque to me.",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5034#issuecomment-507303574
https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495:142,Performance,perform,performance,142,Look good in the separated perf tests so 👍 from me. @salonishah11 - I'll merge this for you so that I can get started with horizontalling the performance tests.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495
https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495:32,Testability,test,tests,32,Look good in the separated perf tests so 👍 from me. @salonishah11 - I'll merge this for you so that I can get started with horizontalling the performance tests.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495
https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495:154,Testability,test,tests,154,Look good in the separated perf tests so 👍 from me. @salonishah11 - I'll merge this for you so that I can get started with horizontalling the performance tests.,MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5036#issuecomment-503651495
https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505027777:233,Availability,down,down,233,"I'm really not a big fan of copy/pasting huge chunks of the swagger doc over and checking it into the repo separately. Is there an option in codegen to target only a subset of the endpoints? If not, is there a way to derive this cut-down swagger from the main one before running codegen over it? (eg programmatically parse the yaml, select only the womtool sections and re-write just that section to a file?)",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505027777
https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505242680:151,Usability,clear,clear,151,"> It would be nice to document how to run this - I'm guessing it's running one of the shell scripts?. @aednichols -- I had that thought, but it wasn't clear where they would go. I see three options; 1.) main readme; 2.) separate readme (CLIENT.md); 3.) readthedocs site. Which is the appropriate path for docs like this?",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505242680
https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505468847:94,Integrability,wrap,wrapped,94,"IMO we should document this internally, since IMO the ""forever home"" for the process is to be wrapped up into the publish script for a new client version to be created every time we publish a new Cromwell version. Until then, I'd put the ""how to make clients"" docs either in our releasing Cromwell google doc, or as another heading in https://github.com/broadinstitute/cromwell/tree/develop/processes/release_processes",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-505468847
https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-506080242:5,Testability,test,tests,5,"Once tests pass we can merge. Will iterate on SBT if necessary, okay with me how it is separate",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5038#issuecomment-506080242
https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279:301,Availability,failure,failures,301,"Looks like one test is legit failing. ```; - should successfully run drs_wf_level_read_size *** FAILED *** (44 seconds, 659 milliseconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: 0f9eb46c-44ce-4c92-99f6-0184196298eb). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Failed to evaluate 'wf_level_read_and_size.fileSize1' (reason 1 of 1): Evaluating size(input1) failed: java.lang.IllegalArgumentException: Could not build the path \""dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0\"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, LinuxFileSystem. Failures: \nHTTP: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 does not have an http or https scheme (IllegalArgumentException)\nGoogle Cloud Storage: Cloud Storage URIs must have 'gs' scheme: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; },. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279
https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279:774,Availability,Failure,Failures,774,"Looks like one test is legit failing. ```; - should successfully run drs_wf_level_read_size *** FAILED *** (44 seconds, 659 milliseconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: 0f9eb46c-44ce-4c92-99f6-0184196298eb). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Failed to evaluate 'wf_level_read_and_size.fileSize1' (reason 1 of 1): Evaluating size(input1) failed: java.lang.IllegalArgumentException: Could not build the path \""dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0\"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, LinuxFileSystem. Failures: \nHTTP: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 does not have an http or https scheme (IllegalArgumentException)\nGoogle Cloud Storage: Cloud Storage URIs must have 'gs' scheme: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; },. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279
https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279:366,Integrability,message,message,366,"Looks like one test is legit failing. ```; - should successfully run drs_wf_level_read_size *** FAILED *** (44 seconds, 659 milliseconds); centaur.test.CentaurTestException: Unexpected terminal status Failed but was waiting for Succeeded (workflow ID: 0f9eb46c-44ce-4c92-99f6-0184196298eb). Metadata 'failures' content: [; {; ""causedBy"" : [; {; ""causedBy"" : [; ],; ""message"" : ""Failed to evaluate 'wf_level_read_and_size.fileSize1' (reason 1 of 1): Evaluating size(input1) failed: java.lang.IllegalArgumentException: Could not build the path \""dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0\"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, Google Cloud Storage, LinuxFileSystem. Failures: \nHTTP: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 does not have an http or https scheme (IllegalArgumentException)\nGoogle Cloud Storage: Cloud Storage URIs must have 'gs' scheme: dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from dos://wb-mock-drs-dev.storage.googleapis.com/4a3908ad-1f0b-4e2a-8a92-611f2123e8b0 (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; },. ```",MatchSource.ISSUE_COMMENT,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5039#issuecomment-505086279
