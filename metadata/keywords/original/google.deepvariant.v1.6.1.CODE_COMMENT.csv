id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py:137,Security,access,accessed,137,"""""""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""",MatchSource.CODE_COMMENT,deeptrio/dt_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py:224,Testability,test,tests,224,"""""""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""",MatchSource.CODE_COMMENT,deeptrio/dt_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/dt_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py:49,Availability,down,downsampling,49,"# Sentinel command line flag value indicating no downsampling should occur.",MatchSource.CODE_COMMENT,deeptrio/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py:119,Modifiability,extend,extending,119,"# We are using this flag for determining intervals for both child and parent; # models. In the future, we can consider extending into 3 samples.",MatchSource.CODE_COMMENT,deeptrio/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:34,Usability,learn,learning,34,"# Golden sets are created with; # learning/genomics/internal/create_golden_deep_trio.sh",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:6,Testability,test,tests,6,"# All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:30,Testability,test,test,30,"# In candidate_sweep mode the test stops here.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:13,Security,integrity,integrity,13,"# Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:20,Testability,assert,assertCountEqual,20,"# Despite its name, assertCountEqual checks that all items are equal.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:194,Testability,test,test,194,"""""""Test end to end for long ONT reads with phasing enabled. Args:; denovo_test: If true, denovo parameters will be set.; expected_denovo_variants: Total number of denovo examples expected. This test runs ONT end to end and compares the output with the golden; output. This test is introduced because previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:273,Testability,test,test,273,"""""""Test end to end for long ONT reads with phasing enabled. Args:; denovo_test: If true, denovo parameters will be set.; expected_denovo_variants: Total number of denovo examples expected. This test runs ONT end to end and compares the output with the golden; output. This test is introduced because previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:386,Testability,test,tests,386,"""""""Test end to end for long ONT reads with phasing enabled. Args:; denovo_test: If true, denovo parameters will be set.; expected_denovo_variants: Total number of denovo examples expected. This test runs ONT end to end and compares the output with the golden; output. This test is introduced because previously in training mode the; non training sample would not be phased. So this now tests to make sure; all of the training examples are phased correctly.; """"""",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:12,Testability,test,test,12,"# If denovo test is enabled, then set the parameters for denovo testing.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:64,Testability,test,testing,64,"# If denovo test is enabled, then set the parameters for denovo testing.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:62,Availability,error,error,62,"# Training on parent2 in a duo is not supported (with a clear error; # message).",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:71,Integrability,message,message,71,"# Training on parent2 in a duo is not supported (with a clear error; # message).",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:56,Usability,clear,clear,56,"# Training on parent2 in a duo is not supported (with a clear error; # message).",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:50,Availability,error,errors,50,"# This is only a simple test that it runs without errors.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:24,Testability,test,test,24,"# This is only a simple test that it runs without errors.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:17,Usability,simpl,simple,17,"# This is only a simple test that it runs without errors.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:36,Testability,test,test,36,"# Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:52,Testability,test,test,52,"# Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:336,Deployability,pipeline,pipeline,336,"# Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:61,Testability,assert,asserting,61,"# Finds a call in our actual call set for each NIST variant, asserting; # that we found exactly one.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:11,Usability,simpl,simple,11,"# Verifies simple properties of the Variant protos in variants. For example,; # checks that the reference_name() is our expected chromosome. The flag; # is_gvcf determines how we check the VariantCall field of each variant,; # enforcing expectations for gVCF records if true or variant calls if false.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:11,Usability,simpl,simple,11,"# Verifies simple structural properties of the DeepVariantCall objects; # emitted by the VerySensitiveCaller, such as that the AlleleCount and; # Variant both have the same position.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:10,Usability,simpl,simple,10,"# Do some simple structural checks on the tf.Examples in the file.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:36,Testability,test,test,36,"# pylint: disable=g-explicit-length-test",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:26,Integrability,inject,inject,26,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:26,Security,inject,inject,26,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:109,Testability,test,test,109,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:15,Testability,test,tested,15,"# Special case tested below.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py:29,Testability,test,test,29,"# Using a real ref_reader to test that the reference allele matches; # between the variant and the reference at the variant's coordinates.",MatchSource.CODE_COMMENT,deeptrio/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:26,Testability,test,testing,26,"""""""Utilities to help with testing DeepVariant code.""""""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:53,Testability,test,testdata,53,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:167,Testability,test,testdata,167,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:202,Testability,test,testdata,202,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:250,Testability,test,test,250,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:295,Testability,test,testdata,295,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:398,Testability,test,testdata,398,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:265,Usability,learn,learning,265,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py:21,Modifiability,variab,variables,21,"""""""Initialize global variables from flag values.""""""",MatchSource.CODE_COMMENT,deeptrio/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deeptrio/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:327,Availability,error,error,327,"""""""Gets allele frequency of the index-th alt_base of a Variant proto. Args:; variant: A Variant proto.; index: The index where we want to query allele frequency. Returns:; A float. The queried allele frequency. Raises:; ValueError: If the Variant proto does not include 'AF' field or the 'AF'; field encounters an out-of-bound error when querying at position `index`; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:70,Deployability,update,updated,70,"""""""Updates haplotypes for a variant. A list of variant haplotypes are updated given a variant and a reference; haplotype (this consists of a sequence and an offset wrt to the reference).; All ALT alleles are updated as independent updated haplotypes. Args:; variant: A Variant proto.; reference_haplotype: A string extracted from the reference genome.; reference_offset: An integer. The offset of the starting position of; reference_haplotype on reference. Raises:; ValueError: Variant.start is smaller than reference_offset. Returns:; A list of haplotype objects. Haplotype objects are stored as dicts:; {'haplotype': a haplotype (string),; 'alt': an alt allele (string),; 'variant': a Variant proto}; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:208,Deployability,update,updated,208,"""""""Updates haplotypes for a variant. A list of variant haplotypes are updated given a variant and a reference; haplotype (this consists of a sequence and an offset wrt to the reference).; All ALT alleles are updated as independent updated haplotypes. Args:; variant: A Variant proto.; reference_haplotype: A string extracted from the reference genome.; reference_offset: An integer. The offset of the starting position of; reference_haplotype on reference. Raises:; ValueError: Variant.start is smaller than reference_offset. Returns:; A list of haplotype objects. Haplotype objects are stored as dicts:; {'haplotype': a haplotype (string),; 'alt': an alt allele (string),; 'variant': a Variant proto}; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:231,Deployability,update,updated,231,"""""""Updates haplotypes for a variant. A list of variant haplotypes are updated given a variant and a reference; haplotype (this consists of a sequence and an offset wrt to the reference).; All ALT alleles are updated as independent updated haplotypes. Args:; variant: A Variant proto.; reference_haplotype: A string extracted from the reference genome.; reference_offset: An integer. The offset of the starting position of; reference_haplotype on reference. Raises:; ValueError: Variant.start is smaller than reference_offset. Returns:; A list of haplotype objects. Haplotype objects are stored as dicts:; {'haplotype': a haplotype (string),; 'alt': an alt allele (string),; 'variant': a Variant proto}; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:57,Deployability,update,update,57,"""""""Match candidate haplotypes with cohort haplotypes and update frequency. First, we look for exact haplotype matches between candidate and cohorts.; If there're any matches, the REF allele frequency associated with the matching; ALT allele is updated as well. Second, if no matches are found, we try to find inexact matches, where only; REF alleles are matched. The inexact matching step is only used to update REF; allele frequency. If no exact and inexact matches are found, set REF allele; frequency to 1. Args:; candidate_haps: A list of haplotype objects from a candidate.; cohort_haps_and_freqs: A list of haplotype objects from cohorts. Haplotype; objects are stored as dicts: {'haplotype': a haplotype (string), 'alt': an; alt allele (string), 'variant': a Variant proto}. Returns:; A dict with candidate alt alleles as keys, and associated frequencies; as values.; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:244,Deployability,update,updated,244,"""""""Match candidate haplotypes with cohort haplotypes and update frequency. First, we look for exact haplotype matches between candidate and cohorts.; If there're any matches, the REF allele frequency associated with the matching; ALT allele is updated as well. Second, if no matches are found, we try to find inexact matches, where only; REF alleles are matched. The inexact matching step is only used to update REF; allele frequency. If no exact and inexact matches are found, set REF allele; frequency to 1. Args:; candidate_haps: A list of haplotype objects from a candidate.; cohort_haps_and_freqs: A list of haplotype objects from cohorts. Haplotype; objects are stored as dicts: {'haplotype': a haplotype (string), 'alt': an; alt allele (string), 'variant': a Variant proto}. Returns:; A dict with candidate alt alleles as keys, and associated frequencies; as values.; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:405,Deployability,update,update,405,"""""""Match candidate haplotypes with cohort haplotypes and update frequency. First, we look for exact haplotype matches between candidate and cohorts.; If there're any matches, the REF allele frequency associated with the matching; ALT allele is updated as well. Second, if no matches are found, we try to find inexact matches, where only; REF alleles are matched. The inexact matching step is only used to update REF; allele frequency. If no exact and inexact matches are found, set REF allele; frequency to 1. Args:; candidate_haps: A list of haplotype objects from a candidate.; cohort_haps_and_freqs: A list of haplotype objects from cohorts. Haplotype; objects are stored as dicts: {'haplotype': a haplotype (string), 'alt': an; alt allele (string), 'variant': a Variant proto}. Returns:; A dict with candidate alt alleles as keys, and associated frequencies; as values.; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:181,Usability,simpl,simply,181,"# Calculate REF allele frequency if no exact match was found.; # It is possible a novel mutation happens at a site where there are other; # cohort variants. In this case, we cannot simply set REF frequency to 1.",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:475,Performance,perform,performing,475,"""""""Finds the allele frequencies of all the alt alleles for a candidate. Args:; variant: A Variant proto generated by make_examples. Note that it can be; multi-allelic.; population_vcf_reader: A VcfReader object that reads associated VCF file for; a candidate. We want to extract allele frequency information in the VCF.; ref_reader: A IndexedFastaReader object that reads the reference FASTA.; padding_bases: An integer that specifies the number of padding bases added; when performing a VCF query. By default it is set to 0. Returns:; A dict with alleles as keys, and allele frequencies as values; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py:364,Usability,simpl,simply,364,"""""""Creates VcfReaders for the given VCF file paths, organized by reference. VcfReaders can be made either from a single VCF that covers all the relevant; reference sequences or strictly one VCF per reference sequence. By returning; a defaultdict, any code using the output of this function does not have to; consider whether there are multiple VCFs or not, it can simply query by; chromosome and get a reader. Args:; population_vcf_filenames: Paths to files (VCF or VCF.gz) with population; genotypes. Raises:; ValueError: If there is more than one VCF file containing variants; from the same chromosome. Returns:; A defaultdict that maps from a reference name to an associated VcfReader.; If there was only one VCF provided, all references will map to that one; reader. If more than one VCF was provided, the references will have a; reader each, while any that were not included will map to None.; """"""",MatchSource.CODE_COMMENT,deepvariant/allele_frequency.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/allele_frequency.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py:162,Deployability,patch,patching,162,"# TODO: Externally, we can try to use older version of; # average_model_checkpoint.py. For example: r0.13, so that it will be compatible; # to this version we're patching internally.",MatchSource.CODE_COMMENT,deepvariant/average_model_checkpoint_patched.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py:79,Modifiability,variab,variables,79,"# Note: `model.get_weights()` gives us the weights (non-ref); # whereas `model.variables` returns references to the variables.",MatchSource.CODE_COMMENT,deepvariant/average_model_checkpoint_patched.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py:116,Modifiability,variab,variables,116,"# Note: `model.get_weights()` gives us the weights (non-ref); # whereas `model.variables` returns references to the variables.",MatchSource.CODE_COMMENT,deepvariant/average_model_checkpoint_patched.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/average_model_checkpoint_patched.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:14,Security,validat,validation,14,"# Default, no validation.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:34,Availability,avail,available,34,"# Don't use accelerators, even if available.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:38,Availability,error,error,38,"# Must be hardware acceleration or an error will be raised.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:25,Safety,predict,predict,25,"""""""Custom callbacks for `predict`.""""""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:259,Performance,perform,performed,259,"""""""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:35,Safety,predict,prediction,35,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:168,Safety,predict,prediction,168,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:218,Safety,predict,predicted,218,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:35,Performance,load,loading,35,"# TODO: Consider creating one data loading function to re-use simliar; # code with training in train_inceptionv3.py.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:141,Performance,queue,queue,141,"""""""Post processing of called variants. Args:; output_file: Path to output file where outputs will be written.; output_queue: Multiprocessing queue to fetch predictions from.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:156,Safety,predict,predictions,156,"""""""Post processing of called variants. Args:; output_file: Path to output file where outputs will be written.; output_queue: Multiprocessing queue to fetch predictions from.; include_debug_info: If true, include debug information.; debugging_true_label_mode: If true, include true label from the example.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:16,Availability,avail,available,16,"# See if GPU is available",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:12,Availability,avail,available,12,"# If GPU is available then use all CPUs for writing.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:104,Availability,down,down,104,"# Use maximum _MAX_WRITER_THREADS threads, this is to lower the overhead of; # spinning up and shutting down many processes.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py:25,Performance,queue,queue,25,"# Put none values in the queue so the running processes can terminate.",MatchSource.CODE_COMMENT,deepvariant/call_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:14,Security,validat,validation,14,"# Default, no validation.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:34,Availability,avail,available,34,"# Don't use accelerators, even if available.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:38,Availability,error,error,38,"# Must be hardware acceleration or an error will be raised.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:44,Testability,log,logic,44,"# This number is estimated by the following logic:; # For a sample with 10,000,000 examples, if we log every 50,000 examples,; # there will be 200 lines per sample.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:99,Testability,log,log,99,"# This number is estimated by the following logic:; # For a sample with 10,000,000 examples, if we log every 50,000 examples,; # there will be 200 lines per sample.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:259,Performance,perform,performed,259,"""""""Returns genotype likelihoods rounded to the desired precision level. Args:; gls: A list of floats. The input genotype likelihoods at any precision.; precision: Positive int. The number of places past the decimal point to; round to. If None, no rounding is performed. Returns:; A list of floats rounded to the desired precision. Raises:; ValueError: The input gls do not sum to nearly 1.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:35,Safety,predict,prediction,35,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:168,Safety,predict,prediction,168,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:218,Safety,predict,predicted,218,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:381,Safety,predict,prediction,381,"""""""Write the variant call based on prediction. Args:; writer: A object with a write() function that will be called for each; encoded_variant and genotype likelihoods.; prediction: A [3] tensor of floats. These are the predicted genotype; likelihoods (p00, p0x, pxx) for some alt allele x, in the same order as; encoded_variants.; use_tpu: bool. Decode the tpu specific encoding of prediction. Returns:; The return status from writer.; """"""",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:49,Performance,load,loading,49,"# Read a single TFExample to make sure we're not loading an older version.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:10,Safety,sanity check,sanity check,10,"# Perform sanity check.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:22,Safety,detect,detection,22,"# TODO. Sort out auto-detection of TPU. Just calling; # sess.list_devices here doesn't return the correct answer. That can only; # work later, after the device (on the other VM) has been initialized,; # which is generally not yet.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:18,Safety,predict,prediction,18,"# Instantiate the prediction ""stream"", and select the EMA values from; # the model.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:7,Testability,test,tests,7,"# Unit tests use this branch.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:10,Safety,predict,predictions,10,"# Consume predictions one at a time and write them to output_file.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py:11,Testability,log,log,11,"# One last log to capture the extra examples.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:138,Energy Efficiency,allocate,allocated,138,"# NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:32,Testability,test,tests,32,"# NB. This entire collection of tests will be invoked with '--use_tpu=' 'true'; # and 'false' by the BUILD file, and a tpu device will be allocated when; # necessary.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:52,Availability,checkpoint,checkpoint,52,"# For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:141,Modifiability,variab,variables,141,"# For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:6,Testability,test,tests,6,"# For tests that don't actually want to read a real checkpoint,; # return a fake one. The estimator understands None to mean; # that all the variables should be left uninitialized.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:18,Testability,test,test,18,"# If we point the test at a headless server, it will often be 2x2,; # which has 8 replicas. Otherwise a smaller batch size is fine.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:383,Testability,test,test,383,"# Check that our CallVariantsOutput (CVO) have the following critical; # properties:; # - we have one CVO for each example we processed.; # - the variant in the CVO is exactly what was in the example.; # - the alt_allele_indices of the CVO match those of its corresponding; # example.; # - there are 3 genotype probabilities and these are between 0.0 and 1.0.; # We can only do this test when processing all of the variants (max_batches; # is None), since we processed all of the examples with that model.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:90,Testability,log,logic,90,"# Check the CVO debug_info: not filled if include_debug_info is False;; # else, filled by logic based on CVO.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:2,Safety,predict,predict,2,"# predict batch size must be divisible by number of replicas.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py:12,Security,access,access,12,"# We cannot access the full _DeviceAttribute as it's not exported. So use a; # namedtuple with the same field names instead.",MatchSource.CODE_COMMENT,deepvariant/call_variants_slim_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_slim_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_test.py:10,Testability,test,test,10,"# Load in test data and get input shape",MatchSource.CODE_COMMENT,deepvariant/call_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/call_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:8,Availability,checkpoint,checkpoint,8,"# Model checkpoint:",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:151,Availability,checkpoint,checkpoint,151,"""""""Initializes the model and gathers parameters. Args:; example_info_json: Path to json file containing example shape.; checkpoint_path: Path to model checkpoint. Returns:; An initialized model.; """"""",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:58,Availability,checkpoint,checkpoint,58,"# model.load_weights(checkpoint_path).expect_partial(); # checkpoint = tf.train.Checkpoint(model=model); # Note that the `print_model_summary` is necessary because we need to run a; # forward pass with the model in order for assert_existing_objects_matched to; # work as expected. If you don't do this, then assert_existing_objects_matched; # will not raise an error even if the wrong checkpoint is used.; # Some context here: internal.",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:361,Availability,error,error,361,"# model.load_weights(checkpoint_path).expect_partial(); # checkpoint = tf.train.Checkpoint(model=model); # Note that the `print_model_summary` is necessary because we need to run a; # forward pass with the model in order for assert_existing_objects_matched to; # work as expected. If you don't do this, then assert_existing_objects_matched; # will not raise an error even if the wrong checkpoint is used.; # Some context here: internal.",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:385,Availability,checkpoint,checkpoint,385,"# model.load_weights(checkpoint_path).expect_partial(); # checkpoint = tf.train.Checkpoint(model=model); # Note that the `print_model_summary` is necessary because we need to run a; # forward pass with the model in order for assert_existing_objects_matched to; # work as expected. If you don't do this, then assert_existing_objects_matched; # will not raise an error even if the wrong checkpoint is used.; # Some context here: internal.",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py:2,Availability,checkpoint,checkpoint,2,"# checkpoint.restore(; # checkpoint_path; # ).expect_partial().assert_existing_objects_matched()",MatchSource.CODE_COMMENT,deepvariant/convert_to_saved_model.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/convert_to_saved_model.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py:559,Integrability,wrap,wrapping,559,"""""""Makes the html report with all the charts inserted. Args:; specs: A list of dictionaries with keys ""id"" (unique name) and either; ""chart"" (should be an Altair chart object) or ""html"" (a string to be; inserted as html into the report).; html_output: A writable file object.; title: The title to show at the top of the report.; subtitle: The subtitle to show just below the title on the report.; charts_on_separate_lines: Put charts on separate lines. If false, charts; will set next to each other as space allows and flow to the next line,; similar to text wrapping.; include_outline: If true, an outline with chart IDs will be added on top. Returns:; None. Writes into the html_output file object.; """"""",MatchSource.CODE_COMMENT,deepvariant/dashboard_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py:8,Safety,sanity check,sanity check,8,"# First sanity check input specs list.",MatchSource.CODE_COMMENT,deepvariant/dashboard_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py:6,Integrability,depend,dependencies,6,"# Add dependencies vega and vega-lite, which render the altair charts.",MatchSource.CODE_COMMENT,deepvariant/dashboard_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dashboard_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:106,Performance,concurren,concurrency,106,"# These are empirically determined to work well on TPU with our data sets,; # where lots of buffering and concurrency is necessary to keep the device; # busy.; # These are settable in the constructor.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:161,Deployability,configurat,configuration,161,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:151,Modifiability,config,config,151,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:161,Modifiability,config,configuration,161,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:19,Performance,load,loading,19,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:206,Performance,tune,tune,206,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:214,Safety,predict,predict,214,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:330,Testability,test,testing,330,"""""""tf.data.Dataset loading function. Args:; path: the input filename for a tfrecord[.gz] file containing examples. Can; contain sharding designators.; config: A configuration file.; mode: One of ['train', 'tune', 'predict']; strategy: A tf.distribute.Strategy.; n_epochs: Number of epochs.; limit: Limit the number of batches for testing purposes. Returns:; tf.data.Dataset; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:132,Performance,concurren,concurrently,132,"# Calling this object like a function returns a stream of variadic tuples.; # Essentially it is a buffered io library, that handles concurrently; # reading and possibly shuffling input records from a set of files. It; # knows how to parse features we care about from tf.examples. It records; # some extra information about the source of the input, such as the name; # and number of classes.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:344,Energy Efficiency,schedul,schedule,344,"""""""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is 16 * 1000 * 1000.; sloppy: boolean, allow parallel_interleave to be sloppy. Default True.; list_files_shuffle: boolean, allow list_files to shuffle. Default True.; debugging_true_label_mode: boolean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:922,Performance,tune,tuned,922,"""""""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is 16 * 1000 * 1000.; sloppy: boolean, allow parallel_interleave to be sloppy. Default True.; list_files_shuffle: boolean, allow list_files to shuffle. Default True.; debugging_true_label_mode: boolean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:852,Testability,test,testing,852,"""""""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is 16 * 1000 * 1000.; sloppy: boolean, allow parallel_interleave to be sloppy. Default True.; list_files_shuffle: boolean, allow list_files to shuffle. Default True.; debugging_true_label_mode: boolean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:37,Usability,usab,usable,37,"""""""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is 16 * 1000 * 1000.; sloppy: boolean, allow parallel_interleave to be sloppy. Default True.; list_files_shuffle: boolean, allow list_files to shuffle. Default True.; debugging_true_label_mode: boolean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:330,Usability,learn,learning,330,"""""""Create a DeepVariantInput object, usable as an `input_fn`. Args:; mode: the mode string (from `tf.estimator.ModeKeys`).; input_file_spec: the input filename for a tfrecord[.gz] file containing; examples. Can contain sharding designators.; num_examples: the number of examples contained in the input file. Required; for setting learning rate schedule in train/eval only.; num_classes: The number of classes in the labels of this dataset.; Currently defaults to DEFAULT_NUM_CLASSES.; max_examples: The maximum number of examples to use. If None, all examples; will be used. If not None, the first n = min(max_examples, num_examples); will be used. This works with training, and the n examples will repeat; over and over.; tensor_shape: None (which means we get the shape from the first example in; source), or list of int [height, width, channel] for testing.; name: string, name of the dataset.; use_tpu: use code paths tuned for TPU, in particular protobuf encoding.; Default False.; input_read_threads: number of threads for reading data. Default 32.; shuffle_buffer_size: size of the final shuffle buffer, in elements.; Default 100.; initial_shuffle_buffer_size: int; the size of the dataset.shuffle buffer; in elements. Default is 1024.; prefetch_dataset_buffer_size: int; the size of the TFRecordDataset buffer; in bytes. Default is 16 * 1000 * 1000.; sloppy: boolean, allow parallel_interleave to be sloppy. Default True.; list_files_shuffle: boolean, allow list_files to shuffle. Default True.; debugging_true_label_mode: boolean. If true, the input examples are; created with ""training"" mode. We'll parse the 'label' field even if the; `mode` is PREDICT. Raises:; ValueError: if `num_examples` not provided, in a context requiring it.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:5,Deployability,update,update,5,"# We update our num_examples in the situation where num_examples is set; # (i.e., is not None) to the smaller of max_examples and num_examples.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:20,Performance,load,loading,20,"# Cast to int32 for loading onto the TPU",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:39,Availability,error,error,39,"# Passing a string to a TPU draws this error: TypeError: <dtype:; # 'string'> is not a supported TPU infeed type. Supported types are:; # [tf.float32, tf.int32, tf.complex64, tf.int64, tf.bool, tf.bfloat16]; # Thus, we must encode the string as a tensor of int.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:6,Safety,predict,predict,6,"# For predict model, label is not present. So, returns features only.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:56,Integrability,contract,contract,56,"""""""Interface to get a data batch, fulfilling `input_fn` contract. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'; and, if not PREDICT mode, also:; 'locus'. Aside from 'image', these may be encoded specially for TPU. - label is the Tensor-valued prediction label; in train/eval; mode the label value is is populated from the data source; in; inference mode, the value is a constant empty Tensor value ""()"".; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:435,Safety,predict,prediction,435,"""""""Interface to get a data batch, fulfilling `input_fn` contract. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'; and, if not PREDICT mode, also:; 'locus'. Aside from 'image', these may be encoded specially for TPU. - label is the Tensor-valued prediction label; in train/eval; mode the label value is is populated from the data source; in; inference mode, the value is a constant empty Tensor value ""()"".; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:125,Performance,optimiz,optimized,125,"# See https://cloud.google.com/tpu/docs/tutorials/inception-v3-advanced; # for some background on tuning this on TPU.; # TPU optimized implementation for prediction mode",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:154,Safety,predict,prediction,154,"# See https://cloud.google.com/tpu/docs/tutorials/inception-v3-advanced; # for some background on tuning this on TPU.; # TPU optimized implementation for prediction mode",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:105,Availability,avail,available,105,"# Optimized following:; # https://www.tensorflow.org/guide/performance/datasets; # using the information available from xprof.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:59,Performance,perform,performance,59,"# Optimized following:; # https://www.tensorflow.org/guide/performance/datasets; # using the information available from xprof.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:53,Usability,guid,guide,53,"# Optimized following:; # https://www.tensorflow.org/guide/performance/datasets; # using the information available from xprof.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:32,Integrability,contract,contract,32,"""""""Implementation of `input_fn` contract for prediction mode. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'. Aside from 'image', these may be encoded specially for TPU.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:45,Safety,predict,prediction,45,"""""""Implementation of `input_fn` contract for prediction mode. Args:; params: a dict containing an integer value for key 'batch_size'. Returns:; the tuple (features, labels), where:; - features is a dict of Tensor-valued input features; keys populated; are:; 'image'; 'variant'; 'alt_allele_indices'. Aside from 'image', these may be encoded specially for TPU.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:85,Deployability,configurat,configuration,85,"# This is the entry point to get a DeepVariantInput when you start with; # a dataset configuration file name.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:85,Modifiability,config,configuration,85,"# This is the entry point to get a DeepVariantInput when you start with; # a dataset configuration file name.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:40,Modifiability,config,config,40,"""""""Creates an input_fn from the dataset config file. Args:; dataset_config_filename: str. Path to the dataset config pbtxt file.; mode: one of tf.estimator.ModeKeys.{TRAIN,EVAL,PREDICT}; **kwargs: Additional keyword arguments for DeepVariantInput. Returns:; An input_fn from the specified split in the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:110,Modifiability,config,config,110,"""""""Creates an input_fn from the dataset config file. Args:; dataset_config_filename: str. Path to the dataset config pbtxt file.; mode: one of tf.estimator.ModeKeys.{TRAIN,EVAL,PREDICT}; **kwargs: Additional keyword arguments for DeepVariantInput. Returns:; An input_fn from the specified split in the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:359,Modifiability,config,config,359,"""""""Creates an input_fn from the dataset config file. Args:; dataset_config_filename: str. Path to the dataset config pbtxt file.; mode: one of tf.estimator.ModeKeys.{TRAIN,EVAL,PREDICT}; **kwargs: Additional keyword arguments for DeepVariantInput. Returns:; An input_fn from the specified split in the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:274,Usability,usab,usable,274,"""""""Create a DeepVariantInput function object from a file spec. Args:; input_file_spec: the tf.example input file specification, possibly sharded.; mode: tf.estimator.ModeKeys.; **kwargs: Additional keyword arguments for DeepVariantInput. Returns:; A DeepVariantInput object usable as an input_fn.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:42,Modifiability,config,config,42,"# This reads a pbtxt file and returns the config proto.",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:66,Modifiability,config,config,66,"""""""Returns a DeepVariantDatasetConfig proto read from the dataset config file. Args:; dataset_config_filename: String. Path to the dataset config pbtxt file. Returns:; A DeepVariantDatasetConfig proto from the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:139,Modifiability,config,config,139,"""""""Returns a DeepVariantDatasetConfig proto read from the dataset config file. Args:; dataset_config_filename: String. Path to the dataset config pbtxt file. Returns:; A DeepVariantDatasetConfig proto from the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:267,Modifiability,config,config,267,"""""""Returns a DeepVariantDatasetConfig proto read from the dataset config file. Args:; dataset_config_filename: String. Path to the dataset config pbtxt file. Returns:; A DeepVariantDatasetConfig proto from the dataset_config file. Raises:; ValueError: if the dataset config doesn't have the necessary information.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py:115,Modifiability,config,config,115,"""""""Writes the dataset_config to a human-readable text format. Args:; dataset_config: DeepVariantDatasetConfig. The config to be written out.; dataset_config_filename: String. Path to the output pbtxt file.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:13,Usability,learn,learning,13,"""""""Tests for learning.genomics.deepvariant.data_provider.""""""",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:179,Availability,avail,available,179,"# It looks like tf.data.Dataset.list_files is potentially nondeterministic.; # There's no guaranteed way to get around that (yet, internal).; # A list_files() flag I want is only available in tf 1.7,; # so for the short term, work around the problem by asking; # self.assertTfDataSetExamplesMatchExpected to sort the; # loci it sees. That doesn't generalize well, but we should; # be able to fix this soon.; # pylint: disable=g-complex-comprehension",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:268,Testability,assert,assertTfDataSetExamplesMatchExpected,268,"# It looks like tf.data.Dataset.list_files is potentially nondeterministic.; # There's no guaranteed way to get around that (yet, internal).; # A list_files() flag I want is only available in tf 1.7,; # so for the short term, work around the problem by asking; # self.assertTfDataSetExamplesMatchExpected to sort the; # loci it sees. That doesn't generalize well, but we should; # be able to fix this soon.; # pylint: disable=g-complex-comprehension",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:51,Testability,test,testing,51,"# Get our images, labels, and variants for further testing.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:28,Testability,assert,assert,28,"# pylint: disable=g-generic-assert",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:58,Availability,avail,available,58,"# pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:44,Testability,assert,assertLen,44,"# pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:102,Testability,assert,assert,102,"# pylint: enable=g-complex-comprehension; # assertLen not available OSS.; # pylint: disable=g-generic-assert",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:27,Testability,assert,assert,27,"# pylint: enable=g-generic-assert",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:76,Deployability,update,update,76,"# When num_examples isn't provided (None), but max_examples is, we don't; # update num_examples so it remains None.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:6,Safety,predict,predict,6,"# Use predict mode so we can have num_examples == None.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:50,Testability,test,tests,50,"""""""Tests of input_fn, doing end-to-end I/O. These tests instantiate an input stream and then check it in various ways,; in increasing complexity.; """"""",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:179,Availability,recover,recovered,179,"# Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:130,Safety,predict,predict,130,"# Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:179,Safety,recover,recovered,179,"# Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:52,Testability,test,testInputStream,52,"# Test reading with a larger batch size. Similar to testInputStream,; # but note that the last batch may be truncated when not in predict mode,; # so current_batch_size has to be recovered from the actual output.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py:63,Testability,test,test,63,"# Read and parse the data using tf. This is the function under test,; # although we indirectly check parse_tfexample as well.",MatchSource.CODE_COMMENT,deepvariant/data_providers_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/data_providers_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py:24,Security,validat,validation,24,"# If set to 0, use full validation dataset.",MatchSource.CODE_COMMENT,deepvariant/dv_config.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py:15,Modifiability,config,config,15,"# Use the base config.",MatchSource.CODE_COMMENT,deepvariant/dv_config.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_config.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py:137,Security,access,accessed,137,"""""""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py:224,Testability,test,tests,224,"""""""Common constants shared across DeepVariant's codebase. This file is for very general constants in the code that end up needing to be; accessed in a variety of places, often in live code as well as throughout the; code in tests.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py:9,Availability,avail,available,9,"# Define available OptChannels (optional extra channels).",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py:167,Modifiability,extend,extended,167,"# Used only when phasing is on (phase_reads=true). It allows to set the; # region padding as a percantage over the region length. candidates are; # calculated over an extended region. Output examples are not affected by; # this value.",MatchSource.CODE_COMMENT,deepvariant/dv_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:126,Availability,checkpoint,checkpoint,126,"""""""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:473,Availability,checkpoint,checkpointed,473,"""""""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:290,Modifiability,variab,variables,290,"""""""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:418,Modifiability,variab,variable,418,"""""""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:525,Modifiability,variab,variable,525,"""""""Returns the shape of each tensor in the model at checkpoint_path. Args:; checkpoint_path: string. The path to a tensorflow checkpoint containing a; model whose tensor shapes we want to get.; variables_to_get: options, list of strings. If provided, only returns the; shapes of tensors in variables whose name is present in this list. If; None, the default, gets all of the tensors. A KeyError will be raised if; any variable name in variables_to_get isn't present in the checkpointed; model. Returns:; A dictionary mapping variable names [string] to tensor shapes [tuple].; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:40,Availability,checkpoint,checkpoint,40,"""""""Returns the number of classes in the checkpoint.""""""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:66,Safety,predict,predict,66,"# Figure out how many classes this inception model was trained to predict.",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:34,Availability,avail,available,34,"""""""Return true if a TPU device is available to the default session.""""""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py:137,Energy Efficiency,efficient,efficiently,137,"""""""Applies preprocessing operations for Inception images. Because this will run in model_fn, on the accelerator, we use operations; that efficiently execute there. Args:; images: A Tensor of shape [batch_size height, width, channel] with uint8; values. Returns:; A tensor of images of shape [batch_size height, width, channel]; containing floating point values, with all points rescaled between; -1 and 1 and possibly resized.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:10,Availability,checkpoint,checkpoint,10,"# Saves a checkpoint.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:27,Modifiability,variab,variable,27,"# Model shapes without any variable requests gives you all variables.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:59,Modifiability,variab,variables,59,"# Model shapes without any variable requests gives you all variables.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:10,Availability,checkpoint,checkpoint,10,"# Saves a checkpoint.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:49,Availability,checkpoint,checkpoint,49,"# If the class variable name doesn't existin the checkpoint, return None.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:15,Modifiability,variab,variable,15,"# If the class variable name doesn't existin the checkpoint, return None.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:9,Availability,checkpoint,checkpoint,9,"# If the checkpoint doesn't exist, return none.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py:48,Availability,error,errors,48,"# This calls tf.io.gfile.Glob, which will raise errors.OpError,; # at least on a Posix filesystem. Other filesystems might; # not fail like that, and will return an empty list, which; # is turned into a different exception.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif.py:31,Integrability,depend,dependencies,31,"""""""Utility functions that uses dependencies with CLIF under the hood.""""""",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py:29,Safety,avoid,avoids,29,"# Providing variant directly avoids the call to example_variant().",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py:17,Performance,load,load,17,"# Checks that we load the variant if needed and that our mock is working.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py:57,Testability,mock,mock,57,"# Checks that we load the variant if needed and that our mock is working.",MatchSource.CODE_COMMENT,deepvariant/dv_utils_using_clif_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_utils_using_clif_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py:10,Deployability,release,release,10,"# Current release version of DeepVariant.",MatchSource.CODE_COMMENT,deepvariant/dv_vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py:159,Deployability,pipeline,pipeline,159,"""""""Returns a VcfHeader used for writing VCF output. This function fills out the FILTER, INFO, FORMAT, and extra header information; created by the DeepVariant pipeline using consistent fields that DeepVariant; creates. The `contigs` and `sample_names` fields are unique depending on the; input data used, so are required inputs. Args:; contigs: list(ContigInfo). The list of contigs on which variants were; called.; sample_names: list(str). The list of samples present in the run.; add_info_candidates: Adds the 'CANDIDATES' info field for debugging; purposes.; include_med_dp: boolean. If True, we will include MED_DP. Returns:; A nucleus.genomics.v1.VcfHeader proto with known fixed headers and the given; samples and contigs populated.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py:270,Integrability,depend,depending,270,"""""""Returns a VcfHeader used for writing VCF output. This function fills out the FILTER, INFO, FORMAT, and extra header information; created by the DeepVariant pipeline using consistent fields that DeepVariant; creates. The `contigs` and `sample_names` fields are unique depending on the; input data used, so are required inputs. Args:; contigs: list(ContigInfo). The list of contigs on which variants were; called.; sample_names: list(str). The list of samples present in the run.; add_info_candidates: Adds the 'CANDIDATES' info field for debugging; purposes.; include_med_dp: boolean. If True, we will include MED_DP. Returns:; A nucleus.genomics.v1.VcfHeader proto with known fixed headers and the given; samples and contigs populated.; """"""",MatchSource.CODE_COMMENT,deepvariant/dv_vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/dv_vcf_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:608,Deployability,configurat,configuration,608,"""""""Library for resolving variants into consistent haplotypes. The convolutional neural network that evaluates the probability of a candidate; variant being non-reference evaluates each candidate variant independently.; This can lead to overlapping variant calls that cannot actually exist in an; organism: for example, a diploid human cannot have overlapping variants for; which one is homozygous alternate and the other is heterozygous alternate, since; that implies three total alternate alleles. This library tries to resolve overlapping variant calls into consistent; haplotypes by using the most likely configuration based on individual call; probabilities that is a valid set of two haplotypes. In rare cases where this; is not possible, the haplotypes are left unmodified.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:608,Modifiability,config,configuration,608,"""""""Library for resolving variants into consistent haplotypes. The convolutional neural network that evaluates the probability of a candidate; variant being non-reference evaluates each candidate variant independently.; This can lead to overlapping variant calls that cannot actually exist in an; organism: for example, a diploid human cannot have overlapping variants for; which one is homozygous alternate and the other is heterozygous alternate, since; that implies three total alternate alleles. This library tries to resolve overlapping variant calls into consistent; haplotypes by using the most likely configuration based on individual call; probabilities that is a valid set of two haplotypes. In rare cases where this; is not possible, the haplotypes are left unmodified.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:162,Deployability,configurat,configurations,162,"# The maximum number of overlapping variants to try to resolve into compatible; # haplotypes. This corresponds to generating 3^12 (= 531,441) possible variant; # configurations for diploid individuals.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:162,Modifiability,config,configurations,162,"# The maximum number of overlapping variants to try to resolve into compatible; # haplotypes. This corresponds to generating 3^12 (= 531,441) possible variant; # configurations for diploid individuals.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:300,Performance,tune,tune,300,"""""""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:399,Safety,predict,predicted,399,"""""""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:519,Safety,predict,predicted,519,"""""""Yields variants with compatible genotype calls in order. This function differs from `_resolve_overlapping_variants` below in that the; input here is a block of all candidate calls that overlap in a region, which; may contain candidates that are deemed to be most likely reference calls.; We often tune DeepVariant to be highly sensitive. Consequently, there can be; many candidate calls that are predicted as reference. Since those do not; contribute to potential incompatibilities, we split them out from variants; predicted to contain non-reference genotypes since the computation of; compatible haplotypes is exponential in the number of inputs. Args:; overlapping_candidates: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:20,Usability,simpl,simplest,20,"# Short circuit the simplest case: A single variant in a region is compatible; # with itself by definition.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:54,Deployability,configurat,configurations,54,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:101,Deployability,configurat,configurations,101,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:179,Deployability,configurat,configuration,179,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:327,Deployability,configurat,configurations,327,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:54,Modifiability,config,configurations,54,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:101,Modifiability,config,configurations,101,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:179,Modifiability,config,configuration,179,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:327,Modifiability,config,configurations,327,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:482,Testability,log,log-sum-exp,482,"""""""Container class for genotype likelihoods of allele configurations. When evaluating valid genotype configurations across multiple variants, we; calculate the likelihood of each configuration. To then calculate the marginal; likelihoods for each variant's genotypes, for each genotype we need to sum the; probabilities of all configurations that include that genotype. For numerical stability we do this by storing the genotype likelihoods; = log10(p) and then aggregate using the log-sum-exp trick.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:46,Deployability,configurat,configuration,46,"""""""Add some likelihood to a particular allele configuration. Args:; allele_indices: Pair of (g1, g2) ints representing the genotype.; likelihood: float. log10(probability of this genotype configuration).; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:188,Deployability,configurat,configuration,188,"""""""Add some likelihood to a particular allele configuration. Args:; allele_indices: Pair of (g1, g2) ints representing the genotype.; likelihood: float. log10(probability of this genotype configuration).; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:46,Modifiability,config,configuration,46,"""""""Add some likelihood to a particular allele configuration. Args:; allele_indices: Pair of (g1, g2) ints representing the genotype.; likelihood: float. log10(probability of this genotype configuration).; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:188,Modifiability,config,configuration,188,"""""""Add some likelihood to a particular allele configuration. Args:; allele_indices: Pair of (g1, g2) ints representing the genotype.; likelihood: float. log10(probability of this genotype configuration).; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:213,Safety,predict,predicted,213,"""""""Yields variants with compatible haplotypes, if possible. Args:; overlapping_variants: list(Variant). A non-empty list of Variant protos in; coordinate-sorted order that overlap on the reference genome and are; predicted to contain alternate allele genotypes. Yields:; Variant protos in coordinate-sorted order that try to resolve incompatible; haplotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:20,Usability,simpl,simplest,20,"# Short circuit the simplest case: A single variant in a region is compatible; # with itself by definition.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:113,Deployability,configurat,configuration,113,"# If the actual genotype calls are compatible, we can safely return those; # since they would be the most likely configuration also when restricting to; # only valid configurations of genotype calls.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:166,Deployability,configurat,configurations,166,"# If the actual genotype calls are compatible, we can safely return those; # since they would be the most likely configuration also when restricting to; # only valid configurations of genotype calls.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:113,Modifiability,config,configuration,113,"# If the actual genotype calls are compatible, we can safely return those; # since they would be the most likely configuration also when restricting to; # only valid configurations of genotype calls.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:166,Modifiability,config,configurations,166,"# If the actual genotype calls are compatible, we can safely return those; # since they would be the most likely configuration also when restricting to; # only valid configurations of genotype calls.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:54,Safety,safe,safely,54,"# If the actual genotype calls are compatible, we can safely return those; # since they would be the most likely configuration also when restricting to; # only valid configurations of genotype calls.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:117,Safety,avoid,avoid,117,"# The actual genotype calls produce an inconsistent haplotype. If the number; # of affected variants is ""too large"", avoid processing since this is an; # exponential process.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:137,Deployability,configurat,configurations,137,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:227,Deployability,configurat,configuration,227,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:433,Deployability,configurat,configurations,433,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2061,Deployability,configurat,configurations,2061,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2382,Deployability,configurat,configurations,2382,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2505,Deployability,configurat,configurations,2505,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2614,Integrability,depend,depending,2614,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:137,Modifiability,config,configurations,137,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:227,Modifiability,config,configuration,227,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:433,Modifiability,config,configurations,433,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2061,Modifiability,config,configurations,2061,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2382,Modifiability,config,configurations,2382,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2505,Modifiability,config,configurations,2505,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:1807,Performance,perform,performing,1807,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:502,Safety,predict,predicted,502,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:587,Safety,predict,predicted,587,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:1494,Safety,predict,predict,1494,"# results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two ",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:1889,Safety,predict,predict,1889,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2352,Safety,avoid,avoid,2352,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:742,Testability,log,log,742,"# Otherwise, the actual genotype calls are incompatible. Since the genotype; # likelihoods are generally well-calibrated, we examine all configurations of; # genotypes that create compatible haplotypes and retain the single; # configuration with the highest joint likelihood across all variants as the; # proposed genotype assignment. Separately, we rescale the likelihood of each; # individual variant using only the valid genotype configurations. If the; # results are concordant (i.e., the genotype predicted by the marginal; # likelihood for each variant is the same as the genotype predicted when; # maximizing the joint likelihood across all variants), we return variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modifie",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:2358,Testability,test,testing,2358,"eturn variants; # with those calls and the rescaled likelihoods. Otherwise, we log a warning; # and emit the original (incompatible) variants.; #; # For example, a biallelic deletion with probabilities of homref, het, homalt; # = 0.01, 0.9, 0.09 and inside it a biallelic SNP with probs 0.02, 0.48, 0.5.; # Naively this would be called as a heterozygous indel and a homozygous SNP,; # which is impossible as there are three total alternate genotypes. The; # algorithm does the following:; #; # Indel SNP Joint prob; # 0/0 0/0 0.01 * 0.02 = 0.0002; # 0/0 0/1 0.01 * 0.48 = 0.0048; # 0/0 1/1 0.01 * 0.50 = 0.0050; # 0/1 0/0 0.90 * 0.02 = 0.0180; # 0/1 0/1 0.90 * 0.48 = 0.4320*; # 0/1 1/1 <invalid> = 0; # 1/1 0/0 0.09 * 0.02 = 0.0018; # 1/1 0/1 <invalid> = 0; # 1/1 1/1 <invalid> = 0; #; # So using the highest joint likelihood, we predict het indel and het SNP.; #; # The marginal probability of each genotype for the indel is:; # 0/0: 0.0002 + 0.0048 + 0.0050 = 0.01; # 0/1: 0.0180 + 0.4320 = 0.45; # 1/1: 0.0018 = 0.0018; #; # which after normalizing to sum to 1 is roughly 0.022, 0.974, 0.004.; # The marginal probability for the SNP, after performing similar; # calculations, is 0.043, 0.946, 0.011. So the marginals also predict a het; # indel and a het SNP. Since the two calculations agree, we use this; # genotype call and modified likelihoods.; #; # First, we find all non-reference count configurations that are compatible.; # This represents each variant solely based on its number of non-reference; # genotypes, and assumes that variants are compatible if the total number of; # non-reference genotypes at a single position is at most two. By using; # non-reference counts, we avoid testing multiple allele configurations that; # will return the same result (e.g. a variant with two possible alternate; # alleles has three allele configurations that are homozygous alternate; # [1/1, 1/2, 2/2] and either all or none of them will be valid depending on; # the variants it interacts with).",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:36,Deployability,configurat,configurations,36,"# Collapse the probabilities of all configurations to a single GL for each; # allele, independently for each variant.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:36,Modifiability,config,configurations,36,"# Collapse the probabilities of all configurations to a single GL for each; # allele, independently for each variant.",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:33,Deployability,configurat,configurations,33,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:151,Deployability,configurat,configurations,151,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:418,Deployability,configurat,configuration,418,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:33,Modifiability,config,configurations,33,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:151,Modifiability,config,configurations,151,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:418,Modifiability,config,configuration,418,"""""""Returns an iterable of allele configurations that satisfy the genotype. Args:; variants: list(Variant). The list of variants for which to generate; configurations of valid allele_indices.; nonref_count_configuration: list(int). The list of numbers of non-reference; genotypes that should be generated for each variant. Returns:; Iterable of lists of allele indices to assign to each Variant to satisfy the; desired configuration of number of non-reference genotypes for each variant. Raises:; ValueError: variants and nonref_count_configuration do not have the same; length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:289,Deployability,configurat,configuration,289,"""""""Returns the joint likelihood of the alleles given to the variants. Args:; variants: list(Variant). The variants with associated likelihoods.; allele_indices_config: list((int, int)). The allele indices to assign to; each variant. Returns:; The joint likelihood of the particular allele configuration. Raises:; ValueError: variants and allele_indices_config do not have the same length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py:289,Modifiability,config,configuration,289,"""""""Returns the joint likelihood of the alleles given to the variants. Args:; variants: list(Variant). The variants with associated likelihoods.; allele_indices_config: list((int, int)). The allele indices to assign to; each variant. Returns:; The joint likelihood of the particular allele configuration. Raises:; ValueError: variants and allele_indices_config do not have the same length.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:236,Safety,detect,detection,236,"""""""Creates a Variant record for testing. Args:; chrom: reference name for this variant; start: start position on the contig; end: end position on the contig; ref: reference base(s); alt: list(str). alternate base(s); qual: PHRED scaled detection probability; genotype: list of integers corresponding to the called genotype; likelihoods: genotype likelihoods for this variant; sample_name: sample name for the single call in the variant. Returns:; A Variant record created with the specified arguments. Raises:; ValueError: Both ref and end are specified, and are inconsistent.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:32,Testability,test,testing,32,"""""""Creates a Variant record for testing. Args:; chrom: reference name for this variant; start: start position on the contig; end: end position on the contig; ref: reference base(s); alt: list(str). alternate base(s); qual: PHRED scaled detection probability; genotype: list of integers corresponding to the called genotype; likelihoods: genotype likelihoods for this variant; sample_name: sample name for the single call in the variant. Returns:; A Variant record created with the specified arguments. Raises:; ValueError: Both ref and end are specified, and are inconsistent.; """"""",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:39,Testability,test,tested,39,"# Note: Most of the resolution code is tested below in the; # test_resolve_overlapping_variants function. This test mostly just ensures; # that the interaction with RefCall variants is properly handled.",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:111,Testability,test,test,111,"# Note: Most of the resolution code is tested below in the; # test_resolve_overlapping_variants function. This test mostly just ensures; # that the interaction with RefCall variants is properly handled.",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:6,Usability,simpl,simple,6,"# The simple case where there is a single variant.",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py:16,Testability,test,test,16,"# Same as prior test but using a generator as input.",MatchSource.CODE_COMMENT,deepvariant/haplotypes_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/haplotypes_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:39,Usability,learn,learning,39,"""""""Provides an abstraction around deep learning Keras models in DeepVariant.""""""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:33,Modifiability,config,configured,33,"""""""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:91,Modifiability,extend,extended,91,"""""""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:289,Modifiability,layers,layers,289,"""""""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:303,Modifiability,layers,layers,303,"""""""Returns an output head tensor configured for classification. In the future, this can be extended for regression, or with different params; for different heads. Args:; inputs: The backbone output tensor; used as the input to the head.; l2: The l2 regularization factor used in `tf.keras.layers.Dense` layers. Returns:; A tensor representing the output of the given head.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:284,Deployability,update,updates,284,"""""""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:313,Deployability,configurat,configuration,313,"""""""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:45,Modifiability,layers,layers,45,"""""""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:313,Modifiability,config,configuration,313,"""""""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:590,Modifiability,layers,layers,590,"""""""Adds L2 regularizers to all `layer_class` layers in `model`. Models from `tf.keras.applications` do not support specifying kernel or bias; regularizers. However, adding regularization is important when fine tuning; 'imagenet' pretrained weights. In order to do this, this function updates the; current model's configuration to include regularizers and reloads the model so; that the newly created losses are registered.; Note: this will not overwrite existing `kernel_regularizer` regularizers on; the given layer.; Args:; model: The base model.; layer_class: We add regularizers to all layers of type `layer_class`.; l2: The l2 regularization factor.; regularizer_attr: The layer's regularizer attribute. Returns:; A model with l2 regularization added to each `layer_class` layer.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:39,Modifiability,layers,layers,39,"# Set the L2 `regularizer_attr` on all layers of type `layer_class`. This; # change is only reflected in the model's config file.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:117,Modifiability,config,config,117,"# Set the L2 `regularizer_attr` on all layers of type `layer_class`. This; # change is only reflected in the model's config file.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:11,Deployability,update,updated,11,"# Save the updated model configuration.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:25,Deployability,configurat,configuration,25,"# Save the updated model configuration.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:25,Modifiability,config,configuration,25,"# Save the updated model configuration.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:32,Deployability,update,updated,32,"# Create a ""new"" model from the updated configuration and load the original; # model's weights.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:40,Deployability,configurat,configuration,40,"# Create a ""new"" model from the updated configuration and load the original; # model's weights.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:40,Modifiability,config,configuration,40,"# Create a ""new"" model from the updated configuration and load the original; # model's weights.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:58,Performance,load,load,58,"# Create a ""new"" model from the updated configuration and load the original; # model's weights.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:68,Modifiability,layers,layers,68,"# Ensure model weights have not changed after adding regularization layers.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:219,Deployability,update,updated,219,"""""""Initialize `model` with weights from `input_model` (different #channels). Args:; model: The model we want to output.; input_model: The input model that contains the weights to initialize from. Returns:; `model` with updated weights from `input_model`; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:63,Performance,load,load,63,"# Now that the new_layer_weights list has the value we want to load with,; # and has the right shape.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:43,Availability,checkpoint,checkpoint,43,"""""""Determine the number of channels from a checkpoint path.""""""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:29,Availability,checkpoint,checkpoint,29,"# Loop over variables in the checkpoint.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:12,Modifiability,variab,variables,12,"# Loop over variables in the checkpoint.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:80,Modifiability,variab,variable,80,"# 'layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE' seems to the main; # variable to look at. I'm not sure if this heuristics will always work.; # TODO",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:628,Modifiability,parameteriz,parameterized,628,"""""""Returns `inceptionv3` model with 3 channels; init with `weights=imagenet`. Our `inceptionv3` model (defined in this file as well) allows #channels other; than 3. When the #channels is not 3, we couldn't set `weights=imagenet` to; our backbone tf.keras.applications.InceptionV3 because it will complain the; number of channels is not 3. We created this ""inceptionv3_with_imagenet""; model which has the same architecture, which we can then use our own; ""load_weights_to_model_with_different_channels"" function to initiate an; inceptionv3 model with any numbers of channels. The reason why this function is separate (instead of parameterized in the same; implementation of inceptionv3) is to make it easier to read. Args:; input_shape: a 3-tuple describing the input shape. The 3rd dimension is not; used in this function. We always set that to 3 in this function. Returns:; An InceptionV3-based model with 3 channels and init with `weights=imagenet`.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:340,Availability,down,download,340,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:476,Deployability,configurat,configuration,476,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:460,Modifiability,config,config,460,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:476,Modifiability,config,configuration,476,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:440,Performance,load,loaded,440,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:393,Testability,test,tests,393,"""""""Returns an InceptionV3 architecture. See https://tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3. Args:; input_shape: a 3-tuple describing the input shape.; weights: str. To initial weights from.; init_backbone_with_imagenet: If True, get a model with InceptionV3 that has; `weights='imagenet'` to start with. This will download a model. It should; be set to False in unit tests, or when specific model weights will be; loaded afterwards.; config: a model configuration. Returns:; An InceptionV3-based model.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:155,Performance,load,loading,155,"# If no weights file is specified, initialize with `imagenet`.; # The `init_backbone_with_imagenet` flag should be set to False for unit; # tests to avoid loading the `imagenet` model from online.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:149,Safety,avoid,avoid,149,"# If no weights file is specified, initialize with `imagenet`.; # The `init_backbone_with_imagenet` flag should be set to False for unit; # tests to avoid loading the `imagenet` model from online.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:140,Testability,test,tests,140,"# If no weights file is specified, initialize with `imagenet`.; # The `init_backbone_with_imagenet` flag should be set to False for unit; # tests to avoid loading the `imagenet` model from online.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:144,Performance,load,load,144,"# This step is harder to do directly from `weights`, or even the Checkpoint; # file format. So, create a `input_model` with expected #chanenls, load; # the weights, and then post-process.; # Improve later if possible: find a more readable alternative for this.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:46,Deployability,update,updated,46,"# Leave mean loss as the last metric as it is updated differently.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:17,Availability,checkpoint,checkpoint,17,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:52,Availability,checkpoint,checkpoint,52,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:102,Deployability,configurat,configuration,102,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:85,Modifiability,config,config,85,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:102,Modifiability,config,configuration,102,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:383,Modifiability,variab,variable,383,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:173,Performance,optimiz,optimizer,173,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:323,Performance,optimiz,optimizer,323,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:354,Performance,tune,tune,354,"""""""Initializes a checkpoint manager, and restores a checkpoint if one exists. Args:; config: Training configuration.; model_dir: Where model is stored.; model: a tf Model.; optimizer: A tf Optimizer.; strategy: Distribution strategy. Returns:; The state as `tf.train.Checkpoint`. This includes the `model` (network),; the `optimizer`, metrics (train and tune), and the `global_step` variable.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:23,Performance,optimiz,optimizer,23,"# TODO: Load model and optimizer within this function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:119,Availability,checkpoint,checkpoint,119,"# If init_checkpoint or init_backbone_with_imagenet is specified, then we; # don't want to re-initialie or restore the checkpoint as this will; # overwrite the init_checkpoint weights.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py:17,Availability,checkpoint,checkpoint,17,"# Report current checkpoint state.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:34,Availability,checkpoint,checkpoint,34,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:74,Safety,detect,detect,74,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:51,Testability,test,test,51,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:134,Availability,checkpoint,checkpoint,134,"""""""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:34,Performance,load,load,34,"""""""keras_modeling.inceptionv3 can load weights (even different #channels). Args:; checkpoint_weights_shape: The shape of the weights (checkpoint) file.; input_shape: The shape of the model we're training now.; """"""",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:34,Availability,checkpoint,checkpoint,34,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:74,Safety,detect,detect,74,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:51,Testability,test,test,51,"# Create a model and save it to a checkpoint. Then test whether we can; # detect its number of channels correctly.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:33,Availability,error,errors,33,"# This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py:7,Testability,test,test,7,"# This test should not throw any errors when retrieving the model; # and it's corresponding preprocess function.",MatchSource.CODE_COMMENT,deepvariant/keras_modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/keras_modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py:154,Integrability,message,messages,154,"""""""Control the verbosity of the program. Normally logging at info priority is silent; this; provides flags to adjust that. Note that TF tries to send log messages to stdout,; instead of stderr, if it thinks it is interactive.; There's no flag to override that.; """"""",MatchSource.CODE_COMMENT,deepvariant/logging_level.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py:50,Testability,log,logging,50,"""""""Control the verbosity of the program. Normally logging at info priority is silent; this; provides flags to adjust that. Note that TF tries to send log messages to stdout,; instead of stderr, if it thinks it is interactive.; There's no flag to override that.; """"""",MatchSource.CODE_COMMENT,deepvariant/logging_level.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py:150,Testability,log,log,150,"""""""Control the verbosity of the program. Normally logging at info priority is silent; this; provides flags to adjust that. Note that TF tries to send log messages to stdout,; instead of stderr, if it thinks it is interactive.; There's no flag to override that.; """"""",MatchSource.CODE_COMMENT,deepvariant/logging_level.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/logging_level.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples.py:49,Availability,down,downsampling,49,"# Sentinel command line flag value indicating no downsampling should occur.",MatchSource.CODE_COMMENT,deepvariant/make_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:57,Availability,avail,available,57,"# Maximum length of partition in bases. It is limited by available memory.; # TODO: For better flexibility it may be benefitial to expose it as a; # flag.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:131,Security,expose,expose,131,"# Maximum length of partition in bases. It is limited by available memory.; # TODO: For better flexibility it may be benefitial to expose it as a; # flag.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:320,Integrability,protocol,protocol-buffers,320,"""""""Parses a command line flag string value into a protobuf Enum value. Args:; proto_enum_pb2: a enum_type_wrapper.EnumTypeWrapper type containing a proto; enum definition. For example, this would be; deepvariant_pb2.MakeExamplesOptions.Mode to get the MakeExamplesOptions; Mode enum. See:; https://developers.google.com/protocol-buffers/docs/reference/python-generated#enum; for more information.; flag_value: str. The name of the proto enum option from the command line we; want to convert into the enum value.; skip_unspecified_option: bool. If True, any enum options that include the; string 'unspecified' (in any case) will be excluded from the list of; allowed options in the ValueError raised if flag_value isn't valid. Returns:; The enum value for flag_value in proto_enum_pb2. Raises:; ValueError: if flag_value isn't a valid enum name in proto_enum_pb2.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:39,Testability,log,log,39,"""""""If options contain multiple shards, log with task/shard prefix.""""""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:1694,Testability,log,logic,1694,"""""""Determines the regions to process and partitions them into pieces. This function divides the genomes into regions we should process by; intersecting the Ranges spanning all of the contigs with those from; calling_regions, if provided. These intersected regions are then partitioned; into pieces no bigger than partition_size bp in length. By construction we ensure that the regions are in genomic order, first w.r.t.; the contigs and then within each contig by start and end of each region. This function can further subdivide these regions into a subset appropriate; for a single task (task_id) among N tasks (num_shards) to process. The; function ensures that:. set(all_regions) = union(regions(task_0), ..., regions(task_n)). when called with task_ids 0 ... N for num_shards = N. Args:; contigs: Sequence of ContigInfo protos. Used to determine the initial ranges; to process (i.e., all bases of these contigs) and the order of returned; ranges.; partition_size: The maximum size to make any region when partitioning.; calling_regions: None or RangeSet. If provided, we will intersect the; regions to process so that only those that overlap a region in this set; are included.; task_id: int >= 0 or None. The task_id of this job, which will be used to; subdivide the total set of regions to process into just those that should; be processed by this job. Must be < num_shards.; num_shards: int >= 0 or None. The number of shards (i.e., the total number; of tasks) we are running in parallel. Together with task_id determines the; subset of regions we want to process.; candidates: numpy array of int32 containing candidate positions. If; candidate is provided then partition_by_candidates logic is used. Returns:; An iterable of nucleus.genomics.v1.Range objects. Raises:; ValueError: if task_id and num_shards are bad or inconsistent.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:739,Availability,error,error,739,"""""""Yields the candidate variants whose type is one of select_variant_types. This function iterates through candidates and yield each candidate in order; if it satisfies any of the type constraints implied by select_variant_types.; For example, if select_variant_types = ['snps'] this function will yield; candidates that are bi-allelic SNPs only. Multiple select types are treated; as OR'd together, so ['snps', 'indels'] yields candidates that are bi-allelic; SNPs or indels. Args:; candidates: Iterable of Variant protos. The candidates we want to select; from.; select_variant_types: List of str. The names of the variant type selectors; we want to use to keep/remove variants. Each string must be part of; VARIANT_TYPE_SELECTORS or an error will be raised. Raises:; ValueError: if any str in select_variant_types isn't present in; VARIANT_TYPE_SELECTORS. Yields:; Candidates in order.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:46,Usability,simpl,simpler,46,"# If `max_bases_to_cover` is not set, use the simpler; # reservoir_sample implementation.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:252,Availability,down,downsample,252,"""""""Creates a list of SamReaders, one from each filename. Args:; reads_filenames: A list of string read filenames (e.g. for BAM/CRAM; files). The list may contain empty strings or None, which will be; skipped.; downsample_fraction: Fraction by which to downsample. This applies to each; file in reads_filenames separately. Returns:; A list of sam readers with handles to the files. This may be shorter than; the input reads_filenames if any of the filenames were empty.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:36,Deployability,update,updated,36,"# Initialize labels and types to be updated in the for loop below.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:53,Modifiability,variab,variable,53,"# When candidate partitioning is used region size is variable. Therefore; # we need to calculate the padding for each region.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:292,Availability,error,error,292,"""""""Gets reads overlapping the region. Args:; region: A nucleus.genomics.v1.Range object specifying the region we want; to query reads.; sam_readers: An iterable of sam.SamReader to query from.; reads_filenames: Filenames matching sam_readers. This is only used for; throwing more informative error messages. Returns:; [genomics.deepvariant.core.genomics.Read], reads overlapping the region.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:298,Integrability,message,messages,298,"""""""Gets reads overlapping the region. Args:; region: A nucleus.genomics.v1.Range object specifying the region we want; to query reads.; sam_readers: An iterable of sam.SamReader to query from.; reads_filenames: Filenames matching sam_readers. This is only used for; throwing more informative error messages. Returns:; [genomics.deepvariant.core.genomics.Read], reads overlapping the region.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:70,Modifiability,extend,extend,70,"# TODO: This logic currently only works for single sample.; # Once we extend to multi-sample, we can remove this assert.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:13,Testability,log,logic,13,"# TODO: This logic currently only works for single sample.; # Once we extend to multi-sample, we can remove this assert.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:113,Testability,assert,assert,113,"# TODO: This logic currently only works for single sample.; # Once we extend to multi-sample, we can remove this assert.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:45,Safety,safe,safely,45,"# If we are generating gVCF output we cannot safely abort early here as; # we need to return the gVCF records calculated by the caller below.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:52,Safety,abort,abort,52,"# If we are generating gVCF output we cannot safely abort early here as; # we need to return the gVCF records calculated by the caller below.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:7,Testability,log,logic,7,"# This logic below will write out the DOT files under the directory; # specified by the flag --realigner_diagnostics, if phase_reads is; # set to True.; # TODO: Extend the logic to work for multi-sample cases.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:172,Testability,log,logic,172,"# This logic below will write out the DOT files under the directory; # specified by the flag --realigner_diagnostics, if phase_reads is; # set to True.; # TODO: Extend the logic to work for multi-sample cases.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:22,Modifiability,extend,extend,22,"# Long haplotypes can extend past the window, so enforce the width here.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:951,Deployability,continuous,continuous,951,"""""""Merges input arrays containing sorted candidate positions. positions_array contains all candidate positions for each shart. make_examples; generates candidate positions in a round robin pattern. So, in order to merge; all candidate positions from all shards we take candidate positions from the; first shard, first partition, then second shard first partition and so on.; Partitions within a shard are separated by END_OF_PARTITION special number.; <Shard_1 candidates, partition_1>, <Shard_2 candidates, partition_1>, ...; <Shard_N candidates, partition_1>,; <Shard_1 candidates, partition_2>, <Shard_2 candidates, partition_2> ...; <Shard_N candidates, partition_2>,; ...; <Shard_N candidates, partition_M>, <Shard_2 candidates, partition_M> ...; <Shard_N candidates, partition_M>,. position_arrays is a list of arrays of int32 values. Each list's item contains; candidate positions for one shard. Candidates positions within each shard are; not continuous. See regions_to_process() for details. Args:; position_arrays: list of numpy arrays of int32 containing candidate; positions for each shard. Returns:; List[int] Sorted candidate positions with END_OF_REGION separators.; """"""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:71,Integrability,depend,depend,71,"# Load candidate_positions if the flag is set. Partitioning logic will depend; # on whether candidate_positions is set.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:60,Testability,log,logic,60,"# Load candidate_positions if the flag is set. Partitioning logic will depend; # on whether candidate_positions is set.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:41,Safety,safe,safe,41,"# When using VcfCandidateImporter, it is safe to skip regions without; # candidates as long as gVCF output is not needed. There is a tradeoff; # though because it takes time to read the VCF, which is only worth it if; # there are enough regions.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py:40,Deployability,update,updates,40,"""""""Writes out the example using writer; updates labels and types as needed.""""""",MatchSource.CODE_COMMENT,deepvariant/make_examples_core.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:26,Integrability,inject,inject,26,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:26,Security,inject,inject,26,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:109,Testability,test,test,109,"# We don't really want to inject too much knowledge about the golden right; # here, so we only use a minimal test that (a) the run_info_filename is; # a non-empty string and (b) the number of candidates sites in the labeling; # metrics field is greater than 0. Any reasonable golden output will have at; # least one candidate variant, and the reader should have filled in the; # value.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:16,Safety,detect,detect,16,"# Check that we detect an empty sample name and use default instead.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:51,Availability,error,error,51,"# Fully covered reference contigs don't trigger an error.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:18,Testability,test,tests,18,"# Note that these tests aren't so comprehensive as we are trusting that; # the intersection code logic itself is good and well-tested elsewhere.; # Here we are focusing on some basic tests and handling of missing; # calling_region and confident_region data.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:97,Testability,log,logic,97,"# Note that these tests aren't so comprehensive as we are trusting that; # the intersection code logic itself is good and well-tested elsewhere.; # Here we are focusing on some basic tests and handling of missing; # calling_region and confident_region data.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:127,Testability,test,tested,127,"# Note that these tests aren't so comprehensive as we are trusting that; # the intersection code logic itself is good and well-tested elsewhere.; # Here we are focusing on some basic tests and handling of missing; # calling_region and confident_region data.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:183,Testability,test,tests,183,"# Note that these tests aren't so comprehensive as we are trusting that; # the intersection code logic itself is good and well-tested elsewhere.; # Here we are focusing on some basic tests and handling of missing; # calling_region and confident_region data.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:47,Availability,toler,tolerate,47,"# Chr3 isn't part of our contigs; make sure we tolerate it.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:167,Testability,log,logic,167,"# Check that excluding pieces works. The main checks on taking the; # difference between two RangeSets live in ranges.py so here we are just; # making sure some basic logic works.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:6,Testability,assert,assertEqual,6,"# The assertEqual here is checking the order is exactly what we expect.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:6,Testability,assert,assertEqual,6,"# The assertEqual here is checking the order is exactly what we expect.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:42,Testability,mock,mocks,42,"# Setup our make_allele_counter and other mocks.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:36,Availability,down,downstream,36,"# Setup our make_variant_caller and downstream mocks.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:47,Testability,mock,mocks,47,"# Setup our make_variant_caller and downstream mocks.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:15,Testability,test,tested,15,"# Special case tested below.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:29,Testability,test,test,29,"# Using a real ref_reader to test that the reference allele matches; # between the variant and the reference at the variant's coordinates.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:11,Integrability,interface,interface,11,"# Although interface allows for multiple alt alleles, the test only supports a; # single alt allele. This is done for simplicity. Otherwise we would need to; # prove input_read_attributes/expected_read_attributes for each alt allele; # which will make the source code hard to follow.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:58,Testability,test,test,58,"# Although interface allows for multiple alt alleles, the test only supports a; # single alt allele. This is done for simplicity. Otherwise we would need to; # prove input_read_attributes/expected_read_attributes for each alt allele; # which will make the source code hard to follow.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:118,Usability,simpl,simplicity,118,"# Although interface allows for multiple alt alleles, the test only supports a; # single alt allele. This is done for simplicity. Otherwise we would need to; # prove input_read_attributes/expected_read_attributes for each alt allele; # which will make the source code hard to follow.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:9,Testability,test,test,9,"# Simple test with INS.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:9,Testability,test,test,9,"# Simple test with DEL.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:9,Testability,test,test,9,"# Create test variant.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py:9,Testability,test,test,9,"# Create test reads.",MatchSource.CODE_COMMENT,deepvariant/make_examples_core_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_core_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py:49,Availability,down,downsampling,49,"# Sentinel command line flag value indicating no downsampling should occur.",MatchSource.CODE_COMMENT,deepvariant/make_examples_options.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py:104,Performance,throughput,throughput,104,"# Use a default hts_block_size value of 128 MB (see internal for details) to; # improve SAM/BAM reading throughput, particularly on remote filesystems. Do not; # modify this default parameter without a systematic evaluation of the impact; # across a variety of distributed filesystems!",MatchSource.CODE_COMMENT,deepvariant/make_examples_options.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_options.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_somatic.py:49,Availability,down,downsampling,49,"# Sentinel command line flag value indicating no downsampling should occur.",MatchSource.CODE_COMMENT,deepvariant/make_examples_somatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_somatic.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:27,Testability,test,test,27,"""""""Enum capturing what the test condition we're using.""""""",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:46,Testability,test,test,46,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:200,Testability,test,test,200,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:15,Testability,test,test,15,"# Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:153,Testability,test,test,153,"# Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:254,Testability,test,test,254,"# Because this test is with just one sample, whether; # enable_joint_realignment is True or False doesn't make a difference.; # NOTE: When creating this test, I deliberately change the behavior of; # enable_joint_realignment==False and confirm that this test can fail,; # if the outputs are different when we alter enable_joint_realignment.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:100,Availability,error,errors,100,"# For 'candidate_sweep' mode, it won't create examples, so we just aim; # to run it through without errors.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:46,Testability,test,test,46,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:200,Testability,test,test,200,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:36,Testability,test,test,36,"# Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:52,Testability,test,test,52,"# Now, this is the main part of the test. I want to test the behavior after; # I set max_reads_for_dynamic_bases_per_region.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:6,Testability,test,tests,6,"# All tests are run with fast_pass_aligner enabled. There are no; # golden sets version for ssw realigner.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:16,Testability,test,tests,16,"# The following tests are for CRAM input:",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:16,Testability,test,tests,16,"# The following tests are for multiple BAM inputs:",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:46,Testability,test,test,46,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:200,Testability,test,test,200,"# We need to overwrite bam_fname for USE_CRAM test since Golden Set; # generated from BAM file. BAM filename is stored in candidates. If we; # don't overwrite default_options variants won't match and test fail.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:30,Testability,test,test,30,"# In candidate_sweep mode the test stops here.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:13,Security,integrity,integrity,13,"# Verify the integrity of the examples and then check that they match our; # golden labeled examples. Note we expect the order for both training and; # calling modes to produce deterministic order because we fix the random; # seed.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:20,Testability,assert,assertCountEqual,20,"# Despite the name, assertCountEqual checks that all elements match.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:36,Availability,error,error,36,"# This shows an example of what the error message looks like:; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:42,Integrability,message,message,42,"# This shows an example of what the error message looks like:; # TODO: OpError exception not propagated.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:46,Testability,test,testdata,46,"# Adding the following flags to match how the testdata was created.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:336,Deployability,pipeline,pipeline,336,"# Tests that we call almost all of the real variants (according to NIST's; # Genome in a Bottle callset for NA12878) in our candidate callset.; # Tests that we don't have an enormous number of FP calls. We should have; # no more than 5x (arbitrary) more candidate calls than real calls. If we; # have more it's likely due to some major pipeline problem.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:61,Testability,assert,asserting,61,"# Finds a call in our actual call set for each NIST variant, asserting; # that we found exactly one.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:11,Usability,simpl,simple,11,"# Verifies simple properties of the Variant protos in variants. For example,; # checks that the reference_name() is our expected chromosome. The flag; # is_gvcf determines how we check the VariantCall field of each variant,; # enforcing expectations for gVCF records if true or variant calls if false.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:11,Usability,simpl,simple,11,"# Verifies simple structural properties of the DeepVariantCall objects; # emitted by the VerySensitiveCaller, such as that the AlleleCount and; # Variant both have the same position.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:10,Usability,simpl,simple,10,"# Do some simple structural checks on the tf.Examples in the file.",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py:36,Testability,test,test,36,"# pylint: disable=g-explicit-length-test",MatchSource.CODE_COMMENT,deepvariant/make_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/make_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:136,Performance,load,loading,136,"""""""Provides an abstraction around deep learning models in DeepVariant. This class allows us to encapsulate all of the model management, loading,; saving, and data processing in a single place so those details don't spill over; into the more general deepvariant codebase. The key thing we are aiming for here; is to make sure we can easily play with other model architectures without; modifying the surrounding training and evaluation code.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:39,Usability,learn,learning,39,"""""""Provides an abstraction around deep learning models in DeepVariant. This class allows us to encapsulate all of the model management, loading,; saving, and data processing in a single place so those details don't spill over; into the more general deepvariant codebase. The key thing we are aiming for here; is to make sure we can easily play with other model architectures without; modifying the surrounding training and evaluation code.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:23,Safety,predict,predictions,23,"""""""Binarize labels and predictions. The labels that are equal to target_class parameter are set to 0, else; set to 1. Args:; labels: the ground-truth labels for the examples.; target_class: index of the class that is left as zero. Returns:; Tensor of the same shape as labels.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:224,Safety,predict,predicted,224,"""""""Compute recall from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the recall value.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:227,Safety,predict,predicted,227,"""""""Compute precision from labels and predicted_class for target_class. Examples with label target_class are positives. Other classes are negatives. Args:; labels: the ground-truth labels for the examples.; predicted_class: the predicted labels for the examples.; target_class: index of the class that is left as non-zero. Returns:; Tensor containing the precision value.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:448,Deployability,update,updates,448,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:23,Safety,predict,predictions,23,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:113,Safety,predict,predictions,113,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:170,Safety,predict,predictions,170,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:218,Safety,predict,predicted,218,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:382,Safety,predict,predictions,382,"""""""Compute F1 score of predictions with respect to the labels. Args:; labels: tensor whose dimensions must match predictions. The ground-truth; labels for the examples.; predictions: tensor of arbitrary dimension. The predicted labels for the; examples.; target_class: int. Index of the class that is left as non-zero. Returns:; f1_score: scalar float tensor whose dimensions match predictions. The; calculated f1 score.; update_op: operation that updates the f1 score streaming metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:188,Testability,log,logic,188,"# A set containing the names of the variant types we split our metrics by type; # by. This data structure isn't a dictionary like it's neighbors because; # eval_metric_fn requires special logic to compute the values here associated; # with each of these names.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:338,Performance,perform,performed,338,"""""""Calculate eval metrics from Tensors, on CPU host. Args:; labels: the ground-truth labels for the examples.; predictions: the predicted labels for the examples.; variant_types: variant types (int64 of EncodedVariantType.value) as a tensor; of (batch_size,) or None. The types of these variants. If None, no type; specific evals will be performed. Returns:; A dictionary of string name to metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:111,Safety,predict,predictions,111,"""""""Calculate eval metrics from Tensors, on CPU host. Args:; labels: the ground-truth labels for the examples.; predictions: the predicted labels for the examples.; variant_types: variant types (int64 of EncodedVariantType.value) as a tensor; of (batch_size,) or None. The types of these variants. If None, no type; specific evals will be performed. Returns:; A dictionary of string name to metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:128,Safety,predict,predicted,128,"""""""Calculate eval metrics from Tensors, on CPU host. Args:; labels: the ground-truth labels for the examples.; predictions: the predicted labels for the examples.; variant_types: variant types (int64 of EncodedVariantType.value) as a tensor; of (batch_size,) or None. The types of these variants. If None, no type; specific evals will be performed. Returns:; A dictionary of string name to metric.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:32,Safety,predict,predicted,32,"# Add the metrics stratified by predicted class.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:25,Safety,avoid,avoid,25,"# Special case F1/All to avoid a clash between the two different ways that we; # can compute Precision and Recall (e.g., get_class_precision vs.; # tf.compat.v1.metrics.precision.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:117,Availability,checkpoint,checkpoint,117,"# The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:100,Modifiability,variab,variables,100,"# The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:36,Performance,load,loading,36,"# The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:131,Performance,load,loaded,131,"# The following two classes support loading exponential moving averages into; # their corresponding variables when a checkpoint is loaded. They're called; # as hooks by the Estimators. Note for future work: this is the documented; # way, but someone on the mailing list suggested that using the scaffold_fn; # mechanism might be better.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:82,Availability,checkpoint,checkpoint,82,"""""""Hook to load EMA into their corresponding variables. This looks for the latest checkpoint in the model dir.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:45,Modifiability,variab,variables,45,"""""""Hook to load EMA into their corresponding variables. This looks for the latest checkpoint in the model dir.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:11,Performance,load,load,11,"""""""Hook to load EMA into their corresponding variables. This looks for the latest checkpoint in the model dir.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:81,Availability,checkpoint,checkpoint,81,"""""""Hook to load EMA into their corresponding variables. This reads the specified checkpoint.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:45,Modifiability,variab,variables,45,"""""""Hook to load EMA into their corresponding variables. This reads the specified checkpoint.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:11,Performance,load,load,11,"""""""Hook to load EMA into their corresponding variables. This reads the specified checkpoint.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:604,Availability,checkpoint,checkpoint,604,"""""""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. The name of this model, such as `inception_v3`.; pretrained_model_path: str. Path to a root checkpoint where we can start; training the model, if we are not starting from scratch.; supported_dimensions_message: str. A human-readable string containing info; about what image dimensions are supported by this model. E.g., ""only; widths between 42 and 189"".; use_tpu: bool or None. If True, we are executing the model on a TPU, False; if we are using some other hardware. If None, the execution hardware is; not yet known.; model_dir: str or None. The path to the location where model checkpoint are; being stored. If None, the path hasn't been set yet or is unknown.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1094,Availability,checkpoint,checkpoint,1094,"""""""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. The name of this model, such as `inception_v3`.; pretrained_model_path: str. Path to a root checkpoint where we can start; training the model, if we are not starting from scratch.; supported_dimensions_message: str. A human-readable string containing info; about what image dimensions are supported by this model. E.g., ""only; widths between 42 and 189"".; use_tpu: bool or None. If True, we are executing the model on a TPU, False; if we are using some other hardware. If None, the execution hardware is; not yet known.; model_dir: str or None. The path to the location where model checkpoint are; being stored. If None, the path hasn't been set yet or is unknown.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:469,Performance,load,load,469,"""""""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. The name of this model, such as `inception_v3`.; pretrained_model_path: str. Path to a root checkpoint where we can start; training the model, if we are not starting from scratch.; supported_dimensions_message: str. A human-readable string containing info; about what image dimensions are supported by this model. E.g., ""only; widths between 42 and 189"".; use_tpu: bool or None. If True, we are executing the model on a TPU, False; if we are using some other hardware. If None, the execution hardware is; not yet known.; model_dir: str or None. The path to the location where model checkpoint are; being stored. If None, the path hasn't been set yet or is unknown.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:312,Testability,test,test,312,"""""""Base class for models that compute genotype likelihoods from an image. This class is intended for use anywhere in DeepVariant where we want to train; or evaluate a model that computes genotype likelihoods from a pileup image. A; bit of encapsulation helps us to try new models (beyond inception_v3) and unit; test our code. The base class cannot be used directly; concrete subclasses actually implement; specific models and all of the associated machinery to create/load/save; models. Attributes:; name: str. The name of this model, such as `inception_v3`.; pretrained_model_path: str. Path to a root checkpoint where we can start; training the model, if we are not starting from scratch.; supported_dimensions_message: str. A human-readable string containing info; about what image dimensions are supported by this model. E.g., ""only; widths between 42 and 189"".; use_tpu: bool or None. If True, we are executing the model on a TPU, False; if we are using some other hardware. If None, the execution hardware is; not yet known.; model_dir: str or None. The path to the location where model checkpoint are; being stored. If None, the path hasn't been set yet or is unknown.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:28,Testability,log,log,28,"""""""Construct a host call to log scalars when training on TPU. Args:; metric_dict: A dict of the tensors to be logged.; model_dir: The location to write the summary.; prefix: The prefix (if any) to prepend to the metric names.; record_frequency_in_steps: int; How often should we log our metrics in; step units. Returns:; A tuple of (function, args_to_be_passed_to_said_function); """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:110,Testability,log,logged,110,"""""""Construct a host call to log scalars when training on TPU. Args:; metric_dict: A dict of the tensors to be logged.; model_dir: The location to write the summary.; prefix: The prefix (if any) to prepend to the metric names.; record_frequency_in_steps: int; How often should we log our metrics in; step units. Returns:; A tuple of (function, args_to_be_passed_to_said_function); """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:279,Testability,log,log,279,"""""""Construct a host call to log scalars when training on TPU. Args:; metric_dict: A dict of the tensors to be logged.; model_dir: The location to write the summary.; prefix: The prefix (if any) to prepend to the metric names.; record_frequency_in_steps: int; How often should we log our metrics in; step units. Returns:; A tuple of (function, args_to_be_passed_to_said_function); """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:601,Testability,log,log,601,"""""""Training host call. Creates scalar summaries for training metrics. This function is executed on the CPU and should not directly reference; any Tensors in the rest of the `model_fn`. To pass Tensors from the; model to the `metric_fn`, provide as part of the `host_call`. See; https://www.tensorflow.org/api_docs/python/tf/compat/v1/estimator/tpu/TPUEstimator; for more information.; Arguments should match the list of `Tensor` objects passed as the second; element in the tuple passed to `host_call`.; Args:; global_step: Tensor with shape `[batch]` for the global_step; *args: Remaining tensors to log. Returns:; List of summary ops to run on the CPU host.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:5,Testability,log,log,5,"# To log the current learning rate, and gradient norm for Tensorboard, the; # summary op needs to be run on the host CPU via host_call. host_call; # expects [batch_size, ...] Tensors, thus reshape to introduce a batch; # dimension. These Tensors are implicitly concatenated to; # [params['batch_size']].",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:21,Usability,learn,learning,21,"# To log the current learning rate, and gradient norm for Tensorboard, the; # summary op needs to be run on the host CPU via host_call. host_call; # expects [batch_size, ...] Tensors, thus reshape to introduce a batch; # dimension. These Tensors are implicitly concatenated to; # [params['batch_size']].",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:214,Availability,checkpoint,checkpoints,214,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:807,Availability,checkpoint,checkpoints,807,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1348,Availability,checkpoint,checkpoint,1348,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1642,Integrability,interface,interface,1642,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1362,Performance,load,loaded,1362,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:63,Safety,predict,prediction,63,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:166,Safety,predict,predict,166,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1560,Testability,log,logits,1560,"""""""Returns a new tf.estimator.Estimator object for training or prediction. The estimator needs to know batch_size. We use the same value for all; of eval, train, and predict. The estimator will automatically save; checkpoints to model_dir and keep the specified number of them. The value; of iterations_per_loop is not critical, and we default to the recommended; value. Some optional arguments are only required for use with TPU. This function will use self.model_fn and self.use_tpu when constructing the; model specific Estimator object. Estimators are also sometimes called classifiers. Args:; batch_size: the batch size to use (for TRAIN, EVAL, and PREDICT modes).; model_dir: an (optional) string directory to use as the model directory.; max_checkpoints_to_keep: an (optional) integer count of saved checkpoints.; iterations_per_loop: an (optional) integer count of log_step_count_steps.; params: an (optional) dictionary of parameters to pass to the Estimator; constructor.; unused_device_fn: a device_fn to pass to RunConfig, if not use_tpu.; master: a string necessary for TPU, pass FLAGS.master through.; use_tpu: boolean. set self.use_tpu if not None.; start_from_checkpoint: string. If not None, initialize model from this; path. According to the current implementation of Estimator, this will; only be used in training. The inference checkpoint is loaded in a; different place.; session_config: a tf.ConfigProto to pass to RunConfig, if not use_tpu.; include_debug_info: from call_variants. If True, PREDICT mode will include; extra info such as logits and prelogits. Returns:; an object implementing the tf.estimator.Estimator interface (will be a; TPUEstimator if self.use_tpu is True).; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:19,Integrability,interface,interface,19,"# The TPUEstimator interface implicitly adds batch_size to the params; # dict. Do so explicitly here, so that we can use the same model_fn.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:284,Integrability,depend,depending,284,"""""""A model_fn satisfying the Estimator API. Args:; features: a dictionary supplying features.; labels: a tensor of labels.; mode: one of tf.estimator.ModeKeys.{EVAL,TRAIN}; params: a dictionary of parameters. Returns:; a tf.estimator.EstimatorSpec or tpu_estimator.TPUEstimatorSpec,; depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:110,Modifiability,variab,variables,110,"""""""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated and invoked by; eval_hooks = [; h(model_dir) for h in model.session_eval_hooks(); ]; estimator.evaluate(hooks=...). Note that this is done according to the instructions in; cloud_tpu/models/inception/inception_v3.py. A newer idea is in; tpuestimator-scaffold, but we haven't tried that approach.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:97,Performance,load,load,97,"""""""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated and invoked by; eval_hooks = [; h(model_dir) for h in model.session_eval_hooks(); ]; estimator.evaluate(hooks=...). Note that this is done according to the instructions in; cloud_tpu/models/inception/inception_v3.py. A newer idea is in; tpuestimator-scaffold, but we haven't tried that approach.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:110,Modifiability,variab,variables,110,"""""""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated and invoked by; predict_hooks = [; h(checkpoint_path) for h in model.session_predict_hooks(); ]; estimator.predict(hooks=...). Note that this is done according to the instructions in; cloud_tpu/models/inception/inception_v3.py. A newer idea is in; tpuestimator-scaffold, but we haven't tried that approach.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:97,Performance,load,load,97,"""""""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated and invoked by; predict_hooks = [; h(checkpoint_path) for h in model.session_predict_hooks(); ]; estimator.predict(hooks=...). Note that this is done according to the instructions in; cloud_tpu/models/inception/inception_v3.py. A newer idea is in; tpuestimator-scaffold, but we haven't tried that approach.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:255,Safety,predict,predict,255,"""""""Returns a list of tf.train.SessionRunHook classes. A typical use case is to provide a hook to load the EMA variables. These will be instantiated and invoked by; predict_hooks = [; h(checkpoint_path) for h in model.session_predict_hooks(); ]; estimator.predict(hooks=...). Note that this is done according to the instructions in; cloud_tpu/models/inception/inception_v3.py. A newer idea is in; tpuestimator-scaffold, but we haven't tried that approach.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:144,Safety,predict,prediction,144,"""""""Creates a new model. Args:; images: A 4-D tensor of (batch_size, height, width, channels) of pileup; images.; num_classes: integer. How many prediction classes are we expecting in; model?; is_training: boolean. Should we setup model for training (True) or for; inference (False). Returns:; A dictionary, containing string keys mapped to endpoint tensors of this; model. The dictionary must contain a key 'Predictions' that contains the; probability of having each of 'num_classes' classes.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:189,Availability,checkpoint,checkpoint,189,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:206,Availability,checkpoint,checkpoint,206,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:641,Availability,checkpoint,checkpoint,641,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:26,Modifiability,variab,variables,26,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:247,Modifiability,variab,variables,247,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:323,Modifiability,variab,variables,323,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:405,Modifiability,variab,variables,405,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:534,Modifiability,variab,variables,534,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:622,Modifiability,variab,variables,622,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:693,Modifiability,variab,variables,693,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:824,Modifiability,variab,variables,824,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:882,Modifiability,variab,variables,882,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1045,Modifiability,variab,variables,1045,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1129,Modifiability,variab,variables,1129,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1236,Modifiability,variab,variables,1236,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1384,Modifiability,variab,variables,1384,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:1655,Modifiability,variab,variables,1655,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:499,Performance,optimiz,optimizer,499,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:657,Performance,load,loaded,657,"""""""Gets the list of model variables that should be restored. The primary use of this function is to get a subset of tf.Variables from a; slim-defined model that we'd like to restore from a checkpoint. The; checkpoint generally contains all of the variables in the graph during; training, including things like the backprop variables, moving averages for; visualization, etc. Simply restoring all of those variables is brittle, as; we often want to start a new training run, maybe using a different; optimizer, different visualization variables, or replacing part of the model; with a new classification layer, as unneeded variables from the checkpoint; get loaded into the graph and/or new TF variables not present in the graph; cannot be found, raising exceptions. This function allows a clean API to get; just the *model* variables from a graph, excluding all of those non-model; variables, along with optionally removing parts of the model graph via; exclude scopes. This function calls slim.get_model_variables() to get the raw list of all; variables associated with the MODEL_VARIABLES collection. It then filters; away all variables that match any of the scopes in exclude_scopes. For; example, suppose we have a model with three variables with names:. w1 = model/l1/weight1; w2 = model/l2/weight2; w3 = model/l2/weight3. Without any exclude scopes, we would return these three variables [w1, w2,; and w3]. Providing exclude_scopes=['model/l2'] would return only [w1], while; exclude_scopes=['model/l1'] would return [w2, w3]. Args:; exclude_scopes: None, or a list of strings. Each string is a scope; specification, such as ""model/l1"" to match all variables whose name; starts with ""model/l1"". Returns:; A list of tf.Variable objects.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:26,Modifiability,variab,variables,26,"# We aren't excluding any variables, so just return vars_to_include.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:511,Availability,checkpoint,checkpoint,511,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:680,Availability,checkpoint,checkpoint,680,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:186,Modifiability,variab,variable,186,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:531,Performance,load,loading,531,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:700,Performance,load,loading,700,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:525,Safety,avoid,avoid,525,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:694,Safety,avoid,avoid,694,"""""""Creates an DeepVariant CNN network based on a tf.slim model. Args:; name: see baseclass.; pretrained_model_path: see baseclass.; n_classes_model_variable: str. A fully-qualitified TF variable name in the; model that we can use to determine the shape of the output; classification layer of the model. For example, in inception-v3 from; slim this is 'InceptionV3/Logits/Conv2d_1c_1x1/weights'.; excluded_scopes_for_incompatible_classes: set of str. A set of scopes that; will be excluded when restoring from a checkpoint to avoid loading; incompatible #classes.; excluded_scopes_for_incompatible_channels: set of str. A set of scopes; that will be excluded when restoring from a checkpoint to avoid loading; incompatible #channels. Raises:; ValueError: If any of the arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:137,Energy Efficiency,efficient,efficiently,137,"""""""Applies preprocessing operations for Inception images. Because this will run in model_fn, on the accelerator, we use operations; that efficiently execute there. Args:; images: An Tensor of shape [batch_size height, width, channel] with uint8; values. Returns:; A tensor of images of shape [batch_size height, width, channel]; containing floating point values, with all points rescaled between; -1 and 1 and possibly resized.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:289,Integrability,depend,depending,289,"""""""A model_fn for slim (really inception_v3), satisfying the Estimator API. Args:; features: a single Tensor or dict of same (from input_fn).; labels: a single Tensor or dict of same (from input_fn).; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:642,Integrability,depend,depending,642,"""""""Make EstimatorSpec for the current model. Args:; features: a single Tensor or dict of same (from input_fn).; endpoints: a dictionary, containing string keys mapped to endpoint; tensors of this model. The dictionary must contain a key 'Predictions'; that contains the probability of having each of 'num_classes' classes.; labels: a single Tensor or dict of same (from input_fn).; logits: a single Tensor with logits; predictions: A dictionaty that must contain the following keys: 'Logits'; and 'Predictions'.; total_loss: a single Tensor with a loss; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:419,Safety,predict,predictions,419,"""""""Make EstimatorSpec for the current model. Args:; features: a single Tensor or dict of same (from input_fn).; endpoints: a dictionary, containing string keys mapped to endpoint; tensors of this model. The dictionary must contain a key 'Predictions'; that contains the probability of having each of 'num_classes' classes.; labels: a single Tensor or dict of same (from input_fn).; logits: a single Tensor with logits; predictions: A dictionaty that must contain the following keys: 'Logits'; and 'Predictions'.; total_loss: a single Tensor with a loss; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:382,Testability,log,logits,382,"""""""Make EstimatorSpec for the current model. Args:; features: a single Tensor or dict of same (from input_fn).; endpoints: a dictionary, containing string keys mapped to endpoint; tensors of this model. The dictionary must contain a key 'Predictions'; that contains the probability of having each of 'num_classes' classes.; labels: a single Tensor or dict of same (from input_fn).; logits: a single Tensor with logits; predictions: A dictionaty that must contain the following keys: 'Logits'; and 'Predictions'.; total_loss: a single Tensor with a loss; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:411,Testability,log,logits,411,"""""""Make EstimatorSpec for the current model. Args:; features: a single Tensor or dict of same (from input_fn).; endpoints: a dictionary, containing string keys mapped to endpoint; tensors of this model. The dictionary must contain a key 'Predictions'; that contains the probability of having each of 'num_classes' classes.; labels: a single Tensor or dict of same (from input_fn).; logits: a single Tensor with logits; predictions: A dictionaty that must contain the following keys: 'Logits'; and 'Predictions'.; total_loss: a single Tensor with a loss; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:97,Integrability,depend,depending,97,"# Note, below, one of train_op or eval_metrics will be None, and the other; # will be populated, depending on mode.; # There are a lot of arguments here; that's to avoid referencing flags in; # leaf functions.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:164,Safety,avoid,avoid,164,"# Note, below, one of train_op or eval_metrics will be None, and the other; # will be populated, depending on mode.; # There are a lot of arguments here; that's to avoid referencing flags in; # leaf functions.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:19,Availability,robust,robust,19,"# get() here to be robust when we are in eval mode and batches_per_epoch; # hasn't been provided. In eval mode, model_fn_train will return without; # doing anything.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:32,Availability,down,downstream,32,"# We don't actually use classes downstream right now.; # 'classes': tf.argmax(input=logits, axis=1, output_type=tf.int32),",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:84,Testability,log,logits,84,"# We don't actually use classes downstream right now.; # 'classes': tf.argmax(input=logits, axis=1, output_type=tf.int32),",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:16,Usability,learn,learning,16,"# Configure the learning rate using an exponetial decay.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:249,Energy Efficiency,schedul,schedules,249,"# Set a minimum boundary for the learning rate to be a fixed value of 1e-9.; # It's common to see these tf.max(...) operations when training inception,; # with a max of 1e-4 * initial_learning_rate but this makes it hard to; # explore learning rate schedules that decay quickly or by a lot of each; # step. Here we just use a very small constant 1e-9 as the minimum value.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:33,Usability,learn,learning,33,"# Set a minimum boundary for the learning rate to be a fixed value of 1e-9.; # It's common to see these tf.max(...) operations when training inception,; # with a max of 1e-4 * initial_learning_rate but this makes it hard to; # explore learning rate schedules that decay quickly or by a lot of each; # step. Here we just use a very small constant 1e-9 as the minimum value.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:235,Usability,learn,learning,235,"# Set a minimum boundary for the learning rate to be a fixed value of 1e-9.; # It's common to see these tf.max(...) operations when training inception,; # with a max of 1e-4 * initial_learning_rate but this makes it hard to; # explore learning rate schedules that decay quickly or by a lot of each; # step. Here we just use a very small constant 1e-9 as the minimum value.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:43,Usability,learn,learning,43,"# Compute the current epoch and associated learning rate from global_step.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:309,Safety,predict,prediction,309,"""""""Creates a new inception_v3_embedding model. Args:; inputs: A tuple of two elements (images, sequencing_types). images is a; 4-D tensor of (batch_size, height, width, channels) of pileup images.; sequencing_types is a 1-D tensor of (batch_size) of example sequencing; types.; num_classes: integer. How many prediction classes are we expecting in; model?; is_training: boolean. Should we setup model for training (True) or for; inference (False). Returns:; A dictionary, containing string keys mapped to endpoint tensors of this; model.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:267,Integrability,depend,depending,267,"""""""A model_fn for slim, satisfying the Estimator API. Args:; features: a single Tensor or dict of same (from input_fn).; labels: a single Tensor or dict of same (from input_fn).; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu. Raises:; ValueError: if FLAGS.seq_type_embedding_size is not positive.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:56,Testability,test,testing,56,"""""""BaseClass for placeholder models that are useful for testing and benchmarking.""""""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:68,Testability,benchmark,benchmarking,68,"""""""BaseClass for placeholder models that are useful for testing and benchmarking.""""""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:103,Deployability,pipeline,pipeline,103,"# Note these calculations aren't necessary, but they are included here to; # mimic the data processing pipeline used by inception. We may consider; # removing them in a future CL, or making them optional, to reduce CPU cost; # of this model.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:208,Energy Efficiency,reduce,reduce,208,"# Note these calculations aren't necessary, but they are included here to; # mimic the data processing pipeline used by inception. We may consider; # removing them in a future CL, or making them optional, to reduce CPU cost; # of this model.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:36,Safety,predict,predictions,36,"""""""Creates a constant model. Args:; predictions: list[float]. Values to return for Predictions, which should; be a floatting point value between 0 and 1 for each class, normalized so; the sum of the values is 1. Predictions should have dimension; [num_classes]. Raises:; ValueError: if sum(predictions) is not close to 1.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:290,Safety,predict,predictions,290,"""""""Creates a constant model. Args:; predictions: list[float]. Values to return for Predictions, which should; be a floatting point value between 0 and 1 for each class, normalized so; the sum of the values is 1. Predictions should have dimension; [num_classes]. Raises:; ValueError: if sum(predictions) is not close to 1.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:39,Testability,test,testing,39,"# For the constant model, which is for testing only, we just set the; # variant_types to 0s. This is needed because it doesn't work to fetch; # 'variant_type' from either features or endpoints here. Annoying.; # variant_types = features['variant_type'] # Fails.; # variant_types = endpoints['variant_type'] # Fails.",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:70,Modifiability,layers,layers,70,"""""""A smaller of version of the DeepVariant model. Uses only the first layers of Inception net.; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:289,Integrability,depend,depending,289,"""""""A model_fn for slim (really inception_v3), satisfying the Estimator API. Args:; features: a single Tensor or dict of same (from input_fn).; labels: a single Tensor or dict of same (from input_fn).; mode: tf.estimator.ModeKeys.; params: dict. Returns:; EstimatorSpec or TPUEstimatorSpec depending on self.use_tpu. Raises:; ValueError: If representation_layer was not found in the Inception; architecture; """"""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py:37,Testability,test,test,37,"""""""Gets a list of the models that we test extensively.""""""",MatchSource.CODE_COMMENT,deepvariant/modeling.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:13,Usability,learn,learning,13,"""""""Tests for learning.genomics.deepvariant.modeling.""""""",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:19,Modifiability,variab,variable,19,"# Create two model variable and one regular variables.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:44,Modifiability,variab,variables,44,"# Create two model variable and one regular variables.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:11,Modifiability,variab,variables,11,"# The only variables in the system are the three we've created.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:30,Modifiability,variab,variables,30,"# We get just the three model variables without any excludes.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:21,Modifiability,variab,variables,21,"# Excluding model/l1 variables gives us w2 and w3.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:50,Modifiability,variab,variables,50,"# Excluding the root model scope also produces no variables..",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:100,Testability,test,tests,100,"# Hide the baseclass inside an enclosing scope so that unittest doesn't try to; # run our baseclass tests directly. http://stackoverflow.com/a/1323554.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:397,Testability,assert,assertEqual,397,"# The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where it goes in the image (and the; # calculation is complex. So we are simply checking here that all; # values are zero except for the transformed values we see in values.; # We are relying here on the tf operations to be correct and to not; # change their behavior over time. Because we are doing assertEqual; # we are also testing the order of the values, which means that we; # are sure that the pixels have been translated in the right order in; # the image, wherever the actual translation might be.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:424,Testability,test,testing,424,"# The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where it goes in the image (and the; # calculation is complex. So we are simply checking here that all; # values are zero except for the transformed values we see in values.; # We are relying here on the tf operations to be correct and to not; # change their behavior over time. Because we are doing assertEqual; # we are also testing the order of the values, which means that we; # are sure that the pixels have been translated in the right order in; # the image, wherever the actual translation might be.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:170,Usability,simpl,simply,170,"# The preprocess step resizes the image to h x w as needed by; # inception. We don't really care where it goes in the image (and the; # calculation is complex. So we are simply checking here that all; # values are zero except for the transformed values we see in values.; # We are relying here on the tf operations to be correct and to not; # change their behavior over time. Because we are doing assertEqual; # we are also testing the order of the values, which means that we; # are sure that the pixels have been translated in the right order in; # the image, wherever the actual translation might be.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py:12,Testability,test,test,12,"# Note this test is only applied to inception_v3.",MatchSource.CODE_COMMENT,deepvariant/modeling_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/modeling_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:913,Safety,predict,predict,913,"""""""High-level API for creating images of pileups of reads and reference bases. This class provides a higher-level and more natural API for constructing; images at a candidate variant call site. Given a DeepVariantCall, which; contains the candidate variant call along with key supplementary information,; this class provides create_pileup_images() that will do all of the necessary; fetching of reads and reference bases from readers and pass those off to the; lower-level PileupImageEncoder to construct the image Tensor. for dv_call in candidates:; allele_and_images = pic.create_pileup_images(dv_call); ... A quick note on how we deal with multiple alt alleles:. Suppose variant has ref and two alt alleles. Assuming the sample is diploid,; we have the following six possible genotypes:. ref/ref => 0/0; ref/alt1 => 0/1; alt1/alt1 => 1/1; ref/alt2 => 0/2; alt1/alt2 => 1/2; alt2/alt2 => 2/2. In DeepVariant we predict the genotype count (0, 1, 2) for a specific set of; alternate alleles. If we only had a single alt, we'd construct an image for; ref vs. alt1:. image1 => ref vs. alt1 => determine if we are 0/0, 0/1, 1/1. If we add a second image for alt2, we get:. image2 => ref vs. alt2 => determine if we are 0/0, 0/2, 2/2. but the problem here is that we don't have a good estimate for the het-alt; state 1/2. So we construct a third image contrasting ref vs. either alt1 or; alt2:. image3 => ref vs. alt1 or alt2 => determines 0/0, 0/{1,2}, {1,2}/{1,2}. Given the predictions for each image:. image1 => p00, p01, p11; image2 => p00, p02, p22; image3 => p00, p0x, pxx where x is {1,2}. we calculate our six genotype likelihoods as:. 0/0 => p00 [from any image]; 0/1 => p01 [image1]; 1/1 => p11 [image1]; 0/2 => p02 [image2]; 2/2 => p22 [image2]; 1/2 => pxx [image3]. The function create_pileup_images() returns all of the necessary images, along; with the alt alleles used for each image.; """"""",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:1473,Safety,predict,predictions,1473,"""""""High-level API for creating images of pileups of reads and reference bases. This class provides a higher-level and more natural API for constructing; images at a candidate variant call site. Given a DeepVariantCall, which; contains the candidate variant call along with key supplementary information,; this class provides create_pileup_images() that will do all of the necessary; fetching of reads and reference bases from readers and pass those off to the; lower-level PileupImageEncoder to construct the image Tensor. for dv_call in candidates:; allele_and_images = pic.create_pileup_images(dv_call); ... A quick note on how we deal with multiple alt alleles:. Suppose variant has ref and two alt alleles. Assuming the sample is diploid,; we have the following six possible genotypes:. ref/ref => 0/0; ref/alt1 => 0/1; alt1/alt1 => 1/1; ref/alt2 => 0/2; alt1/alt2 => 1/2; alt2/alt2 => 2/2. In DeepVariant we predict the genotype count (0, 1, 2) for a specific set of; alternate alleles. If we only had a single alt, we'd construct an image for; ref vs. alt1:. image1 => ref vs. alt1 => determine if we are 0/0, 0/1, 1/1. If we add a second image for alt2, we get:. image2 => ref vs. alt2 => determine if we are 0/0, 0/2, 2/2. but the problem here is that we don't have a good estimate for the het-alt; state 1/2. So we construct a third image contrasting ref vs. either alt1 or; alt2:. image3 => ref vs. alt1 or alt2 => determines 0/0, 0/{1,2}, {1,2}/{1,2}. Given the predictions for each image:. image1 => p00, p01, p11; image2 => p00, p02, p22; image3 => p00, p0x, pxx where x is {1,2}. we calculate our six genotype likelihoods as:. 0/0 => p00 [from any image]; 0/1 => p01 [image1]; 1/1 => p11 [image1]; 0/2 => p02 [image2]; 2/2 => p22 [image2]; 1/2 => pxx [image3]. The function create_pileup_images() returns all of the necessary images, along; with the alt alleles used for each image.; """"""",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:470,Availability,down,downstream,470,"""""""Yields the set of all alt_alleles for variant. This function computes the sets of alt_alleles we want to use to cover all; genotype likelihood calculations we need for n alt alleles (see class docs; for background). The easiest way to do this is to calculate all combinations; of 2 alleles from ref + alts and then strip away the reference alleles,; leaving us with the set of alts for the pileup image encoder. The sets are; converted to sorted lists at the end for downstream consistency. Args:; variant: third_party.nucleus.protos.Variant to generate the alt allele; combinations for. Yields:; A series of lists containing the alt alleles we want to use for a single; pileup image. The entire series covers all combinations of alt alleles; needed for variant. Raises:; ValueError: if options.multi_allelic_mode is UNSPECIFIED.; """"""",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:56,Usability,learn,learning,56,"""""""Creates a pileup tensor for dv_call. Args:; dv_call: learning.genomics.deepvariant.DeepVariantCall object with; information on our candidate call and allele support information.; refbases: A string options.width in length containing the reference base; sequence to encode. The middle base of this string should be at the; start of the variant in dv_call.; reads_for_samples: list by sample of Iterable of; third_party.nucleus.protos.Read objects that we'll use to encode the; read information supporting our call. Assumes each read is aligned and; is well-formed (e.g., has bases and quality scores, cigar). Rows of the; image are encoded in the same order as reads.; alt_alleles: A collection of alternative_bases from dv_call.variant that; we are treating as ""alt"" when constructing this pileup image. A read; will be considered supporting the ""alt"" allele if it occurs in the; support list for any alt_allele in this collection.; sample_order: A list of indices representing the order in which samples; should be represented in the pileup image. Example: [1,0,2] to swap the; first two samples out of three. This is None by default which puts the; samples in order.; custom_ref: True if refbases should not be checked for matching against; variant's reference_bases. Returns:; A uint8 Tensor image of shape; [self.width, <sum of sample pileup heights>, DEFAULT_NUM_CHANNEL]. Raises:; ValueError: if any arguments are invalid.; """"""",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:39,Availability,down,down-sampling,39,"# We add a row for each read in order, down-sampling if the number of; # reads is greater than the max reads for each sample. Sort the reads by; # their alignment position.",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py:126,Usability,learn,learning,126,"""""""Creates a DeepVariant TF.Example for the DeepVariant call dv_call. See class documents for more details. Args:; dv_call: A learning.genomics.deepvariant.DeepVariantCall proto that we; want to create a TF.Example pileup image of.; reads_for_samples: list of read generators, one for each sample.; sample_order: A list of indices representing the order in which samples; should be represented in the pileup image. Example: [1,0,2] to swap the; first two samples out of three. This is None by default which puts the; samples in order.; haplotype_alignments_for_samples: list with a dict for each sample of read; alignments keyed by haplotype.; haplotype_sequences: dict of sequences keyed by haplotype. Returns:; A list of tuples. The first element of the tuple is a set of alternate; alleles used as 'alt' when encoding this image. The second element is a; [w, h, DEFAULT_NUM_CHANNEL] uint8 Tensor of the pileup image for those; alt alleles.; """"""",MatchSource.CODE_COMMENT,deepvariant/pileup_image.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:7,Testability,test,test,7,"# Same test case as test_encode_read_matches(), with --add_hp_channel.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:7,Testability,test,test,7,"# Same test case as test_encode_read_matches(), with allele frequency.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:44,Integrability,rout,routine,44,"""""""Tests of PileupImageCreator build_pileup routine.""""""",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:19,Testability,mock,mocks,19,"# Setup our shared mocks.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:66,Testability,test,test,66,"# Change height to 7 so that we have at least 5 rows for reads to test; # sorting by haplotypes.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:44,Integrability,rout,routine,44,"""""""Tests of PileupImageCreator build_pileup routine for Trio.""""""",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:19,Testability,mock,mocks,19,"# Setup our shared mocks.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:83,Testability,mock,mock,83,"# The represent_alt_aligned_pileups function checks for shape of the; # arrays, so mock with actual numpy arrays here.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:48,Availability,error,error,48,"# Different shapes of input images should raise error.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py:48,Availability,error,error,48,"# Different shapes of input images should raise error.",MatchSource.CODE_COMMENT,deepvariant/pileup_image_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/pileup_image_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:47,Testability,log,log,47,"# When this was set, it's about 20 seconds per log.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:231,Safety,detect,detection,231,"""""""Computes the filter fields for this variant. Variant filters are generated based on its quality score value and particular; genotype call. Args:; variant: Variant to filter.; min_quality: Minimum acceptable phred scaled variant detection probability. Returns:; Filter field strings to be added to the variant.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:171,Modifiability,config,configured,171,"""""""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:43,Security,access,accessing,43,"""""""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:128,Security,access,access,128,"""""""Prepends a prefix to the file_path when accessing Google files. Args:; file_path: str. Full path pointing a specific file to access with pysam. Returns:; str. The full configured file path for pysam to open.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:38,Safety,predict,predictions,38,"""""""Gets the most likely genotype from predictions. From https://samtools.github.io/hts-specs/VCFv4.3.pdf:. Genotype Ordering. In general case of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:1183,Safety,predict,predictions,1183,"of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not yet implemented.; ValueError: If n_alleles < 2.; ValueError: If we cannot determine the genotype given prediction, n_alts,; and ploidy.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:1315,Safety,predict,predictions,1315,"of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not yet implemented.; ValueError: If n_alleles < 2.; ValueError: If we cannot determine the genotype given prediction, n_alts,; and ploidy.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:1736,Safety,predict,prediction,1736,"of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not yet implemented.; ValueError: If n_alleles < 2.; ValueError: If we cannot determine the genotype given prediction, n_alts,; and ploidy.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:1751,Safety,predict,predictions,1751,"of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not yet implemented.; ValueError: If n_alleles < 2.; ValueError: If we cannot determine the genotype given prediction, n_alts,; and ploidy.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:2105,Safety,predict,prediction,2105,"of ploidy P and N alternate alleles (0 is; the REF and 1..N the alternate alleles), the ordering of genotypes for the; likelihoods can be expressed by the following pseudocode with as many nested; loops as ploidy:. * Note that we use inclusive for loop boundaries.; for a_P = 0 . . . N; for a_P-1 = 0 . . . aP; . . .; for a_1 = 0 . . . a2; println a1 a2 . . . aP. Alternatively, the same can be achieved recursively with the following; pseudocode:. Ordering (P , N , suffix =""""):; for a in 0 . . . N; if (P == 1) println str (a) + suffix; if (P > 1) Ordering (P -1 , a, str (a) + suffix). Examples:; * for P=2 and N=1, the ordering is 00,01,11; * for P=2 and N=2, the ordering is 00,01,11,02,12,22; * for P=3 and N=2, the ordering is 000,001,011,111,002,012,112,022,122,222; * for P=1, the index of the genotype a is a; * for P=2, the index of the genotype ""a/b"", where a <= b, is b(b + 1)/2 + a; * for P=2 and arbitrary N, the ordering can be easily derived from a; triangular matrix:; b / a 0 1 2 3; 0 0; 1 1 2; 2 3 4 5; 3 6 7 8 9. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant. The number of elements in predictions is; related to ploidy and n_alleles is given by N = choose(ploidy + n_alleles; - 1, n_alleles -1) for more information see:; http://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes; ploidy: int >= 1. The ploidy (e.g., number of chromosomes) of this sample.; n_alleles: int >= 2. The number of alleles (ref + n_alts). Returns:; Two values. The first is the index of the most likely prediction in; predictions. The second is a list of P elements with the VCF-style genotype; indices corresponding to this index. For example, with P = 2 and an index of; 1, this returns the value (1, [0, 1]). Raises:; NotImplementedError: if ploidy != 2 as this not yet implemented.; ValueError: If n_alleles < 2.; ValueError: If we cannot determine the genotype given prediction, n_alts,; and ploidy.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:39,Safety,predict,predictions,39,"# TODO: would be nice to add test that predictions has the right; # number of elements. But that would involve calculating the binomial; # coefficient of n_alleles and ploidy, which would be expensive. Probably; # need to memoize the whole function if we are going to add this.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:29,Testability,test,test,29,"# TODO: would be nice to add test that predictions has the right; # number of elements. But that would involve calculating the binomial; # coefficient of n_alleles and ploidy, which would be expensive. Probably; # need to memoize the whole function if we are going to add this.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:37,Safety,predict,prediction,37,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:250,Safety,predict,predictions,250,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:363,Safety,predict,predictions,363,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:377,Safety,predict,predictions,377,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:507,Safety,predict,predictions,507,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:581,Safety,predict,prediction,581,"""""""Fills in Variant record using the prediction probabilities. This functions sets the call[0].genotype, call[0].info['GQ'],; call[0].genotype_probabilities, variant.filter, and variant.quality fields of; variant based on the genotype likelihoods in predictions. Args:; variant: third_party.nucleus.protos.Variant protobuf to be filled in with; info derived from predictions.; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; qual_filter: float. If predictions implies that this isn't a reference call; and the QUAL of the prediction isn't larger than qual_filter variant will; be marked as FILTERed.; sample_name: str. The name of the sample to assign to the Variant proto; call_set_name field. Returns:; A Variant record. Raises:; ValueError: If variant doesn't have exactly one variant.call record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:45,Safety,predict,prediction,45,"""""""Computes GQ and QUAL values from a set of prediction probabilities. Prediction probabilities are represented as a probability distribution over; the N genotype states (e.g., for 3 genotype states {HOM_REF, HET, HOM_VAR}).; Genotype Quality (or GQ) represents the PHRED scaled confidence in the; particular genotype assignment. Likewise the QUAL representes the PHRED scaled; confidence in variant as compared to reference, that is, P(NON_REF) / P(ALL); which in the diploid genotype case is P(HET) + P(HOM_VAR) / P(ALL). These; quality scores are capped by _MAX_CONFIDENCE. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; prediction_index: int. The actual called genotype from the distribution. Returns:; GQ and QUAL values for output in a Variant record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:584,Safety,predict,predictions,584,"""""""Computes GQ and QUAL values from a set of prediction probabilities. Prediction probabilities are represented as a probability distribution over; the N genotype states (e.g., for 3 genotype states {HOM_REF, HET, HOM_VAR}).; Genotype Quality (or GQ) represents the PHRED scaled confidence in the; particular genotype assignment. Likewise the QUAL representes the PHRED scaled; confidence in variant as compared to reference, that is, P(NON_REF) / P(ALL); which in the diploid genotype case is P(HET) + P(HOM_VAR) / P(ALL). These; quality scores are capped by _MAX_CONFIDENCE. Args:; predictions: N element array-like. The real-space probabilities of each; genotype state for this variant.; prediction_index: int. The actual called genotype from the distribution. Returns:; GQ and QUAL values for output in a Variant record.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:76,Safety,avoid,avoid,76,"# QUAL is prob(variant genotype) / prob(all genotypes); # Taking the min to avoid minor numerical issues than can push sum > 1.0.; # TODO: this is equivalent to the likely better implementation:; # genomics_math.perror_to_phred(max(predictions[0], min_ref_confidence)); # where min_ref_confidence is roughly 1.25e-10 (producing a qual of 99).",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:232,Safety,predict,predictions,232,"# QUAL is prob(variant genotype) / prob(all genotypes); # Taking the min to avoid minor numerical issues than can push sum > 1.0.; # TODO: this is equivalent to the likely better implementation:; # genomics_math.perror_to_phred(max(predictions[0], min_ref_confidence)); # where min_ref_confidence is roughly 1.25e-10 (producing a qual of 99).",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:159,Safety,sanity check,sanity check,159,"""""""Returns True if the call_variants_outputs follows our assumptions. Args:; call_variants_outputs: list of CallVariantsOutput to check. Returns:; True if the sanity check passes.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:100,Deployability,update,update,100,"""""""Updates variant.call fields indexed by ref + alt_alleles. Args:; variant: Variant proto. We will update the info fields of the Variant.call; protos.; fields: Iterable of string. Each string should provide a key to an; alternative allele indexed field in VariantCall.info fields. Each field; specified here will be updated to remove values associated with alleles; no longer wanted according to this remapper object.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:317,Deployability,update,updated,317,"""""""Updates variant.call fields indexed by ref + alt_alleles. Args:; variant: Variant proto. We will update the info fields of the Variant.call; protos.; fields: Iterable of string. Each string should provide a key to an; alternative allele indexed field in VariantCall.info fields. Each field; specified here will be updated to remove values associated with alleles; no longer wanted according to this remapper object.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:33,Deployability,update,updated,33,"# We cannot do entry.values[:] = updated as the ListValue type ""does; # not support assignment"" so we have to do this grossness.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:13,Safety,predict,predictions,13,"""""""Normalize predictions and handle soft-filtered alt alleles.""""""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:14,Safety,predict,predictions,14,"""""""Merges the predictions from the multi-allelic calls.""""""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:10,Testability,log,logic,10,"# See the logic described in the class PileupImageCreator pileup_image.py; #; # Because of the logic above, this function expects all cases above to have; # genotype_predictions that we can combine from.; # Removed par regions from parameter because RangeSet is not pickle-able.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:95,Testability,log,logic,95,"# See the logic described in the class PileupImageCreator pileup_image.py; #; # Because of the logic above, this function expects all cases above to have; # genotype_predictions that we can combine from.; # Removed par regions from parameter because RangeSet is not pickle-able.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:65,Safety,predict,predictions,65,"# Note the simplify_variant_alleles call *must* happen after the predictions; # calculation above. flattened_probs_dict is indexed by alt allele, and; # simplify can change those alleles so we cannot simplify until afterwards.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:153,Usability,simpl,simplify,153,"# Note the simplify_variant_alleles call *must* happen after the predictions; # calculation above. flattened_probs_dict is indexed by alt allele, and; # simplify can change those alleles so we cannot simplify until afterwards.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:200,Usability,simpl,simplify,200,"# Note the simplify_variant_alleles call *must* happen after the predictions; # calculation above. flattened_probs_dict is indexed by alt allele, and; # simplify can change those alleles so we cannot simplify until afterwards.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:294,Modifiability,variab,variable,294,"""""""Return True if CSI index is to be used over tabix index format. If the length of any reference chromosomes exceeds 512M; (here we use 5e8 to keep a safety margin), we will choose csi; as the index format. Otherwise we use tbi as default. Args:; contigs: list of contigs. Returns:; A boolean variable indicating if the csi format is to be used or not.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:151,Safety,safe,safety,151,"""""""Return True if CSI index is to be used over tabix index format. If the length of any reference chromosomes exceeds 512M; (here we use 5e8 to keep a safety margin), we will choose csi; as the index format. Otherwise we use tbi as default. Args:; contigs: list of contigs. Returns:; A boolean variable indicating if the csi format is to be used or not.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:154,Availability,avail,available,154,"""""""Determines the sample name to be used for the output VCF and gVCF. We check the following sources to determine the sample name and use the first; name available:; 1) CallVariantsOutput; 2) nonvariant site TFRecords; 3) --sample_name flag; 4) default sample name. Returns:; sample_name used when writing the output VCF and gVCF.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:112,Security,access,access,112,"# Dump all processed variants to the disk so that the C++; # merge_and_write_variants_and_nonvariants logic can access them.; # Note: This takes a really long time, but not because of the writing to; # the disk, but rather because it runs all the transformations on the; # variants at this point and not later on.; # That is fine, and there is no need to blame this part of the code when; # noticing how long it takes.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py:102,Testability,log,logic,102,"# Dump all processed variants to the disk so that the C++; # merge_and_write_variants_and_nonvariants logic can access them.; # Note: This takes a really long time, but not because of the writing to; # the disk, but rather because it runs all the transformations on the; # variants at this point and not later on.; # That is fine, and there is no need to blame this part of the code when; # noticing how long it takes.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:5,Testability,mock,mock,5,"""""""A mock VcfWriter that records the variants written in a list.""""""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:217,Safety,detect,detection,217,"""""""Creates a Variant record for testing. Args:; ref_name: reference name for this variant; start: start position on the contig; ref_base: reference base(s); alt_bases: list(str). alternate base(s); qual: PHRED scaled detection probability; filter_field: filter string for this variant; genotype: list of integers corresponding to the called genotype; gq: PHRED scaled genotype quality; likelihoods: genotype likelihoods for this variant; ad: list of integers corresponding to allelic depths. Returns:; A Variant record created with the specified arguments.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:32,Testability,test,testing,32,"""""""Creates a Variant record for testing. Args:; ref_name: reference name for this variant; start: start position on the contig; ref_base: reference base(s); alt_bases: list(str). alternate base(s); qual: PHRED scaled detection probability; filter_field: filter string for this variant; genotype: list of integers corresponding to the called genotype; gq: PHRED scaled genotype quality; likelihoods: genotype likelihoods for this variant; ad: list of integers corresponding to allelic depths. Returns:; A Variant record created with the specified arguments.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:44,Testability,test,testing,44,"""""""Creates a non-variant Variant record for testing. Args:; ref_name: str. Reference name for this variant.; start: int. start position on the contig [0-based, half open).; end: int. end position on the contig [0-based, half open).; ref_base: str. reference base at the start position. Returns:; A non-variant Variant record created with the specified arguments.; """"""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:58,Testability,test,test,58,"# Call variants now produce sharded outputs so the golden test has been; # changed to have sharded input.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:28,Testability,log,logic,28,"# An extreme case where our logic could result in ZeroDivisionError if; # we don't handle this special case.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:28,Testability,log,logic,28,"# An extreme case where our logic could result in ZeroDivisionError if; # we don't handle this special case.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:16,Testability,test,test,16,"# Multi-allelic test examples.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:6,Testability,test,tests,6,"# Q20 tests",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:6,Testability,test,tests,6,"# Q30 tests",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:6,Testability,test,tests,6,"# Q40 tests",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:20,Availability,robust,robust,20,"# Make sure code is robust to minor numerical issues where the sum of; # the vector isn't exactly 1.0.; # This vector sums to ~1.0, minus any parsing uncertainty, and will; # return a GQ of 40 but a qual of MAX_QUAL.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:37,Modifiability,parameteriz,parameterized,37,"# This generates too many tests as a parameterized test.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:26,Testability,test,tests,26,"# This generates too many tests as a parameterized test.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:51,Testability,test,test,51,"# This generates too many tests as a parameterized test.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:8,Testability,test,test,8,"# First test with no alleleic depth.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:20,Usability,simpl,simplifying,20,"# Check that we are simplifying alleles and that the simplification deps; # on the alleles we've removed.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:53,Usability,simpl,simplification,53,"# Check that we are simplifying alleles and that the simplification deps; # on the alleles we've removed.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:37,Usability,simpl,simplify,37,"# Removing the C allele allows us to simplify CAA + CA => CA + C.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:43,Usability,simpl,simplification,43,"# Removing the CA allele doesn't allow any simplification.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:33,Usability,simpl,simplifies,33,"""""""Checks that merge_predictions simplifies alleles.""""""",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py:49,Testability,test,test,49,"# TODO use itertools.permutations to improve the test.",MatchSource.CODE_COMMENT,deepvariant/postprocess_variants_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/postprocess_variants_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:250,Energy Efficiency,monitor,monitor,250,"""""""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:287,Energy Efficiency,monitor,monitor,287,"""""""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:29,Performance,perform,performance,29,"""""""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:62,Security,expose,exposes,62,"""""""Library to gather runtime performance metrics. This module exposes the ResourceMonitor class, which client code can use to; gather resource usage metrics about their program. An example usage would look; something like:. with ResourceMonitor() as monitor:; ... do work ...; metrics = monitor.metrics(); """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:140,Integrability,depend,depend,140,"""""""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:208,Usability,learn,learning,208,"""""""Returns an initialized ResourceMetrics proto. This function also fills in the ""constant"" fields of the ResourceMetrics; proto that don't depend on the actual running commands, such as host_name. Returns:; learning.genomics.deepvariant.ResourceMetrics proto.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:135,Energy Efficiency,monitor,monitor,135,"""""""Starts timers associated with resource collection. This method must be called before metrics(). Returns:; self to enable the idiom `monitor = ResourceMonitor().start()`.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:253,Integrability,message,message,253,"""""""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:201,Usability,learn,learning,201,"""""""Collects and return runtime metrics as a ResourceMetrics proto. This method can be called multiple times, but wall clock time is always; reckoned from the time of the last start() call. Returns:; A learning.genomics.deepvariant.ResourceMetrics proto message. Raises:; RuntimeError: if start() was not called previously.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:170,Testability,mock,mockable,170,"# ------------------------------------------------------------------------------; # Simple functions for getting host_name, cpu count, etc. Isolated here to make; # them mockable.; # ------------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py:155,Availability,avail,available,155,"""""""Gets the frequency in MHz of the cpus in this machine. Returns:; float > 0 if the call to get the cpu_frequency succeeded. This information; may not be available on all systems, in which case we return 0.0.; """"""",MatchSource.CODE_COMMENT,deepvariant/resources.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:13,Usability,learn,learning,13,"""""""Tests for learning.genomics.deepvariant.resources.""""""",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:130,Safety,sanity check,sanity checks,130,"# We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:64,Testability,test,test,64,"# We want to actually make all of the real function calls under test, but; # we of course don't know their values and can only do sanity checks.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:246,Availability,avail,available,246,"# We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:102,Testability,test,tests,102,"# We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:135,Testability,assert,assertGreater,135,"# We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:180,Testability,assert,assertGreater,180,"# We unfortunately cannot make sure that read_bytes and write_bytes is; # greater than zero, so these tests are commented out.; # self.assertGreater(metrics.read_bytes, 0); # self.assertGreater(metrics.write_bytes, 0); # CPU frequency may not be available on all systems, so the value is; # either a real frequency (> 0) or the magic value of 0.0 indicating that; # the value could not be determined.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:27,Testability,mock,mocked,27,"# Environment metrics; all mocked out.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:32,Testability,mock,mocked,32,"# Runtime metrics; they are all mocked out.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:61,Integrability,depend,depending,61,"# Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:61,Integrability,depend,depending,61,"# Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py:61,Integrability,depend,depending,61,"# Some psutil functions, such as cpu_freq(), can return None depending on; # the environment; make sure we don't crash when that occurs.",MatchSource.CODE_COMMENT,deepvariant/resources_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/resources_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:17,Deployability,update,updated,17,"# Once pandas is updated to 0.24+, pd.read_csv will work for gs://; # without this workaround.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:23,Usability,simpl,simple,23,"# 'total runtime' is a simple sum of the runtime columns.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:27,Energy Efficiency,reduce,reduce,27,"# Limit columns to greatly reduce the size of the html report.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:191,Safety,avoid,avoid,191,"# This chart needs to use the same dataframe as the first chart to enable the; # brushing on one to affect the other. Using max(task) for 'text' is a; # trick that causes bundling by task to avoid showing multiple overlapping; # points which otherwise make the text look funky.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:27,Safety,avoid,avoid,27,"# Sample the bottom 99% to avoid outliers that obscure general trends.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py:47,Testability,test,testing,47,"# Abstracted out the file open/close to enable testing.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis_test.py:34,Testability,test,testdata,34,"# Json strings of dataframes from testdata.RUNTIME_BY_REGION.",MatchSource.CODE_COMMENT,deepvariant/runtime_by_region_vis_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/runtime_by_region_vis_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples.py:56,Testability,log,logging,56,"# Print another dot on the same line, using print since logging does; # not support printing without a newline.",MatchSource.CODE_COMMENT,deepvariant/show_examples.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples_test.py:46,Availability,error,error,46,"# With 6 channel names, it should run without error:",MatchSource.CODE_COMMENT,deepvariant/show_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/show_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:26,Testability,test,testing,26,"""""""Utilities to help with testing DeepVariant code.""""""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:53,Testability,test,testdata,53,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:167,Testability,test,testdata,167,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:202,Testability,test,testdata,202,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:250,Testability,test,test,250,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:295,Testability,test,testdata,295,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:398,Testability,test,testdata,398,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:265,Usability,learn,learning,265,"""""""Gets the path to filename in genomics/deepvariant/testdata. These paths are only known at runtime, after flag parsing; has occurred. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""learning/genomics/deepvariant/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py:21,Modifiability,variab,variables,21,"""""""Initialize global variables from flag values.""""""",MatchSource.CODE_COMMENT,deepvariant/testdata.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/testdata.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:7,Modifiability,config,config,7,"# Load config",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:28,Availability,checkpoint,checkpoint,28,"# Copy example_info.json to checkpoint path.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:33,Modifiability,config,config,33,"# TODO: Define learning rate via config.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:15,Usability,learn,learning,15,"# TODO: Define learning rate via config.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:18,Usability,learn,learning,18,"# This is initial learning rate.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:64,Performance,optimiz,optimizer,64,"# Define Optimizer.; # TODO: Add function for retrieving custom optimizer.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:94,Availability,checkpoint,checkpointing,94,"# ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:136,Modifiability,variab,variables,136,"# ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:157,Performance,optimiz,optimizer,157,"# ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:184,Performance,tune,tune,184,"# ================= #; # Setup Checkpoint #; # ================= #; # The state object allows checkpointing of the model and associated variables; # for the optimizer, step, and train/tune metrics.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:26,Performance,tune,tune,26,"""""""Single non-distributed tune step.""""""",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:29,Performance,optimiz,optimizing,29,"""""""Returns the metric we are optimizing for.""""""",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:8,Performance,tune,tune,8,"# Reset tune metrics",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:12,Performance,tune,tune,12,"# ==== #; # tune #; # ==== #; # Run tune at every epoch, periodically, and at final step.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:36,Performance,tune,tune,36,"# ==== #; # tune #; # ==== #; # Run tune at every epoch, periodically, and at final step.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:8,Performance,tune,tune,8,"# Reset tune metrics",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:44,Availability,checkpoint,checkpoint,44,"# After training completes, load the latest checkpoint and create; # a saved model (.pb) and keras model formats.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:28,Performance,load,load,28,"# After training completes, load the latest checkpoint and create; # a saved model (.pb) and keras model formats.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:13,Availability,checkpoint,checkpoint,13,"# The latest checkpoint will be the best performing checkpoint.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:52,Availability,checkpoint,checkpoint,52,"# The latest checkpoint will be the best performing checkpoint.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py:41,Performance,perform,performing,41,"# The latest checkpoint will be the best performing checkpoint.",MatchSource.CODE_COMMENT,deepvariant/train.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:241,Performance,load,loading,241,"# Image preprocessing and one-hot encoding were previously done inside the; # TF Estimator API's model_fn. Though we can subclass the Keras InceptionV3; # class and do it in the forward pass, it seems more fitting to do it during; # dataset loading along with the above image loading steps.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:276,Performance,load,loading,276,"# Image preprocessing and one-hot encoding were previously done inside the; # TF Estimator API's model_fn. Though we can subclass the Keras InceptionV3; # class and do it in the forward pass, it seems more fitting to do it during; # dataset loading along with the above image loading steps.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:18,Usability,learn,learning,18,"# This is initial learning rate.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:144,Safety,safe,safe,144,"# Our ""steps_per_epoch"" in model.fit is:; # steps_per_epoch // FLAGS.train_config.num_mini_epochs_per_epoch.; # I divided that by 10 just to be safe. In case that gets too small,; # I set a max with 128 here.; # Note that this might only make sense for TPUs. In the future we'll want to; # check whether this works for GPU or not.; # We should also keep an eye on this feature which might allow autotune in; # the future: https://github.com/keras-team/keras/issues/16573.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:22,Performance,optimiz,optimizers,22,"# TODO: Try different optimizers; # and sweep over these hyperparams",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:46,Usability,guid,guide,46,"# This is from:; # https://www.tensorflow.org/guide/tpu#train_the_model_using_keras_high-level_apis.; # Anything between 2 and `steps_per_epoch` could help here.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:35,Performance,tune,tuned,35,"# `patient` below might need to be tuned.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:12,Security,validat,validation,12,"# Calculate validation attributes.",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py:74,Security,validat,validation,74,"# Even with ""mini epoch"", we still want to evaluate the same amount of; # validation examples per point. So, I'm not dividing this by; # FLAGS.train_config.num_mini_epochs_per_epoch",MatchSource.CODE_COMMENT,deepvariant/train_inceptionv3.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/train_inceptionv3.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py:797,Availability,down,down,797,"""""""Computes the confidence that a site in the genome has no variation. Computes this confidence using only the counts of the number of reads; supporting the reference allele and the total number of reads at this site. See: https:www.broadinstitute.org/gatk/guide/article?id=4017 for; background. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_to",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py:2271,Deployability,configurat,configurations,2271,"und. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_total: int >= 0 and >= n_ref: The number of reads supporting any allele; at this site. Returns:; A tuple of two values. The first is an integer value for the GQ (genotype; quality) and the second is an array-like of the log10 probabilities for; each of the three genotype configurations.; """"""",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py:2271,Modifiability,config,configurations,2271,"und. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_total: int >= 0 and >= n_ref: The number of reads supporting any allele; at this site. Returns:; A tuple of two values. The first is an integer value for the GQ (genotype; quality) and the second is an array-like of the log10 probabilities for; each of the three genotype configurations.; """"""",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py:257,Usability,guid,guide,257,"""""""Computes the confidence that a site in the genome has no variation. Computes this confidence using only the counts of the number of reads; supporting the reference allele and the total number of reads at this site. See: https:www.broadinstitute.org/gatk/guide/article?id=4017 for; background. Computes the reference confidence for site allele_count. Examines the number of reference supporting and alternate supporting reads; in allele_count and estimates the genotype likelihoods and confidence that; this site is homozygous reference. These values are written into the first; VariantCall record of variant, into the repeated field genotype_likelihood; and the map field GQ. The genotype likelihoods are computed against any possible alternative; allele, the so-called <*> allele, which boils down to a model that looks; like:. log10_p_ref = (1 - p_error)^(ref_n) (p_error)^(non_ref_n); log10_p_het = (0.5)^(total_n); log10_p_hom_alt = (p_e)^(ref_n) (1 - p_error)^(non_ref_n). ref_n is the number of reference supporting reads and non_ref_n is the sum; of any reads supporting any alternate alleles. Non-informative reads are; excluded from the calculation. and written in as the normalized log10 values so that:. sum(10^genotype_likelihoods) = 1. The GQ, according to the VCF specification, is the conditional genotype; quality, encoded as a phred quality -10 * log10 p(genotype call is wrong,; conditioned on the site's being variant, as an integer. See:; https:samtools.github.io/hts-specs/VCFv4.3.pdf; We are calculating the GQ not for the best genotype, but the GQ of the 0/0; genotype, regardless of the likelihoods.; 1 = pRR + pRA + pAA; [R is reference, A=<*> is any alternative alternative]; GQ of 0/0 = -10 * log10(pRA + pAA) [prob that any other differen genotype]; = -10 * log10(1 - pRR) [substitution from the previous equation]; Here we don't have pRR directly, but rather log10(pRR). Args:; n_ref: int >= 0 and <= n_total: The number of reads supporting the; reference allele.; n_to",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py:11,Integrability,interface,interface,11,"""""""Primary interface function for computing gVCF confidence at a site. Looks at the counts in the provided list of AlleleCountSummary protos and; returns properly-formatted Variant protos containing gVCF reference; blocks for all sites in allele_count_summaries. The returned Variant has; reference_name, start, end are set and contains a single VariantCall in the; calls field with call_set_name of options.sample_name, genotypes set to 0/0; (diploid reference), a GQ value bound in the info field appropriate to the; data in allele_count, and a MIN_DP value which is the minimum read coverage; seen in the block. The provided allele count must have either a canonical DNA sequence base (; A, C, G, T) or be ""N"". Args:; allele_count_summaries: iterable of AlleleCountSummary protos in; coordinate-sorted order. Each proto is used to get the read counts for; reference and alternate alleles, the reference position, and reference; base.; include_med_dp: boolean. If True, in the gVCF records, we will include; MED_DP. Yields:; third_party.nucleus.protos.Variant proto in; coordinate-sorted order containing gVCF records.; """"""",MatchSource.CODE_COMMENT,deepvariant/variant_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:149,Testability,test,tested,149,"""""""A placeholder VariantCaller. This class provides a get_candidates implementation and so allows; the base class to be instantiated and its methods tested.; """"""",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:24,Testability,test,testdata,24,"# R code to produce the testdata expectation table.; # expected <- function(n_ref, n_alt, perr, max_gq = 100) {; # p_ref <- dbinom(n_alt, n_ref, perr); # p_het <- dbinom(n_alt, n_ref, 0.5); # p_alt <- dbinom(n_ref - n_alt, n_ref, perr); # raw <- c(p_ref, p_het, p_alt); # norm <- raw / sum(raw); # gq = min(floor(-10 * log10(1 - norm[1])), max_gq); # likelihoods = paste(sprintf(""%.6f"", log10(norm)), collapse="", ""); # likelihoods = paste(""["", likelihoods, ""]"", sep=""""); # result = paste(n_ref, n_alt, perr, 100, 1, likelihoods, gq, sep="", ""); # cat(paste(""["", result, ""],\n"", sep="""")); # }; #; # for (n in c(10, 20)) {; # for (k in seq(0, n)) {; # expected(n, k, 0.01); # }; # }; #; # for (perr in c(0.1, 0.01, 0.001, 0.0001)) {; # expected(10, 0, perr); # expected(10, 1, perr); # }; #; # for (n_ref in c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 1000, 10000)) {; # expected(n_ref, 0, 0.01); # }",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:34,Testability,test,testcase,34,"# I saw a bug at runtime, and the testcase makes sure we scale values of; # n_ref_reads close to n_total_reads appropriately.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:7,Testability,test,tests,7,"# Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:109,Testability,test,tested,109,"# Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:146,Performance,cache,cached,146,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:170,Performance,cache,cache,170,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:293,Performance,cache,cache,293,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:367,Performance,cache,cache,367,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:265,Testability,test,test,265,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py:350,Testability,test,test,350,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:149,Testability,test,tested,149,"""""""A placeholder VariantCaller. This class provides a get_candidates implementation and so allows; the base class to be instantiated and its methods tested.; """"""",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:24,Testability,test,testdata,24,"# R code to produce the testdata expectation table.; # expected <- function(n_ref, n_alt, perr, max_gq = 100) {; # p_ref <- dbinom(n_alt, n_ref, perr); # p_het <- dbinom(n_alt, n_ref, 0.5); # p_alt <- dbinom(n_ref - n_alt, n_ref, perr); # raw <- c(p_ref, p_het, p_alt); # norm <- raw / sum(raw); # gq = min(floor(-10 * log10(1 - norm[1])), max_gq); # likelihoods = paste(sprintf(""%.6f"", log10(norm)), collapse="", ""); # likelihoods = paste(""["", likelihoods, ""]"", sep=""""); # result = paste(n_ref, n_alt, perr, 100, 1, likelihoods, gq, sep="", ""); # cat(paste(""["", result, ""],\n"", sep="""")); # }; #; # for (n in c(10, 20)) {; # for (k in seq(0, n)) {; # expected(n, k, 0.01); # }; # }; #; # for (perr in c(0.1, 0.01, 0.001, 0.0001)) {; # expected(10, 0, perr); # expected(10, 1, perr); # }; #; # for (n_ref in c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 1000, 10000)) {; # expected(n_ref, 0, 0.01); # }",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:34,Testability,test,testcase,34,"# I saw a bug at runtime, and the testcase makes sure we scale values of; # n_ref_reads close to n_total_reads appropriately.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:7,Testability,test,tests,7,"# Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:109,Testability,test,tested,109,"# Only tests the 'gvcfs' creation part of calls_and_gvcfs. The `calls`; # portion of this method needs to be tested in subclasses, which have; # implemented the get_candidates method.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:146,Performance,cache,cached,146,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:170,Performance,cache,cache,170,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:293,Performance,cache,cache,293,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:367,Performance,cache,cache,367,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:265,Testability,test,test,265,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py:350,Testability,test,test,350,"# Note that we only expect the gq and gls to be close if we are not; # rescaling the counts, so we are only looping over values that should be; # cached. In practice the cache is set to values sufficiently large that; # these differences don't matter, but for this test we are limiting the; # cache size to a small value in _CACHE_COVERAGE so we can test that the; # cache lookups are correct.",MatchSource.CODE_COMMENT,deepvariant/variant_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/variant_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py:6,Testability,test,test,6,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py:315,Testability,test,testing,315,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py:207,Usability,simpl,simply,207,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py:228,Usability,simpl,simplifies,228,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py:31,Usability,learn,learning,31,"# Golden sets are created with learning/genomics/internal/create_golden.sh.",MatchSource.CODE_COMMENT,deepvariant/vcf_candidate_importer_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_candidate_importer_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py:51,Availability,error,error,51,"# Check for missing GT in VCF to avoid a confusing error downstream.",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_report.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py:57,Availability,down,downstream,57,"# Check for missing GT in VCF to avoid a confusing error downstream.",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_report.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py:33,Safety,avoid,avoid,33,"# Check for missing GT in VCF to avoid a confusing error downstream.",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_report.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_report.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py:19,Usability,guid,guide,19,"# vertical line as guide",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py:35,Safety,avoid,avoid,35,"# Show TiTv ratio with fallback to avoid division by 0",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py:46,Integrability,interface,interface,46,"""""""Build all charts and combine into a single interface.""""""",MatchSource.CODE_COMMENT,deepvariant/vcf_stats_vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vcf_stats_vis.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller.py:102,Integrability,interface,interface,102,"""""""A VerySensitiveCaller producing DeepVariantCall and gVCF records. This module provides the primary interface for calling candidate variants using; for the AlleleCounts in an AlleleCounter by wrapping the low-level C++ code and; adding a nicer API and functions to compute gVCF records as well.; """"""",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller.py:194,Integrability,wrap,wrapping,194,"""""""A VerySensitiveCaller producing DeepVariantCall and gVCF records. This module provides the primary interface for calling candidate variants using; for the AlleleCounts in an AlleleCounter by wrapping the low-level C++ code and; adding a nicer API and functions to compute gVCF records as well.; """"""",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py:6,Testability,test,test,6,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py:315,Testability,test,testing,315,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py:207,Usability,simpl,simply,207,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py:228,Usability,simpl,simplifies,228,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py:6,Testability,test,test,6,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py:315,Testability,test,testing,315,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py:207,Usability,simpl,simply,207,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py:228,Usability,simpl,simplifies,228,"# Our test AlleleCounts are 5 positions:; #; # 10: A ref [no reads]; # 11: G/C variant; # 12: G ref [no reads]; # 13: G ref [no reads]; # 14: T/C variant; #; # The ref sites have no reads for ref or any alt simply because it; # simplifies comparing them with the expected variant genotype likelihoods.; # We aren't testing the correctness of the gvcf calculation here (that's; # elsewhere) but rather focusing here on the separation of variants from; # gvcf records, and the automatic merging of the gvcf blocks.",MatchSource.CODE_COMMENT,deepvariant/very_sensitive_caller_trio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/very_sensitive_caller_trio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:9,Testability,test,tests,9,"""""""Smoke tests for the genomics environment.""""""",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:60,Testability,test,test,60,"# We use unittest and not TF Test because the point of this test is to be; # able to test our environment without having to build TensorFlow.",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:85,Testability,test,test,85,"# We use unittest and not TF Test because the point of this test is to be; # able to test our environment without having to build TensorFlow.",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:14,Testability,test,test,14,"""""""End-to-end test of model_train script.""""""",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:54,Modifiability,variab,variable,54,"# Test various imports work; # pylint: disable=unused-variable; # pylint: disable=g-import-not-at-top",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py:24,Modifiability,variab,variable,24,"# pylint: enable=unused-variable; # pylint: enable=g-import-not-at-top",MatchSource.CODE_COMMENT,deepvariant/environment_tests/env_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/environment_tests/env_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py:137,Safety,predict,predict,137,"""""""Computes the label value for an example. This function computes the TensorFlow label value (0, 1, 2, .. N-1) we train; DeepVariant to predict.; The `alt_alleles_indices` being passed in is from the candidates (not; truth), so they could still have multiple alts. If any of the alt alleles; matches the truth, we'll return the label of the truth.; TODO: Fix multi-allelic cases. Add corresponding unit test cases.; Note that this function currently doesn't handle multi-allelic cases; correctly. For example it assumes `truth_alt` is the first one. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices. Returns:; int >= 0. Label for the classes in `classes_dict`.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py:404,Testability,test,test,404,"""""""Computes the label value for an example. This function computes the TensorFlow label value (0, 1, 2, .. N-1) we train; DeepVariant to predict.; The `alt_alleles_indices` being passed in is from the candidates (not; truth), so they could still have multiple alts. If any of the alt alleles; matches the truth, we'll return the label of the truth.; TODO: Fix multi-allelic cases. Add corresponding unit test cases.; Note that this function currently doesn't handle multi-allelic cases; correctly. For example it assumes `truth_alt` is the first one. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices. Returns:; int >= 0. Label for the classes in `classes_dict`.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py:17,Testability,log,logic,17,"# Note that this logic below might not be the best when; # `alt_alleles_indices` is a composite one, like [0, 1]. For now we'll; # return the corresponding label if any of them matches truth_alt.",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py:88,Availability,error,error,88,"# TODO: check the following cases:; # no_class_status; # invalid_class_status; # (Value error should be produced in both cases)",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py:9,Testability,test,tests,9,"# Simple tests: we get back our matching variants in the confident regions",MatchSource.CODE_COMMENT,deepvariant/labeler/customized_classes_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/customized_classes_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:291,Testability,benchmark,benchmarking-tools,291,"""""""Haplotype-based labeling algorithm for DeepVariant. This module provides a haplotype-aware labeling algorithm. This is a more; sophisticated approach to labeling that allows for slight representational; differences between candidate and truth variant sets. See:. https://github.com/ga4gh/benchmarking-tools; https://www.biorxiv.org/content/early/2018/03/15/270157. for an introduction to the concepts and why this is important. The module is implemented in two big pieces of functionality:. find_best_matching_haplotypes(candidates, truths) provides an function that; accepts a list of candidate variants and a list of truth variants with known; genotypes and finds an assignment of genotypes for candidates and truth that; results in the same two haplotype sequences in the region. Since the truth; variants have known genotypes, the search there is constrained to those; genotypes and their potential set of false negatives (e.g., if truth is (0, 1); we may have missed the variant so we consider both (0, 1) and (0, 0)). The; returned value is a HaplotypeMatch object describing the genotype assignments; for candidates and truth. HaplotypeLabeler implements the variant_labeler.VariantLabeler API by calling; our find_best_matching_haplotypes function to get the HaplotypeMatch objects and; returning variant_labeler.VariantLabel objects for each candidate variant.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:52,Testability,log,logs,52,"# True we will generate enough information into our logs to help debug bad; # regions.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:96,Safety,safe,safely,96,"# Grab our truth variants and group up variants + truth into small enough; # chunks that we can safely send them into our find_best_matching_haplotypes; # function.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:12,Testability,test,test,12,"# Note this test must be 'is None' since label_variants can return an; # empty list.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:7,Testability,log,logic,7,"# This logic doesn't make a huge amount of sense when you are doing; # haplotype-based labeling. Currently we only say a variant is confident; # if it overlaps the confident regions, which is the baseline behavior.; # However, it may be useful to rethink how we establish a variant is; # confident, as the ""event"" may be within the confident regions but; # shifted outside due to differences in representational choices. Seems; # like another approach would be to assign confidence if it has a; # non-ref genotype (as we only consider confident truth variants) or if; # it overlaps the confident regions.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:80,Deployability,update,updates,80,"""""""Update self._metrics with the HaplotypeMatch labeling results. This function updates the LabelingMetrics information in self._metrics using; the labeling results in labeling. Args:; labeling: HaplotypeMatch. The labeling information to use to update our; LabelingMetrics.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:246,Deployability,update,update,246,"""""""Update self._metrics with the HaplotypeMatch labeling results. This function updates the LabelingMetrics information in self._metrics using; the labeling results in labeling. Args:; labeling: HaplotypeMatch. The labeling information to use to update our; LabelingMetrics.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:236,Deployability,update,update,236,"# Use the truth_by_pos dict to determine which candidates occur at the; # same position as a truth variant. If there is one, grab it and its; # genotypes so we can compute metrics on exact position, allele, genotype; # matches. If not, update the number of inexact matches if our candidate; # is non-reference itself.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:33,Performance,cache,cached,33,"""""""Allows us to get bases from a cached reference interval.""""""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:378,Safety,avoid,avoid,378,"""""""Splits candidate and truth variants into smaller groups if necessary. This function takes in a list of candidate and truth variants and splits up; those lists into groups that respect the requirements of the max_group_size; and max_separation arguments. This is necessary because the labeling algorithm; is very expensive as a function of the number of input variants, so to avoid; excessive runtime we break up our potentially large list of candidate and; truth variants into smaller groups (max number controlled by max_group_size); based on a maximum distance allowed between the closest variants within the; group. The current algorithm is a simple greedy one; we effectively merge the two; variant lists together, make groups greedily on that list until either the; maximum number of elements of a specific type (i.e., max_group_size of 2; implies we can have up to two candidate variants or truth variants within a; group) or we encounter a variant further away from the closest variant within; the current group than allowed by max_separation. Args:; candidates: list[nucleus.proto.Variant]. A sorted list of candidate variants; on the same chromosome.; truths: list[nucleus.proto.Variant]. A sorted list of truth variants on the; same chromosome.; max_group_size: int >= 0. The maximum number of variants of a specific type; allowed within a group.; max_separation: int >= 0. The maximum distance, in basepairs, allowed; between the closest variants within a group.; max_gt_options_product: int >= 0. The maximum number of combinations of; genotypes (product of all genotypes in the group).; force_group_within_bp: int >= 0. Variants within this many bps will be; forced to be put in the same group. This is to ensure that we do not; decouple candidates and truths in variant-dense regions. This value can be; set to -1 for unit-test purposes. Setting -1 will not force any grouping; of variants. Returns:; A list of grouped variants in 2-tuples, such as:. [(candidates1, truth_variants1), ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:1840,Testability,test,test,1840,"ts up; those lists into groups that respect the requirements of the max_group_size; and max_separation arguments. This is necessary because the labeling algorithm; is very expensive as a function of the number of input variants, so to avoid; excessive runtime we break up our potentially large list of candidate and; truth variants into smaller groups (max number controlled by max_group_size); based on a maximum distance allowed between the closest variants within the; group. The current algorithm is a simple greedy one; we effectively merge the two; variant lists together, make groups greedily on that list until either the; maximum number of elements of a specific type (i.e., max_group_size of 2; implies we can have up to two candidate variants or truth variants within a; group) or we encounter a variant further away from the closest variant within; the current group than allowed by max_separation. Args:; candidates: list[nucleus.proto.Variant]. A sorted list of candidate variants; on the same chromosome.; truths: list[nucleus.proto.Variant]. A sorted list of truth variants on the; same chromosome.; max_group_size: int >= 0. The maximum number of variants of a specific type; allowed within a group.; max_separation: int >= 0. The maximum distance, in basepairs, allowed; between the closest variants within a group.; max_gt_options_product: int >= 0. The maximum number of combinations of; genotypes (product of all genotypes in the group).; force_group_within_bp: int >= 0. Variants within this many bps will be; forced to be put in the same group. This is to ensure that we do not; decouple candidates and truths in variant-dense regions. This value can be; set to -1 for unit-test purposes. Setting -1 will not force any grouping; of variants. Returns:; A list of grouped variants in 2-tuples, such as:. [(candidates1, truth_variants1), ...]. where each tuple contains the candidate and truth variants for that group. Raises:; ValueError: if any of the inputs are malformed.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:649,Usability,simpl,simple,649,"""""""Splits candidate and truth variants into smaller groups if necessary. This function takes in a list of candidate and truth variants and splits up; those lists into groups that respect the requirements of the max_group_size; and max_separation arguments. This is necessary because the labeling algorithm; is very expensive as a function of the number of input variants, so to avoid; excessive runtime we break up our potentially large list of candidate and; truth variants into smaller groups (max number controlled by max_group_size); based on a maximum distance allowed between the closest variants within the; group. The current algorithm is a simple greedy one; we effectively merge the two; variant lists together, make groups greedily on that list until either the; maximum number of elements of a specific type (i.e., max_group_size of 2; implies we can have up to two candidate variants or truth variants within a; group) or we encounter a variant further away from the closest variant within; the current group than allowed by max_separation. Args:; candidates: list[nucleus.proto.Variant]. A sorted list of candidate variants; on the same chromosome.; truths: list[nucleus.proto.Variant]. A sorted list of truth variants on the; same chromosome.; max_group_size: int >= 0. The maximum number of variants of a specific type; allowed within a group.; max_separation: int >= 0. The maximum distance, in basepairs, allowed; between the closest variants within a group.; max_gt_options_product: int >= 0. The maximum number of combinations of; genotypes (product of all genotypes in the group).; force_group_within_bp: int >= 0. Variants within this many bps will be; forced to be put in the same group. This is to ensure that we do not; decouple candidates and truths in variant-dense regions. This value can be; set to -1 for unit-test purposes. Setting -1 will not force any grouping; of variants. Returns:; A list of grouped variants in 2-tuples, such as:. [(candidates1, truth_variants1), ",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:42,Deployability,configurat,configuration,42,"""""""Indicates that an impossible haplotype configuration has been observed.""""""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:42,Modifiability,config,configuration,42,"""""""Indicates that an impossible haplotype configuration has been observed.""""""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:90,Usability,simpl,simply,90,"# See comment in create_haplotypes_recursive for more information, but in; # this case we simply `pass`, as we cannot construct any valid haplotypes.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:62,Deployability,configurat,configurations,62,"""""""Enumeration type indicating how we should explore genotype configurations. See genotype_options_for_variants for more information.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:62,Modifiability,config,configurations,62,"""""""Enumeration type indicating how we should explore genotype configurations. See genotype_options_for_variants for more information.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:298,Energy Efficiency,efficient,efficiently,298,"""""""Returns a map from phased genotypes => haplotype sequences. This function creates a map from all possible haploid genotypes of the; genotypes in variants_and_genotypes to their corresponding haplotype sequences; implied by the variants, ref, start, and their genotypes. This map can be used; to efficiently look up the haplotype sequence for any haploid genotype. Args:; variants_and_genotypes: list[VariantAndGenotypes]. The variants and; associated genotypes to use to build the dictionary.; start: int >= 0. The position on the genome to start constructing our; haplotypes at.; ref: ReferenceRegion. Object containing the reference genome bases we use to; construct our haplotypes. Returns:; A 2-tuple. The first element is a dictionary[tuple, string], where each key; is a phased haploid genotype and its value is the haplotype sequence implied; by that genotype given the variants and the reference genome. The second; position is the ending position of the haplotype on the reference genome.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:22,Modifiability,variab,variable,22,"# Update our position variable to be the next reference base we want to; # use when further constructing our haplotype string. If we are using; # the reference base, we start our position at the base after variant; # start, whereas if we are using a non-reference base we use the; # variant.end.; #; # This special-case is needed to handle deletion alleles properly. If we; # have a deletion (e.g., AA => A with start = 10 and end = 12) then we; # only want to skip to position 12 for the next reference bases if we; # have have the deletion, otherwise we'd miss the second 'A' base which; # is really there (the variant isn't present, after all). Another; # consequence of this choice we only want to add the first base of the; # reference allele, not the whole string, since this would append all of; # deletion bases inappropriately to our haplotype.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:607,Deployability,configurat,configurations,607,"""""""Returns a new dictionary with deduplicated value. Type description:; Genotype = Tuple[int, int]; Genotypes = List[Genotype]; Haplotypes = FrozenSet[str]. The type of the input `haplotypes_to_genotypes_dict` is:; Dict[Haplotypes, List[Genotypes]]. whereas the return type of deduplicate_haplotypes (this function) is:. Dict[Haplotypes, Genotypes]. This function goes through the values in `haplotypes_to_genotypes_dict` and; keeps only a single example of Genotypes if there are multiple elements of; the list that have the same haplotypes. Duplicates are expected; in the list because different genotype configurations can sometimes produce; the same set of haplotypes, and analyzing a dict of possible; haplotypes/genotypes combinations with duplicates is much harder and less; efficient than the deduplicated dict. Args:; haplotypes_to_genotypes_dict: Dict[Haplotypes, List[Genotypes]]. Returns:; Dict[Haplotypes, Genotypes].; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:782,Energy Efficiency,efficient,efficient,782,"""""""Returns a new dictionary with deduplicated value. Type description:; Genotype = Tuple[int, int]; Genotypes = List[Genotype]; Haplotypes = FrozenSet[str]. The type of the input `haplotypes_to_genotypes_dict` is:; Dict[Haplotypes, List[Genotypes]]. whereas the return type of deduplicate_haplotypes (this function) is:. Dict[Haplotypes, Genotypes]. This function goes through the values in `haplotypes_to_genotypes_dict` and; keeps only a single example of Genotypes if there are multiple elements of; the list that have the same haplotypes. Duplicates are expected; in the list because different genotype configurations can sometimes produce; the same set of haplotypes, and analyzing a dict of possible; haplotypes/genotypes combinations with duplicates is much harder and less; efficient than the deduplicated dict. Args:; haplotypes_to_genotypes_dict: Dict[Haplotypes, List[Genotypes]]. Returns:; Dict[Haplotypes, Genotypes].; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:607,Modifiability,config,configurations,607,"""""""Returns a new dictionary with deduplicated value. Type description:; Genotype = Tuple[int, int]; Genotypes = List[Genotype]; Haplotypes = FrozenSet[str]. The type of the input `haplotypes_to_genotypes_dict` is:; Dict[Haplotypes, List[Genotypes]]. whereas the return type of deduplicate_haplotypes (this function) is:. Dict[Haplotypes, Genotypes]. This function goes through the values in `haplotypes_to_genotypes_dict` and; keeps only a single example of Genotypes if there are multiple elements of; the list that have the same haplotypes. Duplicates are expected; in the list because different genotype configurations can sometimes produce; the same set of haplotypes, and analyzing a dict of possible; haplotypes/genotypes combinations with duplicates is much harder and less; efficient than the deduplicated dict. Args:; haplotypes_to_genotypes_dict: Dict[Haplotypes, List[Genotypes]]. Returns:; Dict[Haplotypes, Genotypes].; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:47,Testability,log,logging,47,"""""""Write basic information about haplotypes to logging.info.""""""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py:45,Testability,log,logging,45,"""""""Write basic information about variants to logging.info.""""""",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:14,Testability,test,tests,14,"# A few basic tests of functionality to start:; # We group a single variant without associated truth variants.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:10,Testability,test,test,10,"# Another test of grouping across candidates and truth.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:8,Testability,test,tests,8,"# These tests actually result in broken up groups, with isolated truth; # and candidates as well as grouped ones.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:11,Testability,test,tests,11,"# Now some tests to exercise the max group size with both candidates and; # truth variants. We vary the max group size to make sure the grouping; # algorithm splits correctly.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:137,Integrability,depend,depends,137,"# The actual result returned by group_variants is a list of tuples; # containing the grouped candidates and truth. The order they appear depends; # on the truth_position, since our deletion starts at 10.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:10,Usability,simpl,simple,10,"# Check a simple case of two SNPs.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:10,Modifiability,parameteriz,parameterized,10,"# This is parameterized over the max_separation so we can test that the; # metrics are properly calculated no matter the grouping. The candidates and; # truth variants below should give the same metrics regardless of grouping.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:58,Testability,test,test,58,"# This is parameterized over the max_separation so we can test that the; # metrics are properly calculated no matter the grouping. The candidates and; # truth variants below should give the same metrics regardless of grouping.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:139,Testability,test,test,139,"# ref looks like AACTG. Truth is just a single SNP turning the C into a G.; # Candidates do the same but via an insertion + deletion. This test ensures; # that the metrics work even in the case where we have different; # representations for the same haplotype.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:16,Testability,test,tests,16,"# Many of these tests are cases from our labeler analysis doc:; # https://docs.google.com/document/d/1V89IIT0YM3P0gH_tQb-ahodf8Jvnz0alXEnjCf6JVNo",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:31,Usability,simpl,simple,31,"# All possible genotypes for a simple tri-allelic case.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:20,Deployability,configurat,configurations,20,"# Simple bi-allelic configurations:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:20,Modifiability,config,configurations,20,"# Simple bi-allelic configurations:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:16,Deployability,configurat,configurations,16,"# Multi-allelic configurations:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:16,Modifiability,config,configurations,16,"# Multi-allelic configurations:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:27,Availability,down,downstream,27,"# Deletion overlapping two downstream events (SNP and insertion):; # ref: xTGC; # v1: A--; # v2: C; # v3: TTT",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:13,Usability,simpl,simple,13,"# Check that simple bi-allelic matching works for all possible possible; # genotypes and a variety of types of alleles.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:47,Energy Efficiency,efficient,efficiently,47,"# This test will time out if we aren't able to efficiently handle the case; # where we have a lot of candidate or truth variants but none of the other.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:7,Testability,test,test,7,"# This test will time out if we aren't able to efficiently handle the case; # where we have a lot of candidate or truth variants but none of the other.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Deployability,configurat,configurations,12,"# Check all configurations for the TRUTH enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Modifiability,config,configurations,12,"# Check all configurations for the TRUTH enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Deployability,configurat,configurations,12,"# Check all configurations for the CANDIDATES enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Modifiability,config,configurations,12,"# Check all configurations for the CANDIDATES enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Deployability,configurat,configurations,12,"# Check all configurations for the ONLY_HOM_REF enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:12,Modifiability,config,configurations,12,"# Check all configurations for the ONLY_HOM_REF enumeration:",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:22,Testability,test,test,22,"# TODO: retarget this test to a higher-level version of the API; # that accepts a whole region of variants so we make sure it divides up the; # problem into more fine-grained pieces that run quickly. The current call is; # to a lower-level API that doesn't do variant chunking.; # Commented out because this remains super slow.; # def test_super_slow_example(self):; # self.assertGetsCorrectLabels(; # candidates=[; # _test_variant(32274452, ['C', 'G']),; # _test_variant(32274453, ['T', 'G']),; # _test_variant(32274456, ['A', 'G']),; # _test_variant(32274459, ['C', 'G']),; # _test_variant(32274461, ['T', 'G']),; # _test_variant(32274465, ['GACA', 'G']),; # _test_variant(32274467, ['CA', 'C']),; # _test_variant(32274470, ['C', 'G']),; # _test_variant(32274473, ['A', 'G']),; # _test_variant(32274474, ['AC', 'A']),; # _test_variant(32274475, ['C', 'A']),; # _test_variant(32274477, ['T', 'A']),; # _test_variant(32274480, ['G', 'C']),; # ],; # true_variants=[; # _test_variant(32274470, ['C', 'G'], (1, 1)),; # ],; # ref=haplotype_labeler.ReferenceRegion(; # 'GCTGGAGGCGTGGGGACACCGGAACATAGGCCCCGCCCCGCCCCGACGC', 32274451),; # expected_genotypes=[; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [1, 1],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # ]); # Variants were getting incorrect genotypes in an exome callset.; #; # ref: AGACACACACACACAAAAAAAAATCATAAAATGAAG, start=214012389; # candidates 2:214012390:G->GAC; # candidates 2:214012402:CAA->C; # candidates 2:214012404:A->C; # true_variants 2:214012404:A->C; #; # 2:214012390:G->GAC => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012402:CAA->C => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012404:A->C => gt=(0, 0) new_label=0 old_label=2 alts=[0]; #; # 90--------- 0---------10--------20---; # pos : 90 1234567890123456789012345678901234; # ref : AG ACACACACACACAAAAAAAAATCATAAAATGAAG; # truth : C => AGACACACACACACACAAAAAAATCATAAAATGAAG; # DV 1 : GAC => [doesn't match]; # DV 2 :",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:374,Testability,assert,assertGetsCorrectLabels,374,"# TODO: retarget this test to a higher-level version of the API; # that accepts a whole region of variants so we make sure it divides up the; # problem into more fine-grained pieces that run quickly. The current call is; # to a lower-level API that doesn't do variant chunking.; # Commented out because this remains super slow.; # def test_super_slow_example(self):; # self.assertGetsCorrectLabels(; # candidates=[; # _test_variant(32274452, ['C', 'G']),; # _test_variant(32274453, ['T', 'G']),; # _test_variant(32274456, ['A', 'G']),; # _test_variant(32274459, ['C', 'G']),; # _test_variant(32274461, ['T', 'G']),; # _test_variant(32274465, ['GACA', 'G']),; # _test_variant(32274467, ['CA', 'C']),; # _test_variant(32274470, ['C', 'G']),; # _test_variant(32274473, ['A', 'G']),; # _test_variant(32274474, ['AC', 'A']),; # _test_variant(32274475, ['C', 'A']),; # _test_variant(32274477, ['T', 'A']),; # _test_variant(32274480, ['G', 'C']),; # ],; # true_variants=[; # _test_variant(32274470, ['C', 'G'], (1, 1)),; # ],; # ref=haplotype_labeler.ReferenceRegion(; # 'GCTGGAGGCGTGGGGACACCGGAACATAGGCCCCGCCCCGCCCCGACGC', 32274451),; # expected_genotypes=[; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [1, 1],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # ]); # Variants were getting incorrect genotypes in an exome callset.; #; # ref: AGACACACACACACAAAAAAAAATCATAAAATGAAG, start=214012389; # candidates 2:214012390:G->GAC; # candidates 2:214012402:CAA->C; # candidates 2:214012404:A->C; # true_variants 2:214012404:A->C; #; # 2:214012390:G->GAC => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012402:CAA->C => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012404:A->C => gt=(0, 0) new_label=0 old_label=2 alts=[0]; #; # 90--------- 0---------10--------20---; # pos : 90 1234567890123456789012345678901234; # ref : AG ACACACACACACAAAAAAAAATCATAAAATGAAG; # truth : C => AGACACACACACACACAAAAAAATCATAAAATGAAG; # DV 1 : GAC => [doesn't match]; # DV 2 :",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:2606,Testability,test,test,2606,"4, ['AC', 'A']),; # _test_variant(32274475, ['C', 'A']),; # _test_variant(32274477, ['T', 'A']),; # _test_variant(32274480, ['G', 'C']),; # ],; # true_variants=[; # _test_variant(32274470, ['C', 'G'], (1, 1)),; # ],; # ref=haplotype_labeler.ReferenceRegion(; # 'GCTGGAGGCGTGGGGACACCGGAACATAGGCCCCGCCCCGCCCCGACGC', 32274451),; # expected_genotypes=[; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [1, 1],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # [0, 0],; # ]); # Variants were getting incorrect genotypes in an exome callset.; #; # ref: AGACACACACACACAAAAAAAAATCATAAAATGAAG, start=214012389; # candidates 2:214012390:G->GAC; # candidates 2:214012402:CAA->C; # candidates 2:214012404:A->C; # true_variants 2:214012404:A->C; #; # 2:214012390:G->GAC => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012402:CAA->C => gt=(1, 1) new_label=2 old_label=0 alts=[0]; # 2:214012404:A->C => gt=(0, 0) new_label=0 old_label=2 alts=[0]; #; # 90--------- 0---------10--------20---; # pos : 90 1234567890123456789012345678901234; # ref : AG ACACACACACACAAAAAAAAATCATAAAATGAAG; # truth : C => AGACACACACACACACAAAAAAATCATAAAATGAAG; # DV 1 : GAC => [doesn't match]; # DV 2 : C-- => [doesn't match]; # DV 1+2 : AGACACACACACACAC AAAAAAATCATAAAATGAAG; # DV 1+2 : => AGACACACACACACACAAAAAAATCATAAAATGAAG [match]; # DV 3 : C => AGACACACACACACACAAAAAAATCATAAAATGAAG [match]; #; # So this is an interesting case. G->GAC + CAA->C matches the true haplotype,; # and the SNP itself gets assigned a FP status since we can have either two; # FPs (dv1 and dv2 candidates) or have just one (dv3). What's annoying here is; # that DV3 exactly matches the variant as described in the truth set. It's; # also strange that we've generated multiple equivalent potential variants; # here.; #; # This test ensures that we are picking the most parsimonous genotype; # assignment (e.g., fewest number of TPs) needed to explain the truth, after; # accounting for minimizing the number of FNs and FPs.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:7,Deployability,configurat,configuration,7,"# This configuration makes the most sense but we cannot choose it; # if we want to minimize the number of FNs, FPs, and then TPs.; # [0, 0],; # [0, 0],; # [1, 1],",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:7,Modifiability,config,configuration,7,"# This configuration makes the most sense but we cannot choose it; # if we want to minimize the number of FNs, FPs, and then TPs.; # [0, 0],; # [0, 0],; # [1, 1],",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:576,Testability,test,test,576,"# ref: GGGTGTGTGTGTGTGTGTGTGTGTGTGCGTGTGTGTGTTTGTGTTG, start=9508942; # candidates 20:9508943:GGT->G; # candidates 20:9508967:T->C/TGC; # candidates 20:9508967:T->C/TGC; # candidates 20:9508967:T->C/TGC; # true_variants 20:9508943:GGT->G [0, 1]; # true_variants 20:9508967:T->C/TGC [1, 2]; # 20:9508943:GGT->G => gt=(0, 0) new_label=0 old_label=1 alts=[0; # 20:9508967:T->C/TGC => gt=(1, 1) new_label=2 old_label=1 alts=[0]; # 20:9508967:T->C/TGC => gt=(1, 1) new_label=0 old_label=1 alts=[1]; # 20:9508967:T->C/TGC => gt=(1, 1) new_label=2 old_label=2 alts=[0, 1]; #; # This test fixes a bug where we weren't scoring our matches properly.; # Previously we were not accounting for FPs in our score, so we were taking; # a match with 0 FN, 1 FP, 1 TP over one with 0 FN, 0 FP, and 2 TP!; #; # 40------50--------60---------; # pos: 2345678901234567890123456789012345678901234567; # ref: GGGTGTGTGTGTGTGTGTGTGTGTGTGCGTGTGTGTGTTTGTGTTG; # t1: G--; # t2a: C; # t2b: Tgc; #",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py:7,Testability,test,test,7,"# This test checks that we can label end-to-end variants at occur at the; # start and at the end of a chromosome. This is unlikely in humans but can; # occur in bacterial genomes. See internal for a motivating example.",MatchSource.CODE_COMMENT,deepvariant/labeler/haplotype_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/haplotype_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:175,Availability,down,down,175,"""""""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:497,Safety,detect,detected,497,"""""""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:740,Safety,detect,detected,740,"""""""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:754,Testability,log,logic,754,"""""""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:596,Usability,simpl,simplification,596,"""""""Get a truth variant matching variant. A matching variant is defined here as one that starts at the same position; on the genome as variant. The best match is then narrowed down by finding; the variant with a matching alt allele, if it exists, otherwise the first; matching variant is used regardless of alt alleles. This allows the client; to make decisions on how to translate a matched between variant and; truth_variant into a label (e.g. by comparing the alleles). If multiple variants are detected, this code will attempt to find the best; match by comparing to `variant`. Note that some simplification of alleles; are applied first before we compare. For example, 'GAAA->GAA' should be the; same as 'GA->G'. If no good matches are detected, the logic currently falls; back to the first element in matches. Args:; variant: Our candidate third_party.nucleus.protos.Variant variant. Returns:; A tuple of (match_status, truth_variant) where match_status is True if; we are confident in our truth_variant call or False if not. truth_variant; is a third_party.nucleus.protos.Variant object of; the truth variant that matched; variant, or None if none was found and we aren't confident in being; hom-ref here, or a synthetic variant with the same position and alleles as; variant but with a hom-ref genotype.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:464,Integrability,rout,routine,464,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:497,Integrability,rout,routine,497,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:838,Integrability,rout,routine,838,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py:802,Usability,simpl,simplified,802,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py:9,Testability,test,tests,9,"# Simple tests: we get back our matching variants in the confident regions",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py:81,Usability,simpl,simplify,81,"# GAAA->GAA is the same as GA->A (the second one in matches), but if we; # don't simplify the alleles before comparing, there will be no match and; # will incorrectly fall back to the first one.",MatchSource.CODE_COMMENT,deepvariant/labeler/positional_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/positional_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:155,Safety,predict,predict,155,"""""""Computes the label value for an example using alt_alleles_indices. This function computes the TensorFlow label value (0, 1, 2) we train; DeepVariant to predict. The label value is an int >= which is the number of; copies of the alt allele present, which is computed from the true genotypes; (self.genotypes) and the alt_allele_indices ([0] for the first alt, [1] for; the second, [0, 1] to combine the first and second). For example, suppose we; have a variant with alts A and C, and a true genotype of (0, 1), indicating; that we have 1 copy of the A allele. We'd expect:. label_for_alt_alleles([0]) => 1 since there's 1 copy of the first alt.; label_for_alt_alleles([1]) => 0 since there's 0 copies of the second alt.; label_for_alt_alleles([0, 1]) => 1 since there's 1 copy of the first or; second allele. Args:; alt_alleles_indices: list[int]. A list of the alt_allele_indices used to; compute the tf.Example for this candidate. Returns:; int >= 0. The number of copies of alt_allele_indices we'd expect to be; called for this example.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:221,Security,access,accessible,221,"""""""BaseClass for systems that want to provide training labels for examples. A VariantLabeler provides methods to assign a genotype label to each of a; series of candidate variants using data from a truth set of variants; accessible with vcf_reader and an optional RangeSet of confident regions. The basic logic of this class is something like:. candidates = [third_party.nucleus.protos.Variant(...), ...]; labeler = ConcreteSubclassOfVariantLabeler(vcf_reader, confident_regions); for label in labeler.label_variants(candidates):; if label.is_confident:; for i in range(len(label.variant.alternate_bases); genotype_label_value = label.label_for_alt_alleles([i]). See the docs on each individual function to get a better understanding of what; each function does and the meaning of the return values.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:305,Testability,log,logic,305,"""""""BaseClass for systems that want to provide training labels for examples. A VariantLabeler provides methods to assign a genotype label to each of a; series of candidate variants using data from a truth set of variants; accessible with vcf_reader and an optional RangeSet of confident regions. The basic logic of this class is something like:. candidates = [third_party.nucleus.protos.Variant(...), ...]; labeler = ConcreteSubclassOfVariantLabeler(vcf_reader, confident_regions); for label in labeler.label_variants(candidates):; if label.is_confident:; for i in range(len(label.variant.alternate_bases); genotype_label_value = label.label_for_alt_alleles([i]). See the docs on each individual function to get a better understanding of what; each function does and the meaning of the return values.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:205,Availability,down,down,205,"""""""Gets truth variants within region to use in labeling calculations. This function queries _truth_vcf_reader in region to get a complete list of; truth variants that overlap region, and then filters them down by removing; filtered truth variants and ones that aren't contained in the truth; intervals. Args:; region: nucleus.Range proto describing the region on the genome where we; want to get our truth variants. Yields:; nucleus.Variant proto.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:464,Integrability,rout,routine,464,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:497,Integrability,rout,routine,497,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:838,Integrability,rout,routine,838,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py:802,Usability,simpl,simplified,802,"""""""Gets the diploid genotype for candidate_variant from matched truth_variant. This method figures out the genotype for candidate_variant by matching alleles; in candidate_variant with those used by the genotype assigned to; truth_variant. For example, if candidate is A/C and truth is A/C with a 0/1; genotype, then this function would return (0, 1) indicating that there's one; copy of the A allele and one of C in truth. If the true genotype is 1/1, then; this routine would return (1, 1). The routine allows candidate_variant and truth_variant to differ in both; the number of alternate alleles, and even in the representation of the same; alleles due to those differences. For example, candidate could be:. AGT/A/AGTGT => 2 bp deletion and 2 bp insertion. and truth could have:. A/AGT => just the simplified 2 bp insertion. And this routine will correctly equate the AGT/AGTGT allele in candidate; with the A/AGT in truth and use the number of copies of AGT in truth to; compute the number of copies of AGTGT when determining the returned genotype. Args:; candidate_variant: Our candidate third_party.nucleus.protos.Variant variant.; truth_variant: Our third_party.nucleus.protos.Variant truth variant; containing true alleles and genotypes. Returns:; A tuple genotypes with the same semantics at the genotype field of the; VariantCall proto. Raises:; ValueError: If candidate_variant is None, truth_variant is None, or; truth_variant doesn't have genotypes.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:150,Testability,test,tested,150,"""""""A placeholder VariantLabeler. This class provides a label_variants implementation and so allows the base; class to be instantiated and its methods tested.; """"""",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:16,Usability,simpl,simple,16,"# Checks that a simple query gets all our non-filtered variants.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:22,Testability,test,tests,22,"# Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:57,Usability,simpl,simplifying,57,"# Basic multi-allelic tests, without having to deal with simplifying; # alleles as all of the alleles are SNPs. Our candidates have an extra; # allele, but the true GT is A/C.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:33,Deployability,configurat,configuration,33,"# We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite as hom_var as; # we have two copies of the C/G alt.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:33,Modifiability,config,configuration,33,"# We are considering the het-alt configuration here of A vs. C+G. We've; # got one copy of the C allele so our true genotype is het. If truth is; # hom-var for the C, though, we again label the composite as hom_var as; # we have two copies of the C/G alt.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:122,Usability,simpl,simply,122,"# Here we have an extra allele in truth, while candidate is bi-allelic.; # This example 'G' is unused in truth, so we are simply the normal; # bi-allelic result.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py:42,Usability,simpl,simple,42,"# We have a multi-allelic candidate but a simple bi-allelic truth. Make; # sure we match correctly. This is an key case, as we should expect that; # our candidates frequently have extra alleles changing the represention; # relative to our truth candidates.",MatchSource.CODE_COMMENT,deepvariant/labeler/variant_labeler_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/labeler/variant_labeler_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/allelecounter_wrap_test.py:39,Integrability,wrap,wrappers,39,"""""""Tests for AlleleCounter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,deepvariant/python/allelecounter_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/allelecounter_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_multisample_wrap_test.py:40,Integrability,wrap,wrappers,40,"""""""Tests for VariantCalling CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,deepvariant/python/variant_calling_multisample_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_multisample_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_wrap_test.py:40,Integrability,wrap,wrappers,40,"""""""Tests for VariantCalling CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,deepvariant/python/variant_calling_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/python/variant_calling_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:85,Deployability,configurat,configuration,85,"# ---------------------------------------------------------------------------; # Set configuration settings.; # ---------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:85,Modifiability,config,configuration,85,"# ---------------------------------------------------------------------------; # Set configuration settings.; # ---------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:96,Deployability,configurat,configuration,96,"""""""Creates a WindowSelectorOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.WindowSelector protobuf. Raises:; ValueError: If either ws_{min,max}_supporting_reads are set and; ws_use_window_selector_model is True.; Or if ws_window_selector_model > ws_max_num_supporting_reads.; Or if ws_use_window_selector_model is False and; ws_window_selector_model is not None.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:96,Modifiability,config,configuration,96,"""""""Creates a WindowSelectorOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.WindowSelector protobuf. Raises:; ValueError: If either ws_{min,max}_supporting_reads are set and; ws_use_window_selector_model is True.; Or if ws_window_selector_model > ws_max_num_supporting_reads.; Or if ws_use_window_selector_model is False and; ws_window_selector_model is not None.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:91,Deployability,configurat,configuration,91,"""""""Creates a RealignerOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:91,Modifiability,config,configuration,91,"""""""Creates a RealignerOptions proto based on input and default settings. Args:; flags_obj: configuration FLAGS. Returns:; realigner_pb2.RealignerOptions protobuf. Raises:; ValueError: If we observe invalid flag values.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:329,Testability,log,logic,329,"# The normalize_reads flag could came from the `flags_obj` arg, passed in; # from make_examples_options.py. It is already part of AlleleCounterOptions in; # MakeExamplesOptions. Here, we need to set it in RealignerOptions as well; # because an if statement in fast_pass_aligner.cc needs it to decide whether; # to run a specific logic.; # This is not ideal. If there's a way to improve this, please do.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:75,Safety,safe,safe,75,"""""""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:135,Security,access,accessor,135,"""""""A region to assemble, holding the region Range and the reads. It is not safe to directly modify any of the attributes here. Use the accessor; functions to add a read to the reads. Attributes:; candidate_haplotypes: realigner.CandidateHaplotypes for this region.; reads: list[reads_pb2.Read]. Reads for this region.; region: range_pb2.Range. This is the span of the assembled region on the; genome.; read_span: range_pb2.Range. This is the span of reads added to this region.; The read_span in general is expected to be wider than the region itself,; since we often include all reads that overlap the region at all. It is; possible that read_span will be smaller than region, which can happen, for; example, when we only have reads starts in the middle of the region.; Here's a picture of when this can happen: ref : acgtACGTACgtgt region; : ------ read1 : GGa; read_span: ---; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:43,Performance,cache,cache,43,"# Adding a read invalidates our _read_span cache.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:208,Usability,learn,learning,208,"""""""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[AssemblyRegion], list of AssemblyRegion to assign; reads to. Does not assume AssemblyRegion are sorted.; reads: iterable[learning.genomics.genomics.Read], to be processed. Does not; assume the reads are sorted. Returns:; [AssemblyRegion], information on assigned reads for each assembled region.; list[learning.genomics.genomics.Read], the list of unassigned reads.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:389,Usability,learn,learning,389,"""""""Assign each read to the maximally overlapped window. Args:; assembled_regions: list[AssemblyRegion], list of AssemblyRegion to assign; reads to. Does not assume AssemblyRegion are sorted.; reads: iterable[learning.genomics.genomics.Read], to be processed. Does not; assume the reads are sorted. Returns:; [AssemblyRegion], information on assigned reads for each assembled region.; list[learning.genomics.genomics.Read], the list of unassigned reads.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:35,Modifiability,config,config,35,"""""""Creates a new Realigner. Args:; config: realigner_pb2.RealignerOptions protobuf.; ref_reader: GenomeReferenceFai, indexed reference genome to query bases.; shared_header: header info from the input bam file; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:13,Usability,simpl,simple,13,"# Create our simple container to store candidate / read mappings.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:312,Energy Efficiency,reduce,reduced,312,"# Testing found that when the prefix and suffix both go right up to the; # ref/alt variants, the alignment does not work well, so a margin of 100; # bases on each side of the variant are used here to pad each; # haplotype with enough sequence to align against. While some further; # testing showed this could be reduced, 100 is the only value that has been; # tested with a full training experiment.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:283,Testability,test,testing,283,"# Testing found that when the prefix and suffix both go right up to the; # ref/alt variants, the alignment does not work well, so a margin of 100; # bases on each side of the variant are used here to pad each; # haplotype with enough sequence to align against. While some further; # testing showed this could be reduced, 100 is the only value that has been; # tested with a full training experiment.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:360,Testability,test,tested,360,"# Testing found that when the prefix and suffix both go right up to the; # ref/alt variants, the alignment does not work well, so a margin of 100; # bases on each side of the variant are used here to pad each; # haplotype with enough sequence to align against. While some further; # testing showed this could be reduced, 100 is the only value that has been; # tested with a full training experiment.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:15,Availability,down,down,15,"""""""Trim a read down to the part that aligns within a given region. The following properties of the read are updated, trimming on both sides as; necessary to save only the parts of the read that fit fully within the; region, potentially starting and ending at the region's boundaries:; - The alignment position (read.alignment.position.position).; - The read sequence (read.aligned_sequence).; - Base qualities (read.aligned_quality).; - The cigar string of the alignment (read.alignment.cigar). Args:; read: A `nucleus.protos.Read` that is aligned to the region.; region: A `nucleus.protos.Range` region. Returns:; a new `nucleus.protos.Read` trimmed to the region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:108,Deployability,update,updated,108,"""""""Trim a read down to the part that aligns within a given region. The following properties of the read are updated, trimming on both sides as; necessary to save only the parts of the read that fit fully within the; region, potentially starting and ending at the region's boundaries:; - The alignment position (read.alignment.position.position).; - The read sequence (read.aligned_sequence).; - Base qualities (read.aligned_quality).; - The cigar string of the alignment (read.alignment.cigar). Args:; read: A `nucleus.protos.Read` that is aligned to the region.; region: A `nucleus.protos.Range` region. Returns:; a new `nucleus.protos.Read` trimmed to the region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:34,Integrability,message,message,34,"# Direct assignment on a repeated message field is not allowed, so setting; # the cigar by using 'extend'.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py:98,Modifiability,extend,extend,98,"# Direct assignment on a repeated message field is not allowed, so setting; # the cigar by using 'extend'.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:14,Testability,test,tests,14,"# Single read tests.; # read1 overlaps r1.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:25,Modifiability,extend,extends,25,"# read4 starts in r3 but extends beyond it.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:19,Testability,test,tests,19,"# TODO: Update the tests to reflect the new default (False).",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:86,Modifiability,parameteriz,parameterized,86,"# This indirection is needed because the symbols in testdata are not set; # when the @parameterized decorator is called.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:52,Testability,test,testdata,52,"# This indirection is needed because the symbols in testdata are not set; # when the @parameterized decorator is called.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:88,Integrability,depend,depends,88,"# At or below read_buffer_length=15 the reads start to come back; # unaligned, but this depends on the specific ref and alt alleles, so; # this does not include exhaustive tests for how low these values can go.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:172,Testability,test,tests,172,"# At or below read_buffer_length=15 the reads start to come back; # unaligned, but this depends on the specific ref and alt alleles, so; # this does not include exhaustive tests for how low these values can go.",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py:57,Availability,down,down,57,"# Start with long prefix and suffix to enable cutting it down as necessary",MatchSource.CODE_COMMENT,deepvariant/realigner/realigner_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/realigner_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:31,Performance,perform,perform,31,"""""""Determine genomic ranges to perform local assembly.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:49,Modifiability,config,config,49,"""""""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:494,Modifiability,config,config,494,"""""""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:57,Usability,learn,learning,57,"""""""Returns a list of candidate positions. Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: list[nucleus.protos.Read]. The reads we are processing into candidate; positions.; region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region. Raises:; ValueError: if config.window_selector_model.model_type isn't a valid enum; name in realigner_pb2.WindowSelectorModel.ModelType.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:574,Usability,learn,learning,574,"""""""Returns a list of candidate positions. Following cigar operations generate candidate position:; - ALIGNMENT_MATCH, SEQUENCE_MISMATCH, SEQUENCE_MATCH: at mismatch positions; in the read when compared to the reference sequence.; - DELETE: at positions within [cigar_start, cigar_start + cigar_len); - INSERT, CLIP_SOFT: at positions within; [cigar_start - cigar_len, cigar_start + cigar_len). Note. Function implementation has changed to return positions beyond input; region in case we have variants there. See the change at internal and; internal. Args:; allele_counter: learning.genomics.deepvariant.realigner.AlleleCounter in the; considered region.; model_conf: learning.genomics.deepvariant.realigner; .WindowSelectorOptions.VariantReadsThresholdModel options determining the; behavior of this window selector.; expanded_region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:668,Usability,learn,learning,668,"""""""Returns a list of candidate positions. Following cigar operations generate candidate position:; - ALIGNMENT_MATCH, SEQUENCE_MISMATCH, SEQUENCE_MATCH: at mismatch positions; in the read when compared to the reference sequence.; - DELETE: at positions within [cigar_start, cigar_start + cigar_len); - INSERT, CLIP_SOFT: at positions within; [cigar_start - cigar_len, cigar_start + cigar_len). Note. Function implementation has changed to return positions beyond input; region in case we have variants there. See the change at internal and; internal. Args:; allele_counter: learning.genomics.deepvariant.realigner.AlleleCounter in the; considered region.; model_conf: learning.genomics.deepvariant.realigner; .WindowSelectorOptions.VariantReadsThresholdModel options determining the; behavior of this window selector.; expanded_region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:573,Usability,learn,learning,573,"""""""Returns a list of candidate positions. Candidate positions for realignment are generated by scoring each location.; The score at a location is a weighted sum of the number of reads with each; CIGAR operation at the location, where the weights are determined by the model; coefficients. Locations whose score exceed the model decision boundary value; are used to create realignment windows. Note. Function implementation has changed to return positions beyond input; region in case we have variants there. See the change at internal and; internal. Args:; allele_counter: learning.genomics.deepvariant.realigner.AlleleCounter in the; considered region.; model_conf: learning.genomics.deepvariant.realigner; .WindowSelectorOptions.AlleleCountLinearModel options determining the; behavior of this window selector.; expanded_region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:667,Usability,learn,learning,667,"""""""Returns a list of candidate positions. Candidate positions for realignment are generated by scoring each location.; The score at a location is a weighted sum of the number of reads with each; CIGAR operation at the location, where the weights are determined by the model; coefficients. Locations whose score exceed the model decision boundary value; are used to create realignment windows. Note. Function implementation has changed to return positions beyond input; region in case we have variants there. See the change at internal and; internal. Args:; allele_counter: learning.genomics.deepvariant.realigner.AlleleCounter in the; considered region.; model_conf: learning.genomics.deepvariant.realigner; .WindowSelectorOptions.AlleleCountLinearModel options determining the; behavior of this window selector.; expanded_region: nucleus.protos.Range. The region we are processing. Returns:; A list. The elements are reference positions within region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:114,Modifiability,config,config,114,"""""""""Process candidate positions to determine windows for local assembly. Windows are within range of; [min(pos) - config.min_windows_distance,; max(pos) + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; candidate_pos: A list of ref_pos.; ref_name: Reference name, used in setting the output; genomics.range.reference_name value. Returns:; A sorted list of nucleus.protos.Range protos for all windows in this region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:155,Modifiability,config,config,155,"""""""""Process candidate positions to determine windows for local assembly. Windows are within range of; [min(pos) - config.min_windows_distance,; max(pos) + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; candidate_pos: A list of ref_pos.; ref_name: Reference name, used in setting the output; genomics.range.reference_name value. Returns:; A sorted list of nucleus.protos.Range protos for all windows in this region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:192,Modifiability,config,config,192,"""""""""Process candidate positions to determine windows for local assembly. Windows are within range of; [min(pos) - config.min_windows_distance,; max(pos) + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; candidate_pos: A list of ref_pos.; ref_name: Reference name, used in setting the output; genomics.range.reference_name value. Returns:; A sorted list of nucleus.protos.Range protos for all windows in this region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:200,Usability,learn,learning,200,"""""""""Process candidate positions to determine windows for local assembly. Windows are within range of; [min(pos) - config.min_windows_distance,; max(pos) + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; candidate_pos: A list of ref_pos.; ref_name: Reference name, used in setting the output; genomics.range.reference_name value. Returns:; A sorted list of nucleus.protos.Range protos for all windows in this region.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:103,Modifiability,config,config,103,"""""""""Process reads to determine candidate windows for local assembly. Windows are within range of; [0 - config.min_windows_distance, ref_len + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: A list of genomics.Read records.; region: nucleus.protos.Range. The region we are processing. Returns:; A list of nucleus.protos.Range protos sorted by their genomic position.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:142,Modifiability,config,config,142,"""""""""Process reads to determine candidate windows for local assembly. Windows are within range of; [0 - config.min_windows_distance, ref_len + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: A list of genomics.Read records.; region: nucleus.protos.Range. The region we are processing. Returns:; A list of nucleus.protos.Range protos sorted by their genomic position.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:179,Modifiability,config,config,179,"""""""""Process reads to determine candidate windows for local assembly. Windows are within range of; [0 - config.min_windows_distance, ref_len + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: A list of genomics.Read records.; region: nucleus.protos.Range. The region we are processing. Returns:; A list of nucleus.protos.Range protos sorted by their genomic position.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py:187,Usability,learn,learning,187,"""""""""Process reads to determine candidate windows for local assembly. Windows are within range of; [0 - config.min_windows_distance, ref_len + config.min_windows_distance). Args:; config: learning.genomics.deepvariant.realigner.WindowSelectorOptions; options determining the behavior of this window selector.; ref_reader: GenomeReference. Indexed reference genome to query bases.; reads: A list of genomics.Read records.; region: nucleus.protos.Range. The region we are processing. Returns:; A list of nucleus.protos.Range protos sorted by their genomic position.; """"""",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:114,Testability,test,test,114,"# ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:98,Usability,simpl,simple,98,"# ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:82,Usability,simpl,simple,82,"# --------------------------------------------------; # Systematic combination of simple CIGAR operations.; # --------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:114,Testability,test,test,114,"# ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:98,Usability,simpl,simple,98,"# ------------------------------------------------------------------------; # These reads are all simple and just test the basic position calculation.; # ------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:90,Testability,test,test,90,"# ------------------------------------------------------------------------; # These reads test that we correctly ignore bases with low qualities.; # ------------------------------------------------------------------------",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:17,Testability,test,test,17,"# Systematically test all combinations of cigar operations and positions in a; # read.",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:195,Testability,test,test,195,"# The python version raises an exception when seeing a PAD, which is ok; # but isn't strictly necessary. The C++ implementation handles PADs when; # counting alleles, so we've commented out this test.; # C++ version:; # dict(bases='AA', cigar='1M1P1M', expected=[]),; # dict(bases='AA', cigar='1M2P1M', expected=[]),; # Python version:; # dict(bases='AA', cigar='1M1P1M', expected=ValueError),; # dict(bases='AA', cigar='1M2P1M', expected=ValueError),",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:173,Modifiability,extend,extended,173,"# Our region is 5-8 and we are testing that the read's mismatch is only; # included when it's within the region and not when it's outside.; # Expected region boundaries are extended according to region_expansion_in_bp; # flag. region_expansion_in_bp is set to 20 by default,; # so 5 to 8 becomes 5 - 20 to 8 + 20 <=> 0 to 28",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:31,Testability,test,testing,31,"# Our region is 5-8 and we are testing that the read's mismatch is only; # included when it's within the region and not when it's outside.; # Expected region boundaries are extended according to region_expansion_in_bp; # flag. region_expansion_in_bp is set to 20 by default,; # so 5 to 8 becomes 5 - 20 to 8 + 20 <=> 0 to 28",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:203,Modifiability,extend,extended,203,"# Our region is 5-8 and we have a 4 basepair deletion in our read. We expect; # a mismatch count of one for each position in the deletion that overlaps the; # interval.; # Expected region boundaries are extended according to region_expansion_in_bp; # flag. region_expansion_in_bp is set to 20 by default,; # so 5 to 8 becomes 5 - 20 to 8 + 20 <=> 0 to 28",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:10,Usability,simpl,simple,10,"# Check a simple example where we have two candidates from the same; # region:",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:10,Usability,simpl,simple,10,"# Check a simple example where we have candidates from two regions:",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py:20,Testability,test,test,20,"# Simple end-to-end test of the high-level select_windows function. We give; # it a few reads with a single candidate at 100 and we expect a window back; # centered at 100.",MatchSource.CODE_COMMENT,deepvariant/realigner/window_selector_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/window_selector_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:23,Integrability,wrap,wrapped,23,"""""""Basic tests for the wrapped DeBruijnGraph class.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:9,Testability,test,tests,9,"""""""Basic tests for the wrapped DeBruijnGraph class.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:45,Safety,avoid,avoid,45,"# Remove all whitespace before comparison to avoid failing over trivial; # indentation / newline differences.",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:24,Testability,test,test,24,"""""""This is a regression test for internal.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:24,Testability,test,test,24,"""""""This is a regression test for internal.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py:33,Safety,detect,detector,33,"# Actual example where the cycle detector failed because the cycle only; # occurs with the last kmer in the reference.",MatchSource.CODE_COMMENT,deepvariant/realigner/python/debruijn_graph_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/debruijn_graph_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_misc_test.py:17,Integrability,wrap,wrapped,17,"""""""Tests for the wrapped SSW aligner in a way that fails with gcc5.4.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_misc_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_misc_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py:23,Integrability,wrap,wrapped,23,"""""""Basic tests for the wrapped SSW aligner.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py:9,Testability,test,tests,9,"""""""Basic tests for the wrapped SSW aligner.""""""",MatchSource.CODE_COMMENT,deepvariant/realigner/python/ssw_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/realigner/python/ssw_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py:142,Modifiability,variab,variable,142,"""""""Resets and starts a timer. This allows Timer to be used as a ContextManager type. Returns:; The object itself so that it can be bound to a variable in a with; statement.; """"""",MatchSource.CODE_COMMENT,deepvariant/vendor/timer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py
https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py:91,Integrability,interface,interface,91,"""""""A timer that automatically starts when you construct it. This is otherwise identical in interface to the Timer class in this module.; """"""",MatchSource.CODE_COMMENT,deepvariant/vendor/timer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/deepvariant/vendor/timer.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:194,Availability,avail,available,194,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:396,Deployability,release,released,396,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:442,Deployability,release,released,442,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:167,Security,access,access,167,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script is used to run DeepSomatic, which is an extension of DeepVariant.; If you want to access more flags that are available in `make_examples_somatic`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. DeepSomatic is not officially supported or released yet. This script does not; include a released model yet.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:10,Deployability,release,release,10,"# Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:45,Testability,log,logfile,45,"""""""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples_somatic. Returns:; (string, string) A command to run, and a log file to output to.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:491,Testability,log,log,491,"""""""Returns a make_examples_somatic (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads_tumor: Input tumor BAM file.; reads_normal: Input normal BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples_somatic. Returns:; (string, string) A command to run, and a log file to output to.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:37,Testability,log,logfile,37,"""""""Returns a call_variants (command, logfile) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:44,Testability,log,logfile,44,"""""""Returns a postprocess_variants (command, logfile) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:40,Testability,log,logfile,40,"""""""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base.; title: Passed straight to command unless it's None. Returns:; [command string for subprocess, optional log directory path]; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:275,Testability,log,log,275,"""""""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base.; title: Passed straight to command unless it's None. Returns:; [command string for subprocess, optional log directory path]; """"""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:45,Testability,log,logfile,45,"""""""Returns a runtime_by_region_vis (command, logfile=None) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:14,Testability,log,logic,14,"""""""Additional logic to make sure flags are set appropriately.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:32,Availability,checkpoint,checkpoint,32,"""""""Return the path to the model checkpoint based on the input args.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py:23,Testability,log,logfile,23,"""""""Creates 3 (command, logfile) to be executed later.""""""",MatchSource.CODE_COMMENT,scripts/run_deepsomatic.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepsomatic.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:200,Availability,avail,available,200,"""""""Runs all 3 steps to go from input DNA reads_child to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image.; """"""",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:173,Security,access,access,173,"""""""Runs all 3 steps to go from input DNA reads_child to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image.; """"""",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:41,Deployability,release,release,41,"# TODO: Change to True as default before release.",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:10,Deployability,release,release,10,"# Current release version of DeepTrio.; # Should be the same in dv_vcf_constants.py.",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:44,Safety,avoid,avoid,44,"# Should be approximately read; # length to avoid having high; # coverage intervals in multiple shards at a time",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:14,Testability,log,logic,14,"""""""Additional logic to make sure flags are set appropriately.""""""",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py:32,Availability,checkpoint,checkpoint,32,"""""""Return the path to the model checkpoint based on the input args.""""""",MatchSource.CODE_COMMENT,scripts/run_deeptrio.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py:53,Integrability,message,messages,53,"# Confirm that these basic commands don't have extra messages printed out; # to stdout.",MatchSource.CODE_COMMENT,scripts/run_deeptrio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py:28,Testability,assert,assert,28,"# pylint: disable=g-generic-assert; # Because PACBIO model will always have use_candidate_partition on,; # so there will be one extra make_examples command.",MatchSource.CODE_COMMENT,scripts/run_deeptrio_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deeptrio_test.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:194,Availability,avail,available,194,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:167,Security,access,access,167,"""""""Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. This script currently provides the most common use cases and standard models.; If you want to access more flags that are available in `make_examples`,; `call_variants`, and `postprocess_variants`, you can also call them separately; using the binaries in the Docker image. For more details, see:; https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:41,Deployability,release,release,41,"# TODO: Change to True as default before release.",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:10,Deployability,release,release,10,"# Current release version of DeepVariant.; # Should be the same in dv_vcf_constants.py.",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:37,Testability,log,logfile,37,"""""""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string, string) A command to run, and a log file to output to.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:425,Testability,log,log,425,"""""""Returns a make_examples (command, logfile) for subprocess. Args:; ref: Input FASTA file.; reads: Input BAM file.; examples: Output tfrecord file containing tensorflow.Example files.; extra_args: Comma-separated list of flag_name=flag_value.; runtime_by_region_path: Output path for runtime by region metrics.; **kwargs: Additional arguments to pass in for make_examples. Returns:; (string, string) A command to run, and a log file to output to.; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:37,Testability,log,logfile,37,"""""""Returns a call_variants (command, logfile) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:44,Testability,log,logfile,44,"""""""Returns a postprocess_variants (command, logfile) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:40,Testability,log,logfile,40,"""""""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base.; title: Passed straight to command unless it's None. Returns:; [command string for subprocess, optional log directory path]; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:275,Testability,log,log,275,"""""""Returns a vcf_stats_report (command, logfile) for subprocess. Args:; vcf_path: Path to VCF, which will be passed to --input_vcf and; suffix-trimmed for --outfile_base.; title: Passed straight to command unless it's None. Returns:; [command string for subprocess, optional log directory path]; """"""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:45,Testability,log,logfile,45,"""""""Returns a runtime_by_region_vis (command, logfile=None) for subprocess.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:14,Testability,log,logic,14,"""""""Additional logic to make sure flags are set appropriately.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:32,Availability,checkpoint,checkpoint,32,"""""""Return the path to the model checkpoint based on the input args.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py:23,Testability,log,logfile,23,"""""""Creates 3 (command, logfile) to be executed later.""""""",MatchSource.CODE_COMMENT,scripts/run_deepvariant.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/scripts/run_deepvariant.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py:11,Integrability,wrap,wrapper,11,"# See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello')",MatchSource.CODE_COMMENT,third_party/nucleus/core/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py:119,Testability,assert,assertEqual,119,"# See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello')",MatchSource.CODE_COMMENT,third_party/nucleus/core/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/statusor_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py:11,Integrability,wrap,wrapper,11,"# See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello')",MatchSource.CODE_COMMENT,third_party/nucleus/core/python/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py:119,Testability,assert,assertEqual,119,"# See CLIF wrapper for a discussion of why this is commented out.; # def test_make_str_ok_stripped_type(self):; # self.assertEqual(statusor_examples.MakeStrOKStrippedType(), 'hello')",MatchSource.CODE_COMMENT,third_party/nucleus/core/python/statusor_examples_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/core/python/statusor_examples_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bed.py:369,Integrability,protocol,protocol,369,"""""""Classes for reading and writing BED files. The BED format is described at; https://genome.ucsc.edu/FAQ/FAQformat.html#format1. API for reading:. ```python; from third_party.nucleus.io import bed. # Iterate through all records.; with bed.BedReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bed; from third_party.nucleus.protos import bed_pb2. # records is an iterable of nucleus.genomics.v1.BedRecord protocol buffers.; records = ... # header defines how many fields to write out.; header = bed_pb2.BedHeader(num_fields=5). # Write all records to the desired output path.; with bed.BedWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BED file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true BED file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/bed.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bed.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bed.py:561,Integrability,protocol,protocol,561,"""""""Classes for reading and writing BED files. The BED format is described at; https://genome.ucsc.edu/FAQ/FAQformat.html#format1. API for reading:. ```python; from third_party.nucleus.io import bed. # Iterate through all records.; with bed.BedReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bed; from third_party.nucleus.protos import bed_pb2. # records is an iterable of nucleus.genomics.v1.BedRecord protocol buffers.; records = ... # header defines how many fields to write out.; header = bed_pb2.BedHeader(num_fields=5). # Write all records to the desired output path.; with bed.BedWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BED file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true BED file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/bed.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bed.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bedgraph.py:397,Integrability,protocol,protocol,397,"""""""Classes for reading and writing BedGraph files. The BedGraph format is described at; https://genome.ucsc.edu/goldenpath/help/bedgraph.html. API for reading:. ```python; from third_party.nucleus.io import bedgraph. # Iterate through all records.; with bed.BedGraphReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedGraphRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bedgraph; from third_party.nucleus.protos import bedgraph_pb2. # records is an iterable of nucleus.genomics.v1.BedGraphRecord protocol buffers.; records = ... # Write all records to the desired output path.; with bed.BedGraphWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BedGraph file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a BedGraph file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/bedgraph.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bedgraph.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bedgraph.py:604,Integrability,protocol,protocol,604,"""""""Classes for reading and writing BedGraph files. The BedGraph format is described at; https://genome.ucsc.edu/goldenpath/help/bedgraph.html. API for reading:. ```python; from third_party.nucleus.io import bedgraph. # Iterate through all records.; with bed.BedGraphReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.BedGraphRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import bedgraph; from third_party.nucleus.protos import bedgraph_pb2. # records is an iterable of nucleus.genomics.v1.BedGraphRecord protocol buffers.; records = ... # Write all records to the desired output path.; with bed.BedGraphWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true BedGraph file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a BedGraph file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/bedgraph.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/bedgraph.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py:219,Testability,benchmark,benchmark,219,"""""""A universal converter program for nucleus-supported genomics file formats. Invoked with a single argument, this program will open a genomics data file and; iterate over its contents, doing no writing. This is a good benchmark for I/O; and reader processing speed. Invoked with two arguments, the program will open the first file, read its; records, and write them, one at a time, to the second file. The filetypes for; the first and second filename must be compatible ways of encoding the same; nucleus genomics record type (for example, `infile.gff` and; `outfile.gff.tfrecord.gz` are compatible, but `infile.gff` and `outfile.bam` are; not. Note: at present we have no convention for encoding a file *header* in; tfrecords, so conversion is not possible from tfrecord to any native file format; for which a header is compulsory.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py:47,Availability,error,error,47,"""""""An exception used to signal file conversion error.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:71,Testability,test,tests,71,"""""""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:127,Testability,test,tests,127,"""""""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:226,Testability,test,tests,226,"""""""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:232,Usability,simpl,simply,232,"""""""Tests for third_party.nucleus.examples.convert_genomics_file. These tests do NOT establish the correctness of conversions---tests of the; fidelity of the Reader and Writer classes exist elsewhere in Nucleus. Rather,; these tests simply exercise that the conversion *runs* for each input/output; file type.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:168,Availability,error,error,168,"# Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py:174,Integrability,message,message,174,"# Test conversion from tfrecord format back to native format. Ensure that; # conversions where we would need a header, but don't have one from the; # input, trigger an error message.",MatchSource.CODE_COMMENT,third_party/nucleus/io/converter_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/converter_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:33,Integrability,protocol,protocol,33,"# TODO: Replace this with a real protocol buffer definition.",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:239,Performance,cache,cache,239,"""""""Initializes an IndexedFastaReader. Args:; input_path: string. A path to a resource containing FASTA records.; keep_true_case: bool. If False, casts all bases to uppercase before; returning them.; cache_size: integer. Number of bases to cache from previous queries.; Defaults to 64K. The cache can be disabled using cache_size=0.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:290,Performance,cache,cache,290,"""""""Initializes an IndexedFastaReader. Args:; input_path: string. A path to a resource containing FASTA records.; keep_true_case: bool. If False, casts all bases to uppercase before; returning them.; cache_size: integer. Number of bases to cache from previous queries.; Defaults to 64K. The cache can be disabled using cache_size=0.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:30,Performance,cache,cache,30,"# Use the C++-defined default cache size.",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:253,Performance,cache,cache,253,"""""""An `IndexedFastaReader` getting its bases from an in-memory data structure. An `InMemoryFastaReader` provides the same API as `IndexedFastaReader` but; doesn't fetch its data from an on-disk FASTA file but rather fetches the bases; from an in-memory cache containing (chromosome, start, bases) tuples. In particular, the `query(Range(chrom, start, end))` operation fetches bases; from the tuple where `chrom` == chromosome, and then from the bases where the; first base of bases starts at start. If start > 0, then the bases string is; assumed to contain bases starting from that position in the region. For; example, the record ('1', 10, 'ACGT') implies that; `query(ranges.make_range('1', 11, 12))` will return the base 'C', as the 'A'; base is at position 10. This makes it straightforward to cache a small region; of a full chromosome without having to store the entire chromosome sequence in; memory (potentially big!).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py:799,Performance,cache,cache,799,"""""""An `IndexedFastaReader` getting its bases from an in-memory data structure. An `InMemoryFastaReader` provides the same API as `IndexedFastaReader` but; doesn't fetch its data from an on-disk FASTA file but rather fetches the bases; from an in-memory cache containing (chromosome, start, bases) tuples. In particular, the `query(Range(chrom, start, end))` operation fetches bases; from the tuple where `chrom` == chromosome, and then from the bases where the; first base of bases starts at start. If start > 0, then the bases string is; assumed to contain bases starting from that position in the region. For; example, the record ('1', 10, 'ACGT') implies that; `query(ranges.make_range('1', 11, 12))` will return the base 'C', as the 'A'; base is at position 10. This makes it straightforward to cache a small region; of a full chromosome without having to store the entire chromosome sequence in; memory (potentially big!).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta_test.py:50,Safety,detect,detects,50,"# Spans into the start of the bases; make sure it detects it's bad.",MatchSource.CODE_COMMENT,third_party/nucleus/io/fasta_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fasta_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fastq.py:341,Integrability,protocol,protocol,341,"""""""Classes for reading and writing FASTQ files. The FASTQ format is described at; https://en.wikipedia.org/wiki/FASTQ_format. API for reading:. ```python; from third_party.nucleus.io import fastq. with fastq.FastqReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.FastqRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import fastq. # records is an iterable of nucleus.genomics.v1.FastqRecord protocol buffers.; records = ... with fastq.FastqWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true FASTQ file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true FASTQ file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fastq.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fastq.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fastq.py:489,Integrability,protocol,protocol,489,"""""""Classes for reading and writing FASTQ files. The FASTQ format is described at; https://en.wikipedia.org/wiki/FASTQ_format. API for reading:. ```python; from third_party.nucleus.io import fastq. with fastq.FastqReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.FastqRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import fastq. # records is an iterable of nucleus.genomics.v1.FastqRecord protocol buffers.; records = ... with fastq.FastqWriter(output_path) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true FASTQ file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true FASTQ file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/fastq.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/fastq.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py:27,Modifiability,plugin,plugin,27,"""""""Tests for genomics_io's plugin system.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py:30,Availability,error,error,30,"""""""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py:45,Modifiability,plugin,plugin,45,"""""""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py:59,Performance,load,load,59,"""""""Test that we get the right error when the plugin cannot load.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_io_noplugin_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_io_noplugin_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:28,Integrability,interface,interface,28,"""""""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:390,Integrability,protocol,protocol,390,"""""""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:613,Integrability,protocol,protocol,613,"""""""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:697,Integrability,depend,dependent,697,"""""""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:341,Usability,usab,usable,341,"""""""Classes that provide the interface for reading genomics data. `GenomicsReader` defines the core API supported by readers, and is subclassed; directly or indirectly (via `DispatchingGenomicsReader`) for all concrete; implementations. `TFRecordReader` is an implementation of the `GenomicsReader` API for reading; `TFRecord` files. This is usable for all data types when encoding data in; protocol buffers. `DispatchingGenomicsReader` is an abstract class defined for convenience on top; of `GenomicsReader` that supports reading from either the native file format or; from `TFRecord` files of the corresponding protocol buffer used to encode data; of that file type. The input format assumed is dependent upon the filename of; the input data. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. The instantiation of readers; may have reader-specific requirements documented there. General examples of the; `iterate()` and `query()` functionality are shown below. ```python; # Equivalent ways to iterate through all elements in a reader.; # 1. Using the reader itself as an iterable object.; kwargs = ... # Reader-specific keyword arguments.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader:; do_something(reader.header, proto). # 2. Calling the iterate() method of the reader explicitly.; with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.iterate():; do_something(reader.header, proto). # Querying for all elements within a specific region of the genome.; from third_party.nucleus.protos import range_pb2; region = range_pb2.Range(reference_name='chr1', start=10, end=20). with GenomicsReaderSubClass(output_path, **kwargs) as reader:; for proto in reader.query(region):; do_something(reader.header, proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:146,Modifiability,variab,variable,146,"""""""Abstract base class for reading genomics data. In addition to the abstractmethods defined below, subclasses should; also set a `header` member variable in their objects.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:31,Integrability,protocol,protocol,31,"""""""A GenomicsReader that reads protocol buffers from a TFRecord file. Example usage:; reader = TFRecordReader('/tmp/my_file.tfrecords.gz',; proto=tensorflow.Example); for example in reader:; process(example). Note that TFRecord files do not have headers, and do not need; to be wrapped in a ""with"" block.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:278,Integrability,wrap,wrapped,278,"""""""A GenomicsReader that reads protocol buffers from a TFRecord file. Example usage:; reader = TFRecordReader('/tmp/my_file.tfrecords.gz',; proto=tensorflow.Example); for example in reader:; process(example). Note that TFRecord files do not have headers, and do not need; to be wrapped in a ""with"" block.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:100,Integrability,protocol,protocol,100,"""""""Initializes the TFRecordReader. Args:; input_path: The filename of the file to read.; proto: The protocol buffer type the TFRecord file is expected to; contain. For example, variants_pb2.Variant or reads_pb2.Read.; compression_type: Either 'ZLIB', 'GZIP', '' (uncompressed), or; None. If None, __init__ will guess the compression type based on; the input_path's suffix. Raises:; IOError: if there was any problem opening input_path for reading.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:212,Security,access,access,212,"""""""Returns an iterator for going through the records in the region. NOTE: This function is not currently implemented by TFRecordReader as the; TFRecord format does not provide a general mechanism for fast random access; to elements in genome order.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py:15,Integrability,protocol,protocol,15,"""""""Returns the protocol buffer type used by this reader.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_reader.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_reader.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:28,Integrability,interface,interface,28,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:400,Integrability,protocol,protocol,400,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:619,Integrability,protocol,protocol,619,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:703,Integrability,depend,dependent,703,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:1060,Integrability,protocol,protocol,1060,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:341,Usability,usab,usable,341,"""""""Classes that provide the interface for writing genomics data. `GenomicsWriter` defines the core API supported by writers, and is subclassed; directly or indirectly (via `DispatchingGenomicsWriter`) for all concrete; implementations. `TFRecordWriter` is an implementation of the `GenomicsWriter` API for reading; `TFRecord` files. This is usable for all data types when writing data as; serialized protocol buffers. `DispatchingGenomicsWriter` is an abstract class defined for convenience on top; of `GenomicsWriter` that supports writing to either the native file format or to; `TFRecord` files of the corresponding protocol buffer used to encode data of; that file type. The output format chosen is dependent upon the filename to which; the data are being written. Concrete implementations for individual file types (e.g. BED, SAM, VCF, etc.); reside in type-specific modules in this package. A general example of the write; functionality is shown below. ```python; # options is a writer-specific set of options.; options = ... # records is an iterable of protocol buffers of the specific data type.; records = ... with GenomicsWriterSubClass(output_path, options) as writer:; for proto in records:; writer.write(proto); ```; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:118,Integrability,protocol,protocol,118,"""""""Abstract base class for writing genomics data. A GenomicsWriter only has one method, write, which writes a single; protocol buffer to a file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:45,Integrability,protocol,protocol,45,"""""""Writes proto to the file. Args:; proto: A protocol buffer.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:69,Integrability,protocol,protocol,69,"""""""Writes proto to the file with somatic processing. Args:; proto: A protocol buffer.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:212,Integrability,wrap,wrapped,212,"""""""A GenomicsWriter that writes to a TFRecord file. Example usage:; writer = TFRecordWriter('/tmp/my_output.tfrecord.gz'); for record in records:; writer.write(record). Note that TFRecord files do not need to be wrapped in a ""with"" block.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:233,Integrability,depend,depend,233,"""""""Initializer. Args:; output_path: str. The output path to which the records are written.; header: An optional header for the particular data type. This can be; useful for file types that have logical headers where some operations; depend on that header information (e.g. VCF using its headers to; determine type information of annotation fields).; compression_type: Either 'ZLIB', 'GZIP', '' (uncompressed), or; None. If None, __init__ will guess the compression type based on; the input_path's suffix. Raises:; IOError: if there was any problem opening output_path for writing.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py:194,Testability,log,logical,194,"""""""Initializer. Args:; output_path: str. The output path to which the records are written.; header: An optional header for the particular data type. This can be; useful for file types that have logical headers where some operations; depend on that header information (e.g. VCF using its headers to; determine type information of annotation fields).; compression_type: Either 'ZLIB', 'GZIP', '' (uncompressed), or; None. If None, __init__ will guess the compression type based on; the input_path's suffix. Raises:; IOError: if there was any problem opening output_path for writing.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/genomics_writer.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/genomics_writer.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff.py:394,Integrability,protocol,protocol,394,"""""""Classes for reading and writing GFF files. The GFF format is described at; https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md. API for reading:. ```python; from third_party.nucleus.io import gff. # Iterate through all records.; with gff.GffReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.GffRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import gff; from third_party.nucleus.protos import gff_pb2. # records is an iterable of nucleus.genomics.v1.GffRecord protocol buffers.; records = ... header = gff_pb2.GffHeader(). # Write all records to the desired output path.; with gff.GffWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true GFF file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true GFF file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/gff.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff.py:586,Integrability,protocol,protocol,586,"""""""Classes for reading and writing GFF files. The GFF format is described at; https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md. API for reading:. ```python; from third_party.nucleus.io import gff. # Iterate through all records.; with gff.GffReader(input_path) as reader:; for record in reader:; print(record); ```. where `record` is a `nucleus.genomics.v1.GffRecord` protocol buffer. API for writing:. ```python; from third_party.nucleus.io import gff; from third_party.nucleus.protos import gff_pb2. # records is an iterable of nucleus.genomics.v1.GffRecord protocol buffers.; records = ... header = gff_pb2.GffHeader(). # Write all records to the desired output path.; with gff.GffWriter(output_path, header) as writer:; for record in records:; writer.write(record); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true GFF file. Files that end in a '.gz' suffix cause the file to be treated as compressed; (with BGZF if it is a true GFF file, and with gzip if it is a TFRecord file).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/gff.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff_test.py:11,Testability,test,testdata,11,"# Names of testdata GFF files; we also reuse these basenames for output files; # in the tmp directory.",MatchSource.CODE_COMMENT,third_party/nucleus/io/gff_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gff_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gfile.py:12,Integrability,interface,interface,12,"""""""A Python interface for files.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/gfile.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/gfile.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:390,Integrability,protocol,protocol,390,"""""""Classes for reading and writing SAM and BAM files. The SAM/BAM/CRAM formats are described at; https://samtools.github.io/hts-specs/SAMv1.pdf; https://samtools.github.io/hts-specs/CRAMv3.pdf. API for reading:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(input_path) as reader:; for read in reader:; print(read); ```. where `read` is a `nucleus.genomics.v1.Read` protocol buffer. input_path will; dynamically decode the underlying records depending the file extension, with; `.sam` for SAM files, `.bam` for BAM files, and `.cram` for CRAM files. It will; also search for an appropriate index file to use to enable calls to the; `query()` method. API for writing SAM/BAM:. ```python; from third_party.nucleus.io import sam. # reads is an iterable of nucleus.genomics.v1.Read protocol buffers.; reads = ... with sam.SamWriter(output_path, header=header) as writer:; for read in reads:; writer.write(read); ```. API for writing CRAM:. ```python; # ref_path is required for writing CRAM files. If embed_ref, the output CRAM; # file will embed reference sequences.; with sam.SamWriter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression w",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:466,Integrability,depend,depending,466,"""""""Classes for reading and writing SAM and BAM files. The SAM/BAM/CRAM formats are described at; https://samtools.github.io/hts-specs/SAMv1.pdf; https://samtools.github.io/hts-specs/CRAMv3.pdf. API for reading:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(input_path) as reader:; for read in reader:; print(read); ```. where `read` is a `nucleus.genomics.v1.Read` protocol buffer. input_path will; dynamically decode the underlying records depending the file extension, with; `.sam` for SAM files, `.bam` for BAM files, and `.cram` for CRAM files. It will; also search for an appropriate index file to use to enable calls to the; `query()` method. API for writing SAM/BAM:. ```python; from third_party.nucleus.io import sam. # reads is an iterable of nucleus.genomics.v1.Read protocol buffers.; reads = ... with sam.SamWriter(output_path, header=header) as writer:; for read in reads:; writer.write(read); ```. API for writing CRAM:. ```python; # ref_path is required for writing CRAM files. If embed_ref, the output CRAM; # file will embed reference sequences.; with sam.SamWriter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression w",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:802,Integrability,protocol,protocol,802,"""""""Classes for reading and writing SAM and BAM files. The SAM/BAM/CRAM formats are described at; https://samtools.github.io/hts-specs/SAMv1.pdf; https://samtools.github.io/hts-specs/CRAMv3.pdf. API for reading:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(input_path) as reader:; for read in reader:; print(read); ```. where `read` is a `nucleus.genomics.v1.Read` protocol buffer. input_path will; dynamically decode the underlying records depending the file extension, with; `.sam` for SAM files, `.bam` for BAM files, and `.cram` for CRAM files. It will; also search for an appropriate index file to use to enable calls to the; `query()` method. API for writing SAM/BAM:. ```python; from third_party.nucleus.io import sam. # reads is an iterable of nucleus.genomics.v1.Read protocol buffers.; reads = ... with sam.SamWriter(output_path, header=header) as writer:; for read in reads:; writer.write(read); ```. API for writing CRAM:. ```python; # ref_path is required for writing CRAM files. If embed_ref, the output CRAM; # file will embed reference sequences.; with sam.SamWriter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression w",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2585,Modifiability,plugin,plugin,2585,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2177,Performance,cache,cache,2177,"riter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htsli",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2513,Performance,load,load,2513,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2908,Safety,safe,safety,2908,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2071,Security,access,accessible,2071,"riter(output_path, header=header, ref_path=ref_path,; embed_ref=embed_ref) as writer:; for read in reads:; writer.write(read); ```. For both reading and writing, if the path provided to the constructor contains; '.tfrecord' as an extension, a `TFRecord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htsli",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2886,Security,access,access,2886,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:3264,Testability,benchmark,benchmarking,3264,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:3325,Testability,benchmark,benchmarks,3325,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2893,Usability,simpl,simplicity,2893,"cord` file is assumed and attempted to be; read or written. Otherwise, the filename is treated as a true SAM/BAM/CRAM file. For `TFRecord` files, ending in a '.gz' suffix causes the file to be treated as; compressed with gzip. Notes on using CRAM with SamReader; --------------------------------. Nucleus supports reading from CRAM files using the same API as for SAM/BAM:. ```python; from third_party.nucleus.io import sam. with sam.SamReader(""/path/to/sample.cram"") as reader:; for read in reader:; print(read); ```. There is one type of CRAM file, though, that has a slightly more complicated; API. If the CRAM file uses read sequence compression with an external reference; file, and this reference file is no longer accessible in the location specified; by the CRAM file's ""UR"" tag and cannot be found in the local genome cache, its; location must be passed to SamReader via the ref_path parameter:. ```python; from third_party.nucleus.io import sam. cram_path = ""/path/to/sample.cram""; ref_path = ""/path/to/genome.fasta""; with sam.SamReader(cram_path, ref_path=ref_path) as reader:; for read in reader:; print(read); ```. Unfortunately, htslib is unable to load the ref_path from anything other than a; POSIX filesystem. (htslib plugin filesystems like S3 or GCS buckets won't work).; For that reason, we don't recommend the use of CRAM files with external; reference files, but instead suggest using read sequence compression with; embedded reference data. (This has a minor impact on file size, but; significantly improves file access simplicity and safety.). For more information about CRAM, see:; * The `samtools` documentation at http://www.htslib.org/doc/samtools.html; * The ""Global Options"" section of the samtools docs at http://www.htslib.org/doc/samtools.html#GLOBAL_OPTIONS; * How reference sequences are encoded in CRAM at http://www.htslib.org/doc/samtools.html#REFERENCE_SEQUENCES; * Finally, benchmarking of different CRAM options http://www.htslib.org/benchmarks/CRAM.html; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:1072,Modifiability,config,configures,1072,"ut_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, and only; necessary if the UR encoded path in the CRAM itself needs to be; overridden. If provided, we will tell the CRAM decoder to use this FASTA; for the reference sequence.; read_requirements: optional ReadRequirement proto. If not None, this proto; is used to control which reads are filtered out by the reader before; they are passed to the client.; parse_aux_fields: optional bool, defaulting to False. If False, we do not; parse the auxiliary fields of the SAM/BAM/CRAM records (see SAM spec for; details). Parsing the aux fields is unnecessary for many applications,; and adds a significant parsing cost to access. If you need these aux; fields, set parse_aux_fields to True and these fields will be parsed and; populate the appropriate Read proto fields (e.g., read.info).; hts_block_size: int or None. If specified, this configures the block size; of the underlying htslib file object. Larger values (e.g. 1M) may be; beneficial for reading remote files. If None, the reader uses the; default htslib block size.; downsample_fraction: float in the interval [0.0, 1.0] or None. If; specified as a positive float, the reader will only keep each read with; probability downsample_fraction, randomly. If None or zero, all reads; are kept.; random_seed: None or int. The random seed to use with this sam reader, if; needed. If None, a fixed random value will be assigned.; use_original_base_quality_scores: optional bool, defaulting to False. If; True, quality scores are read from OQ tag.; aux_fields_to_keep: None or list[str]. If None, we keep all aux fields if; they are parsed. If set, we only keep the aux fields with the names in; this list. Raises:; ValueError: If downsample_fraction is not None and not in the interval; (0.0, 1.0].; ImportError: If someone tries to load a tfbam file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:2021,Performance,load,load,2021,"ut_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, and only; necessary if the UR encoded path in the CRAM itself needs to be; overridden. If provided, we will tell the CRAM decoder to use this FASTA; for the reference sequence.; read_requirements: optional ReadRequirement proto. If not None, this proto; is used to control which reads are filtered out by the reader before; they are passed to the client.; parse_aux_fields: optional bool, defaulting to False. If False, we do not; parse the auxiliary fields of the SAM/BAM/CRAM records (see SAM spec for; details). Parsing the aux fields is unnecessary for many applications,; and adds a significant parsing cost to access. If you need these aux; fields, set parse_aux_fields to True and these fields will be parsed and; populate the appropriate Read proto fields (e.g., read.info).; hts_block_size: int or None. If specified, this configures the block size; of the underlying htslib file object. Larger values (e.g. 1M) may be; beneficial for reading remote files. If None, the reader uses the; default htslib block size.; downsample_fraction: float in the interval [0.0, 1.0] or None. If; specified as a positive float, the reader will only keep each read with; probability downsample_fraction, randomly. If None or zero, all reads; are kept.; random_seed: None or int. The random seed to use with this sam reader, if; needed. If None, a fixed random value will be assigned.; use_original_base_quality_scores: optional bool, defaulting to False. If; True, quality scores are read from OQ tag.; aux_fields_to_keep: None or list[str]. If None, we keep all aux fields if; they are parsed. If set, we only keep the aux fields with the names in; this list. Raises:; ValueError: If downsample_fraction is not None and not in the interval; (0.0, 1.0].; ImportError: If someone tries to load a tfbam file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:856,Security,access,access,856,"""""""Initializes a NativeSamReader. Args:; input_path: str. A path to a resource containing SAM/BAM/CRAM records.; Currently supports SAM text format, BAM binary format, and CRAM.; ref_path: optional str or None. Only used for CRAM decoding, and only; necessary if the UR encoded path in the CRAM itself needs to be; overridden. If provided, we will tell the CRAM decoder to use this FASTA; for the reference sequence.; read_requirements: optional ReadRequirement proto. If not None, this proto; is used to control which reads are filtered out by the reader before; they are passed to the client.; parse_aux_fields: optional bool, defaulting to False. If False, we do not; parse the auxiliary fields of the SAM/BAM/CRAM records (see SAM spec for; details). Parsing the aux fields is unnecessary for many applications,; and adds a significant parsing cost to access. If you need these aux; fields, set parse_aux_fields to True and these fields will be parsed and; populate the appropriate Read proto fields (e.g., read.info).; hts_block_size: int or None. If specified, this configures the block size; of the underlying htslib file object. Larger values (e.g. 1M) may be; beneficial for reading remote files. If None, the reader uses the; default htslib block size.; downsample_fraction: float in the interval [0.0, 1.0] or None. If; specified as a positive float, the reader will only keep each read with; probability downsample_fraction, randomly. If None or zero, all reads; are kept.; random_seed: None or int. The random seed to use with this sam reader, if; needed. If None, a fixed random value will be assigned.; use_original_base_quality_scores: optional bool, defaulting to False. If; True, quality scores are read from OQ tag.; aux_fields_to_keep: None or list[str]. If None, we keep all aux fields if; they are parsed. If set, we only keep the aux fields with the names in; this list. Raises:; ValueError: If downsample_fraction is not None and not in the interval; (0.0, 1.0].; ImportError: ",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:10,Performance,load,loading,10,"# Delayed loading of tfbam_lib.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py:10,Integrability,interface,interface,10,"""""""Python interface class for in-memory SAM/BAM/CRAM reader. Attributes:; reads: list[nucleus.genomics.v1.Read]. The list of in-memory reads.; is_sorted: bool, True if reads are sorted.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:26,Availability,error,error,26,"# If we didn't detect the error, make sure we actually still parsed the; # read itself.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:15,Safety,detect,detect,15,"# If we didn't detect the error, make sure we actually still parsed the; # read itself.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:91,Testability,test,test,91,"# These expected counts are deterministic because we always set the random; # seed in each test.; # There are 106 total reads if we iterate.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:39,Availability,down,downsample,39,"# There are 45 total reads if we don't downsample.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:87,Testability,test,test,87,"# Note that CRAM version 2.1 files work with Nucleus but they cannot be used in; # our test here because CRAM 2.1 embeds an exact path to the reference file; # which LEAKR flags as leaking internal google paths.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py:127,Testability,test,test,127,"# Otherwise we need to explicitly override the reference encoded in the UR; # of the CRAM file to use the path provided to our test.fasta.",MatchSource.CODE_COMMENT,third_party/nucleus/io/sam_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sam_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py:494,Safety,detect,detecting,494,"""""""Utility functions for working with sharded files. A sharded file is a single conceptual file that is broken into a collection; of files to make parallelization easier. A sharded file spec is like a; filename for a sharded file; the file spec ""/some/path/prefix@200.txt""; says that the sharded file consists of 200 actual files that have names like; ""/some/path/prefix-00000-of-00200.txt"", ""/some/path/prefix-00001-of-00200.txt"",; etc. This module contains functions for parsing, generating, detecting and; resolving sharded file specs.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sharded_file_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py:10,Availability,error,error,10,"""""""An I/O error.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/sharded_file_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/sharded_file_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py:136,Integrability,protocol,protocol,136,"""""""I/O for TFRecord files. Utilities for reading and writing TFRecord files, especially those containing; serialized TensorFlow Example protocol buffers.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/tfrecord.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py:17,Integrability,wrap,wrapper,17,"""""""A convenience wrapper around genomics_writer.TFRecordWriter.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/tfrecord.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py:543,Performance,perform,performed,543,"""""""Yields the parsed records in a TFRecord file path in sorted order. The input TFRecord file must have each shard already in sorted order when; using the key function for comparison (but elements can be interleaved across; shards). Under those constraints, the elements will be yielded in a global; sorted order. Args:; path: String. A path to a TFRecord-formatted file containing protos.; key: Callable. A function that takes as input a single instance of the proto; class and returns a value on which the comparison for sorted ordering is; performed.; proto: A proto class. proto.FromString() will be called on each serialized; record in path to parse it.; max_records: int >= 0 or None. Maximum number of records to read from path.; If None, the default, all records will be read.; compression_type: 'GZIP', 'ZLIB', '' (uncompressed), or None to autodetect; based on file extension. Yields:; proto.FromString() values on each record in path in sorted order.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/tfrecord.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/tfrecord.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:411,Integrability,protocol,protocol,411,"""""""Classes for reading and writing VCF files. The VCF format is described at; https://samtools.github.io/hts-specs/VCFv4.3.pdf. API for reading:. ```python; from third_party.nucleus.io import vcf. with vcf.VcfReader(input_path) as reader:; for variant in reader:; print(variant); ```. API for writing:. ```python; from third_party.nucleus.io import vcf. # variants is an iterable of nucleus.genomics.v1.Variant protocol buffers.; variants = ... with vcf.VcfWriter(output_path, header=header) as writer:; for variant in variants:; writer.write(variant); ```. The class attempts to infer the file format (`TFRecord` vs VCF) from the file; path provided to the constructor. 1. For files that end with '.tfrecord' and '.tfrecord.gz' (a gzipped version),; a `TFRecord` file is assumed and is attempted to be read or written. 2. For all other files, the VCF format will be used. VCF format used in writing is inferred from file paths:; - ending in '.bcf.gz': BGZF compressed BCF format will be written;; - ending in '.bcf': uncompressed BCF format will be written;; - ending in '.gz' and not in '.bcf.gz': BGZP compressed VCF format will be; written;; - all other suffixes: uncompressed VCF format will be written. VCF format used in reading is inferred from the contents of the file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:24,Performance,cache,cache,24,"""""""This class creates a cache of accessors to structured fields in Variants. The INFO and FORMAT fields within Variant protos are structured and typed,; with types defined by the corresponding VCF header. This cache object provides; provides {info,format}_field_{get,set}_fn functions that can be used to; extract information from the structured Variant protos based on the types; defined therein. NOTE: Users should not need to interact with this class at all. It is used; by the variant_utils.{get,set}_info and variantcall_utils.{get,set}_format; functions for interacting with the INFO and FORMAT fields in a Variant proto.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:210,Performance,cache,cache,210,"""""""This class creates a cache of accessors to structured fields in Variants. The INFO and FORMAT fields within Variant protos are structured and typed,; with types defined by the corresponding VCF header. This cache object provides; provides {info,format}_field_{get,set}_fn functions that can be used to; extract information from the structured Variant protos based on the types; defined therein. NOTE: Users should not need to interact with this class at all. It is used; by the variant_utils.{get,set}_info and variantcall_utils.{get,set}_format; functions for interacting with the INFO and FORMAT fields in a Variant proto.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:33,Security,access,accessors,33,"""""""This class creates a cache of accessors to structured fields in Variants. The INFO and FORMAT fields within Variant protos are structured and typed,; with types defined by the corresponding VCF header. This cache object provides; provides {info,format}_field_{get,set}_fn functions that can be used to; extract information from the structured Variant protos based on the types; defined therein. NOTE: Users should not need to interact with this class at all. It is used; by the variant_utils.{get,set}_info and variantcall_utils.{get,set}_format; functions for interacting with the INFO and FORMAT fields in a Variant proto.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:87,Security,access,accessor,87,"""""""Initializer. Args:; header: nucleus.genomics.v1.VcfHeader proto. Used to define the accessor; functions needed.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:118,Integrability,depend,depending,118,"""""""Returns the underlying C++ reader. Note that the C++ reader might be a VcfReader or it might be a; TFRecordReader, depending on the input_path's extension.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:950,Integrability,contract,contract,950,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:56,Performance,cache,cache,56,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:571,Performance,cache,cache,571,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:1184,Performance,cache,cache,1184,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:1330,Performance,optimiz,optimizations,1330,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:1650,Performance,optimiz,optimizations,1650,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:1579,Safety,avoid,avoid,1579,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py:851,Testability,test,testing,851,"""""""Class for ""reading"" Variant protos from an in-memory cache of variants. ```python; from third_party.nucleus.io import vcf; from third_party.nucleus.protos import variants_pb2. variants = [... Variant protos ...]; header = variants_pb2.VcfHeader(). with vcf.InMemoryVcfReader(variants, header) as reader:; for variant in reader:; print(variant); ```. This class accepts a collection of variants and optionally a header and; provides all of the standard API functions of VcfReader but instead of; fetching variants from a file the variants are queried from an in-memory cache; of variant protos. Note that the input variants provided to this class aren't checked in any way,; and their ordering determines the order of variants emitted by this class for; the iterate() and query() operations. This is intentional, to make this class; easy to use for testing where you often want to use less-than-perfectly formed; inputs. In order to fully meet the contract of a standard VcfReader, variants; should be sorted by their contig ordering and then by their start and finally; by their ends. Implementation note:; The current implementation will be very slow for query() if the provided; cache of variants is large, as we do a O(n) search to collect all of the; overlapping variants for each query. There are several straightforward; optimizations to do if we need/want to scale this up. (a) sort the variants; and use a binary search to find overlapping variants (b) partition the; variants by contig, so we have dict[contig] => [variants on contig], which; allows us to completely avoid considering any variants on any other contigs.; Neither of these optimizations are worth it if len(variants) is small, but; it may be worth considering if we want to use this functionality with a; large number of variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/io/vcf.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/vcf.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_reader_wrap_test.py:36,Integrability,wrap,wrappers,36,"""""""Tests for bed_reader CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py:35,Integrability,wrap,wrappers,35,"""""""Tests for BedWriter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py:22,Availability,error,error,22,"# We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/bed_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/bed_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_reader_wrap_test.py:38,Integrability,wrap,wrappers,38,"""""""Tests for fastq_reader CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py:37,Integrability,wrap,wrappers,37,"""""""Tests for FastqWriter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py:22,Availability,error,error,22,"# We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/fastq_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/fastq_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_reader_wrap_test.py:36,Integrability,wrap,wrappers,36,"""""""Tests for gff_reader CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py:35,Integrability,wrap,wrappers,35,"""""""Tests for GffWriter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py:22,Availability,error,error,22,"# We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/gff_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/gff_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/reference_wrap_test.py:41,Integrability,wrap,wrappers,41,"""""""Tests for GenomeReference CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/reference_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/reference_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/sam_reader_wrap_test.py:36,Integrability,wrap,wrappers,36,"""""""Tests for sam_reader CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/sam_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/sam_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py:36,Integrability,wrap,wrappers,36,"""""""Tests for vcf_reader CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py:41,Safety,detect,detect,41,"# Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py:113,Safety,detect,detect,113,"# Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py:413,Testability,assert,assertIsNotNone,413,"# Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py:458,Testability,assert,assertRaises,458,"# Commented out because we in fact don't detect the malformed VCF yet. It is; # unclear if it's even possible to detect the issue with the API provided by; # htslib.; # def test_vcf_iterate_raises_on_malformed_record(self):; # malformed = test_utils.genomics_core_testdata('malformed.vcf'); # reader = vcf_reader.VcfReader.from_file(malformed, self.unindexed_options); # iterable = iter(reader.iterate()); # self.assertIsNotNone(next(iterable)); # with self.assertRaises(ValueError):; # print(list(iterable))",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_reader_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_reader_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py:35,Integrability,wrap,wrappers,35,"""""""Tests for VcfWriter CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py:22,Availability,error,error,22,"# We want to raise an error on exit, so nothing to do in context.",MatchSource.CODE_COMMENT,third_party/nucleus/io/python/vcf_writer_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/io/python/vcf_writer_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:28,Deployability,install,installing,28,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:131,Deployability,install,install,131,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:174,Deployability,install,installation,174,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:488,Deployability,install,install,488,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:608,Deployability,install,install,608,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:709,Deployability,install,install-headers,709,"""""""Fake setup.py module for installing Nucleus. Usually, setup.py is invoked twice: first, to build the pip package; and second to install it. This setup.py is only used for installation; build_pip_package.sh is; used to create the package. We do it this way because we need our; package to include symbolic links, which normal setup.py doesn't; support. For the same reason, this setup.py is not implemented using setuptools.; Instead, we directly implement the four commands run by pip install; (https://pip.pypa.io/en/stable/reference/pip_install/#id46):; * setup.py egg_info [--egg-base XXX]; * setup.py install --record XXX [--single-version-externally-managed]; [--root XXX] [--compile|--no-compile] [--install-headers XXX]; * setup.py bdist_wheel -d XXX; * setup.py clean; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:44,Deployability,install,install,44,"""""""Returns the directory we are supposed to install into.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py:139,Availability,failure,failure,139,"""""""Copies the .egg-info directory to the specified location. Args:; dest_dir: str. The destination directory. Returns:; 0 on success, 1 on failure.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/pip_package/setup.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/pip_package/setup.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/protobuf_implementation_test.py:41,Testability,test,testing,41,"# This next import is unused, but we are testing that any program; # which includes a Nucleus library uses the cpp protobuf; # implementation.; # pylint: disable=unused-import",MatchSource.CODE_COMMENT,third_party/nucleus/testing/protobuf_implementation_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/protobuf_implementation_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py:25,Deployability,install,installation,25,"""""""Test that our Nucleus installation does not cause issues with TensorFlow.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/tensorflow_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py:12,Testability,test,test,12,"# N.B. This test is only invoked when testing the pip package.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/tensorflow_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py:38,Testability,test,testing,38,"# N.B. This test is only invoked when testing the pip package.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/tensorflow_smoke_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/tensorflow_smoke_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:26,Testability,test,testing,26,"""""""Utilities to help with testing code.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:43,Testability,test,testdata,43,"# In the OSS version this becomes 'nucleus/testdata'",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:22,Testability,test,testdata,22,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:91,Testability,test,testdata,91,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:176,Testability,test,test,176,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:207,Testability,test,testdata,207,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:251,Testability,test,testdata,251,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:359,Testability,test,testing,359,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:418,Testability,test,testdata,418,"""""""Gets the path to a testdata file in genomics at relative path. Args:; path: A path to a testdata file *relative* to the genomics root; directory. For example, if you have a test file in; ""datadir/nucleus/testdata/foo.txt"", path should be; ""nucleus/testdata/foo.txt"" to get a path to it.; datadir: The path of the genomics root directory *relative* to; the testing source directory. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:57,Integrability,rout,routine,57,"# Google code uses FLAG.test_srcdir; # TensorFlow uses a routine googletest.test_src_dir_path.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:22,Testability,test,testdata,22,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:54,Testability,test,testdata,54,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:95,Testability,test,testdata,95,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:130,Testability,test,testdata,130,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:178,Testability,test,test,178,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:218,Testability,test,testdata,218,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:321,Testability,test,testdata,321,"""""""Gets the path to a testdata named filename in util/testdata. Args:; filename: The name of a testdata file in the core genomics testdata; directory. For example, if you have a test file in; ""third_party/nucleus/util/testdata/foo.txt"", filename should be; ""foo.txt"" to get a path to it. Returns:; The absolute path to a testdata file.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:304,Testability,test,test,304,"""""""Returns a path to a tempfile named name in the test_tmpdir. Args:; name: str; the name of the file, should not contain any slashes.; contents: bytes, or None. If not None, tmpfile's contents will be set to; contents before returning the path. Returns:; str path to a tmpfile with filename name in our test tmpfile directory.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:20,Modifiability,extend,extend,20,"# list_value.values.extend(vals)",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:40,Testability,test,testing,40,"""""""Makes a nucleus.genomics.v1.Read for testing.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:82,Integrability,wrap,wrap,82,"""""""Count the number of elements in an Iterable object. Args:; cc_iterable: a CLIF-wrap of a subclass of the C++ Iterable class. Returns:; integer count; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:53,Testability,mock,mock,53,"# TODO: remove and replace uses when bug is fixed in mock.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:274,Deployability,patch,patch,274,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:350,Deployability,patch,patch,350,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:18,Testability,mock,mock,18,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:61,Testability,mock,mock,61,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:84,Testability,assert,assert,84,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:106,Testability,mock,mock,106,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:140,Testability,mock,mock,140,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:215,Testability,mock,mock,215,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:373,Testability,mock,mock,373,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:451,Testability,test,testing-cabal,451,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:465,Testability,mock,mock,465,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:482,Testability,mock,mock,482,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:487,Testability,mock,mock,487,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:530,Testability,mock,mock,530,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:568,Testability,test,testing-cabal,568,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:582,Testability,mock,mock,582,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:713,Testability,mock,mock,713,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:723,Testability,mock,mock,723,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:731,Testability,assert,assert,731,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:783,Testability,mock,mock,783,"""""""Asserts that a mock has not been called. There's a bug in mock where some of the assert functions on a mock are being; dropped when that mock is created with an autospec:. https://bugs.python.org/issue28380. The mock 2.0.0 backport doesn't have the fix yet. The required patch is:. https://bugs.python.org/file44991/fix_autospecced_mock_functions.patch. but the current mock (checked 07/22/17) backport code is missing the fix:. https://github.com/testing-cabal/mock/blob/master/mock/mock.py#L315. This is an open issue on the mock github repo:. https://github.com/testing-cabal/mock/issues/398. And they claim that it'll be a few months (as of April 2017) before it is; incorporated into the backport. Args:; mock: The mock to assert hasn't been called. Raises:; AssertionError: mock has been called.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:53,Testability,mock,mock,53,"# TODO: remove and replace uses when bug is fixed in mock.",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:18,Testability,mock,mock,18,"""""""Asserts that a mock has been called exactly once. See assert_not_called_workaround for the backstory on why this function; exists. Args:; mock: The mock that should have been called exactly once. Raises:; AssertionError: mock wasn't called exactly once.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:141,Testability,mock,mock,141,"""""""Asserts that a mock has been called exactly once. See assert_not_called_workaround for the backstory on why this function; exists. Args:; mock: The mock that should have been called exactly once. Raises:; AssertionError: mock wasn't called exactly once.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:151,Testability,mock,mock,151,"""""""Asserts that a mock has been called exactly once. See assert_not_called_workaround for the backstory on why this function; exists. Args:; mock: The mock that should have been called exactly once. Raises:; AssertionError: mock wasn't called exactly once.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py:224,Testability,mock,mock,224,"""""""Asserts that a mock has been called exactly once. See assert_not_called_workaround for the backstory on why this function; exists. Args:; mock: The mock that should have been called exactly once. Raises:; AssertionError: mock wasn't called exactly once.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils_test.py:23,Testability,test,testing,23,"""""""Tests for nucleus's testing.test_utils.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/testing/test_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/testing/test_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar.py:115,Availability,avail,available,115,"""""""Utility functions for working with alignment CIGAR operations. The CIGAR format is defined within the SAM spec, available at; https://samtools.github.io/hts-specs/SAMv1.pdf. This module provides utility functions for interacting with the parsed; representations of CIGAR strings.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py:13,Integrability,wrap,wrapped,13,"# Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py:39,Modifiability,parameteriz,parameterized,39,"# Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py:115,Testability,test,test,115,"# Have to be wrapped in a list to stop parameterized from treating the; # tuple as the positional arguments to the test function.",MatchSource.CODE_COMMENT,third_party/nucleus/util/cigar_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/cigar_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:35,Availability,error,errors,35,"""""""Library of application-specific errors.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:23,Availability,error,error,23,"""""""Base class for core error types.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:18,Integrability,message,message,18,"""""""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:91,Integrability,message,message,91,"""""""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:102,Testability,log,log,102,"""""""Logs the given message at ERROR level and raises exception. Args:; msg: [`string`]. The message to log and use in the raised exception.; exception_class: [`Exception`]. The class of exception to raise. Raises:; Error: An exception of the type specified by the input exception_class.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:187,Availability,error,errors,187,"""""""Wraps commands to capture certain exceptions and exit without stacktraces. This function is intended to wrap all code within main() of Python binaries; to provide a mechanism for user errors to exit abnormally without causing; exceptions to be thrown. Any exceptions that are subclasses of those listed; in `allowed_exceptions` will be caught and the program will quietly exit with; `exit_value`. Other exceptions are propagated normally. NOTE: This function should only be used as a context manager and its usage; should be limited to main(). Args:; allowed_exceptions: [`tuple of Exception`]. A tuple of Exception classes; that should not be raised, but instead quietly caused to exit the program.; exit_value: [`int`]. The value to return upon program exit. Yields:; The yield in this function is used to allow the block nested in the ""with""; statement to be executed.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py:107,Integrability,wrap,wrap,107,"""""""Wraps commands to capture certain exceptions and exit without stacktraces. This function is intended to wrap all code within main() of Python binaries; to provide a mechanism for user errors to exit abnormally without causing; exceptions to be thrown. Any exceptions that are subclasses of those listed; in `allowed_exceptions` will be caught and the program will quietly exit with; `exit_value`. Other exceptions are propagated normally. NOTE: This function should only be used as a context manager and its usage; should be limited to main(). Args:; allowed_exceptions: [`tuple of Exception`]. A tuple of Exception classes; that should not be raised, but instead quietly caused to exit the program.; exit_value: [`int`]. The value to return upon program exit. Yields:; The yield in this function is used to allow the block nested in the ""with""; statement to be executed.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors_test.py:38,Availability,error,errors,38,"""""""Tests for third_party.nucleus.util.errors.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/errors_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/errors_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:960,Integrability,depend,dependent,960,"""""""Mathematics functions for working with genomics data. A quick note on terminology here. There are a bunch kinds of probabilities used commonly in genomics:. -- pError: the probability of being wrong.; -- pTrue: the probability of being correct. Normalized probabilities vs. unnormalized likelihoods:. -- Normalized probabilities: p_1, ..., p_n such that sum(p_i) == 1 are said; said to be normalized because they represent a valid probability; distribution over the states 1 ... n.; -- Unnormalized likelihoods: p_1, ..., p_n where sum(p_i) != 1. These are not; normalized and so aren't a valid probabilities distribution. To add even more complexity, probabilities are often represented in three; semi-equivalent spaces:. -- Real-space: the classic space, with values ranging from [0.0, 1.0]; inclusive.; -- log10-space: If p is the real-space value, in log10-space this would be; represented as log10(p). How the p == 0 case is handled is often function; dependent, which may accept/return -Inf or not handle the case entirely.; -- Phred-scaled: See https://en.wikipedia.org/wiki/Phred_quality_score for; more information. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:1798,Performance,perform,performance,1798,"""""""Mathematics functions for working with genomics data. A quick note on terminology here. There are a bunch kinds of probabilities used commonly in genomics:. -- pError: the probability of being wrong.; -- pTrue: the probability of being correct. Normalized probabilities vs. unnormalized likelihoods:. -- Normalized probabilities: p_1, ..., p_n such that sum(p_i) == 1 are said; said to be normalized because they represent a valid probability; distribution over the states 1 ... n.; -- Unnormalized likelihoods: p_1, ..., p_n where sum(p_i) != 1. These are not; normalized and so aren't a valid probabilities distribution. To add even more complexity, probabilities are often represented in three; semi-equivalent spaces:. -- Real-space: the classic space, with values ranging from [0.0, 1.0]; inclusive.; -- log10-space: If p is the real-space value, in log10-space this would be; represented as log10(p). How the p == 0 case is handled is often function; dependent, which may accept/return -Inf or not handle the case entirely.; -- Phred-scaled: See https://en.wikipedia.org/wiki/Phred_quality_score for; more information. Briefly, the Phred-scale maintains resolution in the lower; parts of the probability space using integer quality scores (though using; ints is optional, really). The phred-scale is defined as. `phred(p) = -10 * log10(p)`. where p is a real-space probability. The functions in math.h dealing with probabilities are very explicit about what; kinds of probability and representation they expect and return, as unfortunately; these are all commonly represented as doubles in C++. Though it is tempting to; address this issue with classic software engineering practices like creating; a Probability class, in practice this is extremely difficult to do as this; code is often performance critical and the low-level mathematical operations; used in this code (e.g., log10) don't distiguish themselves among the types; of probabilities.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:146,Availability,avail,available,146,"# C++ CLIF functions:; #; # We are enumerating the C++ functions exported by python/math.clif here, so; # it's clear to people what functions are available in python without digging; # into the raw python/C++ CLIF code.",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:111,Usability,clear,clear,111,"# C++ CLIF functions:; #; # We are enumerating the C++ functions exported by python/math.clif here, so; # it's clear to people what functions are available in python without digging; # into the raw python/C++ CLIF code.",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:476,Testability,log,log,476,"""""""Calculates numerically-stable value of log10(binomial(k, n, p)). Returns the log10 of the binomial density for k successes in n trials where; each success has a probability of occurring of p. In real-space, we would calculate:. result = (n choose k) * (1-p)^(n-k) * p^k. This function computes the log10 of result, which is:. log10(result) = log10(n choose k) + (n-k) * log10(1-p) + k * log10(p). This is equivalent to invoking the R function:; dbinom(x=k, size=n, prob=p, log=TRUE). See https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Binomial.html; for more details on the binomial. Args:; k: int >= 0. Number of successes.; n: int >= k. Number of trials.; p: 0.0 <= float <= 1.0. Probability of success. Returns:; log10 probability of seeing k successes in n trials with p.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:374,Availability,robust,robust,374,"""""""Approximately normalizes log10 probabilities. This function normalizes log10 probabilities. What this means is that we; return an equivalent array of probabilities but whereas sum(10^log10_probs) is; not necessarily 1.0, the resulting array is sum(10^result) ~= 1.0. The ~=; indicates that the result is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To understand the approximation,; let's start with the exact calculation. Suppose I have three models, each; emitting a probability that some data was generated by that model:. data = {0.1, 0.01, 0.001} => probabilities from models A, B, and C. These probabilities are unnormalized, in the sense that the total probability; over the vector doesn't sum to 1 (sum(data) = 0.111). In many applications we; want to normalize this vector so that sum(normalized(data)) = 1 and the; relative magnitudes of the original probabilities are preserved (i.e,:. data[i] / data[j] = normalized(data)[i] / normalized(data)[j]. for all pairs of values indexed by i and j. For much of the work we do in; genomics, we have so much data that representing these raw probability; vectors in real-space risks numeric underflow/overflow, so we instead; represent our probability vectors in log10 space:. log10_data = log10(data) = {-1, -2, -3}. Given that we expect numeric problems in real-space, normalizing this log10; vector is hard, because the standard way you'd do the normalization is via:. data[i] = data[i] / sum(data); log10_data[i] = log10_data[i] - log10(sum(10^data)). But computing the sum of log10 values this way is dangerous because the naive; implementation converts back to real-space to do the sum, the very operation; we're trying to avoid due to numeric instability. This function implements an approximate normalization, which relaxes the need; for an exact calculation of the sum. This function ensures that the; normalization is numer",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:1245,Safety,risk,risks,1245,"ulting array is sum(10^result) ~= 1.0. The ~=; indicates that the result is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To understand the approximation,; let's start with the exact calculation. Suppose I have three models, each; emitting a probability that some data was generated by that model:. data = {0.1, 0.01, 0.001} => probabilities from models A, B, and C. These probabilities are unnormalized, in the sense that the total probability; over the vector doesn't sum to 1 (sum(data) = 0.111). In many applications we; want to normalize this vector so that sum(normalized(data)) = 1 and the; relative magnitudes of the original probabilities are preserved (i.e,:. data[i] / data[j] = normalized(data)[i] / normalized(data)[j]. for all pairs of values indexed by i and j. For much of the work we do in; genomics, we have so much data that representing these raw probability; vectors in real-space risks numeric underflow/overflow, so we instead; represent our probability vectors in log10 space:. log10_data = log10(data) = {-1, -2, -3}. Given that we expect numeric problems in real-space, normalizing this log10; vector is hard, because the standard way you'd do the normalization is via:. data[i] = data[i] / sum(data); log10_data[i] = log10_data[i] - log10(sum(10^data)). But computing the sum of log10 values this way is dangerous because the naive; implementation converts back to real-space to do the sum, the very operation; we're trying to avoid due to numeric instability. This function implements an approximate normalization, which relaxes the need; for an exact calculation of the sum. This function ensures that the; normalization is numerically safe at the expense of the sum not being exactly; equal to 1 but rather just close. Args:; log10_probs: array-like of floats. An array of log10 probabilties. Returns:; np.array with the same shape as log10_probs but where su",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:1797,Safety,avoid,avoid,1797," is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To understand the approximation,; let's start with the exact calculation. Suppose I have three models, each; emitting a probability that some data was generated by that model:. data = {0.1, 0.01, 0.001} => probabilities from models A, B, and C. These probabilities are unnormalized, in the sense that the total probability; over the vector doesn't sum to 1 (sum(data) = 0.111). In many applications we; want to normalize this vector so that sum(normalized(data)) = 1 and the; relative magnitudes of the original probabilities are preserved (i.e,:. data[i] / data[j] = normalized(data)[i] / normalized(data)[j]. for all pairs of values indexed by i and j. For much of the work we do in; genomics, we have so much data that representing these raw probability; vectors in real-space risks numeric underflow/overflow, so we instead; represent our probability vectors in log10 space:. log10_data = log10(data) = {-1, -2, -3}. Given that we expect numeric problems in real-space, normalizing this log10; vector is hard, because the standard way you'd do the normalization is via:. data[i] = data[i] / sum(data); log10_data[i] = log10_data[i] - log10(sum(10^data)). But computing the sum of log10 values this way is dangerous because the naive; implementation converts back to real-space to do the sum, the very operation; we're trying to avoid due to numeric instability. This function implements an approximate normalization, which relaxes the need; for an exact calculation of the sum. This function ensures that the; normalization is numerically safe at the expense of the sum not being exactly; equal to 1 but rather just close. Args:; log10_probs: array-like of floats. An array of log10 probabilties. Returns:; np.array with the same shape as log10_probs but where sum(10^result) ~= 1.0. Raises:; ValueError: if any log10_probs > 0.0; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py:2008,Safety,safe,safe,2008," is not necessarily == 1.0 but very close. This function is a fast and robust approximation of the true normalization of; a log10 transformed probability vector. To understand the approximation,; let's start with the exact calculation. Suppose I have three models, each; emitting a probability that some data was generated by that model:. data = {0.1, 0.01, 0.001} => probabilities from models A, B, and C. These probabilities are unnormalized, in the sense that the total probability; over the vector doesn't sum to 1 (sum(data) = 0.111). In many applications we; want to normalize this vector so that sum(normalized(data)) = 1 and the; relative magnitudes of the original probabilities are preserved (i.e,:. data[i] / data[j] = normalized(data)[i] / normalized(data)[j]. for all pairs of values indexed by i and j. For much of the work we do in; genomics, we have so much data that representing these raw probability; vectors in real-space risks numeric underflow/overflow, so we instead; represent our probability vectors in log10 space:. log10_data = log10(data) = {-1, -2, -3}. Given that we expect numeric problems in real-space, normalizing this log10; vector is hard, because the standard way you'd do the normalization is via:. data[i] = data[i] / sum(data); log10_data[i] = log10_data[i] - log10(sum(10^data)). But computing the sum of log10 values this way is dangerous because the naive; implementation converts back to real-space to do the sum, the very operation; we're trying to avoid due to numeric instability. This function implements an approximate normalization, which relaxes the need; for an exact calculation of the sum. This function ensures that the; normalization is numerically safe at the expense of the sum not being exactly; equal to 1 but rather just close. Args:; log10_probs: array-like of floats. An array of log10 probabilties. Returns:; np.array with the same shape as log10_probs but where sum(10^result) ~= 1.0. Raises:; ValueError: if any log10_probs > 0.0; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py:63,Safety,safe,safety,63,"# This probability is still calculated correctly, included for safety.",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py:105,Testability,log,log,105,"# R code to produce the expectation table.; # expected <- function(k, n, p) {; # pbin <- dbinom(k, n, p, log=T) * log10(exp(1)); # likelihoods = paste(sprintf(""%.6f"", pbin), collapse="", ""); # result = paste(k, n, p, pbin, sep="", ""); # cat(paste(""("", result, ""),\n"", sep="""")); # }; #; # for (n in c(0, 5, 10)) {; # for (k in seq(0, n)) {; # for (p in c(0.01, 0.5)) {; # expected(k, n, p); # }; # }; # }; # expected(0, 1000, 0.5); # expected(0, 10000, 0.5); # expected(100, 10000, 0.5)",MatchSource.CODE_COMMENT,third_party/nucleus/util/genomics_math_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/genomics_math_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/proto_utils.py:13,Availability,error,error,13,"""""""Raises an error if a slow protobuf implementation is being used.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/proto_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/proto_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:31,Safety,detect,detection,31,"""""""Utilities for Range overlap detection.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:155,Deployability,update,update,155,"# Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:173,Integrability,message,message,173,"# Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:165,Testability,log,logging,165,"# Logging frequency when building our rangeset objects, which can take some time; # to complete. Rather than just pausing for a few minutes, we provide an update; # logging message every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records added. See; # internal for more information.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:16,Safety,detect,detection,16,"""""""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:88,Testability,log,log,88,"""""""Fast overlap detection of a genomic position against a database of Ranges. Enables O(log n) computation of whether a point chr:pos falls within one of a; large number of genomic ranges. This class does not supports overlapping or adjacent intervals. Any such; intervals will be automatically merged together in the constructor. This class is immutable. No methods should be added that directly modify the; ranges held by the class.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:726,Integrability,message,message,726,"""""""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigInfo) protos. Used to define the; iteration order over contigs (i.e., by contig.pos_in_fasta). If this; list is not provided, the iteration order will be determined by the; alphabetical order of the contig names.; quiet: bool; defaults to False: If False, we will emit a logging message; every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records processed while; building this intervaltree. Set to True to stop all of the logging. Raises:; ValueError: if any range's reference_name does not correspond to any; contig in `contigs`.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:123,Safety,safe,safely,123,"""""""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigInfo) protos. Used to define the; iteration order over contigs (i.e., by contig.pos_in_fasta). If this; list is not provided, the iteration order will be determined by the; alphabetical order of the contig names.; quiet: bool; defaults to False: If False, we will emit a logging message; every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records processed while; building this intervaltree. Set to True to stop all of the logging. Raises:; ValueError: if any range's reference_name does not correspond to any; contig in `contigs`.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:718,Testability,log,logging,718,"""""""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigInfo) protos. Used to define the; iteration order over contigs (i.e., by contig.pos_in_fasta). If this; list is not provided, the iteration order will be determined by the; alphabetical order of the contig names.; quiet: bool; defaults to False: If False, we will emit a logging message; every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records processed while; building this intervaltree. Set to True to stop all of the logging. Raises:; ValueError: if any range's reference_name does not correspond to any; contig in `contigs`.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:862,Testability,log,logging,862,"""""""Creates a RangeSet backed by ranges. Note that the Range objects in ranges are *not* stored directly here, so; they can safely be modified after they are passed to this RangeSet. Args:; ranges: list(nucleus.genomics.v1.Range) protos (or anything with; reference_name, start, and end properties following the Range; convention). If None, no ranges will be used, and overlaps() will always; return False.; contigs: list(nucleus.genomics.v1.ContigInfo) protos. Used to define the; iteration order over contigs (i.e., by contig.pos_in_fasta). If this; list is not provided, the iteration order will be determined by the; alphabetical order of the contig names.; quiet: bool; defaults to False: If False, we will emit a logging message; every _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records processed while; building this intervaltree. Set to True to stop all of the logging. Raises:; ValueError: if any range's reference_name does not correspond to any; contig in `contigs`.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:63,Integrability,message,messages,63,"# We do our test directly here on i > 0 so we only see the log messages; # if we add at least _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:12,Testability,test,test,12,"# We do our test directly here on i > 0 so we only see the log messages; # if we add at least _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:59,Testability,log,log,59,"# We do our test directly here on i > 0 so we only see the log messages; # if we add at least _LOG_EVERY_N_RANGES_IN_RANGESET_INIT records.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:1169,Energy Efficiency,allocate,allocated,1169,"""""""Computes the intersection among this RangeSet and *others RangeSets. This function computes the intersection of all of the intervals in self and; *others, returning a RangeSet containing only intervals common to all. The; intersection here is an ranged intersection, not an identity intersection,; so the resulting set of intervals may not contain any of the original; intervals in any of the sets. To be concrete, suppose we have three sets to intersect, each having two; intervals:. self : chr1:1-10, chr2:20-30; other1 : chr1:5-8, chr3:10-40; other2 : chr1:3-7, chr3:10-30. self.intersection(other1, other2) produces a RangeSet with one interval; chr1:5-7, the common bases on chr1 in self, other1, and other2. No intervals; on chr2 or chr3 are included since the chr2 only occurs in self and the two; intervals on chr3, despite having some shared bases, don't have an; overlapping interval in self. Args:; *others: A list of RangeSet objects to intersect with the intervals in; this RangeSet. Returns:; A RangeSet. If *others is empty, this function returns self rather than; making an unnecessary copy. In all other cases, the returned value will be; a freshly allocated RangeSet.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:198,Safety,safe,safe,198,"# Yields all of the overlapping intervals from each interval of tree1; # found in tree2. Since each tree has only non-adjacent, non-overlapping,; # intervals this calculation is straightforward and safe and produces only; # non-adjacent, non-overlapping intervals.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:165,Performance,optimiz,optimize,165,"# Iteratively intersect each of our *other RangeSets with this RangeSet.; # Sort by size so we do the smallest number of element merge first.; # TODO: Note we could optimize this code by computing the set of; # common contigs upfront across all others and only looping over those.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:28,Security,access,access,28,"# pylint: disable=protected-access; # So we can intersect intervals within each contig separately.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:109,Performance,perform,performance,109,"""""""Chops out all of the intervals in other from this this RangeSet. NOTE: This is a *MUTATING* operation for performance reasons. Make a copy; of self if you want to avoid modifying the RangeSet. Args:; other: A RangeSet object whose intervals will be removed from this; RangeSet.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:166,Safety,avoid,avoid,166,"""""""Chops out all of the intervals in other from this this RangeSet. NOTE: This is a *MUTATING* operation for performance reasons. Make a copy; of self if you want to avoid modifying the RangeSet. Args:; other: A RangeSet object whose intervals will be removed from this; RangeSet.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:28,Security,access,access,28,"# pylint: disable=protected-access",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:131,Testability,log,log,131,"""""""Returns True if chr:pos overlaps with any range in this RangeSet. Uses a fast bisection algorithm to determine the overlap in O(log n) time. Args:; chrom: str. The chromosome name.; pos: int. The position (0-based). Returns:; True if chr:pos overlaps with a range.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:97,Integrability,interface,interface,97,"""""""Parses each region of `regions` into a Range proto. This function provides a super high-level interface for; reading/parsing/converting objects into Range protos. Each `region` of; `regions` is processed in turn, yielding one or more Range protos. This; function inspects the contents of `region` to determine how to convert it to; Range(s) protos. The following types of `region` strings are supported:. * If region ends with an extension known in _get_parser_for_file, we treat; region as a file and read the Range protos from it with the corresponding; reader from _get_parser_for_file, yielding each Range from the file in; order.; * Otherwise we parse region as a region literal (`chr20:1-10`) and return; the Range proto. Args:; regions: iterable[str]. Converts each element of this iterable into; region(s).; contig_map: An optional dictionary mapping from contig names to ContigInfo; protobufs. If provided, allows literals of the format ""contig_name"",; which will be parsed into a Range with reference_name=contig_name,; start=0, end=n_bases where n_bases comes from the ContigInfo. Yields:; A Range proto.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:371,Energy Efficiency,allocate,allocated,371,"""""""Sorts ranges by reference_name, start, and end. Args:; ranges: Iterable of nucleus.genomics.v1.Range protos that we want to sort.; contigs: None or an iterable of ContigInfo protos. If not None, we will use; the order of the contigs (as defined by their pos_in_fasta field values); to sort the Ranges on different contigs with respect to each other. Returns:; A newly allocated list of nucleus.genomics.v1.Range protos.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py:220,Energy Efficiency,allocate,allocated,220,"""""""Returns a region that spans all of the bases in regions. This function returns a Range(chrom, start, stop), where start is the min; of the starts in regions, and stop is the max end in regions. It may not be; freshly allocated. Args:; regions: list[Range]: a list of Range protos. Returns:; A single Range proto. Raises:; ValueError: if not all regions have the same reference_name.; ValueError: if regions is empty.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py:28,Testability,test,test,28,"# For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py:91,Testability,test,testdata,91,"# For convenience we allow 'test.bed' in our regions but the actual file; # path is in our testdata directory.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py:27,Deployability,configurat,configurations,27,"# Test some simple overlap configurations.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py:27,Modifiability,config,configurations,27,"# Test some simple overlap configurations.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py:12,Usability,simpl,simple,12,"# Test some simple overlap configurations.",MatchSource.CODE_COMMENT,third_party/nucleus/util/ranges_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/ranges_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils.py:8,Availability,error,error,8,"""""""Base error class.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/sequence_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils_test.py:9,Availability,error,error,9,"""""""Tests error is raised when complement_dict does not cover given seq.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/sequence_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/sequence_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils.py:47,Integrability,wrap,wrappers,47,"""""""Struct proto utilities. This class provides wrappers for conveniently interacting with protos defined; in struct.proto, mostly ListValue and Value objects. It should primarily be used; by variant_utils and variantcallutils rather than being used directly.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/struct_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils_test.py:142,Integrability,protocol,protocol,142,"""""""Returns a proto Map(str --> ListValue) with the given fields set. Args:; d: dict(str --> list(Value)). The data to populate. Returns:; The protocol buffer-defined Map(str --> ListValue).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/struct_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/struct_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py:138,Performance,optimiz,optimized,138,"""""""Returns True if read overlaps read. This function is equivalent to calling:. `ranges.ranges_overlap(region, read_range(read))`. But is optimized for speed and memory performance in C++. Args:; read: nucleus.genomics.v1.Read.; region: nucleus.genomics.v1.Range. Returns:; True if read and region overlap (i.e, have the same reference_name and their; start/ends overlap at least one basepair).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py:169,Performance,perform,performance,169,"""""""Returns True if read overlaps read. This function is equivalent to calling:. `ranges.ranges_overlap(region, read_range(read))`. But is optimized for speed and memory performance in C++. Args:; read: nucleus.genomics.v1.Read.; region: nucleus.genomics.v1.Range. Returns:; True if read and region overlap (i.e, have the same reference_name and their; start/ends overlap at least one basepair).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py:280,Energy Efficiency,allocate,allocate,280,"""""""Samples k elements with uniform probability from an iterable. Selects a subset of k elements from n input elements with uniform probability; without needing to hold all n elements in memory at the same time. This; implementation has max space complexity O(min(k, n)), i.e., we allocate up to; min(k, n) elements to store the samples. This means that we only use ~n; elements when n is smaller than k, which can be important when k is large. If; n elements are added to this sampler, and n <= k, all n elements will be; retained. If n > k, each added element will be retained with a uniform; probability of k / n. The order of the k retained samples from our n elements is undefined. In; particular that means that the elements in the returned list can occur in a; different order than they appeared in the iterable. More details about reservoir sampling (and the specific algorithm used here; called Algorithm R) can be found on wikipedia:. https://en.wikipedia.org/wiki/Reservoir_sampling#Algorithm_R. Args:; iterable: Python iterable. The iterable to sample from.; k: int. The number of elements to sample.; random: A random number generator or None. Returns:; A list containing the k sampled elements. Raises:; ValueError: If k is negative.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils_test.py:35,Testability,test,test,35,"# Use a fixed random number so our test is deterministic.",MatchSource.CODE_COMMENT,third_party/nucleus/util/utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variantcall_utils.py:619,Deployability,update,update,619,"""""""Sets a field of the info map of the `VariantCall` to the given value(s). `variant_call.info` is analogous to the FORMAT field of a VCF call. Example usage:; with vcf.VcfReader('/path/to/my.vcf') as vcf_reader:; for variant in vcf_reader:; first_call = variant.calls[0]; # Type can be inferred for reserved VCF fields.; set_format(first_call, 'AD', 25); # Specify the reader explicitly for unknown fields.; set_format(first_call, 'MYFIELD', 30, vcf_reader). Args:; variant_call: VariantCall proto. The VariantCall to modify.; field_name: str. The name of the field to set.; value: A single value or list of values to update the VariantCall with.; The type of the value is determined by the `vcf_object` if one is given,; otherwise is looked up based on the reserved FORMAT fields in the VCF; specification.; vcf_object: (Optional) A VcfReader or VcfWriter object. If not None, the; type of the field is inferred from the associated VcfReader or VcfWriter; based on its name. Otherwise, the type is inferred if it is a reserved; field.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variantcall_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variantcall_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:43,Usability,simpl,simply,43,"""""""Is variant an indel?. An indel event is simply one where the size of at least one of the alleles; is > 1. Args:; variant: nucleus.genomics.v1.Variant.; exclude_alleles: list(str). The alleles in this list will be ignored. Returns:; True if the alleles in variant indicate an insertion/deletion event; occurs at this site.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:55,Safety,detect,detect,55,"""""""An enumeration of the types of allele mismatches we detect.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:273,Availability,down,down,273,"""""""Determines the set of allele mismatch discordances between evalv and truev. Compares the alleles present in evalv and truev to determine if there are any; disagreements between the set of called alleles in the two Variant protos. The; type of differences basically boil down to:. -- Are there duplicate alt alleles?; -- Can we find a matching allele in the truev for each allele in evalv, and; vice versa?. Two alleles A and B match when they would produce the same sequence of bases; in ref and alt haplotypes starting at the same position. So CA=>TA is the same; as C=>T (position is the same, replacing A by A is a noop) but AC=>AT isn't; the same as C=>T because the former event changes bases 1 bp further along in; the reference genome than the C=>T allele. Args:; evalv: A nucleus.genomics.v1.Variant.; truev: A nucleus.genomics.v1.Variant. Returns:; A set of AlleleMismatchType values.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:314,Availability,down,down,314,"""""""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:74,Usability,simpl,simplify,74,"""""""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:186,Usability,simpl,simplify,186,"""""""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:294,Usability,simpl,simplify,294,"""""""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:581,Usability,simpl,simplify,581,"""""""Simplifies alleles by stripping off common postfix bases. For example, simplify(""AC"", ""GC"") would produce the tuple ""A"", ""G"" as the ""C""; base is a common postfix of both alleles. But simplify(""AC"", ""GT"") would; produce ""AC"", ""GT"" as there is no common postfix. Note this function will never simplify any allele down to the empty string. So; if alleles = ['CACA', 'CA'], the longest common postfix is 'CA' but we will; not produce ['CA', ''] as this is an invalid Variant allele encoding. Instead; we produce ['CAC', 'C']. Args:; *alleles: A tuple of bases, each as a string, to simplify. Returns:; A tuple, one for each allele in alleles in order, with any common postfix; bases stripped off.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:195,Energy Efficiency,reduce,reduces,195,"# Loop over the alleles to determine the length of the shared postfix. Start; # at 1 so every allele, even after trimming the postfix, has at least len 1.; # For example, alleles = ['ATT', 'TT'] reduces to ['AT', 'T'] not ['A', ''].",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:47,Usability,simpl,simplified,47,"""""""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:314,Usability,learn,learning,314,"""""""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:366,Usability,simpl,simplify,366,"""""""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:443,Usability,simpl,simplified,443,"""""""Replaces the alleles in variants with their simplified versions. This function takes a variant and replaces its ref and alt alleles with those; produced by a call to variant_utils.simplify_alleles() to remove common; postfix bases in the alleles that may be present due to pruning away alleles. Args:; variant: learning.genomics.genomics.Variant proto we want to simplify. Returns:; variant with its ref and alt alleles replaced with their simplified; equivalents.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:249,Deployability,configurat,configurations,249,"""""""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be considered. The function will return; True if any of those calls are variant.; apply_filter: If set to True, will never treat this site as variant when; any filter other than PASS or . is set. Returns:; True if variant is really a mutation call.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:249,Modifiability,config,configurations,249,"""""""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be considered. The function will return; True if any of those calls are variant.; apply_filter: If set to True, will never treat this site as variant when; any filter other than PASS or . is set. Returns:; True if variant is really a mutation call.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:301,Testability,assert,asserting,301,"""""""Is variant a non-reference call?. A Variant proto doesn't always imply that there's a variant present in the; genome. The call may not have alternate bases, may be filtered, may a have; hom-ref genotype, etc. This function looks for all of those configurations; and returns true iff the variant is asserting that a mutation is present; in the same. Note that this code allows a variant without a calls field to be variant,; but one with a genotype call must have a non-reference genotype to be; considered variant (if require_non_ref_genotype is True, the default). If; False, a variant that passes all of the site-level requirements for being; a variant_call will return a True value, regardless of the genotypes, which; means that we'll consider a site with a sample with a hom-ref or no-call site; a variant call. Args:; variant: nucleus.genomics.v1.Variant.; require_non_ref_genotype: Should we require a site with a genotype call to; have a non-reference (het, hom-var) genotype for the site to be considered; a variant call?; no_calls_are_variant: If a site has genotypes, should we consider no_call; genotypes as being variant or not? e.g. -1/1 listed as ./. in VCF; call_indices: A list of 0-based indices. If specified, only the calls; at the given indices will be considered. The function will return; True if any of those calls are variant.; apply_filter: If set to True, will never treat this site as variant when; any filter other than PASS or . is set. Returns:; True if variant is really a mutation call.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:90,Safety,abort,aborted,90,"# All tests after this point should only look at genotype-based fields, as; # we may have aborted out in the prev. line due to require_non_ref_genotype.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:6,Testability,test,tests,6,"# All tests after this point should only look at genotype-based fields, as; # we may have aborted out in the prev. line due to require_non_ref_genotype.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:150,Integrability,depend,depending,150,"""""""Gets the GenotypeType for variant. If variant doesn't have genotypes, returns no_call. Otherwise; returns one of no_call, hom_ref, het, or hom_var depending on the; status of the genotypes in the call field of variant. Args:; variant: nucleus.genomics.v1.Variant. Returns:; A GenotypeType. Raises:; ValueError: If variant has more than one call (i.e., is multi-sample).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:36,Deployability,configurat,configurations,36,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:241,Deployability,configurat,configurations,241,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:366,Deployability,configurat,configurations,366,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:442,Deployability,configurat,configurations,442,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:36,Modifiability,config,configurations,36,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:241,Modifiability,config,configurations,241,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:366,Modifiability,config,configurations,366,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:442,Modifiability,config,configurations,442,"""""""Returns a list of allele indices configurations with `num_alts` alternates. Args:; variant: nucleus.genomics.v1.Variant. The variant of interest, which; defines the candidate alternate alleles that can be used to generate; allele indices configurations.; num_alts: int in [0, `ploidy`]. The number of non-reference alleles for; which to create the allele indices configurations.; ploidy: int. The ploidy for which to return allele indices configurations. Returns: A list of tuples. Each tuple is of length `ploidy` and represents the; allele indices of all `ploidy` genotypes that contain `num_alts`; non-reference alleles. Raises:; ValueError: The domain of `num_alts` is invalid.; NotImplementedError: `ploidy` is not diploid.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py:281,Deployability,update,update,281,"""""""Sets a field of the info map of the `Variant` to the given value(s). `variant.info` is analogous to the INFO field of a VCF record. Args:; variant: Variant proto. The Variant to modify.; field_name: str. The name of the field to set.; value: A single value or list of values to update the Variant with. The type; of the value is determined by the `vcf_object` if one is given, otherwise; is looked up based on the reserved INFO fields in the VCF specification.; vcf_object: (Optional) A VcfReader or VcfWriter object. If not None, the; type of the field is inferred from the associated VcfReader or VcfWriter; based on its name. Otherwise, the type is inferred if it is a reserved; field.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:46,Testability,test,testing,46,"# These two are not allowed in VCF, but worth testing our; # code's behavior",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:21,Energy Efficiency,reduce,reduce,21,"# Make sure we don't reduce an allele to nothing.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:59,Energy Efficiency,reduce,reduce,59,"# One pair can simplify, but not the other, so nothing can reduce.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:15,Usability,simpl,simplify,15,"# One pair can simplify, but not the other, so nothing can reduce.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:38,Usability,simpl,simplify,38,"# trailing A.; # preceding A, doesn't simplify so it's a mismatch.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:37,Usability,simpl,simplify,37,"# both training preceding A, doesn't simplify, so mismatches",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:38,Usability,simpl,simplified,38,"# These are examples where ref is not simplified, such as could occur; # a multi-allelic record, such as the following:; # alleles = AT, A, ATT, CT (1 deletion, 1 insertion, 1 SNP)",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py:56,Safety,detect,detect,56,"# Check that variants_are_sorted() is correct, which we detect if; # the range_tuples of permutation == the range_tuples of sorted_variants.",MatchSource.CODE_COMMENT,third_party/nucleus/util/variant_utils_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/variant_utils_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vcf_constants.py:438,Integrability,depend,depending,438,"""""""Returns a callable that extracts the typed information from a ListValue. Args:; value_type: str. The value type stored as defined in the VCF 4.3 spec.; number: str. The number of entries of this value as defined in the VCF spec. Returns:; A callable that takes two inputs: A Map(str --> ListValue) and a string; field name and returns the associated typed value(s). The return value is; a list of typed values or a single typed value, depending on the expected; number of values returned.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vcf_constants.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vcf_constants.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:282,Energy Efficiency,green,green,282,"""""""Convert 6-channel image from DeepVariant to RGB for quick visualization. The 6 channels are: ""read base"", ""base quality"", ""mapping quality"", ""strand"",; ""supports variant"", ""base != reference"". Args:; channels: a list of 6 numpy arrays. Returns:; 3D numpy array of 3 colors (Red, green, blue).; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:53,Availability,error,error,53,"""""""Find image type based on array dimensions. Raises error on invalid image dimensions.; Args:; arr: numpy array. Input array. Returns:; str. ""RGB"" or ""L"", meant for PIL.Image.fromarray.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:116,Energy Efficiency,adapt,adapt,116,"""""""Adjust an array to prepare it for saving to an image. Re-scale numbers in the input array to go from 0 to 255 to adapt them for a; PNG image. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; vmin: number (float or int). Minimum data value, which will correspond to; black in greyscale or lack of each color in RGB images. Default None takes; the minimum of the data from arr.; vmax: number (float or int). Maximum data value, which will correspond to; white in greyscale or full presence of each color in RGB images. Default; None takes the max of the data from arr. Returns:; (modified numpy array, image_mode); """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:116,Modifiability,adapt,adapt,116,"""""""Adjust an array to prepare it for saving to an image. Re-scale numbers in the input array to go from 0 to 255 to adapt them for a; PNG image. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; vmin: number (float or int). Minimum data value, which will correspond to; black in greyscale or lack of each color in RGB images. Default None takes; the minimum of the data from arr.; vmax: number (float or int). Maximum data value, which will correspond to; white in greyscale or full presence of each color in RGB images. Default; None takes the max of the data from arr. Returns:; (modified numpy array, image_mode); """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:843,Energy Efficiency,adapt,adapts,843,"""""""Make a PNG and show it from a numpy array of dtype=np.uint8. Args:; arr: numpy array. Input array to save.; path: str. File path at which to save the image. A .png prefix is added if; the path does not already have one. Leave empty to save at /tmp/tmp.png,; which is useful when only temporarily showing the image in a Colab; notebook.; image_mode: ""RGB"" or ""L"". Leave as default=None to choose based on image; dimensions.; show: bool. Whether to display the image using IPython (for notebooks).; labels: list of str. Labels to show across the top of the image.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:843,Modifiability,adapt,adapts,843,"""""""Make a PNG and show it from a numpy array of dtype=np.uint8. Args:; arr: numpy array. Input array to save.; path: str. File path at which to save the image. A .png prefix is added if; the path does not already have one. Leave empty to save at /tmp/tmp.png,; which is useful when only temporarily showing the image in a Colab; notebook.; image_mode: ""RGB"" or ""L"". Leave as default=None to choose based on image; dimensions.; show: bool. Whether to display the image using IPython (for notebooks).; labels: list of str. Labels to show across the top of the image.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:1065,Usability,simpl,simple,1065,"""""""Make a PNG and show it from a numpy array of dtype=np.uint8. Args:; arr: numpy array. Input array to save.; path: str. File path at which to save the image. A .png prefix is added if; the path does not already have one. Leave empty to save at /tmp/tmp.png,; which is useful when only temporarily showing the image in a Colab; notebook.; image_mode: ""RGB"" or ""L"". Leave as default=None to choose based on image; dimensions.; show: bool. Whether to display the image using IPython (for notebooks).; labels: list of str. Labels to show across the top of the image.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:987,Energy Efficiency,adapt,adapts,987,"""""""Save an array as a PNG image with PIL and show it. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; path: str. Path for the image output. Default is /tmp/tmp.png for quickly; showing the image in a notebook.; show: bool. Whether to show the image using IPython utilities, only works in; notebooks.; vmin: number. Minimum data value, which will correspond to black in; greyscale or lack of each color in RGB images. Default None takes the; minimum of the data from arr.; vmax: number. Maximum data value, which will correspond to white in; greyscale or full presence of each color in RGB images. Default None takes; the max of the data from arr.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content.; labels: list of str. Labels to show across the top of the image. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:987,Modifiability,adapt,adapts,987,"""""""Save an array as a PNG image with PIL and show it. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; path: str. Path for the image output. Default is /tmp/tmp.png for quickly; showing the image in a notebook.; show: bool. Whether to show the image using IPython utilities, only works in; notebooks.; vmin: number. Minimum data value, which will correspond to black in; greyscale or lack of each color in RGB images. Default None takes the; minimum of the data from arr.; vmax: number. Maximum data value, which will correspond to white in; greyscale or full presence of each color in RGB images. Default None takes; the max of the data from arr.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content.; labels: list of str. Labels to show across the top of the image. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:1209,Usability,simpl,simple,1209,"""""""Save an array as a PNG image with PIL and show it. Args:; arr: numpy array. Should be 2-dimensional or 3-dimensional where the third; dimension has 3 channels.; path: str. Path for the image output. Default is /tmp/tmp.png for quickly; showing the image in a notebook.; show: bool. Whether to show the image using IPython utilities, only works in; notebooks.; vmin: number. Minimum data value, which will correspond to black in; greyscale or lack of each color in RGB images. Default None takes the; minimum of the data from arr.; vmax: number. Maximum data value, which will correspond to white in; greyscale or full presence of each color in RGB images. Default None takes; the max of the data from arr.; scale: integer. Number of pixels wide and tall to show each cell in the; array. This sizes up the image while keeping exactly the same number of; pixels for every cell in the array, preserving resolution and preventing; any interpolation or overlapping of pixels. Default None adapts to the; size of the image to multiply it up until a limit of 500 pixels, a; convenient size for use in notebooks. If saving to a file for automated; processing, scale=1 is recommended to keep output files small and simple; while still retaining all the information content.; labels: list of str. Labels to show across the top of the image. Returns:; None. Saves an image at path and optionally shows it with IPython.display.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:293,Integrability,depend,dependency,293,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:271,Safety,avoid,avoids,271,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:36,Testability,test,test,36,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:189,Testability,test,test,189,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:488,Testability,test,test,488,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:110,Usability,simpl,simplifies,110,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:197,Usability,simpl,simply,197,"""""""Calculates a two-tailed binomial test with p=0.5, without scipy. Since the expected probability is 0.5, it simplifies a few things:; 1) (0.5**x)*(0.5**(n-x)) = (0.5**n); 2) A two-tailed test is simply doubling when p = 0.5.; Scipy is much larger than Nucleus, so this avoids adding it as a dependency. Args:; k: Number of ""successes"", in this case, the number of supporting reads.; n: Number of ""trials"", in this case, the total number of reads. Returns:; The p-value for the binomial test.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:59,Usability,simpl,simplification,59,"# With p=0.5, the distribution is symmetric, allowing this simplification:",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:37,Testability,test,test,37,"# Doubling because it's a two-tailed test.",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:239,Testability,test,test,239,"""""""Calculates a rough p-value for strand bias in pileup. Using the strand and read-supports-variant channels, compares the numbers of; forward and reverse reads among the supporting reads and returns a p-value; using a two-tailed binomial test. Args:; channels: List of DeepVariant channels. Uses channels[3] (strand) and; channels[4] (read support). Returns:; P-value for whether the supporting reads show strand bias.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:290,Availability,error,errors,290,"""""""Analyzes which differences belong to nearby variants and which do not. This attempts to identify putative nearby variants from the pileup image; alone, and then excludes these columns of the pileup to calculate the; remaining fraction of differences that may be attributed to sequencing errors. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[5], the 'differs from ref' channel. Returns:; Two outputs: diff fraction, number of likely nearby variants.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:93,Safety,avoid,avoids,93,"# Divide to get the fraction of reads showing a diff at each base (column).; # Adding 1 here avoids dividing by zero (exact fraction here is not vital).",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:46,Availability,error,error,46,"# Exclude potential variants when calculating error fraction.",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:247,Availability,error,errors,247,"""""""Describes a pileup image by its diff channel, including nearby variants. Returns Diff.MANY_DIFFS if the fraction of differences outside potential; nearby variants is above the diff_fraction_threshold, which is usually; indicative of sequencing errors. Otherwise return Diff.NEARBY_VARIANTS if; there are five or more of these, or Diff.FEW_DIFFS if neither of these; special cases apply. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[5], the 'differs from ref' channel.; diff_fraction_threshold: Fraction of total bases of all reads that can; differ, above which the pileup will be designated as 'many_diffs'.; Differences that appear due to nearby variants (neater columns) do not; count towards this threshold. The default is set by visual curation of; Illumina reads, so it may be necessary to increase this for higher-error; sequencing types. Returns:; One Diff value.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py:870,Availability,error,error,870,"""""""Describes a pileup image by its diff channel, including nearby variants. Returns Diff.MANY_DIFFS if the fraction of differences outside potential; nearby variants is above the diff_fraction_threshold, which is usually; indicative of sequencing errors. Otherwise return Diff.NEARBY_VARIANTS if; there are five or more of these, or Diff.FEW_DIFFS if neither of these; special cases apply. Args:; channels: A list of channels of a DeepVariant pileup image. This only uses; channels[5], the 'differs from ref' channel.; diff_fraction_threshold: Fraction of total bases of all reads that can; differ, above which the pileup will be designated as 'many_diffs'.; Differences that appear due to nearby variants (neater columns) do not; count towards this threshold. The default is set by visual curation of; Illumina reads, so it may be necessary to increase this for higher-error; sequencing types. Returns:; One Diff value.; """"""",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis_test.py:28,Availability,error,error,28,"# Test that it runs without error.",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis_test.py:28,Availability,error,error,28,"# Test that it runs without error.",MatchSource.CODE_COMMENT,third_party/nucleus/util/vis_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/vis_test.py
https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/python/math_wrap_test.py:30,Integrability,wrap,wrappers,30,"""""""Tests for Math CLIF python wrappers.""""""",MatchSource.CODE_COMMENT,third_party/nucleus/util/python/math_wrap_test.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/third_party/nucleus/util/python/math_wrap_test.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:40,Deployability,pipeline,pipeline,40,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:147,Deployability,pipeline,pipeline,147,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:374,Deployability,pipeline,pipeline,374,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:512,Deployability,pipeline,pipeline,512,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:565,Deployability,pipeline,pipeline,565,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:181,Modifiability,config,configure,181,"""""""Parse the commandline into known and pipeline arguments. The known arguments are required for this specific program to function,; and the other pipeline arguments can be used to configure beam and the; specific beam backend being used. See; https://github.com/apache/beam/blob/master/sdks/python/apache_beam/options/pipeline_options.py; for a list and description of the pipeline arguments accepted. Args:; argv: List containing command-line arguments. Returns:; A pair, the first of which are the known (non-pipeline) arguments; and the second of which are the pipeline arguments.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:45,Deployability,pipeline,pipeline,45,"""""""Reads records from TFRecord files. Args:; pipeline: Beam pipeline object.; input_filename_pattern_list: List of filename patterns. Returns:; A PCollection of read tf.Examples.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:60,Deployability,pipeline,pipeline,60,"""""""Reads records from TFRecord files. Args:; pipeline: Beam pipeline object.; input_filename_pattern_list: List of filename patterns. Returns:; A PCollection of read tf.Examples.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:20,Security,hash,hash,20,"""""""Returns the sha1 hash of input_bytes.""""""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:65,Deployability,pipeline,pipeline,65,"""""""Writes a file summarizing the PCollection of Examples. Args:; pipeline: Beam pipeline object.; output_examples: PCollection of examples.; input_pattern_list: str. A comma-separated string of input files.; dataset_name: str. The name of the dataset to be written in the output.; output_pattern_prefix: str. The prefix of the sharded output files.; output_filename: the output text file that contains the summary that can be; parsed into DeepVariantDatasetConfig.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:80,Deployability,pipeline,pipeline,80,"""""""Writes a file summarizing the PCollection of Examples. Args:; pipeline: Beam pipeline object.; output_examples: PCollection of examples.; input_pattern_list: str. A comma-separated string of input files.; dataset_name: str. The name of the dataset to be written in the output.; output_pattern_prefix: str. The prefix of the sharded output files.; output_filename: the output text file that contains the summary that can be; parsed into DeepVariantDatasetConfig.; """"""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:43,Deployability,pipeline,pipeline,43,"# Beam currently has no way to materialize pipeline values, so we have; # to construct the file entirely in Beam pipeline operations.",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:113,Deployability,pipeline,pipeline,113,"# Beam currently has no way to materialize pipeline values, so we have; # to construct the file entirely in Beam pipeline operations.",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:42,Deployability,pipeline,pipeline,42,"""""""Main entry point; defines and runs the pipeline.""""""",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py:50,Deployability,pipeline,pipeline,50,"# Copy over the example_info.json file before the pipeline starts.",MatchSource.CODE_COMMENT,tools/shuffle_tfrecords_beam.py,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/tree/v1.6.1/tools/shuffle_tfrecords_beam.py
