id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:1699,Security,hash,hash,1699,"1);; }; }. // Finalize the hash. Default output length is 32 bytes.; auto output = hasher.final();. // Print the hash as hexadecimal.; for (uint8_t byte : output) {; printf(""%02x"", byte);; }; printf(""\n"");; return 0;; }; ```. Using the C API:. ```c; #include ""llvm-c/blake3.h""; #include <errno.h>; #include <stdio.h>; #include <stdlib.h>; #include <string.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing m",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2038,Security,hash,hashing,2038,"ing.h>; #include <unistd.h>. int main() {; // Initialize the hasher.; llvm_blake3_hasher hasher;; llvm_blake3_hasher_init(&hasher);. // Read input bytes from stdin.; unsigned char buf[65536];; while (1) {; ssize_t n = read(STDIN_FILENO, buf, sizeof(buf));; if (n > 0) {; llvm_blake3_hasher_update(&hasher, buf, n);; } else if (n == 0) {; break; // end of file; } else {; fprintf(stderr, ""read failed: %s\n"", strerror(errno));; exit(1);; }; }. // Finalize the hash. LLVM_BLAKE3_OUT_LEN is the default output length, 32 bytes.; uint8_t output[LLVM_BLAKE3_OUT_LEN];; llvm_blake3_hasher_finalize(&hasher, output, LLVM_BLAKE3_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using B",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2693,Security,hash,hashing,2693,"_OUT_LEN);. // Print the hash as hexadecimal.; for (size_t i = 0; i < LLVM_BLAKE3_OUT_LEN; i++) {; printf(""%02x"", output[i]);; }; printf(""\n"");; return 0;; }; ```. # API. ## The Class/Struct. ```c++; class BLAKE3 {; // API; private:; llvm_blake3_hasher Hasher;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:2936,Security,hash,hasher,2936,"her;; };; ```; ```c; typedef struct {; // private fields; } llvm_blake3_hasher;; ```. An incremental BLAKE3 hashing state, which can accept any number of; updates. This implementation doesn't allocate any heap memory, but; `sizeof(llvm_blake3_hasher)` itself is relatively large, currently 1912 bytes; on x86-64. This size can be reduced by restricting the maximum input; length, as described in Section 5.4 of [the BLAKE3; spec](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf),; but this implementation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:3424,Security,hash,hasher,3424,"ntation doesn't currently support that strategy. ## Common API Functions. ```c++; BLAKE3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for any N up to 256. Longer outputs don't provide any; additional security. Shorter BLAKE3 outputs are prefixes of longer ones. Explicitly; requesting a short output is equivalent to truncating the default-length; output. (Note that this is different between BLAKE2 and BLAKE3.). ## Less Common API Functions. ```c; void llvm_blake3_hasher_init_keyed(; llvm_blake3_hasher *self,; const uint8_t key[LLVM_BLAKE3_KEY_LEN]);; ```. Initialize a `llvm_blake3_hasher` in the keyed hashing mode. The key must be; exactly 32 byt",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:3508,Security,hash,hasher,3508,"3::BLAKE3();. void BLAKE3::init();; ```; ```c; void llvm_blake3_hasher_init(; llvm_blake3_hasher *self);; ```. Initialize a `llvm_blake3_hasher` in the default hashing mode. ---. ```c++; void BLAKE3::update(ArrayRef<uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for any N up to 256. Longer outputs don't provide any; additional security. Shorter BLAKE3 outputs are prefixes of longer ones. Explicitly; requesting a short output is equivalent to truncating the default-length; output. (Note that this is different between BLAKE2 and BLAKE3.). ## Less Common API Functions. ```c; void llvm_blake3_hasher_init_keyed(; llvm_blake3_hasher *self,; const uint8_t key[LLVM_BLAKE3_KEY_LEN]);; ```. Initialize a `llvm_blake3_hasher` in the keyed hashing mode. The key must be; exactly 32 bytes. ---. ```c; void llvm_blake3_hasher_init_derive_key(; llvm_blake3_hasher *self,; con",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:3784,Security,secur,security,3784,"uint8_t> Data);. void BLAKE3::update(StringRef Str);; ```; ```c; void llvm_blake3_hasher_update(; llvm_blake3_hasher *self,; const void *input,; size_t input_len);; ```. Add input to the hasher. This can be called any number of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for any N up to 256. Longer outputs don't provide any; additional security. Shorter BLAKE3 outputs are prefixes of longer ones. Explicitly; requesting a short output is equivalent to truncating the default-length; output. (Note that this is different between BLAKE2 and BLAKE3.). ## Less Common API Functions. ```c; void llvm_blake3_hasher_init_keyed(; llvm_blake3_hasher *self,; const uint8_t key[LLVM_BLAKE3_KEY_LEN]);; ```. Initialize a `llvm_blake3_hasher` in the keyed hashing mode. The key must be; exactly 32 bytes. ---. ```c; void llvm_blake3_hasher_init_derive_key(; llvm_blake3_hasher *self,; const char *context);; ```. Initialize a `llvm_blake3_hasher` in the key derivation mode. The context; string is given as an initialization parameter, and afterwards input key; material should be given with `llvm_blake3_",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:3993,Security,secur,security,3993,"of times. ---. ```c++; template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; using BLAKE3Result = std::array<uint8_t, NumBytes>;. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; void BLAKE3::final(BLAKE3Result<NumBytes> &Result);. template <size_t NumBytes = LLVM_BLAKE3_OUT_LEN>; BLAKE3Result<NumBytes> BLAKE3::final();; ```; ```c; void llvm_blake3_hasher_finalize(; const llvm_blake3_hasher *self,; uint8_t *out,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for any N up to 256. Longer outputs don't provide any; additional security. Shorter BLAKE3 outputs are prefixes of longer ones. Explicitly; requesting a short output is equivalent to truncating the default-length; output. (Note that this is different between BLAKE2 and BLAKE3.). ## Less Common API Functions. ```c; void llvm_blake3_hasher_init_keyed(; llvm_blake3_hasher *self,; const uint8_t key[LLVM_BLAKE3_KEY_LEN]);; ```. Initialize a `llvm_blake3_hasher` in the keyed hashing mode. The key must be; exactly 32 bytes. ---. ```c; void llvm_blake3_hasher_init_derive_key(; llvm_blake3_hasher *self,; const char *context);; ```. Initialize a `llvm_blake3_hasher` in the key derivation mode. The context; string is given as an initialization parameter, and afterwards input key; material should be given with `llvm_blake3_hasher_update`. The context string; is a null-terminated C string which should be **hardcoded, globally; unique, and application-specific**. The context string should not; include any dynamic input like salts, nonces, or iden",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:4401,Security,hash,hashing,4401,"ut,; size_t out_len);; ```. Finalize the hasher and return an output of any length, given in bytes.; This doesn't modify the hasher itself, and it's possible to finalize; again after adding more input. The constant `LLVM_BLAKE3_OUT_LEN` provides; the default output length, 32 bytes, which is recommended for most; callers. Outputs shorter than the default length of 32 bytes (256 bits) provide; less security. An N-bit BLAKE3 output is intended to provide N bits of; first and second preimage resistance and N/2 bits of collision; resistance, for any N up to 256. Longer outputs don't provide any; additional security. Shorter BLAKE3 outputs are prefixes of longer ones. Explicitly; requesting a short output is equivalent to truncating the default-length; output. (Note that this is different between BLAKE2 and BLAKE3.). ## Less Common API Functions. ```c; void llvm_blake3_hasher_init_keyed(; llvm_blake3_hasher *self,; const uint8_t key[LLVM_BLAKE3_KEY_LEN]);; ```. Initialize a `llvm_blake3_hasher` in the keyed hashing mode. The key must be; exactly 32 bytes. ---. ```c; void llvm_blake3_hasher_init_derive_key(; llvm_blake3_hasher *self,; const char *context);; ```. Initialize a `llvm_blake3_hasher` in the key derivation mode. The context; string is given as an initialization parameter, and afterwards input key; material should be given with `llvm_blake3_hasher_update`. The context string; is a null-terminated C string which should be **hardcoded, globally; unique, and application-specific**. The context string should not; include any dynamic input like salts, nonces, or identifiers read from a; database at runtime. A good default format for the context string is; `""[application] [commit timestamp] [purpose]""`, e.g., `""example.com; 2019-12-25 16:18:03 session tokens v1""`. This function is intended for application code written in C. For; language bindings, see `llvm_blake3_hasher_init_derive_key_raw` below. ---. ```c; void llvm_blake3_hasher_init_derive_key_raw(; llvm_blake3_ha",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:6568,Security,hash,hasher,6568," This is intended for writing language bindings, where C string; conversion would add unnecessary overhead and new error cases. Unicode; strings should be encoded as UTF-8. Application code in C should prefer `llvm_blake3_hasher_init_derive_key`,; which takes the context as a C string. If you need to use arbitrary; bytes as a context string in application code, consider whether you're; violating the requirement that context strings should be hardcoded. ---. ```c; void llvm_blake3_hasher_finalize_seek(; const llvm_blake3_hasher *self,; uint64_t seek,; uint8_t *out,; size_t out_len);; ```. The same as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; diff",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/TODO.md:17,Testability,test,test,17,"# Write an XFAIL test for this `FIXME` in `AVRInstrInfo.td`. ```; // :FIXME: DAGCombiner produces an shl node after legalization from these seq:; // BR_JT -> (mul x, 2) -> (shl x, 1); ```. ",MatchSource.DOCS,interpreter/llvm-project/llvm/lib/Target/AVR/TODO.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/AVR/TODO.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:329,Deployability,configurat,configurations,329,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:272,Integrability,depend,dependent,272,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:628,Integrability,depend,dependency,628,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:329,Modifiability,config,configurations,329,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:181,Performance,perform,performance,181,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:679,Performance,perform,performance,679,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:38,Testability,benchmark,benchmarking,38,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:348,Testability,benchmark,benchmarking,348,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:580,Testability,benchmark,benchmarking,580,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:962,Testability,benchmark,benchmarking,962,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:1208,Testability,benchmark,benchmarking,1208,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md:1445,Testability,test,test,1445,"# llvm-exegesis. `llvm-exegesis` is a benchmarking tool that accepts or assembles a snippet and; can measure characteristics of that snippet by executing it while keeping track; of performance counters. ### Currently Supported Platforms. `llvm-exegesis` is quite platform-dependent and currently only supports a couple; platform configurations for benchmarking. The limitations are listed below.; Analysis mode in `llvm-exegesis` is supported on all platforms on which LLVM is. #### Currently Supported Operating Systems for Benchmarking. Currently, `llvm-exegesis` only supports benchmarking on Linux. This is mainly; due to a dependency on the Linux perf subsystem for reading performance; counters. The subprocess execution mode and memory annotations currently only supports; Linux due to a heavy reliance on many Linux specific syscalls/syscall; implementations. #### Currently Supported Architectures for Benchmarking. Currently, using `llvm-exegesis` for benchmarking is supported on the following; architectures:; * x86; * 64-bit only due to this being the only implemented calling convention; in `llvm-exegesis` currently.; * ARM; * AArch64 only; * MIPS; * PowerPC (PowerPC64LE only). Note that not benchmarking functionality is guaranteed to work on all platforms. Memory annotations are currently only supported on 64-bit X86. There is no; inherent limitations for porting memory annotations to other architectures, but; parts of the test harness are implemented as MCJITed assembly that is generated; in `./lib/X86/Target.cpp` that would need to be implemented on other architectures; to bring up support.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/tools/llvm-exegesis/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md:201,Availability,down,downstream,201,"# MLGO Python Utilities. This folder contains MLGO Python utilities, particularly infrastructure; to help enable ML applications within LLVM, especially tooling to extract; corpora that can be used in downstream projects to train ML models and perform; other tasks that benefit from having a large amount of data. ### Python Versioning. Due to type annotations, the MLGO tooling currently only supports a Python; version greater than 3.8, deviating from the current LLVM project-wide; minimum supported version of Python 3.6.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/mlgo-utils/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md:244,Performance,perform,perform,244,"# MLGO Python Utilities. This folder contains MLGO Python utilities, particularly infrastructure; to help enable ML applications within LLVM, especially tooling to extract; corpora that can be used in downstream projects to train ML models and perform; other tasks that benefit from having a large amount of data. ### Python Versioning. Due to type annotations, the MLGO tooling currently only supports a Python; version greater than 3.8, deviating from the current LLVM project-wide; minimum supported version of Python 3.6.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/mlgo-utils/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/mlgo-utils/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:2139,Availability,avail,available,2139,";; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021-how-to-write-a-tablegen-backend.pdf), also available as a; 	[notebook](jupyter/sql_query_backend.ipynb). TableGen in MLIR:; * [Operation Definition Specification](https://mlir.llvm.org/docs/DefiningDialects/Operations/); * [Defining Dialect Attributes and Types](https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/). Useful tools:; * [TableGen Jupyter Kernel](jupyter/); * [TableGen LSP Language Server](https://mlir.llvm.org/docs/Tools/MLIRLSP/#tablegen-lsp-language-server--tblgen-lsp-server). ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:1528,Energy Efficiency,schedul,schedule,1528,"at(""Hello "", Hello:_msg);; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021-how-to-write-a-tablegen-backend.pdf), also available as a; 	[notebook](jupyter/sql_query_backend.ipynb). TableGen in MLIR:; * [Operation Definition Specification](https://mlir.llvm.org/docs/DefiningDialects/Operations/); * [Defining Dialect Attributes and Types](https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/). Useful tools:; * [TableGen Jupyter Kernel](jupyter/); * [TableGen LSP Language Server](https://mlir.llvm.org/docs/Tools/MLIRLSP/#tablegen-lsp-language-serve",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:1073,Usability,learn,learning,1073,"on; from source files that are significantly easier to code than the output files would be, and also easier to maintain and modify over time. The information is coded in a declarative style involving classes and records,; which are then processed by TableGen. ```; class Hello <string _msg> {; string msg = !strconcat(""Hello "", _msg);; }. def HelloWorld: Hello<""world!""> {}; ```; ```; ------------- Classes -----------------; class Hello<string Hello:_msg = ?> {; string msg = !strconcat(""Hello "", Hello:_msg);; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:1189,Usability,guid,guide,1189," be, and also easier to maintain and modify over time. The information is coded in a declarative style involving classes and records,; which are then processed by TableGen. ```; class Hello <string _msg> {; string msg = !strconcat(""Hello "", _msg);; }. def HelloWorld: Hello<""world!""> {}; ```; ```; ------------- Classes -----------------; class Hello<string Hello:_msg = ?> {; string msg = !strconcat(""Hello "", Hello:_msg);; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021-how-to-write-a-tablegen-backend.pdf), also available as a; 	[notebook](jupyter/sql_quer",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md:1382,Usability,learn,learning-llvm-tablegen,1382,"sg = !strconcat(""Hello "", _msg);; }. def HelloWorld: Hello<""world!""> {}; ```; ```; ------------- Classes -----------------; class Hello<string Hello:_msg = ?> {; string msg = !strconcat(""Hello "", Hello:_msg);; }; ------------- Defs -----------------; def HelloWorld { // Hello; string msg = ""Hello world!"";; }; ```; [Try this example on Compiler Explorer.](https://godbolt.org/z/13xo1P5oz). The internalized records are passed on to various backends, which extract; information from a subset of the records and generate one or more output files. These output files are typically .inc files for C++, but may be any type of file; that the backend developer needs. Resources for learning the language:; * [TableGen Overview](https://llvm.org/docs/TableGen/index.html); * [Programmer's reference guide](https://llvm.org/docs/TableGen/ProgRef.html); * [Tutorial](jupyter/tablegen_tutorial_part_1.ipynb); * [Tools for Learning LLVM TableGen](https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/); * [Lessons in TableGen](https://www.youtube.com/watch?v=45gmF77JFBY) (video),; [slides](https://archive.fosdem.org/2019/schedule/event/llvm_tablegen/attachments/slides/3304/export/events/attachments/llvm_tablegen/slides/3304/tablegen.pdf); * [Improving Your TableGen Descriptions](https://www.youtube.com/watch?v=dIEVUlsiktQ); (video), [slides](https://llvm.org/devmtg/2019-10/slides/Absar-ImprovingYourTableGenDescription.pdf). Writing TableGen backends:; * [TableGen Backend Developer's Guide](https://llvm.org/docs/TableGen/BackGuide.html); * [How to write a TableGen backend](https://www.youtube.com/watch?v=UP-LBRbvI_U); (video), [slides](https://llvm.org/devmtg/2021-11/slides/2021-how-to-write-a-tablegen-backend.pdf), also available as a; 	[notebook](jupyter/sql_query_backend.ipynb). TableGen in MLIR:; * [Operation Definition Specification](https://mlir.llvm.org/docs/DefiningDialects/Operations/); * [Defining Dialect Attributes and Types](https://mlir.llvm.org/docs/DefiningDial",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:323,Availability,error,error,323,"# LLVM TableGen Kernel. This notebook is running `llvm-tblgen`. ```tablegen; %reset; // This is some tablegen; class Foo {}; ```. ------------- Classes -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. --------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1120,Availability,error,error,1120,"lasses -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1472,Availability,error,error,1472,"ass Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes ---------------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1521,Availability,error,error,1521," }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes -----------------; ------------- Defs -----------------. It is not valid to have `%reset` and `%noreset` in the",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:2234,Availability,error,error,2234,"agic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes -----------------; ------------- Defs -----------------. It is not valid to have `%reset` and `%noreset` in the same cell. ```tablegen; %reset; %noreset; ```. %reset and %noreset in the same cell is not allowed. Use only one, or neither. Consider setting `cellreset` to the majority usecase for your notebook. For example a tutorial building a large example across many cells will likely want it `off`. One with many standalone examples, `on`. There is a ""magic"" directive `%args` that you can use to send command line arguments to `llvm-tblgen`. For example, here we have some code that shows a warning. ```tablegen; %reset; class Thing <int A, int B> {; int num = A;; }; ```. <stdin>:1:25: warning: unused template argument: Thing:B; class Thing <int A, int B> {; ^. We can pass an argument to ignore that warning. ```tablege",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1200,Modifiability,config,configure,1200,"Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdi",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1250,Modifiability,config,config,1250,"Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdi",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1279,Modifiability,config,config,1279,"t tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thin",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:2315,Modifiability,config,config,2315,"--------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes -----------------; ------------- Defs -----------------. It is not valid to have `%reset` and `%noreset` in the same cell. ```tablegen; %reset; %noreset; ```. %reset and %noreset in the same cell is not allowed. Use only one, or neither. Consider setting `cellreset` to the majority usecase for your notebook. For example a tutorial building a large example across many cells will likely want it `off`. One with many standalone examples, `on`. There is a ""magic"" directive `%args` that you can use to send command line arguments to `llvm-tblgen`. For example, here we have some code that shows a warning. ```tablegen; %reset; class Thing <int A, int B> {; int num = A;; }; ```. <stdin>:1:25: warning: unused template argument: Thing:B; class Thing <int A, int B> {; ^. We can pass an argument to ignore that warning. ```tablegen; %args --no-warn-on-unused-template-args; ```. ------------- Classes -----------------; cl",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:658,Performance,cache,cache,658,"# LLVM TableGen Kernel. This notebook is running `llvm-tblgen`. ```tablegen; %reset; // This is some tablegen; class Foo {}; ```. ------------- Classes -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. --------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1029,Performance,cache,cache,1029,"ernel. This notebook is running `llvm-tblgen`. ```tablegen; %reset; // This is some tablegen; class Foo {}; ```. ------------- Classes -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes --",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1438,Performance,cache,cache,1438,"ass Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes ---------------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:2370,Performance,cache,cache,2370,"--------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thing {}; ^. ```tablegen; %config cellreset off; %reset; // Here we have an empty cache and default reset behaviour.; ```. ------------- Classes -----------------; ------------- Defs -----------------. It is not valid to have `%reset` and `%noreset` in the same cell. ```tablegen; %reset; %noreset; ```. %reset and %noreset in the same cell is not allowed. Use only one, or neither. Consider setting `cellreset` to the majority usecase for your notebook. For example a tutorial building a large example across many cells will likely want it `off`. One with many standalone examples, `on`. There is a ""magic"" directive `%args` that you can use to send command line arguments to `llvm-tblgen`. For example, here we have some code that shows a warning. ```tablegen; %reset; class Thing <int A, int B> {; int num = A;; }; ```. <stdin>:1:25: warning: unused template argument: Thing:B; class Thing <int A, int B> {; ^. We can pass an argument to ignore that warning. ```tablegen; %args --no-warn-on-unused-template-args; ```. ------------- Classes -----------------; cl",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1018,Usability,clear,clear,1018,"ernel. This notebook is running `llvm-tblgen`. ```tablegen; %reset; // This is some tablegen; class Foo {}; ```. ------------- Classes -----------------; class Foo {; }; ------------- Defs -----------------. Errors printed to stderr are shown. ```tablegen; %reset; This is not tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes --",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:473,Availability,down,downloaded,473,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:1554,Availability,error,error,1554,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:628,Deployability,install,install,628,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:665,Deployability,install,installed,665,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:878,Deployability,install,install,878,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:1023,Deployability,install,installed,1023,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:1110,Integrability,interface,interface,1110,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md:1481,Modifiability,variab,variable,1481,"# Jupyter Tools for TableGen. This folder contains notebooks relating to TableGen and a Jupyter kernel for; TableGen. ## Notebooks. [LLVM_TableGen.ipynb](LLVM_TableGen.ipynb) - A demo of the kernel's capabilities. [tablegen_tutorial_part_1.ipynb](tablegen_tutorial_part_1.ipynb) - A tutorial on the TableGen language. [sql_query_backend.ipynb](sql_query_backend.ipynb) - How to write a backend using; JSON output and Python. Notebooks can be viewed in browser on Github or downloaded and run locally. If; that is not possible, there are Markdown versions next to the notebook files. ## TableGen Kernel. To use the kernel, first install it into jupyter. If you have installed Jupyter into a virtual environment, adjust `python3` to; be the interpreter for that environment. This will ensure that tools run the; kernel in the correct context. ```shell; python3 -m tablegen_kernel.install; ```. If you are going to open the notebook in an IDE like Visual Studio Code,; you should restart it now so that it will find the newly installed kernel. Then run one of:. ```shell; jupyter notebook; # Then in the notebook interface, select 'LLVM TableGen' from the 'New' menu. # To run the example notebook in this folder.; jupyter notebook LLVM_TableGen.ipynb. # To use the kernel from the command line.; jupyter console --kernel tablegen; ```. Or open the notebook in a tool with built in Jupyter support. `llvm-tblgen` is expected to be either in the `PATH` or you can set; the environment variable `LLVM_TBLGEN_EXECUTABLE` to point to it directly. If you see an error like this:; ```shell; Cell In[8], line 2; // This is some tablegen; ^; SyntaxError: invalid syntax; ```. You are probably running the notebook using the iPython kernel. Make sure you; have selected the tablegen kernel. To run the kernel's doctests do:. ```shell; python3 tablegen_kernel/kernel.py; ```; ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/README.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:1584,Modifiability,variab,variable,1584,"urce -> llvm-tblgen -> JSON -> Python -> results; ```. The backend here is ported from one of several in ""SQLGen"" which was written by Min-Yih Hsu.; * SQLGen C++ sources - https://github.com/mshockwave/SQLGen; * LLVM dev presentation - https://www.youtube.com/watch?v=UP-LBRbvI_U. I encourage you to use those resources to supplement this notebook. ## Compiling TableGen. Unlike the other tutorial notebooks we are not using the TableGen kernel. This is an iPython notebook and we're going to run `llvm-tblgen` as a subprocess. First let's find it, in the same way the TableGen kernel does. ```python; import os; import shutil. def find_tblgen():; path = os.environ.get(""LLVM_TBLGEN_EXECUTABLE""); if path is not None and os.path.isfile(path) and os.access(path, os.X_OK):; return path; else:; path = shutil.which(""llvm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file like object.; with tempfile.TemporaryFile(""w+"") as f:; f.write(src); f.seek(0); got = subprocess.run(; [find_tblgen(), ""--dump-json""],; stdin=f,; stderr=subprocess.PIPE,; stdout=subprocess.PIPE,; universal_newlines=True,; ); ; if got.stderr:; raise RuntimeError(""llvm-tblgen failed with stderr: "" + got.stderr); ; return json.loads(got.stdout); ; print(json.dumps(run_tblgen(""class Foo {}""), indent=4)); ```. {; ""!instanceof"": {; ""Foo"": []; },; ""!tablegen_json_version"": 1; }. ## Structure of a SQL Query. This backe",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:11157,Modifiability,inherit,inherit,11157,"have `Query` which lists all the queries we defined. ```python; print(full_json[""anonymous_0""][""!superclasses""]); ```. ['Query']. On each def there is also a `!superclasses` that gives you the same information. Meaning you could use `!instanceof` to get a list of keys to lookup, or you could walk all keys and check `!superclasses`. ```python; print(full_json[""anonymous_0""][""Fields""]); ```. {'args': [], 'kind': 'dag', 'operator': {'def': 'all', 'kind': 'def', 'printable': 'all'}, 'printable': '(all)'}. From a def object you can find its attributes. Here we have the fields we want the query to show, which is all of them. # The Backend. The core of a backend is looping over all defs of a certain class and outputting some text based on their properties. Here we're going to loop over all defs of type `Query` and emit SQL queries for them. ```python; def find_all_queries(j):; queries = []; for key in j:; # ! means it is some metadata, not a def.; if not key.startswith(""!""):; value = full_json[key]; # If we inherit from Query.; if ""Query"" in value[""!superclasses""]:; queries.append(value); return queries. queries = find_all_queries(full_json); ; print([q[""!name""] for q in queries]); ```. ['anonymous_0', 'anonymous_1', 'anonymous_2', 'anonymous_3', 'anonymous_4']. Why are the names `anonymous_...`? When we defined them we did `def :` and missed out the name. This is allowed and `llvm-tblgen` just came up with a name for us. For this purpose the names are irrelevant. Now we have the relevant classes we need to ""emit"" them. Meaning produce something from them, in this case a SQL query. ```python; def emit_operator(operator):; return {; 'gt': ' > ',; 'ge': ' >= ',; 'lt': ' < ',; 'le': ' <= ',; 'ne': ' <> ',; 'eq': ' = ',; 'or': ' OR ',; 'and': ' AND '; }[operator]. print(emit_operator('and')); ```. AND . The maps our TableGen constants to the equivalent SQL logical operation. ```python; def emit_fields(args):; # Return a comma separated list of arg names.; return "", "".join([arg[",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:2328,Performance,load,loads,2328,"vm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file like object.; with tempfile.TemporaryFile(""w+"") as f:; f.write(src); f.seek(0); got = subprocess.run(; [find_tblgen(), ""--dump-json""],; stdin=f,; stderr=subprocess.PIPE,; stdout=subprocess.PIPE,; universal_newlines=True,; ); ; if got.stderr:; raise RuntimeError(""llvm-tblgen failed with stderr: "" + got.stderr); ; return json.loads(got.stdout); ; print(json.dumps(run_tblgen(""class Foo {}""), indent=4)); ```. {; ""!instanceof"": {; ""Foo"": []; },; ""!tablegen_json_version"": 1; }. ## Structure of a SQL Query. This backend is going to generate SQL queries. The general form of a SQL query is:; ```; SELECT <some field names> FROM <table name>; WHERE <conditions>; ORDER BY <field tags>;; ```. ## SQL Query TableGen. ```python; query_tblgen = """"""\; def all;; def fields;; def none;. def eq;; def ne;; def gt;; def ge;; def and;; def or;; """"""; ```. Normally you'd write this to a `.td` file but here we have it in a Python string to fit into this notebook. We will add to this string to produce the final source. This section defines some constants. First are the fields we want to get back from the query:; * `all` - Return all fields.; * `fields` - Means that we will provide a list of fields we are interested in. The second set are the logical operators for what will become the `WHERE` clause (called `condition` in the TableGen). T",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:1266,Security,access,access,1266,"port this tutorial to any language that has a JSON parser. This is the process in LLVM, using a C++ backend:; ```; TableGen source -> llvm-tblgen -> backend (within llvm-tblgen) -> results; ```; This is what we will be doing:; ```; TableGen source -> llvm-tblgen -> JSON -> Python -> results; ```. The backend here is ported from one of several in ""SQLGen"" which was written by Min-Yih Hsu.; * SQLGen C++ sources - https://github.com/mshockwave/SQLGen; * LLVM dev presentation - https://www.youtube.com/watch?v=UP-LBRbvI_U. I encourage you to use those resources to supplement this notebook. ## Compiling TableGen. Unlike the other tutorial notebooks we are not using the TableGen kernel. This is an iPython notebook and we're going to run `llvm-tblgen` as a subprocess. First let's find it, in the same way the TableGen kernel does. ```python; import os; import shutil. def find_tblgen():; path = os.environ.get(""LLVM_TBLGEN_EXECUTABLE""); if path is not None and os.path.isfile(path) and os.access(path, os.X_OK):; return path; else:; path = shutil.which(""llvm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file like object.; with tempfile.TemporaryFile(""w+"") as f:; f.write(src); f.seek(0); got = subprocess.run(; [find_tblgen(), ""--dump-json""],; stdin=f,; stderr=subprocess.PIPE,; stdout=subprocess.PIPE,; universal_newlines=True,; ); ; if got.stderr:; raise RuntimeError(""llvm-tblg",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:3236,Testability,log,logical,3236,"blgen failed with stderr: "" + got.stderr); ; return json.loads(got.stdout); ; print(json.dumps(run_tblgen(""class Foo {}""), indent=4)); ```. {; ""!instanceof"": {; ""Foo"": []; },; ""!tablegen_json_version"": 1; }. ## Structure of a SQL Query. This backend is going to generate SQL queries. The general form of a SQL query is:; ```; SELECT <some field names> FROM <table name>; WHERE <conditions>; ORDER BY <field tags>;; ```. ## SQL Query TableGen. ```python; query_tblgen = """"""\; def all;; def fields;; def none;. def eq;; def ne;; def gt;; def ge;; def and;; def or;; """"""; ```. Normally you'd write this to a `.td` file but here we have it in a Python string to fit into this notebook. We will add to this string to produce the final source. This section defines some constants. First are the fields we want to get back from the query:; * `all` - Return all fields.; * `fields` - Means that we will provide a list of fields we are interested in. The second set are the logical operators for what will become the `WHERE` clause (called `condition` in the TableGen). These are string versions of various symbols. For example `ne` means `!=`, which in SQL is `<>`. Finally `none` is used to mean there is no condition to the query (no `WHERE`). ```python; query_tblgen += """"""\; class Query <string table, dag query_fields = (all), dag condition = (none)> {; string TableName = table;; dag Fields = query_fields;; dag WhereClause = condition;; list<string> OrderedBy = [];; }; """"""; ```. Then the Query class. Its arguments are:; * `table` - The name of the table to query (`FROM <table>`).; * `query_fields` - The fields you want returned (`SELECT <fields>`).; * Defaults to `all` meaning return all fields.; * `condition` - Logic to select entries (`WHERE <conditions>`).; * Defaults to `none` meaning there is no condition, or in other words select all entries in the table. ## Using The Query Class. ```python; full_tblgen = query_tblgen + """"""\; def : Query<""Customer"">;. def : Query<""Orders"", (fields ""Per",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:12019,Testability,log,logical,12019,"f find_all_queries(j):; queries = []; for key in j:; # ! means it is some metadata, not a def.; if not key.startswith(""!""):; value = full_json[key]; # If we inherit from Query.; if ""Query"" in value[""!superclasses""]:; queries.append(value); return queries. queries = find_all_queries(full_json); ; print([q[""!name""] for q in queries]); ```. ['anonymous_0', 'anonymous_1', 'anonymous_2', 'anonymous_3', 'anonymous_4']. Why are the names `anonymous_...`? When we defined them we did `def :` and missed out the name. This is allowed and `llvm-tblgen` just came up with a name for us. For this purpose the names are irrelevant. Now we have the relevant classes we need to ""emit"" them. Meaning produce something from them, in this case a SQL query. ```python; def emit_operator(operator):; return {; 'gt': ' > ',; 'ge': ' >= ',; 'lt': ' < ',; 'le': ' <= ',; 'ne': ' <> ',; 'eq': ' = ',; 'or': ' OR ',; 'and': ' AND '; }[operator]. print(emit_operator('and')); ```. AND . The maps our TableGen constants to the equivalent SQL logical operation. ```python; def emit_fields(args):; # Return a comma separated list of arg names.; return "", "".join([arg[0] for arg in args]). print(emit_fields([[""Abc"", None], [""Def"", None]])); ```. Abc, Def. This emits the the fields we are selecting. Each field has a name (`arg[0]`) and an optional tag that we will use later. ```python; from collections.abc import Mapping. def emit_where_clause(where_clause):; output = """"; num_args = len(where_clause[""args""]); ; for idx, arg in enumerate(where_clause[""args""]):; arg_name, arg_type = arg. if isinstance(arg_name, Mapping):; # This is a nested where clause.; output += emit_where_clause(arg_name); else:; # This is some condition.; if arg_type == ""str"":; # String types must be emitted with """" around them.; output += '""' + arg_name + '""'; else:; output += str(arg_name). # If this is not the last arg, emit the condition.; if idx != (num_args-1):; output += emit_operator(where_clause[""operator""][""def""]); ; return output. ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:232,Usability,learn,learn,232,"# Writing a TableGen Backend in Python. This tutorial is going to walk through creating a TableGen backend using Python. We are using Python to better fit into a notebook, but backends in LLVM are written in C++. The principles you learn here will still apply and you could port this tutorial to any language that has a JSON parser. This is the process in LLVM, using a C++ backend:; ```; TableGen source -> llvm-tblgen -> backend (within llvm-tblgen) -> results; ```; This is what we will be doing:; ```; TableGen source -> llvm-tblgen -> JSON -> Python -> results; ```. The backend here is ported from one of several in ""SQLGen"" which was written by Min-Yih Hsu.; * SQLGen C++ sources - https://github.com/mshockwave/SQLGen; * LLVM dev presentation - https://www.youtube.com/watch?v=UP-LBRbvI_U. I encourage you to use those resources to supplement this notebook. ## Compiling TableGen. Unlike the other tutorial notebooks we are not using the TableGen kernel. This is an iPython notebook and we're going to run `llvm-tblgen` as a subprocess. First let's find it, in the same way the TableGen kernel does. ```python; import os; import shutil. def find_tblgen():; path = os.environ.get(""LLVM_TBLGEN_EXECUTABLE""); if path is not None and os.path.isfile(path) and os.access(path, os.X_OK):; return path; else:; path = shutil.which(""llvm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4551,Availability,error,error,4551,"t a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you ma",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4708,Availability,error,error,4708,"hich was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you make an instance of a class using `def`, that instance gets all the members of the class. T",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4813,Availability,error,error,4813,"u write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you make an instance of a class using `def`, that instance gets all the members of the class. Their values will be as set in the class, unless otherwise overridden. In the case of `a` it also keeps the undefined value. Any backend usi",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:5957,Availability,error,error,5957,"b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you make an instance of a class using `def`, that instance gets all the members of the class. Their values will be as set in the class, unless otherwise overridden. In the case of `a` it also keeps the undefined value. Any backend using that definition would have to check for that case. ```tablegen; %noreset. def Y {; int a = ""abc""; }; ```. <stdin>:10:13: error: Field 'a' of type 'int' is incompatible with value '""abc""' of type 'string'; int a = ""abc""; ^; <stdin>:11:1: error: expected ';' after declaration; }; ^. Here we see the type checking in action. Member `a` has type `int` so we cannot assign a `string` to it. ## Let. If we want to override those member values we can use `let` ([documented here](https://llvm.org/docs/TableGen/ProgRef.html#let-override-fields-in-classes-or-records)). This can be done in a couple of ways. The first is where you mark the scope of the `let` using `in {}`. `let <name>=<value> in {`. The code below says that within the `{}` after the `let`, all `a` should have the value 5. ```tablegen; class C {; int a = 9;; }; let a=5 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }. For multiple names, separate them with a comma. ```tablegen; class C {; int a;; int b;; }; let a=5, b=6 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = ?;; int b",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:6073,Availability,error,error,6073,"b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you make an instance of a class using `def`, that instance gets all the members of the class. Their values will be as set in the class, unless otherwise overridden. In the case of `a` it also keeps the undefined value. Any backend using that definition would have to check for that case. ```tablegen; %noreset. def Y {; int a = ""abc""; }; ```. <stdin>:10:13: error: Field 'a' of type 'int' is incompatible with value '""abc""' of type 'string'; int a = ""abc""; ^; <stdin>:11:1: error: expected ';' after declaration; }; ^. Here we see the type checking in action. Member `a` has type `int` so we cannot assign a `string` to it. ## Let. If we want to override those member values we can use `let` ([documented here](https://llvm.org/docs/TableGen/ProgRef.html#let-override-fields-in-classes-or-records)). This can be done in a couple of ways. The first is where you mark the scope of the `let` using `in {}`. `let <name>=<value> in {`. The code below says that within the `{}` after the `let`, all `a` should have the value 5. ```tablegen; class C {; int a = 9;; }; let a=5 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }. For multiple names, separate them with a comma. ```tablegen; class C {; int a;; int b;; }; let a=5, b=6 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = ?;; int b",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:7576,Availability,error,error,7576," ```tablegen; class C {; int a = 9;; }; let a=5 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }. For multiple names, separate them with a comma. ```tablegen; class C {; int a;; int b;; }; let a=5, b=6 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = ?;; int b = ?;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; int b = 6;; }. You can also use `let` within a `def`. This means the scope of the `let` is the same as the scope of the `def` (the def's `{...}`). ```tablegen; class C {; int a = 9;; }; def X: C {; let a=5;; }; def Y: C {}; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }; def Y {	// C; int a = 9;; }. Note that `Y` has `a` as `9` because the `let` was only applied to `X`. It is an error to try to `let` a name that hasn't been defined or to give it a value of the incorrect type. ```tablegen; class C {; int a = 9;; }; def X: C {; let a=""Hello"";; }; ```. <stdin>:5:9: error: Field 'a' of type 'int' is incompatible with value '""Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:7763,Availability,error,error,7763,"// C; int a = 5;; }. For multiple names, separate them with a comma. ```tablegen; class C {; int a;; int b;; }; let a=5, b=6 in {; def X: C {}; }; ```. ------------- Classes -----------------; class C {; int a = ?;; int b = ?;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; int b = 6;; }. You can also use `let` within a `def`. This means the scope of the `let` is the same as the scope of the `def` (the def's `{...}`). ```tablegen; class C {; int a = 9;; }; def X: C {; let a=5;; }; def Y: C {}; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }; def Y {	// C; int a = 9;; }. Note that `Y` has `a` as `9` because the `let` was only applied to `X`. It is an error to try to `let` a name that hasn't been defined or to give it a value of the incorrect type. ```tablegen; class C {; int a = 9;; }; def X: C {; let a=""Hello"";; }; ```. <stdin>:5:9: error: Field 'a' of type 'int' is incompatible with value '""Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }; def Y {	// Base; int var = 6;; }; def Z {	// Base; int var = 7;; }. The first `let` is at what we call the ""top level"". That means the outer most scope in terms of the source code. A bit",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:8071,Availability,error,error,8071,"{	// C; int a = 5;; int b = 6;; }. You can also use `let` within a `def`. This means the scope of the `let` is the same as the scope of the `def` (the def's `{...}`). ```tablegen; class C {; int a = 9;; }; def X: C {; let a=5;; }; def Y: C {}; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }; def Y {	// C; int a = 9;; }. Note that `Y` has `a` as `9` because the `let` was only applied to `X`. It is an error to try to `let` a name that hasn't been defined or to give it a value of the incorrect type. ```tablegen; class C {; int a = 9;; }; def X: C {; let a=""Hello"";; }; ```. <stdin>:5:9: error: Field 'a' of type 'int' is incompatible with value '""Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }; def Y {	// Base; int var = 6;; }; def Z {	// Base; int var = 7;; }. The first `let` is at what we call the ""top level"". That means the outer most scope in terms of the source code. A bit like a global variable in a C file. This is applied first and changes `var` from `4` to `5` for all classes within that `let` (`4` came from the definition of `Base`). def `X` is within the global `let`, therefore `var` is `5` within `X`. Then we have a `let` inside the glo",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:8174,Availability,error,error,8174,"the same as the scope of the `def` (the def's `{...}`). ```tablegen; class C {; int a = 9;; }; def X: C {; let a=5;; }; def Y: C {}; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }; def Y {	// C; int a = 9;; }. Note that `Y` has `a` as `9` because the `let` was only applied to `X`. It is an error to try to `let` a name that hasn't been defined or to give it a value of the incorrect type. ```tablegen; class C {; int a = 9;; }; def X: C {; let a=""Hello"";; }; ```. <stdin>:5:9: error: Field 'a' of type 'int' is incompatible with value '""Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }; def Y {	// Base; int var = 6;; }; def Z {	// Base; int var = 7;; }. The first `let` is at what we call the ""top level"". That means the outer most scope in terms of the source code. A bit like a global variable in a C file. This is applied first and changes `var` from `4` to `5` for all classes within that `let` (`4` came from the definition of `Base`). def `X` is within the global `let`, therefore `var` is `5` within `X`. Then we have a `let` inside the global `let`. This one changes `var` from `5` to `6`. The scope of the `let` only contains the def `Y` therefore wi",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:8304,Availability,down,down,8304,"; }; def X: C {; let a=5;; }; def Y: C {}; ```. ------------- Classes -----------------; class C {; int a = 9;; }; ------------- Defs -----------------; def X {	// C; int a = 5;; }; def Y {	// C; int a = 9;; }. Note that `Y` has `a` as `9` because the `let` was only applied to `X`. It is an error to try to `let` a name that hasn't been defined or to give it a value of the incorrect type. ```tablegen; class C {; int a = 9;; }; def X: C {; let a=""Hello"";; }; ```. <stdin>:5:9: error: Field 'a' of type 'int' is incompatible with value '""Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }; def Y {	// Base; int var = 6;; }; def Z {	// Base; int var = 7;; }. The first `let` is at what we call the ""top level"". That means the outer most scope in terms of the source code. A bit like a global variable in a C file. This is applied first and changes `var` from `4` to `5` for all classes within that `let` (`4` came from the definition of `Base`). def `X` is within the global `let`, therefore `var` is `5` within `X`. Then we have a `let` inside the global `let`. This one changes `var` from `5` to `6`. The scope of the `let` only contains the def `Y` therefore within `Y`, `var` is `6`. Finally def `Z` is within the global `let`, so `var` starts as `5",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:12071,Availability,error,error,12071,"ass C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0, 1> {}; ```. ------------- Classes -----------------; class C<int C:a = ?, int C:b = ?> {; int c = C:a;; int d = C:b;; }; ------------- Defs -----------------; def X {	// C; int c = 0;; int d = 1;; }. This means that to `def` a `C` we must now provide 2 arguments that have type `int` (type checking applies here as it does elsewhere). This is going to look familiar if you have written C++. In C++ it might look like:; ```; template<int a, int b>; class C {; int c = a;; int d = b;; };; C<0, 1> X;; ```. If templates aren't your thing, another way to think of them is as parameters to the constructor of a class. . For instance Python code might look like this:; ```; class C(object):; def __init__(self, a, b):; self.c = a; self.d = b. print(C(0, 1).c); # prints ""0""; ```. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0> {}; ```. <stdin>:5:8: error: value not specified for template argument 'C:b'; def X: C<0> {}; ^; <stdin>:1:21: note: declared in 'C'; class C <int a, int b> {; ^. When not enough arguments are provided, you get an error. Below is what happens when one of those arguments is of the wrong type. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0, ""hello""> {}; ```. <stdin>:5:8: error: Value specified for template argument 'C:b' is of type string; expected type int: ""hello""; def X: C<0, ""hello""> {}; ^. You can also provide default values for template arguments. ```tablegen; class C <int a=10> {; int b = a;; }; def X: C<> {}; ```. ------------- Classes -----------------; class C<int C:a = 10> {; int b = C:a;; }; ------------- Defs -----------------; def X {	// C; int b = 10;; }. Using class template arguments you can enforce a structure on the user of the classes. In our previous register example I could use this to require the the user pass a value for the size. The code below makes the size argument mandatory but the alias optional. ```tablegen; cl",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:12263,Availability,error,error,12263,"--------; class C<int C:a = ?, int C:b = ?> {; int c = C:a;; int d = C:b;; }; ------------- Defs -----------------; def X {	// C; int c = 0;; int d = 1;; }. This means that to `def` a `C` we must now provide 2 arguments that have type `int` (type checking applies here as it does elsewhere). This is going to look familiar if you have written C++. In C++ it might look like:; ```; template<int a, int b>; class C {; int c = a;; int d = b;; };; C<0, 1> X;; ```. If templates aren't your thing, another way to think of them is as parameters to the constructor of a class. . For instance Python code might look like this:; ```; class C(object):; def __init__(self, a, b):; self.c = a; self.d = b. print(C(0, 1).c); # prints ""0""; ```. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0> {}; ```. <stdin>:5:8: error: value not specified for template argument 'C:b'; def X: C<0> {}; ^; <stdin>:1:21: note: declared in 'C'; class C <int a, int b> {; ^. When not enough arguments are provided, you get an error. Below is what happens when one of those arguments is of the wrong type. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0, ""hello""> {}; ```. <stdin>:5:8: error: Value specified for template argument 'C:b' is of type string; expected type int: ""hello""; def X: C<0, ""hello""> {}; ^. You can also provide default values for template arguments. ```tablegen; class C <int a=10> {; int b = a;; }; def X: C<> {}; ```. ------------- Classes -----------------; class C<int C:a = 10> {; int b = C:a;; }; ------------- Defs -----------------; def X {	// C; int b = 10;; }. Using class template arguments you can enforce a structure on the user of the classes. In our previous register example I could use this to require the the user pass a value for the size. The code below makes the size argument mandatory but the alias optional. ```tablegen; class Register<int _size, string _alias=""""> {; int size = _size;; string alias = _alias;; }; def X0: Registe",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:12451,Availability,error,error,12451,"re as it does elsewhere). This is going to look familiar if you have written C++. In C++ it might look like:; ```; template<int a, int b>; class C {; int c = a;; int d = b;; };; C<0, 1> X;; ```. If templates aren't your thing, another way to think of them is as parameters to the constructor of a class. . For instance Python code might look like this:; ```; class C(object):; def __init__(self, a, b):; self.c = a; self.d = b. print(C(0, 1).c); # prints ""0""; ```. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0> {}; ```. <stdin>:5:8: error: value not specified for template argument 'C:b'; def X: C<0> {}; ^; <stdin>:1:21: note: declared in 'C'; class C <int a, int b> {; ^. When not enough arguments are provided, you get an error. Below is what happens when one of those arguments is of the wrong type. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0, ""hello""> {}; ```. <stdin>:5:8: error: Value specified for template argument 'C:b' is of type string; expected type int: ""hello""; def X: C<0, ""hello""> {}; ^. You can also provide default values for template arguments. ```tablegen; class C <int a=10> {; int b = a;; }; def X: C<> {}; ```. ------------- Classes -----------------; class C<int C:a = 10> {; int b = C:a;; }; ------------- Defs -----------------; def X {	// C; int b = 10;; }. Using class template arguments you can enforce a structure on the user of the classes. In our previous register example I could use this to require the the user pass a value for the size. The code below makes the size argument mandatory but the alias optional. ```tablegen; class Register<int _size, string _alias=""""> {; int size = _size;; string alias = _alias;; }; def X0: Register<8> {}; def X29: Register<8, ""frame pointer""> {}; ```. ------------- Classes -----------------; class Register<int Register:_size = ?, string Register:_alias = """"> {; int size = Register:_size;; string alias = Register:_alias;; }; ------------- Defs ----------------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:114,Energy Efficiency,adapt,adapted,114,"## Introduction to TableGen Part 1: Classes, Defs, Basic Types and Let. **Note:** The content in this notebook is adapted from [this document](https://llvm.org/docs/TableGen/index.html). Refer to it if you want more details. This tutorial will cover:; * Classes; * Defs; * Basic types; * `let` in various forms; * Class template arguments. ## What is TableGen?. TableGen is a language used in LLVM to automate the generation of certain types of code. Usually repetitive code that has a common structure. TableGen is used to generate ""records"" that are then processed by a ""backend"" into domain specific code. The compiler for TableGen is the binary `llvm-tblgen`. This contains the logic to convert TableGen source into records that can then be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no c",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:114,Modifiability,adapt,adapted,114,"## Introduction to TableGen Part 1: Classes, Defs, Basic Types and Let. **Note:** The content in this notebook is adapted from [this document](https://llvm.org/docs/TableGen/index.html). Refer to it if you want more details. This tutorial will cover:; * Classes; * Defs; * Basic types; * `let` in various forms; * Class template arguments. ## What is TableGen?. TableGen is a language used in LLVM to automate the generation of certain types of code. Usually repetitive code that has a common structure. TableGen is used to generate ""records"" that are then processed by a ""backend"" into domain specific code. The compiler for TableGen is the binary `llvm-tblgen`. This contains the logic to convert TableGen source into records that can then be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no c",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:1558,Modifiability,config,config,1558,"cessed by a ""backend"" into domain specific code. The compiler for TableGen is the binary `llvm-tblgen`. This contains the logic to convert TableGen source into records that can then be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no classes and no defs. Let's add a class. ## Classes. ```tablegen; class C {}; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------. Followed by a def (definition). ```tablegen; %noreset. def X: C;; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------; def X {	// C; }. `def` creates an instance of a class. Typically, the main loop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I woul",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:1697,Modifiability,config,config,1697,"hen be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no classes and no defs. Let's add a class. ## Classes. ```tablegen; class C {}; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------. Followed by a def (definition). ```tablegen; %noreset. def X: C;; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------; def X {	// C; }. `def` creates an instance of a class. Typically, the main loop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I would look for all defs that are instances of `RegisterInfo` in the example below. ```tablegen; class RegisterInfo {}; def X0: RegisterInfo {}; def X1: RegisterInfo {}; ```. --------",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:2973,Modifiability,inherit,inherit,2973,"agic to override this. No source means no classes and no defs. Let's add a class. ## Classes. ```tablegen; class C {}; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------. Followed by a def (definition). ```tablegen; %noreset. def X: C;; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------; def X {	// C; }. `def` creates an instance of a class. Typically, the main loop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I would look for all defs that are instances of `RegisterInfo` in the example below. ```tablegen; class RegisterInfo {}; def X0: RegisterInfo {}; def X1: RegisterInfo {}; ```. ------------- Classes -----------------; class RegisterInfo {; }; ------------- Defs -----------------; def X0 {	// RegisterInfo; }; def X1 {	// RegisterInfo; }. ## Inheritance. Like many other languages with classes, a class in TableGen can inherit properties of another class. ```tablegen; class C {}; class D : C {}; ```. ------------- Classes -----------------; class C {; }; class D {	// C; }; ------------- Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```.",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:3221,Modifiability,inherit,inherit,3221,"n; %noreset. def X: C;; ```. ------------- Classes -----------------; class C {; }; ------------- Defs -----------------; def X {	// C; }. `def` creates an instance of a class. Typically, the main loop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I would look for all defs that are instances of `RegisterInfo` in the example below. ```tablegen; class RegisterInfo {}; def X0: RegisterInfo {}; def X1: RegisterInfo {}; ```. ------------- Classes -----------------; class RegisterInfo {; }; ------------- Defs -----------------; def X0 {	// RegisterInfo; }; def X1 {	// RegisterInfo; }. ## Inheritance. Like many other languages with classes, a class in TableGen can inherit properties of another class. ```tablegen; class C {}; class D : C {}; ```. ------------- Classes -----------------; class C {; }; class D {	// C; }; ------------- Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it i",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:3290,Modifiability,inherit,inherits,3290,"s -----------------; def X {	// C; }. `def` creates an instance of a class. Typically, the main loop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I would look for all defs that are instances of `RegisterInfo` in the example below. ```tablegen; class RegisterInfo {}; def X0: RegisterInfo {}; def X1: RegisterInfo {}; ```. ------------- Classes -----------------; class RegisterInfo {; }; ------------- Defs -----------------; def X0 {	// RegisterInfo; }; def X1 {	// RegisterInfo; }. ## Inheritance. Like many other languages with classes, a class in TableGen can inherit properties of another class. ```tablegen; class C {}; class D : C {}; ```. ------------- Classes -----------------; class C {; }; class D {	// C; }; ------------- Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:3419,Modifiability,inherit,inheriting,3419,"oop of a TableGen backend will look for all defs that are instances of a certain class. For example if I am generating register information I would look for all defs that are instances of `RegisterInfo` in the example below. ```tablegen; class RegisterInfo {}; def X0: RegisterInfo {}; def X1: RegisterInfo {}; ```. ------------- Classes -----------------; class RegisterInfo {; }; ------------- Defs -----------------; def X0 {	// RegisterInfo; }; def X1 {	// RegisterInfo; }. ## Inheritance. Like many other languages with classes, a class in TableGen can inherit properties of another class. ```tablegen; class C {}; class D : C {}; ```. ------------- Classes -----------------; class C {; }; class D {	// C; }; ------------- Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:3737,Modifiability,inherit,inherit,3737,"asses -----------------; class RegisterInfo {; }; ------------- Defs -----------------; def X0 {	// RegisterInfo; }; def X1 {	// RegisterInfo; }. ## Inheritance. Like many other languages with classes, a class in TableGen can inherit properties of another class. ```tablegen; class C {}; class D : C {}; ```. ------------- Classes -----------------; class C {; }; class D {	// C; }; ------------- Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to le",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4140,Modifiability,inherit,inherits,4140," Defs -----------------. Inheritance is done by putting the class you want to inherit from after `:`, before the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bi",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4217,Modifiability,inherit,inherits,4217,"e the opening `{`. You'll know that `D` inherits from `C` by the `// C` comment on the `class D {` line in the output. Not very interesting though, what are we actually inheriting? The members of the parent class. ```tablegen; class C {; int a;; }; class D : C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; }; class D {	// C; int a = ?;; }; ------------- Defs -----------------. Note that `D` now has the `a` member which was defined in the class `C`. You can inherit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full lis",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:8823,Modifiability,variab,variable,8823,"Hello""' of type 'string'; let a=""Hello"";; ^. Above, the member `a` was defined but with a type of `int`. We therefore cannot `let` it have a value of type `string`. ```tablegen; class C {; int a = 9;; }; def X: C {; let b=5;; }; ```. <stdin>:5:11: error: Value 'b' unknown!; let b=5;; ^. Above, class `C` only has one member, `a`. Therefore we get an error trying to override the value of `b` which doesn't exist. If you have multiple let, the outer scope is applied first then on down to the narrowest scope. ```tablegen; class Base {; int var=4;; }; let var=5 in {; def X: Base {}; let var=6 in {; def Y: Base {}; }; def Z: Base { let var=7; }; }; ```. ------------- Classes -----------------; class Base {; int var = 4;; }; ------------- Defs -----------------; def X {	// Base; int var = 5;; }; def Y {	// Base; int var = 6;; }; def Z {	// Base; int var = 7;; }. The first `let` is at what we call the ""top level"". That means the outer most scope in terms of the source code. A bit like a global variable in a C file. This is applied first and changes `var` from `4` to `5` for all classes within that `let` (`4` came from the definition of `Base`). def `X` is within the global `let`, therefore `var` is `5` within `X`. Then we have a `let` inside the global `let`. This one changes `var` from `5` to `6`. The scope of the `let` only contains the def `Y` therefore within `Y`, `var` is `6`. Finally def `Z` is within the global `let`, so `var` starts as `5`. `Z` has an inner `let` that changes `var` to `7`. That example is quite complex just to demonstrate the feature. Let's look at something more practical. ```tablegen; class Register {; int size=4;; }; let size=8 in {; def X0: Register {}; // Repeats 30 times for X1...X31; }; def W0: Register {}; // Repeats 30 times for W1...W31; ```. ------------- Classes -----------------; class Register {; int size = 4;; }; ------------- Defs -----------------; def W0 {	// Register; int size = 4;; }; def X0 {	// Register; int size = 8;; }. (for a",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:682,Testability,log,logic,682,"## Introduction to TableGen Part 1: Classes, Defs, Basic Types and Let. **Note:** The content in this notebook is adapted from [this document](https://llvm.org/docs/TableGen/index.html). Refer to it if you want more details. This tutorial will cover:; * Classes; * Defs; * Basic types; * `let` in various forms; * Class template arguments. ## What is TableGen?. TableGen is a language used in LLVM to automate the generation of certain types of code. Usually repetitive code that has a common structure. TableGen is used to generate ""records"" that are then processed by a ""backend"" into domain specific code. The compiler for TableGen is the binary `llvm-tblgen`. This contains the logic to convert TableGen source into records that can then be passed to a TableGen backend. TableGen allows you to define Classes and Defs (which are instances of classes) but it doesn't encode what to do with that structure. That's what the backend does. The backend converts this structure into something useful, for example C++ code. These backends are included in the `llvm-tblgen` binary and you can choose which one to run using a command line option. If you don't choose a backend you get a dump of the structure, and that is what this notebook will be showing. This tutorial will focus on the language itself only. The only thing you need to know now is that in addition to `llvm-tblgen` you will see other `*-tblgen` like `clang-tblgen`. The difference between them is the backends they include. The default output from `llvm-tblgen` looks like this:. ```tablegen; %config cellreset on. // Empty source file; ```. ------------- Classes -----------------; ------------- Defs -----------------. **Note:** `%config` is not a TableGen command but a ""magic"" command to the Jupyter kernel for this notebook. By default new cells include the content of previously run cells, but for this notebook we mostly want each to be isolated. On occasion we will use the `%noreset` magic to override this. No source means no c",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:4746,Usability,learn,learn,4746,"rit from multiple classes. In that case the order that that happens in matches the order you write the class names after the `:`. ```tablegen; class C {; int a = 1;; }; class D {; int a = 2;; }; class E : C, D {}; ```. ------------- Classes -----------------; class C {; int a = 1;; }; class D {; int a = 2;; }; class E {	// C D; int a = 2;; }; ------------- Defs -----------------. Class `E` first inherits from class `C`. This gives `E` a member `a` with value `1`. Then it inherits from class `D` which also has a member `a` but with a value of `2`. Meaning the final value of `E`'s `a` is `2`. When a member has the same name this is handled on a ""last one in wins"" basis. Assuming the types match. ```tablegen; class C {; string a = """";; }; class D {; int a = 2;; }; class E : C, D {}; ```. <stdin>:7:14: error: New definition of 'a' of type 'int' is incompatible with previous definition of type 'string'; class E : C, D {}; ^. When they don't match, we get an error. Luckily for us, we're about to learn all about types. ## Types. TableGen is statically typed with error checking to prevent you from assigning things with mismatched types. ```tablegen; class C {; int a;; bit b = 0;; string s = ""Hello"";; }; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------. Here we've created a class C with integer, bit (1 or 0) and string members. See [here](https://llvm.org/docs/TableGen/ProgRef.html#types) for a full list of types. Note that you do not have to give a member a default value, it can be left uninitialised. ```tablegen; %noreset. def X: C {}; ```. ------------- Classes -----------------; class C {; int a = ?;; bit b = 0;; string s = ""Hello"";; }; ------------- Defs -----------------; def X {	// C; int a = ?;; bit b = 0;; string s = ""Hello"";; }. When you make an instance of a class using `def`, that instance gets all the members of the class. Their values will be as set in the class, unless",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md:10633,Usability,simpl,simply,10633,"--------; class Register {; int size = 4;; }; ------------- Defs -----------------; def W0 {	// Register; int size = 4;; }; def X0 {	// Register; int size = 8;; }. (for anyone curious that's AArch64's register naming). The use case here is that we are describing registers. Some are 32 bits wide and some are 64 bits wide. We start by setting a default value of `size` which is 4 (4x8=32 bits) in the class `Register`. Then using a top level `let` we override that value and set it to 8 for all the 64 bit registers at once. So we don't need to do `size=8` over and over again. ## Classes As Class Members. In addition to the built in types, class members can be user defined classes. ```tablegen; class Inner {}; class Outer {; Inner i;; }; ```. ------------- Classes -----------------; class Inner {; }; class Outer {; Inner i = ?;; }; ------------- Defs -----------------. Of course that raises the question, how do we construct an instance of `Inner` to use as the value?. We simply use a `def` like we have done before. ```tablegen; class Inner {}; def AnInner: Inner {}; class Outer {; Inner i = AnInner;; }; def AnOuter: Outer {}; ```. ------------- Classes -----------------; class Inner {; }; class Outer {; Inner i = AnInner;; }; ------------- Defs -----------------; def AnInner {	// Inner; }; def AnOuter {	// Outer; Inner i = AnInner;; }. ## Class Template Arguments. Class template arguments are used to pass parameters to classes when you `def` them. ```tablegen; class C <int a, int b> {; int c = a;; int d = b;; }; def X: C<0, 1> {}; ```. ------------- Classes -----------------; class C<int C:a = ?, int C:b = ?> {; int c = C:a;; int d = C:b;; }; ------------- Defs -----------------; def X {	// C; int c = 0;; int d = 1;; }. This means that to `def` a `C` we must now provide 2 arguments that have type `int` (type checking applies here as it does elsewhere). This is going to look familiar if you have written C++. In C++ it might look like:; ```; template<int a, int b>; class C ",MatchSource.DOCS,interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/dobject.md:1365,Availability,down,down,1365,"\page dobject Format of a class object in DATA. ### Release 3.02.06. Here is the format of a class object in DATA that uses the default streamer.; Objects of many classes with custom streamers can have very similar formats. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------------; 0->3 ByteCount = Number of remaining bytes in object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->.. ClassInfo = Information about class of object; | If this is the first occurrence of an object of this class in the record; | 4->7 -1 = New class tag (constant kNewClassTag = 0xffffffff); | 8->.. Classname = Object Class Name (null terminated string); | Otherwise; | 4->7 clIdx = Byte offset of new class tag in record, plus 2.; | OR'd with kClassMask (0x80000000); 0->3 ByteCount = Number of remaining bytes in object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of Class; </pre></div>. The rest consists of objects of base classes and persistent non-static data members.; Data members marked as transient are not stored. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; 6->.. Sequentially, Objects of each base class from which this class is derived; (rarely more than one); 0->.. Sequentially, Objects of all non-static persistent data members.; </pre></div>. Class objects are broken down recursively as above. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; Built in types are stored as follows:; 1 Byte: char, unsigned char; 2 Bytes: short, unsigned short; 4 Bytes: int, unsigned int, float; 8 Bytes: long, unsigned long, double; </pre></div>; Note that a long (signed or unsigned) is stored as 8 bytes even if it is only four bytes; in memory. In that case, it is filled with leading zeros (or ones, for a negative value). ",MatchSource.DOCS,io/doc/TFile/dobject.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/dobject.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/freesegments.md:81,Deployability,release,release,81,"\page freesegments Format of FreeSegments record. Format of FreeSegments record, release 6.22.06. It is never compressed.; It is probably not accessed by its key, but from its offset given in the file header. If any *individual* free segments refer to bytes beyond 2000000000,; their fFirst/fLast have 8 bytes, not 4 and 1000 is added to the TFree Version. Some free segment records may be 32 bit while others are 64 bit. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey---------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 [18->25] SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 [26->33] SeekPdir = Byte offset of parent directory record (TFile) TKey::fSeekPdir; 26->26 [34->34] lname = Number of bytes in the class name (5) TKey::fClassName; 27->.. [35->..] ClassName = Object Class Name (""TFile"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes with the name of the object `<file-name>` TNamed::fName; 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object `<file-title>` TNamed::fTitle; ----------DATA---------------; 0->1 Version = TFree class version identifier TFree::Class_Version(); 2->5 [ 2-> 9] fFirst = First free byte of first free segment TFree::fFirst; 6->9 [10->17] fLast = Last free byte of first free segment (inclusive) TFree::fLast; (e.g. a free segment that is 1 byte long would have fFirst == fLast); .... Sequentially, Version, fFirst and fLast of addi",MatchSource.DOCS,io/doc/TFile/freesegments.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/freesegments.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/freesegments.md:142,Security,access,accessed,142,"\page freesegments Format of FreeSegments record. Format of FreeSegments record, release 6.22.06. It is never compressed.; It is probably not accessed by its key, but from its offset given in the file header. If any *individual* free segments refer to bytes beyond 2000000000,; their fFirst/fLast have 8 bytes, not 4 and 1000 is added to the TFree Version. Some free segment records may be 32 bit while others are 64 bit. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey---------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 [18->25] SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 [26->33] SeekPdir = Byte offset of parent directory record (TFile) TKey::fSeekPdir; 26->26 [34->34] lname = Number of bytes in the class name (5) TKey::fClassName; 27->.. [35->..] ClassName = Object Class Name (""TFile"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes with the name of the object `<file-name>` TNamed::fName; 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object `<file-title>` TNamed::fTitle; ----------DATA---------------; 0->1 Version = TFree class version identifier TFree::Class_Version(); 2->5 [ 2-> 9] fFirst = First free byte of first free segment TFree::fFirst; 6->9 [10->17] fLast = Last free byte of first free segment (inclusive) TFree::fLast; (e.g. a free segment that is 1 byte long would have fFirst == fLast); .... Sequentially, Version, fFirst and fLast of addi",MatchSource.DOCS,io/doc/TFile/freesegments.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/freesegments.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/header.md:70,Deployability,release,release,70,"\page header File header format. Here is the file header format as of release 6.22.06. It is never compressed. If END, SeekFree, or SeekInfo are located past the 32 bit file limit (> 2000000000); then these fields will be 8 instead of 4 bytes and 1000000 is added to the file format version. | Byte Range | Record Name | Description | |; |------------------|----------------|-----------------------------------------|-|; |0...3 | ""root"" | Identifies this file as a ROOT file | |; |4...7 | Version | File format version | TFile::fVersion (10000major+100minor+cycle (e.g. 62206 for 6.22.06)) |; |8...11 | BEGIN | Byte offset of first data record (100) | TFile::fBEGIN |; |12...15 [12...19] | END | Pointer to first free word at the EOF | TFile::fEND (will be == to file size in bytes) |; |16...19 [20...27] | SeekFree | Byte offset of FreeSegments record | TFile::fSeekFree |; |20...23 [28...31] | NbytesFree | Number of bytes in FreeSegments record | TFile::fNBytesFree |; |24...27 [32...35] | nfree | Number of free data records | |; |28...31 [36...39] | NbytesName | Number of bytes in TKey+TNamed for TFile at creation | TDirectory::fNbytesName |; |32...32 [40...40] | Units | Number of bytes for file pointers (4) | TFile::fUnits |; |33...36 [41...44] | Compress | Zip compression level (i.e. 0-9) | TFile::fCompress |; |37...40 [45...52] | SeekInfo | Byte offset of StreamerInfo record | TFile::fSeekInfo |; |41...44 [53...56] | NbytesInfo | Number of bytes in StreamerInfo record | TFile::fNbytesInfo |; |45...46 [57...58] | UUID vers | TUUID class version identifier | TUUID::Class_Version() |; |47...62 [59...74] | UUID | Universally Unique Identifier | TUUID::fTimeLow through fNode[6] |; |63...99 [75...99] | | Extra space to allow END, SeekFree, or SeekInfo to become 64 bit without moving this header| |. Here is the file header format as of release 3.02.06. It is never compressed. | Byte Range | Record Name | Description | |; |------------------|----------------|------------------------",MatchSource.DOCS,io/doc/TFile/header.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/header.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/header.md:1853,Deployability,release,release,1853,"gments record | TFile::fSeekFree |; |20...23 [28...31] | NbytesFree | Number of bytes in FreeSegments record | TFile::fNBytesFree |; |24...27 [32...35] | nfree | Number of free data records | |; |28...31 [36...39] | NbytesName | Number of bytes in TKey+TNamed for TFile at creation | TDirectory::fNbytesName |; |32...32 [40...40] | Units | Number of bytes for file pointers (4) | TFile::fUnits |; |33...36 [41...44] | Compress | Zip compression level (i.e. 0-9) | TFile::fCompress |; |37...40 [45...52] | SeekInfo | Byte offset of StreamerInfo record | TFile::fSeekInfo |; |41...44 [53...56] | NbytesInfo | Number of bytes in StreamerInfo record | TFile::fNbytesInfo |; |45...46 [57...58] | UUID vers | TUUID class version identifier | TUUID::Class_Version() |; |47...62 [59...74] | UUID | Universally Unique Identifier | TUUID::fTimeLow through fNode[6] |; |63...99 [75...99] | | Extra space to allow END, SeekFree, or SeekInfo to become 64 bit without moving this header| |. Here is the file header format as of release 3.02.06. It is never compressed. | Byte Range | Record Name | Description | |; |------------------|----------------|--------------------------------------------|-|; | 0->3 | ""root"" | Identifies this file as a ROOT file | |; | 4->7 | Version | File format version | TFile::fVersion (10000*major+100*minor+cycle (e.g. 30203 for 3.2.3)) |; | 8->11 | BEGIN | Byte offset of first data record (64) | TFile::fBEGIN |; |12...15 | END | Pointer to first free word at the EOF | TFile::fEND (will be == to file size in bytes) |; |16...19 | SeekFree | Byte offset of FreeSegments record | TFile::fSeekFree |; |20...23 | NbytesFree | Number of bytes in FreeSegments record | TFile::fNBytesFree |; |24...27 | nfree | Number of free data records | |; |28...31 | NbytesName | Number of bytes in TKey+TNamed for TFile at creation | TDirectory::fNbytesName |; |32...32 | Units | Number of bytes for file pointers (4) | TFile::fUnits |; |33...36 | Compress | Zip compression level (i.e. 0-9) | TF",MatchSource.DOCS,io/doc/TFile/header.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/header.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/keyslist.md:71,Deployability,release,release,71,"\page keyslist Format of KeysList record. Format of KeysList record in release 3.02.06. It is never compressed.; There is one KeysList record for the main (TFile) directory and one per non-empty subdirectory.; It is probably not accessed by its key, but from its offset given in the directory data. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey---------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in the key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record (directory) TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (5 or 10) TKey::fClassName; 27->.. ClassName = Object Class Name (""TFile"" or ""TDirectory"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes with the name of the object `<directory-name>` TNamed::fName; 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object `<directory-title>` TNamed::fTitle; ----------DATA---------------; 0->3 NKeys = Number of keys in list (i.e. records in directory (non-recursive)); | Excluded:: The directory itself, KeysList, StreamerInfo, and FreeSegments; 4->.. TKey = Sequentially for each record in directory,; | the entire TKey portion of each record is replicated.; | Note that SeekKey locates the record.; </pre></div>; ",MatchSource.DOCS,io/doc/TFile/keyslist.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/keyslist.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/keyslist.md:229,Security,access,accessed,229,"\page keyslist Format of KeysList record. Format of KeysList record in release 3.02.06. It is never compressed.; There is one KeysList record for the main (TFile) directory and one per non-empty subdirectory.; It is probably not accessed by its key, but from its offset given in the directory data. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey---------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in the key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record (directory) TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (5 or 10) TKey::fClassName; 27->.. ClassName = Object Class Name (""TFile"" or ""TDirectory"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes with the name of the object `<directory-name>` TNamed::fName; 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object `<directory-title>` TNamed::fTitle; ----------DATA---------------; 0->3 NKeys = Number of keys in list (i.e. records in directory (non-recursive)); | Excluded:: The directory itself, KeysList, StreamerInfo, and FreeSegments; 4->.. TKey = Sequentially for each record in directory,; | the entire TKey portion of each record is replicated.; | Note that SeekKey locates the record.; </pre></div>; ",MatchSource.DOCS,io/doc/TFile/keyslist.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/keyslist.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:537,Availability,avail,available,537,"\page rootio %ROOT files layout. \tableofcontents. ## ROOTIO files. A ROOTIO file consists of one ""file header"", one or more ""data; records,"" and zero or more ""free segments"". The file header is always; at the beginning of the file, while the data records and free segments; may in principle appear in any order. The file header is fixed length (64 bytes in the current; release.) It's detailed format is given in \ref header. A free segment is of variable length. One free segment is a set; of contiguous bytes that are unused, and are available for ROOTIO to use; for new or resized data records. The first four bytes of a a free; segment contain the negative of the number of bytes in the segment. The; contents of the remainder of the free segment are irrelevant. A data record represents either user data or data used; internally by ROOTIO. All data records have two portions, a ""key""; portion and a ""data"" portion. The key portion precedes the data; portion. The format of the key portion is the same for all data.; (The key portion corresponds to a class TKey object). The object name; and they key cycle are together sufficient to uniquely determine the; record within the file. The \ref dobject page describes the format; of the data portion of a record for an object that uses the default; streamer. ## Data record types. ### ""core"" record types. There are several types of data records used internally by; ROOTIO to support the storage of byte sequences. These record types; are TFile, TDirectory, ""KeysList"", and ""FreeSegments"". These types; can be considered to be in the ""core"" layer of ROOTIO. A file always contains exactly one TFile data record, which; (nearly?) always immediately follows the file header. The TFile record; consists of either data pertaining to the file as a whole, or data; pertaining to the root ""directory"" of records in the file. Its detailed; format is given in \ref tfile. A file contains zero or more TDirectory data records, each; representing a subdirectory",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:371,Deployability,release,release,371,"\page rootio %ROOT files layout. \tableofcontents. ## ROOTIO files. A ROOTIO file consists of one ""file header"", one or more ""data; records,"" and zero or more ""free segments"". The file header is always; at the beginning of the file, while the data records and free segments; may in principle appear in any order. The file header is fixed length (64 bytes in the current; release.) It's detailed format is given in \ref header. A free segment is of variable length. One free segment is a set; of contiguous bytes that are unused, and are available for ROOTIO to use; for new or resized data records. The first four bytes of a a free; segment contain the negative of the number of bytes in the segment. The; contents of the remainder of the free segment are irrelevant. A data record represents either user data or data used; internally by ROOTIO. All data records have two portions, a ""key""; portion and a ""data"" portion. The key portion precedes the data; portion. The format of the key portion is the same for all data.; (The key portion corresponds to a class TKey object). The object name; and they key cycle are together sufficient to uniquely determine the; record within the file. The \ref dobject page describes the format; of the data portion of a record for an object that uses the default; streamer. ## Data record types. ### ""core"" record types. There are several types of data records used internally by; ROOTIO to support the storage of byte sequences. These record types; are TFile, TDirectory, ""KeysList"", and ""FreeSegments"". These types; can be considered to be in the ""core"" layer of ROOTIO. A file always contains exactly one TFile data record, which; (nearly?) always immediately follows the file header. The TFile record; consists of either data pertaining to the file as a whole, or data; pertaining to the root ""directory"" of records in the file. Its detailed; format is given in \ref tfile. A file contains zero or more TDirectory data records, each; representing a subdirectory",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:4681,Deployability,update,update,4681,"ts are; given in \ref tprocessid, \ref tref, and \ref trefarray respectively.; Of these three objects, only TProcessID objects necessarily comprise; a complete data record (a ""TProcessID"" record). TRef and TRefArray; objects typically are data members of larger objects, and therefore are; only a part of the data portion of a record. In addition, objects that; are referenced by such a pointer have an additional field in the base TObject.; See \ref tobject. A description of how these pointers work is given under; the \ref ptpo ""Pointers to persistent objects"" heading below. ### ""application"" layer record types. These are either user defined record types, or record types supplied; by ROOT that are not needed by ROOTIO. The format of such an object that; uses the default streamer is shown in \ref dobject. ## Data compression. The user can set the data compression level for new or modified data records; when creating or opening a file. When an existing file is opened for update,; the compression level selected need not match that used previously. The; compression level of existing records is not modified unless the record itself; is modified. There are ten compression levels, 0-9, ranging from 0 (no compression) to 9; (maximum compression), with level 1 being the default. The level chosen is; a tradeoff between disk space and compression performance. The decompression; speed is independent of level. Currently, in release 3.2.6, level 2 is not used.; If level 2 is selected, level 1 is used with no notification to the user. The chosen compression level is not applied to the entire file. The following; portions of the file are not compressed, regardless of the compression level; selected:. 1. the file header; 2. the KeysList data record; 3. the FreeSegments data record; 4. any data record (outside of a TTree) where the uncompressed size of; the data portion is 256 bytes or less.; 5. the key portion of any data record. Furthermore, the data portion of the StreamerInfo data re",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:5132,Deployability,release,release,5132,"se TObject.; See \ref tobject. A description of how these pointers work is given under; the \ref ptpo ""Pointers to persistent objects"" heading below. ### ""application"" layer record types. These are either user defined record types, or record types supplied; by ROOT that are not needed by ROOTIO. The format of such an object that; uses the default streamer is shown in \ref dobject. ## Data compression. The user can set the data compression level for new or modified data records; when creating or opening a file. When an existing file is opened for update,; the compression level selected need not match that used previously. The; compression level of existing records is not modified unless the record itself; is modified. There are ten compression levels, 0-9, ranging from 0 (no compression) to 9; (maximum compression), with level 1 being the default. The level chosen is; a tradeoff between disk space and compression performance. The decompression; speed is independent of level. Currently, in release 3.2.6, level 2 is not used.; If level 2 is selected, level 1 is used with no notification to the user. The chosen compression level is not applied to the entire file. The following; portions of the file are not compressed, regardless of the compression level; selected:. 1. the file header; 2. the KeysList data record; 3. the FreeSegments data record; 4. any data record (outside of a TTree) where the uncompressed size of; the data portion is 256 bytes or less.; 5. the key portion of any data record. Furthermore, the data portion of the StreamerInfo data record is always; compressed at level 1 (if over 256 bytes uncompressed), regardless of the; compression level selected (even if no compression is selected). The compression algorithm used is an in memory ZIP compression written for the; DELPHI collaboration at CERN. Its author is E. Chernyaev (IHEP/Protvino).; The source code is internal to ROOTIO. \anchor si; ## StreamerInfo. The ""StreamerInfo"" data record is used by ROOTIO t",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:10763,Deployability,release,release,10763,"; In this case, the StreamerInfo for that class might not be used. In any case, if the; composition/decomposition of the class is explicitly coded, the user should include; the byte count, class information, and version number of the class before the data on; disk as shown in \ref dobject. The special method used for streaming a TClonesArray is described in the TClonesArray; section below. More information on the StreamerInfo record and its use is found in the; [Input/Output chapter of the Root Manual](https://root.cern/manual/storing_root_objects/). NOTE: Some of the classes used internally in ROOTIO (e.g. TObject, TRef, TRefArray); have explicitly coded (de)compositions, and do not use the information in the; StreamerInfo record to do the (de)composition. In this case, the StreamerInfo for; the class may still be present in the StreamerInfo record, but may not match what is; actually written to disk for those objects. \anchor ptpo; ## Pointers to persistent objects. These were introduced in release 3.02, so there is not yet a description in the current; Root Users Guide, which is for a version release 3.1. Here we discuss only the information; on disk. A ROOT file contains zero or more TProcessID records. Each such record contains a globally; unique ID defining a given ROOT job that wrote a referenced object (see \ref tprocessid).; Each referenced object contains a ""pidf"" field referencing the corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; refer",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:10868,Deployability,release,release,10868,"any case, if the; composition/decomposition of the class is explicitly coded, the user should include; the byte count, class information, and version number of the class before the data on; disk as shown in \ref dobject. The special method used for streaming a TClonesArray is described in the TClonesArray; section below. More information on the StreamerInfo record and its use is found in the; [Input/Output chapter of the Root Manual](https://root.cern/manual/storing_root_objects/). NOTE: Some of the classes used internally in ROOTIO (e.g. TObject, TRef, TRefArray); have explicitly coded (de)compositions, and do not use the information in the; StreamerInfo record to do the (de)composition. In this case, the StreamerInfo for; the class may still be present in the StreamerInfo record, but may not match what is; actually written to disk for those objects. \anchor ptpo; ## Pointers to persistent objects. These were introduced in release 3.02, so there is not yet a description in the current; Root Users Guide, which is for a version release 3.1. Here we discuss only the information; on disk. A ROOT file contains zero or more TProcessID records. Each such record contains a globally; unique ID defining a given ROOT job that wrote a referenced object (see \ref tprocessid).; Each referenced object contains a ""pidf"" field referencing the corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful contai",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:12659,Energy Efficiency,allocate,allocated,12659,"he entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful container classes. ### TObjArray and TClonesArray. The TObjArray class can be used to support an array of objects. The objects need not be of the; same type, but each object must be of a class type that inherits from TObject. We have already; seen a specific example of the use of TObjArray, in the StreamerInfo record, where it is used; to hold an array of TStreamerElement objects, each of which is of a class inheriting from; TStreamerElement, which in turn inherits from TObject. The TClonesArray class is a specialization of the TObjArray class for holding an array; of objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:13399,Energy Efficiency,efficient,efficient,13399,"objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:448,Modifiability,variab,variable,448,"\page rootio %ROOT files layout. \tableofcontents. ## ROOTIO files. A ROOTIO file consists of one ""file header"", one or more ""data; records,"" and zero or more ""free segments"". The file header is always; at the beginning of the file, while the data records and free segments; may in principle appear in any order. The file header is fixed length (64 bytes in the current; release.) It's detailed format is given in \ref header. A free segment is of variable length. One free segment is a set; of contiguous bytes that are unused, and are available for ROOTIO to use; for new or resized data records. The first four bytes of a a free; segment contain the negative of the number of bytes in the segment. The; contents of the remainder of the free segment are irrelevant. A data record represents either user data or data used; internally by ROOTIO. All data records have two portions, a ""key""; portion and a ""data"" portion. The key portion precedes the data; portion. The format of the key portion is the same for all data.; (The key portion corresponds to a class TKey object). The object name; and they key cycle are together sufficient to uniquely determine the; record within the file. The \ref dobject page describes the format; of the data portion of a record for an object that uses the default; streamer. ## Data record types. ### ""core"" record types. There are several types of data records used internally by; ROOTIO to support the storage of byte sequences. These record types; are TFile, TDirectory, ""KeysList"", and ""FreeSegments"". These types; can be considered to be in the ""core"" layer of ROOTIO. A file always contains exactly one TFile data record, which; (nearly?) always immediately follows the file header. The TFile record; consists of either data pertaining to the file as a whole, or data; pertaining to the root ""directory"" of records in the file. Its detailed; format is given in \ref tfile. A file contains zero or more TDirectory data records, each; representing a subdirectory",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8680,Modifiability,variab,variable,8680,"k, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user may need to write a specialized streamer for a class.; One reason is that it may be necessary to execute some code before or after data is read; or written, for example, to initialize some non-persistent data members after the; persistent data is read. In this case, the custom streamer can use the StreamerInfo record; to decompose a self-identifying object in the exact same manner as the generated; streamer would have done. An example is given (for the Event class) in the Root User's; Guide (URL below) (Input/Output chapter, Streamers subchapter). On the other hand, if; the user needs to writ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8740,Modifiability,variab,variable,8740,"ever written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user may need to write a specialized streamer for a class.; One reason is that it may be necessary to execute some code before or after data is read; or written, for example, to initialize some non-persistent data members after the; persistent data is read. In this case, the custom streamer can use the StreamerInfo record; to decompose a self-identifying object in the exact same manner as the generated; streamer would have done. An example is given (for the Event class) in the Root User's; Guide (URL below) (Input/Output chapter, Streamers subchapter). On the other hand, if; the user needs to write a streamer for a class that ROOT cannot handle, the user may need; to explicitly code the decomposition and composition of the object to its members.; In this case, th",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:12023,Modifiability,inherit,inherits,12023,"ch record contains a globally; unique ID defining a given ROOT job that wrote a referenced object (see \ref tprocessid).; Each referenced object contains a ""pidf"" field referencing the corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful container classes. ### TObjArray and TClonesArray. The TObjArray class can be used to support an array of objects. The objects need not be of the; same type, but each object must be of a class type that inherits from TObject. We have already; seen a specific example of the use of TObjArray, in the StreamerInfo record, where it is used; to hold an array of TStreamerElement objects, each of which is of a class inheriting from; TStreamerElement, which in turn inherits from TObject. The TClonesArray class is a specialization of the TObjArray class for holding an array; of objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(e",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:12232,Modifiability,inherit,inheriting,12232,"corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful container classes. ### TObjArray and TClonesArray. The TObjArray class can be used to support an array of objects. The objects need not be of the; same type, but each object must be of a class type that inherits from TObject. We have already; seen a specific example of the use of TObjArray, in the StreamerInfo record, where it is used; to hold an array of TStreamerElement objects, each of which is of a class inheriting from; TStreamerElement, which in turn inherits from TObject. The TClonesArray class is a specialization of the TObjArray class for holding an array; of objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:12281,Modifiability,inherit,inherits,12281,"corresponding TProcessID; record and an ""fUniqueID"" field uniquely identifying the referenced object among those; written by that process (see \ref tobject). Similarly, every persistent reference to that; object (a TRef Object, see \ref tref) also contains ""pidf"" and ""fUniqueID"" fields with the; same value, thereby uniquely determining the referenced object (which need not even be in the; same file). In the case of an array of references (a TRefArray object, see \ref trefarray),; there is one ""pidf"" value for the entire array, and a separate ""fUniqueID"" value for each; reference. For further information, see the above URL. ## Some useful container classes. ### TObjArray and TClonesArray. The TObjArray class can be used to support an array of objects. The objects need not be of the; same type, but each object must be of a class type that inherits from TObject. We have already; seen a specific example of the use of TObjArray, in the StreamerInfo record, where it is used; to hold an array of TStreamerElement objects, each of which is of a class inheriting from; TStreamerElement, which in turn inherits from TObject. The TClonesArray class is a specialization of the TObjArray class for holding an array; of objects that are all of the same type. The format of a TClonesArray object; is given in \ref tclonesarray. There are two great advantages in the use of TClonesArray over TObjArray when the objects; all will be of the same class:. 1. Memory for the objects will be allocated only once for the entire array, rather; than the per-object allocation for TObjArray. This can be done because all the; objects are the same size.; 2. In the case of TObjArray, the stored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:13874,Modifiability,variab,variable,13874,"tored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object recursively contains TBranch objects, each of which; contains an array of TBasket objects to hold its data. However, the TTree data record does not necessarily contain the entire TTree object. For each; branch, exactly one TBasket object is contained in the TTree data record. If the data on a; given branch fits in one basket, then all the data for that branch will be in the TTree record; itself. Otherwise, there will be a separate TBasket data record fo",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:13975,Modifiability,variab,variable,13975,"se; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object recursively contains TBranch objects, each of which; contains an array of TBasket objects to hold its data. However, the TTree data record does not necessarily contain the entire TTree object. For each; branch, exactly one TBasket object is contained in the TTree data record. If the data on a; given branch fits in one basket, then all the data for that branch will be in the TTree record; itself. Otherwise, there will be a separate TBasket data record for each additional basket used on; the branch, each containing a TBasket object containing user data. By default, the additional ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:14019,Modifiability,variab,variables,14019,"se; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object recursively contains TBranch objects, each of which; contains an array of TBasket objects to hold its data. However, the TTree data record does not necessarily contain the entire TTree object. For each; branch, exactly one TBasket object is contained in the TTree data record. If the data on a; given branch fits in one basket, then all the data for that branch will be in the TTree record; itself. Otherwise, there will be a separate TBasket data record for each additional basket used on; the branch, each containing a TBasket object containing user data. By default, the additional ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:5055,Performance,perform,performance,5055,"record. In addition, objects that; are referenced by such a pointer have an additional field in the base TObject.; See \ref tobject. A description of how these pointers work is given under; the \ref ptpo ""Pointers to persistent objects"" heading below. ### ""application"" layer record types. These are either user defined record types, or record types supplied; by ROOT that are not needed by ROOTIO. The format of such an object that; uses the default streamer is shown in \ref dobject. ## Data compression. The user can set the data compression level for new or modified data records; when creating or opening a file. When an existing file is opened for update,; the compression level selected need not match that used previously. The; compression level of existing records is not modified unless the record itself; is modified. There are ten compression levels, 0-9, ranging from 0 (no compression) to 9; (maximum compression), with level 1 being the default. The level chosen is; a tradeoff between disk space and compression performance. The decompression; speed is independent of level. Currently, in release 3.2.6, level 2 is not used.; If level 2 is selected, level 1 is used with no notification to the user. The chosen compression level is not applied to the entire file. The following; portions of the file are not compressed, regardless of the compression level; selected:. 1. the file header; 2. the KeysList data record; 3. the FreeSegments data record; 4. any data record (outside of a TTree) where the uncompressed size of; the data portion is 256 bytes or less.; 5. the key portion of any data record. Furthermore, the data portion of the StreamerInfo data record is always; compressed at level 1 (if over 256 bytes uncompressed), regardless of the; compression level selected (even if no compression is selected). The compression algorithm used is an in memory ZIP compression written for the; DELPHI collaboration at CERN. Its author is E. Chernyaev (IHEP/Protvino).; The source code",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8060,Performance,perform,performance,8060,"s of the object or a (non-static and non-transient) data member; of the object. If the base class or data member is itself a class, then there will; also be a streamerinfo object in the record for that class. In this way, each; class is recursively decomposed into its atomic elements, each of which is a simple; type (e.g. ""int""). A ""long"" or ""unsigned long"" member is always written; as an 8 byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8072,Performance,optimiz,optimization,8072,"s of the object or a (non-static and non-transient) data member; of the object. If the base class or data member is itself a class, then there will; also be a streamerinfo object in the record for that class. In this way, each; class is recursively decomposed into its atomic elements, each of which is a simple; type (e.g. ""int""). A ""long"" or ""unsigned long"" member is always written; as an 8 byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8095,Performance,optimiz,optimization,8095,"streamerinfo object in the record for that class. In this way, each; class is recursively decomposed into its atomic elements, each of which is a simple; type (e.g. ""int""). A ""long"" or ""unsigned long"" member is always written; as an 8 byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user may need to write a specialized streamer for a class.; One reason is that it may be necessary to execute some code before or after data is read; or written, f",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8345,Safety,avoid,avoids,8345,"byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user may need to write a specialized streamer for a class.; One reason is that it may be necessary to execute some code before or after data is read; or written, for example, to initialize some non-persistent data members after the; persistent data is read. In this case, the custom streamer can use the StreamerInfo record; to decompose a self-identifying object in the exact same manner as the gen",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:6879,Usability,simpl,simple,6879,"even if no compression is selected). The compression algorithm used is an in memory ZIP compression written for the; DELPHI collaboration at CERN. Its author is E. Chernyaev (IHEP/Protvino).; The source code is internal to ROOTIO. \anchor si; ## StreamerInfo. The ""StreamerInfo"" data record is used by ROOTIO to support the storage of; self-identifying objects. Its detailed format is given in \ref streamerinfo.; A ROOTIO file contains exactly one StreamerInfo record, which is written to disk; automatically when a new or modified file is closed. The StreamerInfo record is a list (ROOTIO class TList) of ""StreamerInfo"" objects; (ROOTIO class TStreamerInfo). There is one StreamerInfo object in the list for; every class used in the file in a data record, other than a core layer record.; There is no streamerinfo object for a class used in a core layer record unless the; class is also used elsewhere in a data record. When reading a self-identifying; object from a file, the system uses the StreamerInfo list to decompose the object; recursively into its simple data members. Each streamerinfo object is an array of ""streamer element"" objects, each of which; describes a base class of the object or a (non-static and non-transient) data member; of the object. If the base class or data member is itself a class, then there will; also be a streamerinfo object in the record for that class. In this way, each; class is recursively decomposed into its atomic elements, each of which is a simple; type (e.g. ""int""). A ""long"" or ""unsigned long"" member is always written; as an 8 byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:7309,Usability,simpl,simple,7309," StreamerInfo record, which is written to disk; automatically when a new or modified file is closed. The StreamerInfo record is a list (ROOTIO class TList) of ""StreamerInfo"" objects; (ROOTIO class TStreamerInfo). There is one StreamerInfo object in the list for; every class used in the file in a data record, other than a core layer record.; There is no streamerinfo object for a class used in a core layer record unless the; class is also used elsewhere in a data record. When reading a self-identifying; object from a file, the system uses the StreamerInfo list to decompose the object; recursively into its simple data members. Each streamerinfo object is an array of ""streamer element"" objects, each of which; describes a base class of the object or a (non-static and non-transient) data member; of the object. If the base class or data member is itself a class, then there will; also be a streamerinfo object in the record for that class. In this way, each; class is recursively decomposed into its atomic elements, each of which is a simple; type (e.g. ""int""). A ""long"" or ""unsigned long"" member is always written; as an 8 byte quantity, even if it occupies only 4 bytes in memory. A data member of a class is marked transient on the line of its declaration by a; comment beginning with ""//!"". Such members are not written to disk, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers ref",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:8511,Usability,simpl,simple,8511,"k, nor is there; any streamerinfo for such a member. A data member that is a C++ pointer (not to be confused with ""pointers to persistent; objects"" described below) is never written to disk as a pointer value. If it is a; pointer to an object, the object itself (or 0 (4 bytes) if the pointer value is NULL); is written. If the declaration line has a comment beginning with ""//->"", this indicates; that the pointer value will never be null, which allows a performance optimization.; Another optimization is that if two or more pointers pointing to the same object are; streamed in the same I/O operation, the object is written only once. The remaining; pointers reference the object through a unique object identifier. This saves space; and avoids the infinite loop that might otherwise arise if the directed graph of object; instance pointer references contains a cycle. If a data member is a pointer to a simple type, the Streamer presumes it is an array,; with the dimension defined in a comment of the form ""//[<length>]"", where length is; either an integer constant or a variable that is an integer data member of the class.; If a variable is used, it must be defined ahead of its use or in a base class. The above describes the function of the StreamerInfo record in decomposing a; self-identifying object if the user uses the streamer generated by ""rootcint"".; There are two reasons why a user may need to write a specialized streamer for a class.; One reason is that it may be necessary to execute some code before or after data is read; or written, for example, to initialize some non-persistent data members after the; persistent data is read. In this case, the custom streamer can use the StreamerInfo record; to decompose a self-identifying object in the exact same manner as the generated; streamer would have done. An example is given (for the Event class) in the Root User's; Guide (URL below) (Input/Output chapter, Streamers subchapter). On the other hand, if; the user needs to writ",MatchSource.DOCS,io/doc/TFile/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:9739,Availability,mask,mask,9739,"TStreamerElement Class; -Begin TNamed object (Base class of TStreamerElement); 6->9 ByteCount = Number of remaining bytes in TNamed object; | OR'd with kByteCountMask (0x40000000); 10->11 Version = Version of TNamed Class; 12->21 = TObject object (Base class of TNamed) (see \ref tobject).; | Objects in StreamerInfo record are not referenced.; | Would be two bytes longer (12->23) if object were referenced.; 22->.. fName = Number of bytes in class name of base class or member name of; | data member that this TStreamerElement object describes,; | followed by the name itself. (TNamed::fName).; 0->.. fTitle = Number of bytes in title of base class or data member that this; | TStreamerElement object describes, followed by the title itself.; | (TNamed::fTitle).; -End TNamed object; 0->3 fType = Type of data described by this TStreamerElement.; | (TStreamerElement::fType); | Built in types:; | 1:char, 2:short, 3:int, 4:long, 5:float, 8:double; | 11, 12, 13, 14:unsigned char, short, int, long respectively; | 6: an array dimension (counter); | 15: bit mask (used for fBits field); |; | Pointers to built in types:; | 40 + fType of built in type (e.g. 43: pointer to int); |; | Objects:; | 65:TString, 66:TObject, 67:TNamed; | 0: base class (other than TObject or TNamed); | 61: object data member derived from TObject (other than TObject or TNamed); | 62: object data member not derived from TObject; | 63: pointer to object derived from TObject (pointer can't be null); | 64: pointer to object derived from TObject (pointer may be null); | 501: pointer to an array of objects; | 500: an STL string or container; |; | Arrays:; | 20 + fType of array element (e.g. 23: array of int); |; 4->7 fSize = Size of built in type or of pointer to built in type. 0 otherwise.; | (TStreamerElement::fSize).; 8->11 fArrayLength = Size of array (0 if not array); | (TStreamerElement::fArrayLength).; 12->15 fArrayDim = Number of dimensions of array (0 if not an array); | (TStreamerElement::fArrayDim).; 16->3",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:83,Deployability,release,release,83,"\page streamerinfo Format of StreamerInfo record. Format of StreamerInfo record in release 3.02.06.; It is probably not accessed by its key, but from its offset given in the file header.; The StreamerInfo record DATA consists of a TList (list) object containing elements; of class TStreamerInfo. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey-(never compressed)----------------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) (64) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record (TFile) TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (5) TKey::fClassName; 27->31 ClassName = Object Class Name (""TList"") TKey::fClassName; 32->32 lname = Number of bytes in the object name (12) TNamed::fName; 33->44 Name = lName bytes with the name of the object (""StreamerInfo"") TNamed::fName; 45->45 lTitle = Number of bytes in the object title (18) TNamed::fTitle; 46->63 Title = lTitle bytes with the title of the object TNamed::fTitle; | (""Doubly linked list""); </pre></div>. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TList-(always compressed at level 1 (even if compression level 0))----; </pre></div>; The DATA is a TList collection object containing TStreamerInfo objects.; Below is the format of this TList data. Here is the format of a TList object in Release 3.02.06.; Comments and offsets refer specifically to its use in the StreamerInfo record. <div style=""background-color: lightgrey; font-size: 0.9vw;",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:6382,Modifiability,inherit,inherit,6382,"rray"" (null terminated); | Otherwise; | 4->7 clIdx = Byte offset of new class tag in record, plus 2.; | OR'd with kClassMask (0x80000000); 0->3 ByteCount = Number of remaining bytes in TObjArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TObjArray Class; 6->15 = TObject object (a base class of TObjArray) (see \ref tobject).; | Objects in StreamerInfo record are not referenced.; | Would be two bytes longer (6->17) if object were referenced.; 16->16 fName = Number of bytes in name of TObjArray object, followed by the; | name itself. (TCollection::fName). TObjArray objects in; | StreamerInfo record are unnamed, so byte contains 0.; 17->20 nObjects = Number of objects (derived from TStreamerElement) in array.; 21->24 fLowerBound = Lower bound of array. Will always be 0 in StreamerInfo record.; 25->.. objects = Sequentially, TStreamerElement objects in the array.; | In a TStreamerInfo object, the objects in the TObjArray are; | of various types (described below), all of which inherit; | directly from TStreamerElement objects. There will be one; | such object for every base class of the class that the; | TStreamerInfo object describes, and also one such object for; | each persistent non-static data member of the class that the; | TStreamerInfo object describes.; -End TObjArray object and TStreamerInfo object; -------; </pre></div>. The objects stored in the TObjectArray in TStreamerInfo are of various classes, each of; which inherits directly from the TStreamerElement class. The possible classes (which; we refer to collectively as TStreamer<XXX>) are:. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; TStreamerBase: Used for a base class. All others below used for data members.; TStreamerBasicType: For a basic type; TStreamerString: For type TString; TStreamerBasicPointer: For pointer to array of basic types; TStreamerObject: For an object derived from TObject; TStreamerObjectPointer: For pointer to an object",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:6839,Modifiability,inherit,inherits,6839,"object were referenced.; 16->16 fName = Number of bytes in name of TObjArray object, followed by the; | name itself. (TCollection::fName). TObjArray objects in; | StreamerInfo record are unnamed, so byte contains 0.; 17->20 nObjects = Number of objects (derived from TStreamerElement) in array.; 21->24 fLowerBound = Lower bound of array. Will always be 0 in StreamerInfo record.; 25->.. objects = Sequentially, TStreamerElement objects in the array.; | In a TStreamerInfo object, the objects in the TObjArray are; | of various types (described below), all of which inherit; | directly from TStreamerElement objects. There will be one; | such object for every base class of the class that the; | TStreamerInfo object describes, and also one such object for; | each persistent non-static data member of the class that the; | TStreamerInfo object describes.; -End TObjArray object and TStreamerInfo object; -------; </pre></div>. The objects stored in the TObjectArray in TStreamerInfo are of various classes, each of; which inherits directly from the TStreamerElement class. The possible classes (which; we refer to collectively as TStreamer<XXX>) are:. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; TStreamerBase: Used for a base class. All others below used for data members.; TStreamerBasicType: For a basic type; TStreamerString: For type TString; TStreamerBasicPointer: For pointer to array of basic types; TStreamerObject: For an object derived from TObject; TStreamerObjectPointer: For pointer to an object derived from TObject; TStreamerLoop: For pointer to an array of objects; TStreamerObjectAny: For an object not derived from TObject; TStreamerSTL: For an STL container (not yet used??); TStreamerSTLString: For an STL string (not yet used??); -------; </pre></div>. Here is the format of a TStreamer<XXX> object in Release 3.02.06.; In description below,. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; 0->3 ByteCount = Number of remaining bytes i",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:120,Security,access,accessed,120,"\page streamerinfo Format of StreamerInfo record. Format of StreamerInfo record in release 3.02.06.; It is probably not accessed by its key, but from its offset given in the file header.; The StreamerInfo record DATA consists of a TList (list) object containing elements; of class TStreamerInfo. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey-(never compressed)----------------------; byte 0->3 Nbytes = Number of bytes in compressed record (TKey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) (64) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record (TFile) TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (5) TKey::fClassName; 27->31 ClassName = Object Class Name (""TList"") TKey::fClassName; 32->32 lname = Number of bytes in the object name (12) TNamed::fName; 33->44 Name = lName bytes with the name of the object (""StreamerInfo"") TNamed::fName; 45->45 lTitle = Number of bytes in the object title (18) TNamed::fTitle; 46->63 Title = lTitle bytes with the title of the object TNamed::fTitle; | (""Doubly linked list""); </pre></div>. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TList-(always compressed at level 1 (even if compression level 0))----; </pre></div>; The DATA is a TList collection object containing TStreamerInfo objects.; Below is the format of this TList data. Here is the format of a TList object in Release 3.02.06.; Comments and offsets refer specifically to its use in the StreamerInfo record. <div style=""background-color: lightgrey; font-size: 0.9vw;",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md:4673,Security,checksum,checksum,4673,"remaining bytes in TStreamerInfo object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TStreamerInfo Class; -Begin TNamed object (Base class of TStreamerInfo); 6->9 ByteCount = Number of remaining bytes in TNamed object; | OR'd with kByteCountMask (0x40000000); 10->11 Version = Version of TNamed Class; 12->21 = TObject object (Base class of TNamed) (see \ref tobject).; | Objects in StreamerInfo record are not referenced.; | Would be two bytes longer (12->23) if object were referenced.; 22->.. fName = Number of bytes in name of class that this TStreamerInfo object; | describes, followed by the class name itself. (TNamed::fName).; 0->.. fTitle = Number of bytes in title of class that this TStreamerInfo object; | describes, followed by the class title itself. (TNamed::fTitle).; | (Class title may be zero length); -End TNamed object; 0->3 fCheckSum = Check sum for class that this TStreamerInfo object describes.; | This checksum is over all base classes and all persistent; | non-static data members. It is computed by TClass::GetCheckSum().; | (TStreamerInfo::fCheckSum); 4->7 fClassVersion = Version of class that this TStreamerInfo object describes.; | (TStreamerInfo::fClassVersion); -Begin TObjArray object (Data member of TStreamerInfo); 0->3 ByteCount = Number of remaining bytes in TObjArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->.. ClassInfo = Information about TObjArray class; | If this is the first occurrence of a TObjArray object in the record; | 4->7 -1 = New class tag (constant kNewClassTag = 0xffffffff); | 8->17 Classname = Object Class Name ""TObjArray"" (null terminated); | Otherwise; | 4->7 clIdx = Byte offset of new class tag in record, plus 2.; | OR'd with kClassMask (0x80000000); 0->3 ByteCount = Number of remaining bytes in TObjArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TObjArray Class; 6->15 = TObject object (a base class of TObjArray) (see \r",MatchSource.DOCS,io/doc/TFile/streamerinfo.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/streamerinfo.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tclonesarray.md:85,Deployability,release,release,85,"\page tclonesarray Format of the DATA for a TClonesArray object. Here is the format (release 3.02.06) of the DATA for a TClonesArray object in a ROOTIO file. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; 0->3 ByteCount = Number of remaining bytes in TClonesArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->.. ClassInfo = Information about TClonesArray class; | If this is the first occurrence of a TClonesArray object in the record; | 4->7 -1 = New class tag (constant kNewClassTag = 0xffffffff); | 8->17 Classname = Object Class Name ""TClonesArray"" (null terminated); | Otherwise; | 4->7 clIdx = Byte offset of new class tag in record, plus 2.; | OR'd with kClassMask (0x80000000); 0->3 ByteCount = Number of remaining bytes in TClonesArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TClonesArray Class; 6->15 = TObject object (a base class of TClonesArray) (see \ref tobject).; | Would be two bytes longer (6->17) if object were referenced.; 16->.. fName = Number of bytes in name of TClonesArray object, followed by the; | name itself. (TCollection::fName). This name will be the; | class name of the cloned object, appended with an 's'; | (e.g. ""TXxxs""); 0->.. = Number of bytes in name and version of the cloned class, followed; | by the name and version themselves (e.g. ""TXxx;1""); 0->3 nObjects = Number of objects in clones array.; 4->7 fLowerBound= Lower bound of clones array.; 8->.. objects = Sequentially, objects in the clones array. However, the data; | ordering depends on whether or not kBypassStreamer (0x1000) is; | set in TObject::fBits. By default, it is set. If it is not set,; | the objects are streamed sequentially using the streamer of the; | cloned class (e.g. TXxx::Streamer()).; |; | If it is set, the cloned class is split into its base classes and; | persistent data members, and those streamers are used. So, if the; | base classes and persistent data members of class TXxx are ",MatchSource.DOCS,io/doc/TFile/tclonesarray.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tclonesarray.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tclonesarray.md:1569,Integrability,depend,depends,1569,"y object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->.. ClassInfo = Information about TClonesArray class; | If this is the first occurrence of a TClonesArray object in the record; | 4->7 -1 = New class tag (constant kNewClassTag = 0xffffffff); | 8->17 Classname = Object Class Name ""TClonesArray"" (null terminated); | Otherwise; | 4->7 clIdx = Byte offset of new class tag in record, plus 2.; | OR'd with kClassMask (0x80000000); 0->3 ByteCount = Number of remaining bytes in TClonesArray object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TClonesArray Class; 6->15 = TObject object (a base class of TClonesArray) (see \ref tobject).; | Would be two bytes longer (6->17) if object were referenced.; 16->.. fName = Number of bytes in name of TClonesArray object, followed by the; | name itself. (TCollection::fName). This name will be the; | class name of the cloned object, appended with an 's'; | (e.g. ""TXxxs""); 0->.. = Number of bytes in name and version of the cloned class, followed; | by the name and version themselves (e.g. ""TXxx;1""); 0->3 nObjects = Number of objects in clones array.; 4->7 fLowerBound= Lower bound of clones array.; 8->.. objects = Sequentially, objects in the clones array. However, the data; | ordering depends on whether or not kBypassStreamer (0x1000) is; | set in TObject::fBits. By default, it is set. If it is not set,; | the objects are streamed sequentially using the streamer of the; | cloned class (e.g. TXxx::Streamer()).; |; | If it is set, the cloned class is split into its base classes and; | persistent data members, and those streamers are used. So, if the; | base classes and persistent data members of class TXxx are TXxxbase,; | TXxxdata0, TXxxdata1, etc., all the TXxxbase data from the entire; | clones array is streamed first, followed by all the TXxxdata0 data,; | etc. This breakdown is not recursive, in that the member objects; | are not again split.; -End TClonesArray object; </pre></div>",MatchSource.DOCS,io/doc/TFile/tclonesarray.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tclonesarray.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md:81,Deployability,release,release,81,"\page tdirectory Format of a TDirectory record. Format of a TDirectory record in release 6.22.06. It is never compressed. If the SeekKeys or SeekPdir in the TKey are located past the 32 bit file limit (> 2000000000),; then these fields will be 8 instead of 4 bytes and 1000 is added to the TKey Version. If the SeekDir, SeekParent, or SeekKeys in the TDirectory header are past the 32 bit file limit,; then these fields will be 8 instead of 4 bytes and 1000 is added to the TDirectory Version. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey--------------; byte 0->3 Nbytes = Number of bytes in compressed record (Tkey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 [18->25] SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 [26->33] SeekPdir = Byte offset of parent directory record TKey::fSeekPdir; 26->26 [33->33] lname = Number of bytes in the class name (10) TKey::fClassName; 27->.. [34->..] ClassName = Object Class Name (""TDirectory"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes with the name of the object `<directory-name>` TNamed::fName; 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object `<directory-title>` TNamed::fTitle; --------DATA----------------; 0->1 Version = TDirectory class version identifier TDirectory::Class_Version(); 2->5 DatimeC = Date and time when directory was created TDirectory::fDatimeC; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 6->9 DatimeM = Date and time when directory was last m",MatchSource.DOCS,io/doc/TFile/tdirectory.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md:2862,Deployability,release,release,2862,"was created TDirectory::fDatimeC; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 6->9 DatimeM = Date and time when directory was last modified TDirectory::fDatimeM; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 10->13 NbytesKeys= Number of bytes in the associated KeysList record TDirectory::fNbyteskeys; 14->17 NbytesName= Number of bytes in TKey+TNamed at creation TDirectory::fNbytesName; 18->21 [18->25] SeekDir = Byte offset of directory record in file TDirectory::fSeekDir; 22->25 [26->33] SeekParent= Byte offset of parent directory record in file TDirectory::fSeekParent; 26->29 [34->41] SeekKeys = Byte offset of associated KeysList record in file TDirectory::fSeekKeys; 30->31 [42->43] UUID vers = TUUID class version identifier TUUID::Class_Version(); 32->47 [44->59] UUID = Universally Unique Identifier TUUID::fTimeLow through fNode[6]; 48->59 Extra space to allow SeekKeys to become 64 bit without moving this header; </pre></div>. Format of a TDirectory record in release 3.02.06. It is never compressed. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey--------------; byte 0->3 Nbytes = Number of bytes in compressed record (Tkey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (10) TKey::fClassName; 27->.. ClassName = Object Class Name (""TDirectory"") TKey::fClassName; 0->0 lname = Number of bytes in the object name TNamed::fName; 1->.. Name = lName bytes w",MatchSource.DOCS,io/doc/TFile/tdirectory.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tdirectory.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tfile.md:104,Deployability,release,release,104,"\page tfile Format of the root (first) directory record. Format of the root (first) directory record in release 6.22.06. It is never compressed. This directory record differs from subdirectories (see \ref tdirectory) in the additional; Name and Title at the beginning of the DATA (after the TKey). If the SeekKeys or SeekPdir in the TKey are located past the 32 bit file limit (> 2000000000),; then these fields will be 8 instead of 4 bytes and 1000 is added to the TKey Version. If the SeekDir, SeekParent, or SeekKeys in the TDirectory header are past the 32 bit file limit,; then these fields will be 8 instead of 4 bytes and 1000 is added to the TDirectory Version. ----------TKey---------------. | Byte Range | Member Name | Description | |; |------------------|----------------|-----------------------------------------|-|; | 0...3 | Nbytes | Number of bytes compressed record (TKey+data) | TKey::fNbytes |; | 4...5 | Version | TKey class version identifier | TKey::fVersion |; | 6...9 | ObjLen | Number of bytes of uncompressed data | TKey::fObjLen |; |10...13 | Datime | Date and time when record was written to file | TKey::fDatime (year-1995)<<26&#124;month<<22&#124;day<<17&#124;hour<<12&#124;minute<<6&#124;second |; |14...15 | KeyLen | Number of bytes in key structure (TKey) | TKey::fKeyLen |; |16...17 | Cycle | Cycle of key | TKey::fCycle |; |18...21 [18...25] | SeekKey | Byte offset of record itself (consistency check) (64) | TKey::fSeekKey |; |22...25 [26...33] | SeekPdir | Byte offset of parent directory record (0) | TKey::fSeekPdir |; |26...26 [34...34] | lname | Number of bytes in the class name (5) | TKey::fClassName |; |27..... [35...] | ClassName | Object Class Name (""TFile"") | TKey::fClassName |; | 0...0 | lname | Number of bytes in the object name | TNamed::fName |; | 1... | Name | lName bytes with the name of the object `<file-name>` | TNamed::fName |; | 0...0 | lTitle | Number of bytes in the object title | TNamed::fTitle |; | 1... | Title | lTitle bytes with t",MatchSource.DOCS,io/doc/TFile/tfile.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tfile.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tobject.md:453,Availability,mask,mask,453,"\page tobject Format of the DATA for a TObject object. Here is the format of the DATA for a TObject object in Release 3.02.06. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; --------; 0->1 Version = Version of TObject Class; 2->5 fUniqueID = Unique ID of object. Currently, unless this object is or was; | referenced by a TRef or TRefArray, or is itself a TRef or TRefArray,; | this field is not used by ROOT.; 6->9 fBits = A 32 bit mask containing status bits for the object.; | The bits relevant to ROOTIO are:; | 0x00000001 - if object in a list can be deleted.; | 0x00000008 - if other objects may need to be deleted when this one is.; | 0x00000010 - if object is referenced by pointer to persistent object.; | 0x00002000 - if object ctor succeeded but object shouldn't be used; | 0x01000000 - if object is on Heap.; | 0x02000000 - if object has not been deleted.; The ""pidf"" field below is present only if this TObject object (or an object inheriting; from it) is referenced by a pointer to persistent object.; 10->11 pidf = An identifier of the TProcessID record for the process that wrote the; | object. This identifier is an unsigned short. The relevant record; | has a name that is the string ""ProcessID"" concatenated with the ASCII; | decimal representation of ""pidf"" (no leading zeros). 0 is a valid pidf.; -------; No object in the StreamerInfo record will be a reference or referenced, and all objects; are on the heap. So, for each occurrence in the StreamerInfo record, fUniqueID will be 0,; fBits will be 0x03000000, and pidf will be absent.; </pre></div>; ",MatchSource.DOCS,io/doc/TFile/tobject.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tobject.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tobject.md:965,Modifiability,inherit,inheriting,965,"\page tobject Format of the DATA for a TObject object. Here is the format of the DATA for a TObject object in Release 3.02.06. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; --------; 0->1 Version = Version of TObject Class; 2->5 fUniqueID = Unique ID of object. Currently, unless this object is or was; | referenced by a TRef or TRefArray, or is itself a TRef or TRefArray,; | this field is not used by ROOT.; 6->9 fBits = A 32 bit mask containing status bits for the object.; | The bits relevant to ROOTIO are:; | 0x00000001 - if object in a list can be deleted.; | 0x00000008 - if other objects may need to be deleted when this one is.; | 0x00000010 - if object is referenced by pointer to persistent object.; | 0x00002000 - if object ctor succeeded but object shouldn't be used; | 0x01000000 - if object is on Heap.; | 0x02000000 - if object has not been deleted.; The ""pidf"" field below is present only if this TObject object (or an object inheriting; from it) is referenced by a pointer to persistent object.; 10->11 pidf = An identifier of the TProcessID record for the process that wrote the; | object. This identifier is an unsigned short. The relevant record; | has a name that is the string ""ProcessID"" concatenated with the ASCII; | decimal representation of ""pidf"" (no leading zeros). 0 is a valid pidf.; -------; No object in the StreamerInfo record will be a reference or referenced, and all objects; are on the heap. So, for each occurrence in the StreamerInfo record, fUniqueID will be 0,; fBits will be 0x03000000, and pidf will be absent.; </pre></div>; ",MatchSource.DOCS,io/doc/TFile/tobject.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tobject.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tprocessid.md:77,Deployability,release,release,77,"\page tprocessid Format of TProcessID record. Format of TProcessID record in release 3.02.06.; Will be present if there are any referenced objects. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------TKey---------------; byte 0->3 Nbytes = Number of bytes in compressed record (Tkey+data) TKey::fNbytes; 4->5 Version = TKey class version identifier TKey::fVersion; 6->9 ObjLen = Number of bytes of uncompressed data TKey::fObjLen; 10->13 Datime = Date and time when record was written to file TKey::fDatime; | (year-1995)<<26|month<<22|day<<17|hour<<12|minute<<6|second; 14->15 KeyLen = Number of bytes in key structure (TKey) TKey::fKeyLen; 16->17 Cycle = Cycle of key TKey::fCycle; 18->21 SeekKey = Byte offset of record itself (consistency check) TKey::fSeekKey; 22->25 SeekPdir = Byte offset of parent directory record TKey::fSeekPdir; 26->26 lname = Number of bytes in the class name (10) TKey::fClassName; 27->36 ClassName= Object Class Name (""TProcessID"") TKey::fClassName; 37->37 lname = Number of bytes in the object name TNamed::fName; 38->.. Name = lName bytes with the name of the object TNamed::fName; | (e.g. ""ProcessID0""); 0->0 lTitle = Number of bytes in the object title TNamed::fTitle; 1->.. Title = lTitle bytes with the title of the object TNamed::fTitle; | (Identifies processor, time stamp, etc.); | See detailed explanation below.; ----------DATA--------------; 0->3 ByteCount = Number of remaining bytes in TProcessID object (uncompressed); | OR'd with kByteCountMask (0x40000000); 4->5 Version = Version of TProcessID Class; -Begin TNamed object (Base class of TProcessID); 6->9 ByteCount = Number of remaining bytes in TNamed object (uncompressed); | OR'd with kByteCountMask (0x40000000); 10->11 Version = Version of TNamed Class; 12->21 = TObject object (Base class of TNamed) (see \ref tobject).; | The TProcessID object is not itself referenced.; 22->22 lname = Number of bytes in the object name TNamed::fName; 23->.. Name = lName bytes with the",MatchSource.DOCS,io/doc/TFile/tprocessid.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tprocessid.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tref.md:568,Availability,mask,mask,568,"\page tref Format of the DATA for a TRef object. Here is the format of the DATA for a TRef object in Release 3.02.06. <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; --------; 0->1 Version = Version of TObject Class (base class of TRef); 2->5 fUniqueID = Unique ID of referenced object. Typically, every referenced; | object has an ID that is a positive integer set to a counter; | of the number of referenced objects in the file, beginning at 1.; | fUniqueID in the TRef object matches fUniqueID in the; | referenced object.; 6->9 fBits = A 32 bit mask containing status bits for the TRef object.; | The bits relevant to ROOTIO are:; | 0x00000008 - Other objects may need to be deleted when this one is.; | 0x00000010 - Object is referenced by pointer to persistent object.; | 0x01000000 - Object is on Heap.; | 0x02000000 - Object has not been deleted.; 10->11 pidf = An identifier of the TProcessID record for the process that wrote the; | referenced object. This identifier is an unsigned short. The relevant; | record has a name that is the string ""ProcessID"" concatenated with the; | ASCII decimal representation of ""pidf"" (no leading zeros).; | 0 is a valid pidf.; -------; </pre></div>",MatchSource.DOCS,io/doc/TFile/tref.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/tref.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md:122,Deployability,release,release,122,"\page ttree Streamer information for TTree related classes. Here is the streamer information for TTree related classes in release 3.02.06:; (For the explanation of the meaning of the type, see ""fType"" in \ref streamerinfo.). <div style=""background-color: lightgrey; font-size: 0.9vw;""><pre>; ----------------------------------------------------; StreamerInfo for class: TTree, version=6; BASE TNamed offset= 0 type=67 The basis for a named object (name, title); BASE TAttLine offset= 0 type= 0 Line attributes; BASE TAttFill offset= 0 type= 0 Fill area attributes; BASE TAttMarker offset= 0 type= 0 Marker attributes; Stat_t fEntries offset= 0 type= 8 Number of entries; Stat_t fTotBytes offset= 0 type= 8 Total number of bytes in all branches before compression; Stat_t fZipBytes offset= 0 type= 8 Total number of bytes in all branches after compression; Stat_t fSavedBytes offset= 0 type= 8 Number of autosaved bytes; Int_t fTimerInterval offset= 0 type= 3 Timer interval in milliseconds; Int_t fScanField offset= 0 type= 3 Number of runs before prompting in Scan; Int_t fUpdate offset= 0 type= 3 Update frequency for EntryLoop; Int_t fMaxEntryLoop offset= 0 type= 3 Maximum number of entries to process; Int_t fMaxVirtualSize offset= 0 type= 3 Maximum total size of buffers kept in memory; Int_t fAutoSave offset= 0 type= 3 Autosave tree when fAutoSave bytes produced; Int_t fEstimate offset= 0 type= 3 Number of entries to estimate histogram limits; TObjArray fBranches offset= 0 type=61 List of Branches; TObjArray fLeaves offset= 0 type=61 Direct pointers to individual branch leaves; TArrayD fIndexValues offset= 0 type=62 Sorted index values; TArrayI fIndex offset= 0 type=62 Index of sorted values; TList* fFriends offset= 0 type=64 pointer to list of friend elements. StreamerInfo for class: TAttLine, version=1; Color_t fLineColor offset= 0 type= 2 line color; Style_t fLineStyle offset= 0 type= 2 line style; Width_t fLineWidth offset= 0 type= 2 line width. StreamerInfo for class: TAttFil",MatchSource.DOCS,io/doc/TFile/ttree.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md:4446,Modifiability,variab,variable,4446," leaves after compression; TObjArray fBranches offset= 0 type=61 -> List of Branches of this branch; TObjArray fLeaves offset= 0 type=61 -> List of leaves of this branch; TObjArray fBaskets offset= 0 type=61 -> List of baskets of this branch; Int_t* fBasketBytes offset= 0 type=43 [fMaxBaskets] Length of baskets on file; Int_t* fBasketEntry offset= 0 type=43 [fMaxBaskets] Table of first entry in eack basket; Seek_t* fBasketSeek offset= 0 type=43 [fMaxBaskets] Addresses of baskets on file; TString fFileName offset= 0 type=65 Name of file where buffers are stored ("""" if in same file as Tree header). StreamerInfo for class: TBranchElement, version=7; BASE TBranch offset= 0 type= 0 Branch descriptor; TString fClassName offset= 0 type=65 Class name of referenced object; TString fParentName offset= 0 type=65 Name of parent class; TString fClonesName offset= 0 type=65 Name of class in TClonesArray (if any); Int_t fClassVersion offset= 0 type= 3 Version number of class; Int_t fID offset= 0 type= 3 element serial number in fInfo; Int_t fType offset= 0 type= 3 branch type; Int_t fStreamerType offset= 0 type= 3 branch streamer type; Int_t fMaximum offset= 0 type= 3 Maximum entries for a TClonesArray or variable array; TBranchElement*fBranchCount offset= 0 type=64 pointer to primary branchcount branch; TBranchElement*fBranchCount2 offset= 0 type=64 pointer to secondary branchcount branch. StreamerInfo for class: TLeaf, version=2; BASE TNamed offset= 0 type=67 The basis for a named object (name, title); Int_t fLen offset= 0 type= 3 Number of fixed length elements; Int_t fLenType offset= 0 type= 3 Number of bytes for this data type; Int_t fOffset offset= 0 type= 3 Offset in ClonesArray object (if one); Bool_t fIsRange offset= 0 type=11 (=kTRUE if leaf has a range, kFALSE otherwise); Bool_t fIsUnsigned offset= 0 type=11 (=kTRUE if unsigned, kFALSE otherwise); TLeaf* fLeafCount offset= 0 type=64 Pointer to Leaf count if variable length. StreamerInfo for class: TLeafElement, version=1",MatchSource.DOCS,io/doc/TFile/ttree.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md:5173,Modifiability,variab,variable,5173,"s offset= 0 type=61 -> List of baskets of this branch; Int_t* fBasketBytes offset= 0 type=43 [fMaxBaskets] Length of baskets on file; Int_t* fBasketEntry offset= 0 type=43 [fMaxBaskets] Table of first entry in eack basket; Seek_t* fBasketSeek offset= 0 type=43 [fMaxBaskets] Addresses of baskets on file; TString fFileName offset= 0 type=65 Name of file where buffers are stored ("""" if in same file as Tree header). StreamerInfo for class: TBranchElement, version=7; BASE TBranch offset= 0 type= 0 Branch descriptor; TString fClassName offset= 0 type=65 Class name of referenced object; TString fParentName offset= 0 type=65 Name of parent class; TString fClonesName offset= 0 type=65 Name of class in TClonesArray (if any); Int_t fClassVersion offset= 0 type= 3 Version number of class; Int_t fID offset= 0 type= 3 element serial number in fInfo; Int_t fType offset= 0 type= 3 branch type; Int_t fStreamerType offset= 0 type= 3 branch streamer type; Int_t fMaximum offset= 0 type= 3 Maximum entries for a TClonesArray or variable array; TBranchElement*fBranchCount offset= 0 type=64 pointer to primary branchcount branch; TBranchElement*fBranchCount2 offset= 0 type=64 pointer to secondary branchcount branch. StreamerInfo for class: TLeaf, version=2; BASE TNamed offset= 0 type=67 The basis for a named object (name, title); Int_t fLen offset= 0 type= 3 Number of fixed length elements; Int_t fLenType offset= 0 type= 3 Number of bytes for this data type; Int_t fOffset offset= 0 type= 3 Offset in ClonesArray object (if one); Bool_t fIsRange offset= 0 type=11 (=kTRUE if leaf has a range, kFALSE otherwise); Bool_t fIsUnsigned offset= 0 type=11 (=kTRUE if unsigned, kFALSE otherwise); TLeaf* fLeafCount offset= 0 type=64 Pointer to Leaf count if variable length. StreamerInfo for class: TLeafElement, version=1; BASE TLeaf offset= 0 type= 0 Leaf: description of a Branch data type; Int_t fID offset= 0 type= 3 element serial number in fInfo; Int_t fType offset= 0 type= 3 leaf type; </pre></div>; ",MatchSource.DOCS,io/doc/TFile/ttree.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/ttree.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:837,Deployability,update,update,837,". ## I/O Libraries. ### I/O Behavior change. #### Classes with custom streamer. Classes for which a Streamer function was externally provided are no longer; split; they were split in v5 if the dictionary was generated via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; ",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1474,Deployability,integrat,integrated,1474,"he custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerger::PartialMerge(flags | kOnlyListed); ```. This will merge only the objects in the files having the names in; the specified list. If a folder is specified, it whole content will; be merged. ``` {.cpp}; TFileMerger::PartialMerge(flags | kSkipListed); ```. This will skip merging for the specified objects. If a folder is; specified, its whole content will be skipped. Important note:; The kOnlyListed and kSkipListed flags have to be bitwise OR-ed; on top of the merging defaults: kA",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1474,Integrability,integrat,integrated,1474,"he custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerger::PartialMerge(flags | kOnlyListed); ```. This will merge only the objects in the files having the names in; the specified list. If a folder is specified, it whole content will; be merged. ``` {.cpp}; TFileMerger::PartialMerge(flags | kSkipListed); ```. This will skip merging for the specified objects. If a folder is; specified, its whole content will be skipped. Important note:; The kOnlyListed and kSkipListed flags have to be bitwise OR-ed; on top of the merging defaults: kA",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1621,Integrability,interface,interface,1621,"ect, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerger::PartialMerge(flags | kOnlyListed); ```. This will merge only the objects in the files having the names in; the specified list. If a folder is specified, it whole content will; be merged. ``` {.cpp}; TFileMerger::PartialMerge(flags | kSkipListed); ```. This will skip merging for the specified objects. If a folder is; specified, its whole content will be skipped. Important note:; The kOnlyListed and kSkipListed flags have to be bitwise OR-ed; on top of the merging defaults: kAll | kIncremental (as in the example $ROOTSYS/tutorials/io/mergeSelective.C). ",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1252,Modifiability,enhance,enhanced,1252,"d via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerger::PartialMerge(flags | kOnlyListed); ```. This will merge only the objects in the files having the names in; the specified list. If a folder is specified, it whole content will; be merged. ``` {.cpp}; TFil",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:957,Security,checksum,checksum,957,"Libraries. ### I/O Behavior change. #### Classes with custom streamer. Classes for which a Streamer function was externally provided are no longer; split; they were split in v5 if the dictionary was generated via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerg",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1006,Security,checksum,checksum,1006,"Libraries. ### I/O Behavior change. #### Classes with custom streamer. Classes for which a Streamer function was externally provided are no longer; split; they were split in v5 if the dictionary was generated via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerg",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1036,Security,checksum,checksum,1036,"Libraries. ### I/O Behavior change. #### Classes with custom streamer. Classes for which a Streamer function was externally provided are no longer; split; they were split in v5 if the dictionary was generated via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerg",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md:1207,Security,checksum,checksum,1207,"d via rootcint but; were not split if the dictionary was generated via genreflex. Classes with a custom Streamer function and classes with an older, non StreamerInfo; based automatic streamer are also no longer split. To force the splitting of those classes, thus by-passing the custom Streamer,; when storing the object in a TTree and in a collection object, use:. ``` {.cpp}; TClass::GetClass(classname)->SetCanSplit(true);; ```. ### I/O Schema Checksum. The algorithm used to calculate a single number giving an indication on whether; the schema layout has changed (i.e. if two StreamerInfo are equivalent) have; been update to. - Use the normalized name for the types (i.e. two different spelling of the same; name will lead to the same checksum); - Take into account the base classes' checksum in the derived class checksum;; this is necessary to properly support base classes during memberwise streaming. The algorithm that checks whether two StreamerInfo are equal even-though their; checksum is different has been significantly enhanced in particular to also; check the base classes. ### TFileMerger. - Added possibility to merge only a list of objects/folders from the; input files, specified by name, \; or to skip them from merging. This is fully integrated with the new; PartialMerge(flags) schema. \; Usage: \; The names of the objects to be merged or skipped have to be; specified using the interface:. ``` {.cpp}; TFileMerger::AddObjectNames(const char *names); ```. This method can be called several times to add object names. Several; names can be added with one call separated by single blancs (no; blanc at the end). Directory names are accepted, applying the; merging selection to all content. Two new options are being; supported for partial merging:. ``` {.cpp}; TFileMerger::PartialMerge(flags | kOnlyListed); ```. This will merge only the objects in the files having the names in; the specified list. If a folder is specified, it whole content will; be merged. ``` {.cpp}; TFil",MatchSource.DOCS,io/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/io/doc/v606/index.md:31,Modifiability,extend,extended,31,## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### I/O New functionalities. ### I/O Behavior change.; ,MatchSource.DOCS,io/doc/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/io/io/doc/index.md:604,Availability,avail,available,604,"\defgroup IO Input/Output Library. The library collecting the ROOT classes dedicated to data input and output. For an overview of I/O in ROOT, see the following pages in the ROOT manual:. - [ROOT files](https://root.cern/manual/root_files); - [Trees](https://root.cern/manual/trees/): ROOT's columnar storage; - [I/O concepts](https://root.cern/manual/io/): a collection of more advanced I/O-related topics; - [I/O of custom classes](root.cern/manual/io_custom_classes/): how to read and write user-defined C++ objects. For ROOT I/O developers, a detailed internal description of the \ref rootio is also available.; ",MatchSource.DOCS,io/io/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/io/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:4225,Availability,avail,available,4225,"trix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the neural network class, TMultiLayerPerceptron based on the NN algorithm from the mlpfit package. - **Quadp** Optimization library with linear and quadratic programming methods. It is based on the Matrix package. Further information is available at the following links:. - [The Math page in the manual](https://root.cern/manual/math); - [The Linear Algebra section in the manual](https://root.cern/manual/math/#linear-algebra-packages); - [The Fitting histograms page in the manual](https://root.cern/manual/fitting/); - [Inventory of Math functions and algorithms] (http://project-mathlibs.web.cern.ch/project-mathlibs/mathTable.html). ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:523,Deployability,integrat,integration,523,"\defgroup Math Math; \brief The %ROOT Mathematical Libraries. They consist of the following components:. - \ref MathCore ""MathCore"": a self-consistent minimal set of tools required for the basic numerical computing.; It provides the major mathematical functions in the namespaces ROOT::Math and TMath,; classes for random number generators, TRandom, class for complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter)",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:3535,Deployability,continuous,continuous,3535,"e contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the neural network class, TMultiLayerPerceptron based on the NN algorithm from the mlpfit package. - **Quadp** Optimization library with linear and quadratic programming methods. It is based on the Matrix package. Further information is available at the following links:. - [The Math page in the manual](https://root.cern/manual/math); - [The Linear Algebra section in the manual](https://root.cern/manual/math/#linear-algebra-packages); - [The Fitting histograms page in the manual](https://root.cern/manual/fitt",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:3678,Deployability,integrat,integrator,3678,"trix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the neural network class, TMultiLayerPerceptron based on the NN algorithm from the mlpfit package. - **Quadp** Optimization library with linear and quadratic programming methods. It is based on the Matrix package. Further information is available at the following links:. - [The Math page in the manual](https://root.cern/manual/math); - [The Linear Algebra section in the manual](https://root.cern/manual/math/#linear-algebra-packages); - [The Fitting histograms page in the manual](https://root.cern/manual/fitting/); - [Inventory of Math functions and algorithms] (http://project-mathlibs.web.cern.ch/project-mathlibs/mathTable.html). ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:3920,Deployability,install,installation,3920,"trix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the neural network class, TMultiLayerPerceptron based on the NN algorithm from the mlpfit package. - **Quadp** Optimization library with linear and quadratic programming methods. It is based on the Matrix package. Further information is available at the following links:. - [The Math page in the manual](https://root.cern/manual/math); - [The Linear Algebra section in the manual](https://root.cern/manual/math/#linear-algebra-packages); - [The Fitting histograms page in the manual](https://root.cern/manual/fitting/); - [Inventory of Math functions and algorithms] (http://project-mathlibs.web.cern.ch/project-mathlibs/mathTable.html). ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:395,Integrability,interface,interfaces,395,"\defgroup Math Math; \brief The %ROOT Mathematical Libraries. They consist of the following components:. - \ref MathCore ""MathCore"": a self-consistent minimal set of tools required for the basic numerical computing.; It provides the major mathematical functions in the namespaces ROOT::Math and TMath,; classes for random number generators, TRandom, class for complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter)",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:523,Integrability,integrat,integration,523,"\defgroup Math Math; \brief The %ROOT Mathematical Libraries. They consist of the following components:. - \ref MathCore ""MathCore"": a self-consistent minimal set of tools required for the basic numerical computing.; It provides the major mathematical functions in the namespaces ROOT::Math and TMath,; classes for random number generators, TRandom, class for complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter)",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:738,Integrability,depend,dependent,738,"\defgroup Math Math; \brief The %ROOT Mathematical Libraries. They consist of the following components:. - \ref MathCore ""MathCore"": a self-consistent minimal set of tools required for the basic numerical computing.; It provides the major mathematical functions in the namespaces ROOT::Math and TMath,; classes for random number generators, TRandom, class for complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter)",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:997,Integrability,interface,interfaces,997,"\defgroup Math Math; \brief The %ROOT Mathematical Libraries. They consist of the following components:. - \ref MathCore ""MathCore"": a self-consistent minimal set of tools required for the basic numerical computing.; It provides the major mathematical functions in the namespaces ROOT::Math and TMath,; classes for random number generators, TRandom, class for complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter)",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:1299,Integrability,interface,interface,1299,"r complex numbers, TComplex,; common interfaces for function evaluation and numerical algorithms.; Basic implementations of some of the numerical algorithms such as integration or derivation, are also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fu",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:1636,Integrability,interface,interface,1636,"also provided by MathCore.; together with the core classes needed to fit any generic data set. - \ref MathMore ""MathMore"": a package incorporating advanced numerical functionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra mat",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:1755,Integrability,interface,interface,1755,"nctionality and dependent on external libraries like the GNU Scientific Library ([GSL](http://www.gnu.org/software/gsl/)). It complements the MathCore library by providing a more complete sets of special mathematical functions and implementations of the numerical algorithms interfaces defined in MathCore using GSL. - **Minimization and Fitting Libraries**; Libraries required for numerical minimization and fitting. The minimization libraries include the numerical methods for solving the fitting problem by finding minimum of multi-dimensional; function. The current common interface for minimization is the class ROOT::Math::Minimizer and implemented by derived classes in the minimization and fitting libraries. The fitting in %ROOT is; organized in fitting classes present in MathCore in the (ROOT::Fit namespace) for providing the fitting functionality and the use the minimization libraries via the common interface (ROOT::Math::Minimizer). In detail the minimization libraries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:3678,Integrability,integrat,integrator,3678,"trix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the neural network class, TMultiLayerPerceptron based on the NN algorithm from the mlpfit package. - **Quadp** Optimization library with linear and quadratic programming methods. It is based on the Matrix package. Further information is available at the following links:. - [The Math page in the manual](https://root.cern/manual/math); - [The Linear Algebra section in the manual](https://root.cern/manual/math/#linear-algebra-packages); - [The Fitting histograms page in the manual](https://root.cern/manual/fitting/); - [Inventory of Math functions and algorithms] (http://project-mathlibs.web.cern.ch/project-mathlibs/mathTable.html). ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:2738,Performance,perform,perform,2738,"ries, implementing all the new and old minimization interface, include:. - \ref MinuitOld ""Minuit"": library providing via a class TMinuit an implementation of the popular MINUIT minimization package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:2867,Performance,optimiz,optimized,2867,"ion package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW pac",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:2886,Performance,perform,performances,2886,"ion package. In addition the library contains also an implementation of the linear fitter (class TLinearFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW pac",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md:3016,Performance,optimiz,optimization,3016,"earFitter), for solving linear least square fits.; - \ref Minuit2Page ""Minuit2"": new object-oriented implementation of MINUIT, with the same minimization algorithms (such as Migrad or Simplex). In addition it provides a new implementation of the Fumili algorithm, a specialized method for finding the minimum of a standard least square or likelihood functions.; - **Fumili**: library providing the implementation of the original Fumili fitting algorithm (class TFumili). - **Linear algebra**. Two libraries are contained in %ROOT for describing linear algebra matrices and vector classes:. - Matrix: general matrix package providing matrix classes (TMatrixD and TMatrixF) and vector classes (TVectorD and TVectorF) and the complete environment to perform linear algebra calculations, like equation solving and eigenvalue decompositions.; - \ref SMatrixPage ""SMatrix"": package optimized for high performances matrix and vector computations of small and fixed size. It is based on expression templates to achieve an high level optimization. - **Physics Vectors**: Classes for describing vectors in 2, 3 and 4 dimensions (relativistic vectors) and their rotation and transformation algorithms. Two package exist in %ROOT:. - Physics: library with the TVector3 and TLorentzVector classes.; - GenVector: new library providing generic class templates for modeling the vectors. See the \ref GenVector ""GenVector"" page. - \ref Unuran ""UNURAN"": Package with universal algorithms for generating non-uniform pseudo-random numbers, from a large classes of continuous or discrete distributions in one or multi-dimensions. - **Foam** Multi-dimensional general purpose Monte Carlo event generator (and integrator). It generates randomly points (vectors) according to an arbitrary probability distribution in n dimensions. - **FFTW** Library with implementation of the fast Fourier transform (FFT) using the FFTW package. It requires a previous installation of [FFTW](http://www.fftw.org). - **MLP** Library with the ",MatchSource.DOCS,math/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1201,Deployability,install,installers,1201,"ource. To extract, run the following commands from the `math/minuit2/build` directory:. ```bash; cmake .. -Dminuit2_standalone=ON; ```. This will fill in the `math/minuit2` directory with all the files needed for Minuit2, copied from the corresponding ROOT files, as part of the configure step.; At this point, you could continue to build (using `make`). Note that the CMake option `minuit2_inroot` will automatically be set to `ON` if you are inside the ROOT source tree. Setting `minuit2_standalone` requires that this be inside the ROOT source tree. As always, any manual setting of a cached variable in CMake will be remembered as long as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it loo",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:2592,Deployability,install,installs,2592,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1805,Integrability,depend,depending,1805," as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:470,Modifiability,config,configure,470,"This is the Minuit2 fitter standalone extractor, from the [ROOT] toolkit. It uses [CMake] 3.1+ to build.; See `README.md` for information about building Minuit2. ## Extracting from the ROOT source. To extract, run the following commands from the `math/minuit2/build` directory:. ```bash; cmake .. -Dminuit2_standalone=ON; ```. This will fill in the `math/minuit2` directory with all the files needed for Minuit2, copied from the corresponding ROOT files, as part of the configure step.; At this point, you could continue to build (using `make`). Note that the CMake option `minuit2_inroot` will automatically be set to `ON` if you are inside the ROOT source tree. Setting `minuit2_standalone` requires that this be inside the ROOT source tree. As always, any manual setting of a cached variable in CMake will be remembered as long as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:786,Modifiability,variab,variable,786,"This is the Minuit2 fitter standalone extractor, from the [ROOT] toolkit. It uses [CMake] 3.1+ to build.; See `README.md` for information about building Minuit2. ## Extracting from the ROOT source. To extract, run the following commands from the `math/minuit2/build` directory:. ```bash; cmake .. -Dminuit2_standalone=ON; ```. This will fill in the `math/minuit2` directory with all the files needed for Minuit2, copied from the corresponding ROOT files, as part of the configure step.; At this point, you could continue to build (using `make`). Note that the CMake option `minuit2_inroot` will automatically be set to `ON` if you are inside the ROOT source tree. Setting `minuit2_standalone` requires that this be inside the ROOT source tree. As always, any manual setting of a cached variable in CMake will be remembered as long as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1443,Modifiability,config,configured,1443,"onding ROOT files, as part of the configure step.; At this point, you could continue to build (using `make`). Note that the CMake option `minuit2_inroot` will automatically be set to `ON` if you are inside the ROOT source tree. Setting `minuit2_standalone` requires that this be inside the ROOT source tree. As always, any manual setting of a cached variable in CMake will be remembered as long as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:2112,Modifiability,variab,variable,2112,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:779,Performance,cache,cached,779,"This is the Minuit2 fitter standalone extractor, from the [ROOT] toolkit. It uses [CMake] 3.1+ to build.; See `README.md` for information about building Minuit2. ## Extracting from the ROOT source. To extract, run the following commands from the `math/minuit2/build` directory:. ```bash; cmake .. -Dminuit2_standalone=ON; ```. This will fill in the `math/minuit2` directory with all the files needed for Minuit2, copied from the corresponding ROOT files, as part of the configure step.; At this point, you could continue to build (using `make`). Note that the CMake option `minuit2_inroot` will automatically be set to `ON` if you are inside the ROOT source tree. Setting `minuit2_standalone` requires that this be inside the ROOT source tree. As always, any manual setting of a cached variable in CMake will be remembered as long as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1866,Testability,test,testing,1866,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1885,Testability,test,test,1885,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:1932,Testability,test,test,1932,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:2745,Usability,guid,guides,2745,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md:2758,Usability,guid,guide,2758,"g as the `CMakeCache.txt` file is not removed. Remember that after building a tarball or a binary package you should remove the copied files using:. ```bash; make purge; ```. Otherwise git shows the file as untracked, unless you explicitly remove their tracking yourself with a .gitignore file. ## Building a tarball. Minuit2 standalone also has support for CPack to make installers for different platforms. To build a source package:. ```bash; make package_source; ```. This will create a source file in several formats that you can distribute. Reminder: You **must** have used `-Dminuit2_standalone=ON` when you configured CMake, or many of the files will be missing. ## Building a binary. To build a binary package (add other generators with `-G`):; ```bash; make; make package; ```. ## Maintenance. If new files are needed by Minuit2 due to additions to [ROOT], they should be added to the source files lists in `src/Math/CMakeLists.txt` and `src/Minuit2/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). For testing, the main `test/CMakeLists.txt` is used by ROOT, and the `test/*/CMakeLists.txt` files are used by the standalone build. ## How it works. Extracting from the ROOT sources is made possible through a few careful design features:. * A CMake variable `minuit2_inroot` lets the build system know we are inside ROOT (it looks for `../../build/version_info`); * All files that are not part of the minuit2 directory are passed into `copy_standalone`, and that handles selecting the correct location; * `copy_standalone` copies the files into the minuit2 source directory if `minuit2_standalone` is `ON`. After this happens, all the standard CMake machinery can produce the source distribution. And, CMake correctly builds and installs in either mode, since all source and header files are explicitly listed. [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/DEVELOP.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/DEVELOP.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1460,Deployability,install,install,1460," information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEV",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1510,Deployability,install,install,1510," information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEV",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1531,Deployability,install,install,1531,"se the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guid",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1843,Deployability,install,installed,1843,"kdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1989,Deployability,install,installing,1989,"kdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1086,Modifiability,variab,variables,1086,"on about the Minuit2 fitter, please see the [documentation in ROOT][minuitdoc]. ## Source. There are two ways to get Minuit2; you can checkout the [ROOT] source, then just build or use `add_subdirectory` with `<ROOT_SOURCE>/math/minuit2`, or you can get a Minuit2 source distribution which contains all the needed files to build with [CMake]. See [DEVELOP.md] for more information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1885,Modifiability,config,config,1885,"kdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1372,Testability,test,test,1372,"nuit2 source distribution which contains all the needed files to build with [CMake]. See [DEVELOP.md] for more information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:1397,Testability,test,test,1397,"nuit2 source distribution which contains all the needed files to build with [CMake]. See [DEVELOP.md] for more information about extracting the source files from [ROOT]. ## Building. To build, use the standard [CMake] procedure; on most systems, this looks like:. ```bash; mkdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:2565,Usability,guid,guides,2565,"kdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md:2578,Usability,guid,guide,2578,"kdir PATH_TO_MINIUT2_BUILD; cd PATH_TO_MINUIT2_BUILD; cmake PATH_TO_MINUIT2_SOURCE; cmake --build .; ```. Of course, GUIs, IDEs, etc. that work with [CMake] will work with this package. The standard method of CMake building, with a build directory inside the Minuit2 source directory and using the makefile generator, would look like:. ```bash; cd PATH_TO_MINUIT2_SOURCE; mkdir build; cd build; cmake ..; make; ```. The standard [CMake] variables, such as `CMAKE_BUILD_TYPE` and `CMAKE_INSTALL_PREFIX`, work with Minuit2. There are two other options:. * `minuit2_mpi` activates the (outdated C++) MPI bindings.; * `minuit2_omp` activates OpenMP (make sure all FCNs are threadsafe). ## Testing. You can run `ctest` or `make test` to run the Minuit2 test suite. ## Installing or using in another package. You can install the package using `cmake --build --target install .` (or `make install` if directly using the make system), or you can use it from the build directory. You can also include it in another CMake project using `add_subdirectory()` and linking to the `Minuit2` target. Since this package also exports targets, `find_package(Minuit2)` will also work once this package is built or installed. (For the curious, CMake adds a config script to `~/.cmake/packages` when building or; `$CMAKE_INSTALL_PREFIX/share/cmake/Modules` when installing a package that has export commands.). To repeat; using this in your own CMake project usually amounts to:. ```cmake; find_package(Minuit2); # OR; add_subdirectory(Minuit2). target_link_libraries(MyExeOrLib PUBLIC Minuit2::Minuit2); ```. You do not need to add include directories or anything else for Minuit2; the CMake target system handles all of this for you. ## Packaging. To build a binary package (add other generators with `-G`):; ```bash; make package; ```. [DEVELOP.md]: ./DEVELOP.md; [ROOT]: https://root.cern; [minuitdoc]: https://root.cern/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#minuit2-package; [CMake]: https://cmake.org; ",MatchSource.DOCS,math/minuit2/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/README.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:559,Availability,mask,mask,559,"# Architecture of the VecOps library. > This document is meant for ROOT developers, to quickly get their bearings around the VecOps library. The main type in the library is `RVec`. Besides `RVec`, the library only contains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1259,Availability,mask,mask,1259,"ontains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data member",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1064,Deployability,patch,patches,1064,"ontains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data member",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1563,Deployability,patch,patches,1563,"s; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyC",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:2130,Integrability,depend,depend,2130," version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1195,Modifiability,inherit,inheritance,1195,"ontains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data member",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:3005,Modifiability,inherit,inherited,3005,": LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec` the parts that are independent of; the small buffer size, to limit the amount of code generated and provide a way to slice the small buffer; size when passing around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorage",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:3397,Modifiability,inherit,inheritance,3397," returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec` the parts that are independent of; the small buffer size, to limit the amount of code generated and provide a way to slice the small buffer; size when passing around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorageSize`: calculates the size of the small buffer in `RVec`. ## Memory adoption. We need RVec to be able to act as a view over an existing buffer rather than use its own; to save copies and allocations when reading ROOT data into `RVec`s, e.g. in `RDataFrame`. The feature is exposed via a dedicated constructor: `RVec(pointer, size)`.; `RVec` then sw",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:485,Performance,optimiz,optimization,485,"# Architecture of the VecOps library. > This document is meant for ROOT developers, to quickly get their bearings around the VecOps library. The main type in the library is `RVec`. Besides `RVec`, the library only contains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1693,Performance,optimiz,optimization,1693,"s; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyC",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:2838,Performance,optimiz,optimized,2838,"ing conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec` the parts that are independent of; the small buffer size, to limit the amount of code generated and provide a way to slice the small buffer; size when passing around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: pr",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:2987,Performance,optimiz,optimizations,2987,": LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data members! We expect the memory after `SmallVectorBase` to be; occupied by the small inline buffer. `SmallVectorTemplateCommon<T>`; - `getFirstEl()`: returns the address of the beginning of the small buffer; - `begin()`, `end()`, `front()`, `back()`, etc. Basically the same as the corresponding LLVM class.; It contains the parts that are independent of whether T is a POD or not. `SmallVectorTemplateBase<T, bool TriviallyCopiable>` and the specialization `SmallVectorTemplateBase<T, true>`; - `grow()`, `uninitialized_copy`, `uninitialized_move`, `push_back()`, `pop_back()`. This class contains the parts of `RVec` that can be optimized for trivially copiable types.; In particular, destruction can be skipped and memcpy can be used in place of copy/move construction.; These optimizations are inherited from LLVM's SmallVector. `RVecImpl<T>`; The analogous of LLVM's `SmallVectorImpl`, it factors out of `RVec` the parts that are independent of; the small buffer size, to limit the amount of code generated and provide a way to slice the small buffer; size when passing around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorage",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:4498,Safety,safe,safety,4498,"ng around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorageSize`: calculates the size of the small buffer in `RVec`. ## Memory adoption. We need RVec to be able to act as a view over an existing buffer rather than use its own; to save copies and allocations when reading ROOT data into `RVec`s, e.g. in `RDataFrame`. The feature is exposed via a dedicated constructor: `RVec(pointer, size)`.; `RVec` then switches to its own storage as soon as a resize is requested.; `fCapacity == -1` indicates that we are in ""memory adoption mode"". ## Exception safety guarantees. As per [its docs](https://llvm.org/doxygen/classllvm_1_1SmallVector.html), LLVM's; `SmallVector` implementation ""does not attempt to be exception-safe"".; In its current implementation, `RVec` does not attempt to fix that.; This should not be a problem for `RVec`'s usecases (an exception thrown during; construction of an `RVec` typically means there is a bug to fix in the analysis code),; and we expect to be able to revisit the implementation and fix broken behavior if it; ever turns out to be problematic. Relevant discussion on GitHub:. - https://github.com/root-project/root/pull/7502#issuecomment-818864506; - https://github.com/root-project/root/pull/7502#issuecomment-818905333; - https://github.com/root-project/root/pull/7502#issuecomment-821054757. ",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:4663,Safety,safe,safe,4663,"ng around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorageSize`: calculates the size of the small buffer in `RVec`. ## Memory adoption. We need RVec to be able to act as a view over an existing buffer rather than use its own; to save copies and allocations when reading ROOT data into `RVec`s, e.g. in `RDataFrame`. The feature is exposed via a dedicated constructor: `RVec(pointer, size)`.; `RVec` then switches to its own storage as soon as a resize is requested.; `fCapacity == -1` indicates that we are in ""memory adoption mode"". ## Exception safety guarantees. As per [its docs](https://llvm.org/doxygen/classllvm_1_1SmallVector.html), LLVM's; `SmallVector` implementation ""does not attempt to be exception-safe"".; In its current implementation, `RVec` does not attempt to fix that.; This should not be a problem for `RVec`'s usecases (an exception thrown during; construction of an `RVec` typically means there is a bug to fix in the analysis code),; and we expect to be able to revisit the implementation and fix broken behavior if it; ever turns out to be problematic. Relevant discussion on GitHub:. - https://github.com/root-project/root/pull/7502#issuecomment-818864506; - https://github.com/root-project/root/pull/7502#issuecomment-818905333; - https://github.com/root-project/root/pull/7502#issuecomment-821054757. ",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:4282,Security,expose,exposed,4282,"ng around `RVec` objects. `RVecN<T, N>`; It aggregates `RVecImpl` and `SmallVectorStorage` (see below) through public inheritance.; `N` is the small buffer size. `RVec<T>`; Inherits from `RVecN` and fixes the small buffer size `N` to a reasonable default.; We expect most users to use this type and only very rarely switch to `RVecN` to tweak the small buffer size. ### Helper types. - `SmallVectorAlignmentAndSize`: used to figure out the offset of the first small-buffer element in; `SmallVectorTemplateCommon::getFirstEl`; - `SmallVectorStorage`: properly aligned ""small buffer"" storage. It's a separate type so that it can be specialized to; be properly aligned also for the case of small buffer size = 0; - `RVecInlineStorageSize`: calculates the size of the small buffer in `RVec`. ## Memory adoption. We need RVec to be able to act as a view over an existing buffer rather than use its own; to save copies and allocations when reading ROOT data into `RVec`s, e.g. in `RDataFrame`. The feature is exposed via a dedicated constructor: `RVec(pointer, size)`.; `RVec` then switches to its own storage as soon as a resize is requested.; `fCapacity == -1` indicates that we are in ""memory adoption mode"". ## Exception safety guarantees. As per [its docs](https://llvm.org/doxygen/classllvm_1_1SmallVector.html), LLVM's; `SmallVector` implementation ""does not attempt to be exception-safe"".; In its current implementation, `RVec` does not attempt to fix that.; This should not be a problem for `RVec`'s usecases (an exception thrown during; construction of an `RVec` typically means there is a bug to fix in the analysis code),; and we expect to be able to revisit the implementation and fix broken behavior if it; ever turns out to be problematic. Relevant discussion on GitHub:. - https://github.com/root-project/root/pull/7502#issuecomment-818864506; - https://github.com/root-project/root/pull/7502#issuecomment-818905333; - https://github.com/root-project/root/pull/7502#issuecomment-821054757. ",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md:1380,Testability,log,logical,1380,"ontains helper types and functions. `RVec` is a vector type that tries to be as `std::vector`-like as possible while adding a; few important features, namely:; - the ability to act as a view over an existing memory buffer (see ""Memory adoption"" below); - a small-buffer optimization; - vectorized operator overloads; - a vectorized `operator[](mask)` to allow quick element selection together with vectorized operators; (e.g. `etas[etas > k]` returns a new `RVec` with all elements greater than `k`); - helper functions such as `InvariantMass`, `DeltaR`, `Argsort` are also provided. The current implementation of `RVec` is based on LLVM's SmallVector, extracted; from the head of LLVM's repo around December 2020.; We are not tracking the upstream implementation. Compared to LLVM's SmallVectors:. - memory adoption capabilities have been added; - patches have been applied to make RVec work with (ROOT's version of) cppyy (notably `using` declarations had to be; lowered in the inheritance hierarchy for cppyy to pick them up); - `operator[](mask)` has been added, as well as several other ""numpy-like"" helper; functions (these latter ones are free functions); - logical operators `==`, `<`, `>` etc. return vectors rather than booleans; - the type of fSize and fCapacity is signed rather than unsigned, and fixed to 32 bits; - a number of minor patches have been applied for backward compatibility with the previous; implementation of RVec (which did not have a small buffer optimization and was implemented; in terms of `std::vector` with a custom allocator) and to make the code more consistent; with ROOT's coding conventions. ## RVec design. `SmallVectorBase`; - `fBeginX`; - `fSize`; - `fCapacity`. Basically the same as the corresponding LLVM class, with the template parameter removed: LLVM's SmallVectorBase; is templated over the type of fSize and fCapacity. It contains the parts of `RVec` that do not depend on the value; type.; No other classes in the hierarchy can contain data member",MatchSource.DOCS,math/vecops/ARCHITECTURE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/vecops/ARCHITECTURE.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md:291,Deployability,patch,patched,291,## Math Libraries. ### Minuit2. - Remove the TFitterMinuit class and the similar ones used to implement the `TVirtualFitter` interface using Minuit2. users should switch to use the; `ROOT::Math::Minimizer` interface. All other changes in the Math packages have been applied also in the 5.34 patched versions of ROOT. See their release notes for the detailed list of applied improvements. ,MatchSource.DOCS,math/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md:327,Deployability,release,release,327,## Math Libraries. ### Minuit2. - Remove the TFitterMinuit class and the similar ones used to implement the `TVirtualFitter` interface using Minuit2. users should switch to use the; `ROOT::Math::Minimizer` interface. All other changes in the Math packages have been applied also in the 5.34 patched versions of ROOT. See their release notes for the detailed list of applied improvements. ,MatchSource.DOCS,math/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md:125,Integrability,interface,interface,125,## Math Libraries. ### Minuit2. - Remove the TFitterMinuit class and the similar ones used to implement the `TVirtualFitter` interface using Minuit2. users should switch to use the; `ROOT::Math::Minimizer` interface. All other changes in the Math packages have been applied also in the 5.34 patched versions of ROOT. See their release notes for the detailed list of applied improvements. ,MatchSource.DOCS,math/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md:206,Integrability,interface,interface,206,## Math Libraries. ### Minuit2. - Remove the TFitterMinuit class and the similar ones used to implement the `TVirtualFitter` interface using Minuit2. users should switch to use the; `ROOT::Math::Minimizer` interface. All other changes in the Math packages have been applied also in the 5.34 patched versions of ROOT. See their release notes for the detailed list of applied improvements. ,MatchSource.DOCS,math/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:2912,Availability,avail,available,2912,"hi)</em> ;; * **3D coordinate system** classes:; * ROOT::Math::Cartesian3D, based on <em>(x,y,z)</em>;; * ROOT::Math::Polar3D, based on <em>(r, theta, phi)</em>;; * ROOT::Math::Cylindrical3D, based on <em>(rho, z, phi)</em>; * ROOT::Math::CylindricalEta3D, based on <em>(rho, eta, phi)</em>;; * **4D coordinate system** classes:; * ROOT::Math::PxPyPzE4D, based on based on <em>(px,py,pz,E)</em>;; * ROOT::Math::PxPyPzM4D, based on based on <em>(px,py,pz,M)</em>;; * ROOT::Math::PtEtaPhiE4D, based on based on <em>(pt,eta,phi,E)</em>;; * ROOT::Math::PtEtaPhiM4D, based on based on <em>(pt,eta,phi,M)</em>;. The angle _theta_ is defined between [0,\f$\pi\f$] and _phi_ between [-\f$\pi\f$,\f$\pi\f$].; The angles are expressed in radians.; The _eta_ component is known as [pseudo-rapidity](https://en.wikipedia.org/wiki/Pseudorapidity). Users can define the Vectors according to the coordinate type which; is most efficient for their use. Transformations between the various coordinate; systems are available through copy constructors or the assignment `operator =`.; The coordinate system classes are templated on the scalar type for maximum flexibility,; and to minimize memory usage for some use cases. ### Coordinate System Tag. The 2D and 3D point and vector classes can be associated to a tag defining the; coordinate system. This can be used to distinguish between vectors of different; coordinate systems like global or local vectors. The coordinate system tag is a; template parameter of the ROOT::Math::DisplacementVector3D; (and ROOT::Math::DisplacementVector2D) and ROOT::Math::PositionVector3D; (and ROOT::Math::PositionVector2D) classes. A default tag,; ROOT::Math::DefaultCoordinateSystemTag, exists for users who don't need this; functionality. \anchor GenVectorTypedefs; ## Concrete Vector typedefs. To avoid exposing templated parameters to the users, typedefs are defined for all types of vectors based an `double`s and `float`s.; The table below lists the `double` versions; the `fl",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:7566,Availability,error,errors,7566,"using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between vector classes, even of different; coordinate system types:. ~~~{.cpp}; v1 += v2;; v1 -= v2;; v1 = - v2;; v1 *= a;; v1 /= a;; v2 = a * v1;; v2 = v1 / a;; v2 = v1 * a;; v3 = v1 + v2;; v3 = v1 - v2;; ~~~. Note that the multiplication between two vectors using the `operator *` is not supported; because it is ambiguous. ### Other Methods. The vector classes support methods for:. - computation of the dot product via Dot(),; - computation of the cross product via Cross(),; - construction of a unit vector via Unit(). \anchor GenVectorTransformations; ## Transformations. The transformations are modeled using simple (non-template) classes, using `double` as; the scalar type to avoid too large numerical errors. The transformations are grouped; in Rotations (in 3 dimensions), Lorentz transformations. Each group has several members which may; model physically equivalent transformations but with different internal representations.; Transformation classes can operate on all type of vectors using the `operator()`; or the `operator *` and the transformations can also be combined via the `operator *`.; In more detail the transformations available are:. ### 3D Rotations. * ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:8001,Availability,avail,available,8001,"2 = a * v1;; v2 = v1 / a;; v2 = v1 * a;; v3 = v1 + v2;; v3 = v1 - v2;; ~~~. Note that the multiplication between two vectors using the `operator *` is not supported; because it is ambiguous. ### Other Methods. The vector classes support methods for:. - computation of the dot product via Dot(),; - computation of the cross product via Cross(),; - construction of a unit vector via Unit(). \anchor GenVectorTransformations; ## Transformations. The transformations are modeled using simple (non-template) classes, using `double` as; the scalar type to avoid too large numerical errors. The transformations are grouped; in Rotations (in 3 dimensions), Lorentz transformations. Each group has several members which may; model physically equivalent transformations but with different internal representations.; Transformation classes can operate on all type of vectors using the `operator()`; or the `operator *` and the transformations can also be combined via the `operator *`.; In more detail the transformations available are:. ### 3D Rotations. * ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described by a vector (axis) and an angle; * ROOT::Math::Quaternion, rotation described by a quaternion (4 numbers); * ROOT::Math::RotationX, specialized rotation along the X axis; * ROOT::Math::RotationY, specialized rotation along the Y axis; * ROOT::Math::RotationZ, specialized rotation along the Z axis. ### 3D Transformation. * ROOT::Math::Translation3D, (only translation) described by a 3D vector; * ROOT::Math::Transform3D, (rotations and then translation) described by a 3x4 matrix (12 ",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:9963,Availability,avail,available,9963,"* ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described by a vector (axis) and an angle; * ROOT::Math::Quaternion, rotation described by a quaternion (4 numbers); * ROOT::Math::RotationX, specialized rotation along the X axis; * ROOT::Math::RotationY, specialized rotation along the Y axis; * ROOT::Math::RotationZ, specialized rotation along the Z axis. ### 3D Transformation. * ROOT::Math::Translation3D, (only translation) described by a 3D vector; * ROOT::Math::Transform3D, (rotations and then translation) described by a 3x4 matrix (12 numbers). ### Lorentz Rotation. * ROOT::Math::LorentzRotation , 4D rotation (3D rotation plus a boost) described by a 4x4 matrix; * ROOT::Math::Boost, a Lorentz boost in an arbitrary direction and described by a 4x4 symmetric matrix (10 numbers); * ROOT::Math::BoostX, a boost in the X axis direction; * ROOT::Math::BoostY, a boost in the Y axis direction; * ROOT::Math::BoostZ, a boost in the Z axis direction. ## Compatibility with CLHEP Vector classes. For compatibility with CLHEP, the vector classes can be constructed easily; from a CLHEP `Hep3Vector` or `HepLorentzVector`, by using a template constructor, which; requires only that the classes implement the accessors `x()`, `y()` and `z()` (and `t()`; for `HepLorentzVector`).; The vector classes also provide member function with the same naming convention; as CLHEP for the most used functions like `x()`, `y()` and `z()`. ## Additional Documentation. A more detailed description of all the GenVector classes is available in this [document](https://root.cern/topical/GenVector.pdf).; ",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:2827,Energy Efficiency,efficient,efficient,2827," system** classes:; * ROOT::Math::Cartesian2D, based on <em>(x,y)</em> ;; * ROOT::Math::Polar2D, based on <em>(r, phi)</em> ;; * **3D coordinate system** classes:; * ROOT::Math::Cartesian3D, based on <em>(x,y,z)</em>;; * ROOT::Math::Polar3D, based on <em>(r, theta, phi)</em>;; * ROOT::Math::Cylindrical3D, based on <em>(rho, z, phi)</em>; * ROOT::Math::CylindricalEta3D, based on <em>(rho, eta, phi)</em>;; * **4D coordinate system** classes:; * ROOT::Math::PxPyPzE4D, based on based on <em>(px,py,pz,E)</em>;; * ROOT::Math::PxPyPzM4D, based on based on <em>(px,py,pz,M)</em>;; * ROOT::Math::PtEtaPhiE4D, based on based on <em>(pt,eta,phi,E)</em>;; * ROOT::Math::PtEtaPhiM4D, based on based on <em>(pt,eta,phi,M)</em>;. The angle _theta_ is defined between [0,\f$\pi\f$] and _phi_ between [-\f$\pi\f$,\f$\pi\f$].; The angles are expressed in radians.; The _eta_ component is known as [pseudo-rapidity](https://en.wikipedia.org/wiki/Pseudorapidity). Users can define the Vectors according to the coordinate type which; is most efficient for their use. Transformations between the various coordinate; systems are available through copy constructors or the assignment `operator =`.; The coordinate system classes are templated on the scalar type for maximum flexibility,; and to minimize memory usage for some use cases. ### Coordinate System Tag. The 2D and 3D point and vector classes can be associated to a tag defining the; coordinate system. This can be used to distinguish between vectors of different; coordinate systems like global or local vectors. The coordinate system tag is a; template parameter of the ROOT::Math::DisplacementVector3D; (and ROOT::Math::DisplacementVector2D) and ROOT::Math::PositionVector3D; (and ROOT::Math::PositionVector2D) classes. A default tag,; ROOT::Math::DefaultCoordinateSystemTag, exists for users who don't need this; functionality. \anchor GenVectorTypedefs; ## Concrete Vector typedefs. To avoid exposing templated parameters to the users, typedefs are defi",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:6048,Energy Efficiency,energy,energy,6048,"oint point based on rho,z,phi coordinates (cylindrical using z); * ROOT::Math::RhoEtaPhiPoint point based on rho,eta,phi coordinates (cylindrical using eta instead of z). ### Vector3D. Type definitions for vectors in three dimensions, based on ROOT::Math::DisplacementVector3D, are defined by `Math/Vector3D.h`:. * ROOT::Math::XYZVector vector based on x,y,z coordinates (cartesian); * ROOT::Math::Polar3DVector vector based on r,theta,phi coordinates (polar); * ROOT::Math::RhoZPhiVector vector based on rho, z,phi coordinates (cylindrical); * ROOT::Math::RhoEtaPhiVector vector based on rho,eta,phi coordinates (cylindrical using eta instead of z). ### LorentzVector. Type definitions for Lorentz vectors in four dimensions, based on ROOT::Math::LorentzVector, are defined by `Math/Vector4D.h`:. * ROOT::Math::XYZTVector vector based on x,y,z,t coordinates (cartesian); * ROOT::Math::PtEtaPhiEVector vector based on pt (rho),eta,phi and E (t) coordinates; * ROOT::Math::PtEtaPhiMVector vector based on pt (rho),eta,phi and M (t) coordinates; * ROOT::Math::PxPyPzMVector vector based on px,py,pz and M (mass) coordinates; * ROOT::Math::PxPyPzEVector vector based on px,py,pz and E (energy) coordinates. The metric used for any such LorentzVector is (-,-,-,+). \anchor GenVectorOperations; ## Operations. ### Constructors and Assignment. A vector can be constructed from its coordinate representation:. ~~~{.cpp}; ROOT::Math::PtEtaPhiMVector v1(10. /*pt*/, 0.1 /*eta*/, 0.24 /*phi*/, 5 /*M*/);; ~~~. In addition, the vector classes can be constructed from any object that implements the; accessors x(), y() and z(). This can be a vector using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between ve",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:3733,Safety,avoid,avoid,3733," coordinate type which; is most efficient for their use. Transformations between the various coordinate; systems are available through copy constructors or the assignment `operator =`.; The coordinate system classes are templated on the scalar type for maximum flexibility,; and to minimize memory usage for some use cases. ### Coordinate System Tag. The 2D and 3D point and vector classes can be associated to a tag defining the; coordinate system. This can be used to distinguish between vectors of different; coordinate systems like global or local vectors. The coordinate system tag is a; template parameter of the ROOT::Math::DisplacementVector3D; (and ROOT::Math::DisplacementVector2D) and ROOT::Math::PositionVector3D; (and ROOT::Math::PositionVector2D) classes. A default tag,; ROOT::Math::DefaultCoordinateSystemTag, exists for users who don't need this; functionality. \anchor GenVectorTypedefs; ## Concrete Vector typedefs. To avoid exposing templated parameters to the users, typedefs are defined for all types of vectors based an `double`s and `float`s.; The table below lists the `double` versions; the `float` counterpart ends on an extra `F`, such as ROOT::Math::XYPointF instead of ROOT::Math::XYPoint. ### Point2D. Type definitions for points in two dimensions, based on ROOT::Math::PositionVector2D, are defined by `Math/Point2D.h`:. * ROOT::Math::XYPoint vector based on x,y coordinates (cartesian); * ROOT::Math::Polar2DPoint vector based on r,phi coordinates (polar). ### Vector2D. Type definitions for vectors in two dimensions, based on ROOT::Math::DisplacementVector2D, are defined by `Math/Vector2D.h`:. * ROOT::Math::XYVector vector based on x,y coordinates (cartesian); * ROOT::Math::Polar2DVector vector based on r,phi coordinates (polar). ### Point3D. Type definitions for points in three dimensions, based on ROOT::Math::PositionVector3D, are defined by `Math/Point3D.h`:. * ROOT::Math::XYZPoint point based on x,y,z coordinates (cartesian); * ROOT::Math::Polar3DPoint ",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:7540,Safety,avoid,avoid,7540,"using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between vector classes, even of different; coordinate system types:. ~~~{.cpp}; v1 += v2;; v1 -= v2;; v1 = - v2;; v1 *= a;; v1 /= a;; v2 = a * v1;; v2 = v1 / a;; v2 = v1 * a;; v3 = v1 + v2;; v3 = v1 - v2;; ~~~. Note that the multiplication between two vectors using the `operator *` is not supported; because it is ambiguous. ### Other Methods. The vector classes support methods for:. - computation of the dot product via Dot(),; - computation of the cross product via Cross(),; - construction of a unit vector via Unit(). \anchor GenVectorTransformations; ## Transformations. The transformations are modeled using simple (non-template) classes, using `double` as; the scalar type to avoid too large numerical errors. The transformations are grouped; in Rotations (in 3 dimensions), Lorentz transformations. Each group has several members which may; model physically equivalent transformations but with different internal representations.; Transformation classes can operate on all type of vectors using the `operator()`; or the `operator *` and the transformations can also be combined via the `operator *`.; In more detail the transformations available are:. ### 3D Rotations. * ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:6453,Security,access,accessors,6453,"RhoEtaPhiVector vector based on rho,eta,phi coordinates (cylindrical using eta instead of z). ### LorentzVector. Type definitions for Lorentz vectors in four dimensions, based on ROOT::Math::LorentzVector, are defined by `Math/Vector4D.h`:. * ROOT::Math::XYZTVector vector based on x,y,z,t coordinates (cartesian); * ROOT::Math::PtEtaPhiEVector vector based on pt (rho),eta,phi and E (t) coordinates; * ROOT::Math::PtEtaPhiMVector vector based on pt (rho),eta,phi and M (t) coordinates; * ROOT::Math::PxPyPzMVector vector based on px,py,pz and M (mass) coordinates; * ROOT::Math::PxPyPzEVector vector based on px,py,pz and E (energy) coordinates. The metric used for any such LorentzVector is (-,-,-,+). \anchor GenVectorOperations; ## Operations. ### Constructors and Assignment. A vector can be constructed from its coordinate representation:. ~~~{.cpp}; ROOT::Math::PtEtaPhiMVector v1(10. /*pt*/, 0.1 /*eta*/, 0.24 /*phi*/, 5 /*M*/);; ~~~. In addition, the vector classes can be constructed from any object that implements the; accessors x(), y() and z(). This can be a vector using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between vector classes, even of different; coordinate system types:. ~~~{.cpp}; v1 += v2;; v1 -= v2;; v1 = - v2;; v1 *= a;; v1 /= a;; v2 = a * v1;; v2 = v1 / a;; v2 = v1 * a;; v3 = v1 + v2;; v3 = v1 - v2;; ~~~. Note that the multiplication between two vectors using the `operator *` is not supported; because it is ambiguous. ### Other Methods. The vector classes support methods for:. - computation of the dot product via Dot(),; - computation of the cross product via Cross(),; - construction of a unit vector via Unit(). \anchor GenVectorTransformations; ## Transf",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:9656,Security,access,accessors,9656,"* ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described by a vector (axis) and an angle; * ROOT::Math::Quaternion, rotation described by a quaternion (4 numbers); * ROOT::Math::RotationX, specialized rotation along the X axis; * ROOT::Math::RotationY, specialized rotation along the Y axis; * ROOT::Math::RotationZ, specialized rotation along the Z axis. ### 3D Transformation. * ROOT::Math::Translation3D, (only translation) described by a 3D vector; * ROOT::Math::Transform3D, (rotations and then translation) described by a 3x4 matrix (12 numbers). ### Lorentz Rotation. * ROOT::Math::LorentzRotation , 4D rotation (3D rotation plus a boost) described by a 4x4 matrix; * ROOT::Math::Boost, a Lorentz boost in an arbitrary direction and described by a 4x4 symmetric matrix (10 numbers); * ROOT::Math::BoostX, a boost in the X axis direction; * ROOT::Math::BoostY, a boost in the Y axis direction; * ROOT::Math::BoostZ, a boost in the Z axis direction. ## Compatibility with CLHEP Vector classes. For compatibility with CLHEP, the vector classes can be constructed easily; from a CLHEP `Hep3Vector` or `HepLorentzVector`, by using a template constructor, which; requires only that the classes implement the accessors `x()`, `y()` and `z()` (and `t()`; for `HepLorentzVector`).; The vector classes also provide member function with the same naming convention; as CLHEP for the most used functions like `x()`, `y()` and `z()`. ## Additional Documentation. A more detailed description of all the GenVector classes is available in this [document](https://root.cern/topical/GenVector.pdf).; ",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md:7471,Usability,simpl,simple,7471,"using a different coordinate; system, or even an object from a different package as long as it implements the required signatures.; One such vector type is CLHEP's `Hep3Vector`:. ~~~{.cpp}; XYZVector v1(1,2,3);; RhoEtaPhiVector r2(v1);; CLHEP::Hep3Vector q(1,2,3);; XYZVector v3(q); ~~~. ### Arithmetic Operations. The following operations are possible between vector classes, even of different; coordinate system types:. ~~~{.cpp}; v1 += v2;; v1 -= v2;; v1 = - v2;; v1 *= a;; v1 /= a;; v2 = a * v1;; v2 = v1 / a;; v2 = v1 * a;; v3 = v1 + v2;; v3 = v1 - v2;; ~~~. Note that the multiplication between two vectors using the `operator *` is not supported; because it is ambiguous. ### Other Methods. The vector classes support methods for:. - computation of the dot product via Dot(),; - computation of the cross product via Cross(),; - construction of a unit vector via Unit(). \anchor GenVectorTransformations; ## Transformations. The transformations are modeled using simple (non-template) classes, using `double` as; the scalar type to avoid too large numerical errors. The transformations are grouped; in Rotations (in 3 dimensions), Lorentz transformations. Each group has several members which may; model physically equivalent transformations but with different internal representations.; Transformation classes can operate on all type of vectors using the `operator()`; or the `operator *` and the transformations can also be combined via the `operator *`.; In more detail the transformations available are:. ### 3D Rotations. * ROOT::Math::Rotation3D, rotation described by a 3x3 matrix of doubles; * ROOT::Math::EulerAngles rotation described by the three Euler angles (phi, theta and psi) following the GoldStein [definition](http://mathworld.wolfram.com/EulerAngles.html).; * ROOT::Math::RotationZYX rotation described by three angles defining a rotation first along the Z axis, then along the rotated Y' axis and then along the rotated X'' axis.; * ROOT::Math::AxisAngle, rotation described",MatchSource.DOCS,math/genvector/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/genvector/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md:532,Availability,error,error,532,"\defgroup MathCore MathCore; \ingroup Math; \brief The Core Mathematical Library of %ROOT. **MathCore** provides a collection of functions and C++ classes for HEP numerical computing.; This library provides only the basic mathematical functions and algorithms and not all the; functionality required by the HEP community. More advanced mathematical functionalities is; provided by the \ref MathMore. The current set includes classes and functions for:. * \ref SpecFunc ""Basic special functions"" used in HEP like the gamma, beta and error function;; * \ref StatFunc : mathematical functions used in statistics, such as the probability density; functions and the cumulative distributions functions (lower and upper integral of the pdf's); for continuous and discrete distributions.;; * \ref CppFunctions :; * \ref GenFunc, including helper class to wrap free (static) and non-static member functions; * \ref ParamFunc; * Numerical algorithms: user classes with (in some cases) basic implementations for:; * \ref Integration; * \ref Deriv; * \ref RootFinders; * \ref Min1D and \ref MultiMin; * \ref Fit :classes for fitting and parameter estimation from a given data set. Note that in this latest release the \ref GenVector ""GenVector"" (physics and geometry vectors; for 2,3 and 4 dimensions with their transformations) is not anymore part of MathCore, but is; built as a separate library. MathCore contains instead now classes which were originally part; of _libCore_. These include:. * **TMath** : namespace with mathematical functions and basic function algorithms.; * **TComplex**: class for complex numbers.; * Random classes: base class **TRandom** and the derived classes TRandom1, TRandom2 and; TRandom3, implementing the pseudo-random number generators.; * Other classes, such as; * TKDTree for partitioning the data using a kd-Tree and TKDTreeBinning for binning data using a kdTree; * ROOT::Math::GoFTest for goodness of fit tests; ",MatchSource.DOCS,math/mathcore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md:741,Deployability,continuous,continuous,741,"\defgroup MathCore MathCore; \ingroup Math; \brief The Core Mathematical Library of %ROOT. **MathCore** provides a collection of functions and C++ classes for HEP numerical computing.; This library provides only the basic mathematical functions and algorithms and not all the; functionality required by the HEP community. More advanced mathematical functionalities is; provided by the \ref MathMore. The current set includes classes and functions for:. * \ref SpecFunc ""Basic special functions"" used in HEP like the gamma, beta and error function;; * \ref StatFunc : mathematical functions used in statistics, such as the probability density; functions and the cumulative distributions functions (lower and upper integral of the pdf's); for continuous and discrete distributions.;; * \ref CppFunctions :; * \ref GenFunc, including helper class to wrap free (static) and non-static member functions; * \ref ParamFunc; * Numerical algorithms: user classes with (in some cases) basic implementations for:; * \ref Integration; * \ref Deriv; * \ref RootFinders; * \ref Min1D and \ref MultiMin; * \ref Fit :classes for fitting and parameter estimation from a given data set. Note that in this latest release the \ref GenVector ""GenVector"" (physics and geometry vectors; for 2,3 and 4 dimensions with their transformations) is not anymore part of MathCore, but is; built as a separate library. MathCore contains instead now classes which were originally part; of _libCore_. These include:. * **TMath** : namespace with mathematical functions and basic function algorithms.; * **TComplex**: class for complex numbers.; * Random classes: base class **TRandom** and the derived classes TRandom1, TRandom2 and; TRandom3, implementing the pseudo-random number generators.; * Other classes, such as; * TKDTree for partitioning the data using a kd-Tree and TKDTreeBinning for binning data using a kdTree; * ROOT::Math::GoFTest for goodness of fit tests; ",MatchSource.DOCS,math/mathcore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md:1194,Deployability,release,release,1194,"\defgroup MathCore MathCore; \ingroup Math; \brief The Core Mathematical Library of %ROOT. **MathCore** provides a collection of functions and C++ classes for HEP numerical computing.; This library provides only the basic mathematical functions and algorithms and not all the; functionality required by the HEP community. More advanced mathematical functionalities is; provided by the \ref MathMore. The current set includes classes and functions for:. * \ref SpecFunc ""Basic special functions"" used in HEP like the gamma, beta and error function;; * \ref StatFunc : mathematical functions used in statistics, such as the probability density; functions and the cumulative distributions functions (lower and upper integral of the pdf's); for continuous and discrete distributions.;; * \ref CppFunctions :; * \ref GenFunc, including helper class to wrap free (static) and non-static member functions; * \ref ParamFunc; * Numerical algorithms: user classes with (in some cases) basic implementations for:; * \ref Integration; * \ref Deriv; * \ref RootFinders; * \ref Min1D and \ref MultiMin; * \ref Fit :classes for fitting and parameter estimation from a given data set. Note that in this latest release the \ref GenVector ""GenVector"" (physics and geometry vectors; for 2,3 and 4 dimensions with their transformations) is not anymore part of MathCore, but is; built as a separate library. MathCore contains instead now classes which were originally part; of _libCore_. These include:. * **TMath** : namespace with mathematical functions and basic function algorithms.; * **TComplex**: class for complex numbers.; * Random classes: base class **TRandom** and the derived classes TRandom1, TRandom2 and; TRandom3, implementing the pseudo-random number generators.; * Other classes, such as; * TKDTree for partitioning the data using a kd-Tree and TKDTreeBinning for binning data using a kdTree; * ROOT::Math::GoFTest for goodness of fit tests; ",MatchSource.DOCS,math/mathcore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md:847,Integrability,wrap,wrap,847,"\defgroup MathCore MathCore; \ingroup Math; \brief The Core Mathematical Library of %ROOT. **MathCore** provides a collection of functions and C++ classes for HEP numerical computing.; This library provides only the basic mathematical functions and algorithms and not all the; functionality required by the HEP community. More advanced mathematical functionalities is; provided by the \ref MathMore. The current set includes classes and functions for:. * \ref SpecFunc ""Basic special functions"" used in HEP like the gamma, beta and error function;; * \ref StatFunc : mathematical functions used in statistics, such as the probability density; functions and the cumulative distributions functions (lower and upper integral of the pdf's); for continuous and discrete distributions.;; * \ref CppFunctions :; * \ref GenFunc, including helper class to wrap free (static) and non-static member functions; * \ref ParamFunc; * Numerical algorithms: user classes with (in some cases) basic implementations for:; * \ref Integration; * \ref Deriv; * \ref RootFinders; * \ref Min1D and \ref MultiMin; * \ref Fit :classes for fitting and parameter estimation from a given data set. Note that in this latest release the \ref GenVector ""GenVector"" (physics and geometry vectors; for 2,3 and 4 dimensions with their transformations) is not anymore part of MathCore, but is; built as a separate library. MathCore contains instead now classes which were originally part; of _libCore_. These include:. * **TMath** : namespace with mathematical functions and basic function algorithms.; * **TComplex**: class for complex numbers.; * Random classes: base class **TRandom** and the derived classes TRandom1, TRandom2 and; TRandom3, implementing the pseudo-random number generators.; * Other classes, such as; * TKDTree for partitioning the data using a kd-Tree and TKDTreeBinning for binning data using a kdTree; * ROOT::Math::GoFTest for goodness of fit tests; ",MatchSource.DOCS,math/mathcore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md:1933,Testability,test,tests,1933,"\defgroup MathCore MathCore; \ingroup Math; \brief The Core Mathematical Library of %ROOT. **MathCore** provides a collection of functions and C++ classes for HEP numerical computing.; This library provides only the basic mathematical functions and algorithms and not all the; functionality required by the HEP community. More advanced mathematical functionalities is; provided by the \ref MathMore. The current set includes classes and functions for:. * \ref SpecFunc ""Basic special functions"" used in HEP like the gamma, beta and error function;; * \ref StatFunc : mathematical functions used in statistics, such as the probability density; functions and the cumulative distributions functions (lower and upper integral of the pdf's); for continuous and discrete distributions.;; * \ref CppFunctions :; * \ref GenFunc, including helper class to wrap free (static) and non-static member functions; * \ref ParamFunc; * Numerical algorithms: user classes with (in some cases) basic implementations for:; * \ref Integration; * \ref Deriv; * \ref RootFinders; * \ref Min1D and \ref MultiMin; * \ref Fit :classes for fitting and parameter estimation from a given data set. Note that in this latest release the \ref GenVector ""GenVector"" (physics and geometry vectors; for 2,3 and 4 dimensions with their transformations) is not anymore part of MathCore, but is; built as a separate library. MathCore contains instead now classes which were originally part; of _libCore_. These include:. * **TMath** : namespace with mathematical functions and basic function algorithms.; * **TComplex**: class for complex numbers.; * Random classes: base class **TRandom** and the derived classes TRandom1, TRandom2 and; TRandom3, implementing the pseudo-random number generators.; * Other classes, such as; * TKDTree for partitioning the data using a kd-Tree and TKDTreeBinning for binning data using a kdTree; * ROOT::Math::GoFTest for goodness of fit tests; ",MatchSource.DOCS,math/mathcore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathcore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1430,Availability,down,downloaded,1430," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1498,Availability,down,downloading,1498," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1660,Availability,down,downloaded,1660," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1318,Deployability,install,installed,1318," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1186,Integrability,wrap,wrapping,1186,"classes for HEP numerical; computing. This is an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distr",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md:1943,Modifiability,config,configure,1943," an extension of the functionality provided by the \ref MathCore. The; current set includes classes and functions for:. * \ref SpecFunc, with all the major functions (Bessel functions, Legendre polynomial, etc..); * \ref StatFunc, Mathematical functions used in statistics such as probability density; functions, cumulative distributions functions and their inverse (quantiles).; * Numerical algorithms:; * \ref Integration; * \ref MCIntegration; * \ref Deriv; * \ref RootFinders; * \ref Min1D; * \ref MultiMin; * \ref Interpolation; * \ref FuncApprox, based on Chebyshev polynomials; * \ref Random. The mathematical functions are implemented as a set of free functions in the namespace \em; ROOT::Math. The naming used for the special functions is the same proposed for the C++; standard (see C++ standard extension [proposal document](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1687.pdf)).; The MathMore library is implemented wrapping in C++ the GNU Scientific Library; ([GSL](http://www.gnu.org/software/gsl)). To build MathMore you need to have first GSL; installed somewhere in your system. A version of GSL larger or equal 1.8 is required. A tar; file of GSL can be downloaded from the [GSL Web site](http://www.gnu.org/software/gsl/#downloading),; or (for version 1.8) from [here](http://seal.web.cern.ch/seal/MathLibs/gsl-1.8.tar.gz).; Windows binaries, compiled using Visual Studio 7.1 can be downloaded from; [this location](http://seal.web.cern.ch/seal/MathLibs/GSL-1.8.zip). MathMore (and its %ROOT CINT dictionary) can be built within %ROOT whenever a GSL library; is found in the system. Optionally the GSL library and header file location can be specified; in the %ROOT configure script with _configure --with-gsl-incdir=... --with-gsl-libdir=..._; MathMore links with the GSL static libraries. On some platform (like Linux x86-64) GSL; needs to be compiled with the option _--with-pic_.; The source code of MathMore is distributed under the GNU General Public License; ",MatchSource.DOCS,math/mathmore/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/mathmore/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:1060,Availability,avail,available,1060," %ROOT Matrix Linear Algebra package. The %ROOT linear algebra package provides a complete environment in %ROOT to perform matrix; calculations such as matrix-vector and matrix-matrix multiplications and other linear; algebra calculations like equation solving and eigenvalue decompositions. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. ### Matrix classes. %ROOT provides the following matrix classes, among others:. - `TMatrixDBase`. - `TMatrixF`. - `TMatrixFSym`. - `TVectorF`. - `TMatrixD`. - `TMatrixDSym`. - `TMatrixDSparse`. - `TDecompBase`. - `TDecompChol`. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify arbitrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). #### Matrix properties. A matrix has five properties, which are all set in the constructor:. - `precision` <br>; If the `precision` is float (i.e. single precision), use the `TMatrixF` class family. If th",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:3373,Availability,toler,tolerance,3373,"0. - `sparse map`<br>; Only relevant for a sparse matrix. It indicates where elements are unequal 0. #### Accessing matrix properties. Use one of the following methods to access the information about the relevant matrix property:. - `Int_t GetRowLwb()`: Row lower-bound index. - `Int_t GetRowUpb()`: Row upper-bound index. - `Int_t GetNrows()`: Number of rows. - `Int_t GetColLwb()`: Column lower-bound index. - `Int_t GetColUpb()`: Column upper-bound index. - `Int_t GetNcols()`: Number of columns. - `Int_t GetNoElements()`: Number of elements, for a dense matrix this equals: `fNrows x fNcols`. - `Double_t GetTol()`: Tolerance number that is used in decomposition operations. - `Int_t *GetRowIndexArray()`: For sparse matrices, access to the row index of `fNrows+1` entries. - `Int_t *GetColIndexArray()`: For sparse matrices, access to the column index of `fNelems` entries. #### Setting matrix properties. Use one of the following methods to set a matrix property:. - `SetTol (Double_t tol)`<br>; Sets the tolerance number. - `ResizeTo (Int_t nrows,Int_t ncols, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `nrows x ncols`. Index will start at 0. - `ResizeTo(Int_t row_lwb,Int_t row_upb, Int_t col_lwb,Int_t col_upb, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `row_lwb:row_upb x col_lwb:col_upb`. - `SetRowIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the row index. The array data should contain at least `fNrows+1` entries column lower-bound index. - `SetColIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the column index. The array data should contain at least `fNelems` entries. - `SetSparseIndex (Int_t nelems new)`<br>; Allocates memory for a sparse map of `nelems_new` elements and copies (if exists) at most `nelems_new` matrix elements over to the new structure. - `SetSparseIndex (const TMatrixDBase &a)`<br>; Copies the sparse map from matrix `a`. - `SetSparseIndexAB (const TMatrixDSparse &a, const TMatrixDSparse &b)`<br>; Sets th",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:5717,Availability,avail,available,5717,""""")`; - `TMatrixD(Int_t row_lwb,Int_t row_upb,Int_t col_lwb,Int_t col_upb, const Double_t *data,Option_t *option="""")`; - `TMatrixDSym(Int_t nrows)`; - `TMatrixDSym(Int_t row_lwb,Int_t row_upb)`; - `TMatrixDSym(Int_t nrows,const Double_t *data,Option_t *option="""")`; - `TMatrixDSym(Int_t row_lwb,Int_t row_upb, const Double_t *data, Option_t *opt="""")`; - `TMatrixDSparse(Int_t nrows,Int_t ncols)`; - `TMatrixDSparse(Int_t row_lwb,Int_t row_upb,Int_t col_lwb, Int_t col_upb)`; - `TMatrixDSparse(Int_t row_lwb,Int_t row_upb,Int_t col_lwb,Int_t col_upb, Int_t nr_nonzeros,Int_t *row,Int_t *col,Double_t *data)`. Use one of the following methods to fill a matrix:. - `SetMatrixArray(const Double_t*data,Option_t*option="""")`<br>; Copies array data. If `option=""F""`, the array fills the matrix column-wise else row-wise. This option is implemented for `TMatrixD` and `TMatrixDSym`. It is expected that the array data contains at least `fNelems` entries. - `SetMatrixArray(Int_t nr,Int_t *irow,Int_t *icol,Double_t *data)`<br>; Only available for sparse matrices. The three arrays should each contain `nr` entries with row index, column index and data entry. Only the entries with non-zero data value are inserted. - `operator()`, `operator[]`<br>; These operators provide the easiest way to fill a matrix but are in particular for a sparse matrix expensive. If no entry for slot (`i`,`j`) is found in the sparse index table it will be entered, which involves some memory management. Therefore, before invoking this method in a loop set the index table first through a call to the `SetSparseIndex()` method. - `SetSub(Int_t row_lwb,Int_t col_lwb,const TMatrixDBase &source)`<br>; The matrix to be inserted at position (`row_lwb`,`col_lwb`) can be both, dense or sparse. - `Use()`<br>; Allows inserting another matrix or data array without actually copying the data.<br>; The following list shows the application of the `Use()` method.; - First for normal matrices:; - `Use(TMatrixD &a)`; - `Use(Int_t row_lwb,",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:8401,Availability,avail,available,8401,"/5;; const Int_t ic = i%5;; data[i] = 1./(ir+ic);; }; h.SetMatrixArray(data.GetArray());; ~~~. You can also assign the data array to the matrix without actually copying it. ~~~ {.cpp}; TMatrixD h; h.Use(5,5,data.GetArray());; h.Invert();; ~~~. The array data now contains the inverted matrix. Now a unit matrix in sparse format is created. ~~~ {.cpp}; TMatrixDSparse unit1(5,5);; TArrayI row(5),col(5);; for (Int_t i = 0; i < 5; i++) row[i] = col[i] = i;; TArrayD data(5); data.Reset(1.);; unit1.SetMatrixArray(5,row.GetArray(),col.GetArray(),data.GetArray());. TMatrixDSparse unit2(5,5);; unit2.SetSparseIndex(5);; unit2.SetRowIndexArray(row.GetArray());; unit2.SetColIndexArray(col.GetArray());; unit2.SetMatrixArray(data.GetArray());; ~~~. ### Inverting a matrix. - Use the `Invert(Double_t &det=0)` function to invert a matrix:. ~~~ {.cpp}; TMatrixD a(...);; a.Invert();; ~~~; -- or --. - Use the appropriate constructor to invert a matrix:. ~~~ {.cpp}; TMatrixD b(kInvert,a);; ~~~; Both methods are available for general and symmetric matrices. For matrices whose size is less than or equal to 6x6, the `InvertFast(Double_t &det=0)`; function is available. Here the Cramer algorithm will be applied, which is faster but; less accurate. #### Using decomposition classes for inverting. You can also use the following decomposition classes (see  [Matrix decompositions](\ref MD)); for inverting a matrix:. | Name | Matrix | Comment |; |---------------|-----------|------------------------------------------|; | TDecompLU | General | |; | TDecompQRH | General | |; | TDecompSVD | General | Can manipulate singular matrix. |; | TDecompBK | Symmetric | |; | TDecompChol | Symmetric | Matrix should also be positive definite. |; | TDecompSparse | Sparse | |. If the required matrix type is general, you also can handle symmetric matrices. _**Example**_. This example shows how to check whether the matrix is singular before attempting to invert it. ~~~ {.cpp}; TDecompLU lu(a);; TMatrixD b;; if (!lu.De",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:8548,Availability,avail,available,8548,"so assign the data array to the matrix without actually copying it. ~~~ {.cpp}; TMatrixD h; h.Use(5,5,data.GetArray());; h.Invert();; ~~~. The array data now contains the inverted matrix. Now a unit matrix in sparse format is created. ~~~ {.cpp}; TMatrixDSparse unit1(5,5);; TArrayI row(5),col(5);; for (Int_t i = 0; i < 5; i++) row[i] = col[i] = i;; TArrayD data(5); data.Reset(1.);; unit1.SetMatrixArray(5,row.GetArray(),col.GetArray(),data.GetArray());. TMatrixDSparse unit2(5,5);; unit2.SetSparseIndex(5);; unit2.SetRowIndexArray(row.GetArray());; unit2.SetColIndexArray(col.GetArray());; unit2.SetMatrixArray(data.GetArray());; ~~~. ### Inverting a matrix. - Use the `Invert(Double_t &det=0)` function to invert a matrix:. ~~~ {.cpp}; TMatrixD a(...);; a.Invert();; ~~~; -- or --. - Use the appropriate constructor to invert a matrix:. ~~~ {.cpp}; TMatrixD b(kInvert,a);; ~~~; Both methods are available for general and symmetric matrices. For matrices whose size is less than or equal to 6x6, the `InvertFast(Double_t &det=0)`; function is available. Here the Cramer algorithm will be applied, which is faster but; less accurate. #### Using decomposition classes for inverting. You can also use the following decomposition classes (see  [Matrix decompositions](\ref MD)); for inverting a matrix:. | Name | Matrix | Comment |; |---------------|-----------|------------------------------------------|; | TDecompLU | General | |; | TDecompQRH | General | |; | TDecompSVD | General | Can manipulate singular matrix. |; | TDecompBK | Symmetric | |; | TDecompChol | Symmetric | Matrix should also be positive definite. |; | TDecompSparse | Sparse | |. If the required matrix type is general, you also can handle symmetric matrices. _**Example**_. This example shows how to check whether the matrix is singular before attempting to invert it. ~~~ {.cpp}; TDecompLU lu(a);; TMatrixD b;; if (!lu.Decompose()) {; cout << ""Decomposition failed, matrix singular ?"" << endl;; cout << ""condition number = "" ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:11534,Availability,toler,tolerance,11534,",B)<br>TMatrixD(A, TMatrixD::kMultTranspose,B)|overwrites A<br> <br> <br>constructor of AB<br>constructor of A<sup>T</sup>B<br>constructor of AB<sup>T</sup> |; | Element wise multiplication |ElementMult(A,B)|A(i,j)*= B(i,j) |; | Element wise division |ElementDiv(A,B)|A(i,j)/= B(i,j). #### Arithmetic operations between matrices and real numbers. | Description | Format | Comment |; |--------------------------|------------------|--------------|; | Element wise sum | C=r+A C=A+r A+=r | overwrites A |; | Element wise subtraction | C=r-A C=A-r A-=r | overwrites A |; | Matrix multiplication | C=r*A C=A*r A*=r | overwrites A |. #### Comparison and Boolean operations. **Comparison between two matrices**. | Description | Output | Descriptions |; |----------------------------------------|--------|-----------------------------------------------|; | A == B | Bool_t | equal to |; | A != B | matrix | not equal |; | A > B | matrix | greater than |; | A >= B | matrix | greater than or equal to |; | A < B | matrix | smaller than |; | A <= B | matrix | smaller than or equal to |; | AreCompatible(A,B) | Bool_t | compare matrix properties |; | Compare(A,B) | Bool_t | return summary of comparison |; | VerifyMatrixIdentity(A,B,verb, maxDev) | | check matrix identity within maxDev tolerance |. **Comparison between matrix and real number**. | Format | Output | Description |; |-------------------------------------|----------|-----------------------------------------------------|; | A == r | Bool_t | equal to |; | A != r | Bool_t | not equal |; | A > r | Bool_t | greater than |; | A >= r | Bool_t | greater than or equal to |; | A < r | Bool_t | smaller than |; | A <= r | Bool_t | smaller than or equal to |; | VerifyMatrixValue(A,r,verb, maxDev) | Bool_t | compare matrix value with r within maxDev tolerance |; | A.RowNorm() | Double_t | norm induced by the infinity vector norm |; | A.NormInf() | Double_t | |; | A.ColNorm() | Double_t | norm induced by the 1 vector norm |; | A.Norm1() | Doub",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:12057,Availability,toler,tolerance,12057,"ultiplication | C=r*A C=A*r A*=r | overwrites A |. #### Comparison and Boolean operations. **Comparison between two matrices**. | Description | Output | Descriptions |; |----------------------------------------|--------|-----------------------------------------------|; | A == B | Bool_t | equal to |; | A != B | matrix | not equal |; | A > B | matrix | greater than |; | A >= B | matrix | greater than or equal to |; | A < B | matrix | smaller than |; | A <= B | matrix | smaller than or equal to |; | AreCompatible(A,B) | Bool_t | compare matrix properties |; | Compare(A,B) | Bool_t | return summary of comparison |; | VerifyMatrixIdentity(A,B,verb, maxDev) | | check matrix identity within maxDev tolerance |. **Comparison between matrix and real number**. | Format | Output | Description |; |-------------------------------------|----------|-----------------------------------------------------|; | A == r | Bool_t | equal to |; | A != r | Bool_t | not equal |; | A > r | Bool_t | greater than |; | A >= r | Bool_t | greater than or equal to |; | A < r | Bool_t | smaller than |; | A <= r | Bool_t | smaller than or equal to |; | VerifyMatrixValue(A,r,verb, maxDev) | Bool_t | compare matrix value with r within maxDev tolerance |; | A.RowNorm() | Double_t | norm induced by the infinity vector norm |; | A.NormInf() | Double_t | |; | A.ColNorm() | Double_t | norm induced by the 1 vector norm |; | A.Norm1() | Double_t | |; | A.E2Norm() | Double_t | square of the Euclidean norm |; | A.NonZeros() | Int_t | |; | A.Sum() | Double_t | number of elements unequal zero |; | A.Min() | Double_t | |; | A.Max() | Double_t | |; | A.NormByColumn (v,""D"") | TMatrixD | |; | A.NormByRow (v,""D"") | TMatrixD | |. ### Matrix views. With the following matrix view classes, you can access the matrix elements:. - `TMatrixDRow`; - `TMatrixDColumn`; - `TMatrixDDiag`; - `TMatrixDSub`. #### Matrix view operators. For the matrix view classes `TMatrixDRow`, `TMatrixDColumn` and `TMatrixDDiag`, the necessary; assign",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:12853,Availability,avail,available,12853,"reater than |; | A >= r | Bool_t | greater than or equal to |; | A < r | Bool_t | smaller than |; | A <= r | Bool_t | smaller than or equal to |; | VerifyMatrixValue(A,r,verb, maxDev) | Bool_t | compare matrix value with r within maxDev tolerance |; | A.RowNorm() | Double_t | norm induced by the infinity vector norm |; | A.NormInf() | Double_t | |; | A.ColNorm() | Double_t | norm induced by the 1 vector norm |; | A.Norm1() | Double_t | |; | A.E2Norm() | Double_t | square of the Euclidean norm |; | A.NonZeros() | Int_t | |; | A.Sum() | Double_t | number of elements unequal zero |; | A.Min() | Double_t | |; | A.Max() | Double_t | |; | A.NormByColumn (v,""D"") | TMatrixD | |; | A.NormByRow (v,""D"") | TMatrixD | |. ### Matrix views. With the following matrix view classes, you can access the matrix elements:. - `TMatrixDRow`; - `TMatrixDColumn`; - `TMatrixDDiag`; - `TMatrixDSub`. #### Matrix view operators. For the matrix view classes `TMatrixDRow`, `TMatrixDColumn` and `TMatrixDDiag`, the necessary; assignment operators are available to interact with the vector class `TVectorD`.<br>The sub; matrix view classes `TMatrixDSub` has links to the matrix classes `TMatrixD` and `TMatrixDSym.`. The next table summarizes how to access the individual matrix elements in the matrix view classes. | Format | Comment |; |--------------------------|------------------|; | TMatrixDRow(A,i)(j) TMatrixDRow(A,i)[j] | element A<sub>ij</sub> |; | TMatrixDColumn(A,j)(i) TMatrixDColumn(A,j)[i] | element A<sub>ij</sub> |; | TMatrixDDiag(A(i) TMatrixDDiag(A[i] | element A<sub>ij</sub> |; | TMatrixDSub(A(i) TMatrixDSub(A,rl,rh,cl,ch)(i,j) | element A<sub>ij</sub><br>element A<sub>rl+i,cl+j</sub> |. \anchor MD; #### Matrix decompositions. There are the following classes available for matrix decompositions:. - TDecompLU: Decomposes a general `n x n` matrix `A` into `P A = L U`.; - TDecompBK: The Bunch-Kaufman diagonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky d",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:13584,Availability,avail,available,13584," classes, you can access the matrix elements:. - `TMatrixDRow`; - `TMatrixDColumn`; - `TMatrixDDiag`; - `TMatrixDSub`. #### Matrix view operators. For the matrix view classes `TMatrixDRow`, `TMatrixDColumn` and `TMatrixDDiag`, the necessary; assignment operators are available to interact with the vector class `TVectorD`.<br>The sub; matrix view classes `TMatrixDSub` has links to the matrix classes `TMatrixD` and `TMatrixDSym.`. The next table summarizes how to access the individual matrix elements in the matrix view classes. | Format | Comment |; |--------------------------|------------------|; | TMatrixDRow(A,i)(j) TMatrixDRow(A,i)[j] | element A<sub>ij</sub> |; | TMatrixDColumn(A,j)(i) TMatrixDColumn(A,j)[i] | element A<sub>ij</sub> |; | TMatrixDDiag(A(i) TMatrixDDiag(A[i] | element A<sub>ij</sub> |; | TMatrixDSub(A(i) TMatrixDSub(A,rl,rh,cl,ch)(i,j) | element A<sub>ij</sub><br>element A<sub>rl+i,cl+j</sub> |. \anchor MD; #### Matrix decompositions. There are the following classes available for matrix decompositions:. - TDecompLU: Decomposes a general `n x n` matrix `A` into `P A = L U`.; - TDecompBK: The Bunch-Kaufman diagonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transpa",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:15471,Availability,down,down,15471,"rn a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much as possible.; That is, to add two matrices, it's much more efficient to write. ~~~ {.cpp}; A += B;; ~~~. than. ~~~ {.cpp}; TMatrixD C = A + B;; ~~~. (if both operand should be preserved, `TMatrixD C = A; C += B;`; is still better). #### 3. Use glorified constructors when returning of an object seems inevitable:. ~~~ {.cpp}; TMatrixD A(TMatrixD::kTransposed,B);; TMatrixD C(A,TMatrixD::kTransposeMult,B);; ~~~. like in the following snippet (from `$ROOTSYS/test/vmatrix.cxx`); that verifies that for an orthogonal matrix T, T'T = TT' = E. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTranspos",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14698,Deployability,integrat,integrated,14698,"gonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp};",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19379,Deployability,install,installation,19379,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19417,Deployability,install,installation,19417,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14655,Energy Efficiency,efficient,efficient,14655,"omposes a general `n x n` matrix `A` into `P A = L U`.; - TDecompBK: The Bunch-Kaufman diagonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14781,Energy Efficiency,efficient,efficiently,14781,"; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:15850,Energy Efficiency,efficient,efficient,15850,"lex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much as possible.; That is, to add two matrices, it's much more efficient to write. ~~~ {.cpp}; A += B;; ~~~. than. ~~~ {.cpp}; TMatrixD C = A + B;; ~~~. (if both operand should be preserved, `TMatrixD C = A; C += B;`; is still better). #### 3. Use glorified constructors when returning of an object seems inevitable:. ~~~ {.cpp}; TMatrixD A(TMatrixD::kTransposed,B);; TMatrixD C(A,TMatrixD::kTransposeMult,B);; ~~~. like in the following snippet (from `$ROOTSYS/test/vmatrix.cxx`); that verifies that for an orthogonal matrix T, T'T = TT' = E. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);; ~~~. #### 4. Accessing row/col/diagonal of a matrix without much fuss. (and without moving a lot of stuff around):. ~~~ {.cpp}; TMatrixD m(n,",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19288,Energy Efficiency,adapt,adapted,19288,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:20093,Energy Efficiency,adapt,adapted,20093,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:14698,Integrability,integrat,integrated,14698,"gonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symmetric decomposition class. ### Matrix Eigen analysis. With the `TMatrixDEigen` and `TMatrixDSymEigen` classes, you can compute eigenvalues and; eigenvectors for general dense and symmetric real matrices. ## Additional Notes. The present package provides all facilities to completely AVOID; returning matrices. Use ""TMatrixD A(TMatrixD::kTransposed,B);""; and other fancy constructors as much as possible. If one really needs; to return a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp};",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19935,Integrability,rout,routines,19935,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:20132,Integrability,rout,routines,20132,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:19288,Modifiability,adapt,adapted,19288,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:20093,Modifiability,adapt,adapted,20093,"(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.mcc.ac.uk/pub/matclass/; 3. Mark Fischler and Steven Haywood of CLHEP; They did the slave labor of spelling out all sub-determinants; for Cramer inversion of (4x4),(5x5) and (6x6) matrices; The stack storage for small matrices was also taken from them; 4. Roldan Pozo of TNT (http://math.nist.gov/tnt/); He converted the EISPACK routines for the eigen-vector analysis to; C++ . We started with his implementation; 5. Siegmund Brandt (http://siux00.physik.uni-siegen.de/~brandt/datan; We adapted his (very-well) documented SVD routines; ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:180,Performance,perform,perform,180,"\defgroup Matrix Matrix Linear Algebra; \ingroup Math; \brief The %ROOT Matrix Linear Algebra package. The %ROOT linear algebra package provides a complete environment in %ROOT to perform matrix; calculations such as matrix-vector and matrix-matrix multiplications and other linear; algebra calculations like equation solving and eigenvalue decompositions. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. ### Matrix classes. %ROOT provides the following matrix classes, among others:. - `TMatrixDBase`. - `TMatrixF`. - `TMatrixFSym`. - `TVectorF`. - `TMatrixD`. - `TMatrixDSym`. - `TMatrixDSparse`. - `TDecompBase`. - `TDecompChol`. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify arbitrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). #### Matrix properties. A matrix has five properties, which are all set in the constructor:. - `precision` <br>; If the `precision` is floa",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:15443,Performance,optimiz,optimized,15443,"rn a matrix, return a TMatrixTLazy object instead. The; conversion is completely transparent to the end user, e.g.; ""TMatrixT m = THaarMatrixT(5);"" and _is_ efficient. Since TMatrixT et al. are fully integrated in %ROOT, they of course; can be stored in a %ROOT database. ### How to efficiently use this package. #### 1. Never return complex objects (matrices or vectors); Danger: For example, when the following snippet:. ~~~ {.cpp}; TMatrixD foo(int n); {; TMatrixD foom(n,n); fill_in(foom); return foom;; }; TMatrixD m = foo(5);; ~~~. runs, it constructs matrix foo:foom, copies it onto stack as a; return value and destroys foo:foom. Return value (a matrix); from foo() is then copied over to m (via a copy constructor),; and the return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much as possible.; That is, to add two matrices, it's much more efficient to write. ~~~ {.cpp}; A += B;; ~~~. than. ~~~ {.cpp}; TMatrixD C = A + B;; ~~~. (if both operand should be preserved, `TMatrixD C = A; C += B;`; is still better). #### 3. Use glorified constructors when returning of an object seems inevitable:. ~~~ {.cpp}; TMatrixD A(TMatrixD::kTransposed,B);; TMatrixD C(A,TMatrixD::kTransposeMult,B);; ~~~. like in the following snippet (from `$ROOTSYS/test/vmatrix.cxx`); that verifies that for an orthogonal matrix T, T'T = TT' = E. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTranspos",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:1089,Safety,avoid,avoiding,1089," %ROOT Matrix Linear Algebra package. The %ROOT linear algebra package provides a complete environment in %ROOT to perform matrix; calculations such as matrix-vector and matrix-matrix multiplications and other linear; algebra calculations like equation solving and eigenvalue decompositions. The present package implements all the basic algorithms dealing; with vectors, matrices, matrix columns, rows, diagonals, etc.; In addition eigen-Vector analysis and several matrix decomposition; have been added (LU,QRH,Cholesky,Bunch-Kaufman and SVD) .; The decompositions are used in matrix inversion, equation solving. ### Matrix classes. %ROOT provides the following matrix classes, among others:. - `TMatrixDBase`. - `TMatrixF`. - `TMatrixFSym`. - `TVectorF`. - `TMatrixD`. - `TMatrixDSym`. - `TMatrixDSparse`. - `TDecompBase`. - `TDecompChol`. For a dense matrix, elements are arranged in memory in a ROW-wise; fashion . For (n x m) matrices where n*m <=kSizeMax (=25 currently); storage space is available on the stack, thus avoiding expensive; allocation/deallocation of heap space . However, this introduces of; course kSizeMax overhead for each matrix object . If this is an; issue recompile with a new appropriate value (>=0) for kSizeMax. Sparse matrices are also stored in row-wise fashion but additional; row/column information is stored, see TMatrixTSparse source for; additional details . Another way to assign and store matrix data is through Use; see for instance stressLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify arbitrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). #### Matrix properties. A matrix has five properties, which are all set in the constructor:. - `precision` <br>; If the `precision` is float (i.e. single precision), use the `TMatrixF` class family. If th",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:2532,Security,access,access,2532,"ssLinear.cxx file . Unless otherwise specified, matrix and vector indices always start; with 0, spanning up to the specified limit-1. However, there are; constructors to which one can specify arbitrary lower and upper; bounds, e.g. TMatrixD m(1,10,1,5) defines a matrix that ranges; from 1..10, 1..5 (a(1,1)..a(10,5)). #### Matrix properties. A matrix has five properties, which are all set in the constructor:. - `precision` <br>; If the `precision` is float (i.e. single precision), use the `TMatrixF` class family. If the precision is double, use the `TMatrixD` class family. - `type`<br>; Possible values are: `general` (`TMatrixD`), `symmetric` (`TMatrixDSym`) or `sparse` (`TMatrixDSparse`). - `size`<br>; Number of rows and columns. - `index`<br>; Range start of row and column index. By default these start at 0. - `sparse map`<br>; Only relevant for a sparse matrix. It indicates where elements are unequal 0. #### Accessing matrix properties. Use one of the following methods to access the information about the relevant matrix property:. - `Int_t GetRowLwb()`: Row lower-bound index. - `Int_t GetRowUpb()`: Row upper-bound index. - `Int_t GetNrows()`: Number of rows. - `Int_t GetColLwb()`: Column lower-bound index. - `Int_t GetColUpb()`: Column upper-bound index. - `Int_t GetNcols()`: Number of columns. - `Int_t GetNoElements()`: Number of elements, for a dense matrix this equals: `fNrows x fNcols`. - `Double_t GetTol()`: Tolerance number that is used in decomposition operations. - `Int_t *GetRowIndexArray()`: For sparse matrices, access to the row index of `fNrows+1` entries. - `Int_t *GetColIndexArray()`: For sparse matrices, access to the column index of `fNelems` entries. #### Setting matrix properties. Use one of the following methods to set a matrix property:. - `SetTol (Double_t tol)`<br>; Sets the tolerance number. - `ResizeTo (Int_t nrows,Int_t ncols, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `nrows x ncols`. Index will start at 0. - `ResizeTo(Int_t ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:3093,Security,access,access,3093,"use the `TMatrixD` class family. - `type`<br>; Possible values are: `general` (`TMatrixD`), `symmetric` (`TMatrixDSym`) or `sparse` (`TMatrixDSparse`). - `size`<br>; Number of rows and columns. - `index`<br>; Range start of row and column index. By default these start at 0. - `sparse map`<br>; Only relevant for a sparse matrix. It indicates where elements are unequal 0. #### Accessing matrix properties. Use one of the following methods to access the information about the relevant matrix property:. - `Int_t GetRowLwb()`: Row lower-bound index. - `Int_t GetRowUpb()`: Row upper-bound index. - `Int_t GetNrows()`: Number of rows. - `Int_t GetColLwb()`: Column lower-bound index. - `Int_t GetColUpb()`: Column upper-bound index. - `Int_t GetNcols()`: Number of columns. - `Int_t GetNoElements()`: Number of elements, for a dense matrix this equals: `fNrows x fNcols`. - `Double_t GetTol()`: Tolerance number that is used in decomposition operations. - `Int_t *GetRowIndexArray()`: For sparse matrices, access to the row index of `fNrows+1` entries. - `Int_t *GetColIndexArray()`: For sparse matrices, access to the column index of `fNelems` entries. #### Setting matrix properties. Use one of the following methods to set a matrix property:. - `SetTol (Double_t tol)`<br>; Sets the tolerance number. - `ResizeTo (Int_t nrows,Int_t ncols, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `nrows x ncols`. Index will start at 0. - `ResizeTo(Int_t row_lwb,Int_t row_upb, Int_t col_lwb,Int_t col_upb, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `row_lwb:row_upb x col_lwb:col_upb`. - `SetRowIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the row index. The array data should contain at least `fNrows+1` entries column lower-bound index. - `SetColIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the column index. The array data should contain at least `fNelems` entries. - `SetSparseIndex (Int_t nelems new)`<br>; Allocates memory for a sparse map of `nelems_n",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:3192,Security,access,access,3192,"ic` (`TMatrixDSym`) or `sparse` (`TMatrixDSparse`). - `size`<br>; Number of rows and columns. - `index`<br>; Range start of row and column index. By default these start at 0. - `sparse map`<br>; Only relevant for a sparse matrix. It indicates where elements are unequal 0. #### Accessing matrix properties. Use one of the following methods to access the information about the relevant matrix property:. - `Int_t GetRowLwb()`: Row lower-bound index. - `Int_t GetRowUpb()`: Row upper-bound index. - `Int_t GetNrows()`: Number of rows. - `Int_t GetColLwb()`: Column lower-bound index. - `Int_t GetColUpb()`: Column upper-bound index. - `Int_t GetNcols()`: Number of columns. - `Int_t GetNoElements()`: Number of elements, for a dense matrix this equals: `fNrows x fNcols`. - `Double_t GetTol()`: Tolerance number that is used in decomposition operations. - `Int_t *GetRowIndexArray()`: For sparse matrices, access to the row index of `fNrows+1` entries. - `Int_t *GetColIndexArray()`: For sparse matrices, access to the column index of `fNelems` entries. #### Setting matrix properties. Use one of the following methods to set a matrix property:. - `SetTol (Double_t tol)`<br>; Sets the tolerance number. - `ResizeTo (Int_t nrows,Int_t ncols, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `nrows x ncols`. Index will start at 0. - `ResizeTo(Int_t row_lwb,Int_t row_upb, Int_t col_lwb,Int_t col_upb, Int_t nr_nonzeros=-1)`<br>; Changes the matrix shape to `row_lwb:row_upb x col_lwb:col_upb`. - `SetRowIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the row index. The array data should contain at least `fNrows+1` entries column lower-bound index. - `SetColIndexArray (Int_t *data)`<br>; For sparse matrices, it sets the column index. The array data should contain at least `fNelems` entries. - `SetSparseIndex (Int_t nelems new)`<br>; Allocates memory for a sparse map of `nelems_new` elements and copies (if exists) at most `nelems_new` matrix elements over to the new structure. ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:12604,Security,access,access,12604," | Format | Output | Description |; |-------------------------------------|----------|-----------------------------------------------------|; | A == r | Bool_t | equal to |; | A != r | Bool_t | not equal |; | A > r | Bool_t | greater than |; | A >= r | Bool_t | greater than or equal to |; | A < r | Bool_t | smaller than |; | A <= r | Bool_t | smaller than or equal to |; | VerifyMatrixValue(A,r,verb, maxDev) | Bool_t | compare matrix value with r within maxDev tolerance |; | A.RowNorm() | Double_t | norm induced by the infinity vector norm |; | A.NormInf() | Double_t | |; | A.ColNorm() | Double_t | norm induced by the 1 vector norm |; | A.Norm1() | Double_t | |; | A.E2Norm() | Double_t | square of the Euclidean norm |; | A.NonZeros() | Int_t | |; | A.Sum() | Double_t | number of elements unequal zero |; | A.Min() | Double_t | |; | A.Max() | Double_t | |; | A.NormByColumn (v,""D"") | TMatrixD | |; | A.NormByRow (v,""D"") | TMatrixD | |. ### Matrix views. With the following matrix view classes, you can access the matrix elements:. - `TMatrixDRow`; - `TMatrixDColumn`; - `TMatrixDDiag`; - `TMatrixDSub`. #### Matrix view operators. For the matrix view classes `TMatrixDRow`, `TMatrixDColumn` and `TMatrixDDiag`, the necessary; assignment operators are available to interact with the vector class `TVectorD`.<br>The sub; matrix view classes `TMatrixDSub` has links to the matrix classes `TMatrixD` and `TMatrixDSym.`. The next table summarizes how to access the individual matrix elements in the matrix view classes. | Format | Comment |; |--------------------------|------------------|; | TMatrixDRow(A,i)(j) TMatrixDRow(A,i)[j] | element A<sub>ij</sub> |; | TMatrixDColumn(A,j)(i) TMatrixDColumn(A,j)[i] | element A<sub>ij</sub> |; | TMatrixDDiag(A(i) TMatrixDDiag(A[i] | element A<sub>ij</sub> |; | TMatrixDSub(A(i) TMatrixDSub(A,rl,rh,cl,ch)(i,j) | element A<sub>ij</sub><br>element A<sub>rl+i,cl+j</sub> |. \anchor MD; #### Matrix decompositions. There are the following classes available ",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:13051,Security,access,access,13051," |; | A.RowNorm() | Double_t | norm induced by the infinity vector norm |; | A.NormInf() | Double_t | |; | A.ColNorm() | Double_t | norm induced by the 1 vector norm |; | A.Norm1() | Double_t | |; | A.E2Norm() | Double_t | square of the Euclidean norm |; | A.NonZeros() | Int_t | |; | A.Sum() | Double_t | number of elements unequal zero |; | A.Min() | Double_t | |; | A.Max() | Double_t | |; | A.NormByColumn (v,""D"") | TMatrixD | |; | A.NormByRow (v,""D"") | TMatrixD | |. ### Matrix views. With the following matrix view classes, you can access the matrix elements:. - `TMatrixDRow`; - `TMatrixDColumn`; - `TMatrixDDiag`; - `TMatrixDSub`. #### Matrix view operators. For the matrix view classes `TMatrixDRow`, `TMatrixDColumn` and `TMatrixDDiag`, the necessary; assignment operators are available to interact with the vector class `TVectorD`.<br>The sub; matrix view classes `TMatrixDSub` has links to the matrix classes `TMatrixD` and `TMatrixDSym.`. The next table summarizes how to access the individual matrix elements in the matrix view classes. | Format | Comment |; |--------------------------|------------------|; | TMatrixDRow(A,i)(j) TMatrixDRow(A,i)[j] | element A<sub>ij</sub> |; | TMatrixDColumn(A,j)(i) TMatrixDColumn(A,j)[i] | element A<sub>ij</sub> |; | TMatrixDDiag(A(i) TMatrixDDiag(A[i] | element A<sub>ij</sub> |; | TMatrixDSub(A(i) TMatrixDSub(A,rl,rh,cl,ch)(i,j) | element A<sub>ij</sub><br>element A<sub>rl+i,cl+j</sub> |. \anchor MD; #### Matrix decompositions. There are the following classes available for matrix decompositions:. - TDecompLU: Decomposes a general `n x n` matrix `A` into `P A = L U`.; - TDecompBK: The Bunch-Kaufman diagonal pivoting method decomposes a real symmetric matrix `A`.; - TDecompChol: The Cholesky decomposition class, which decomposes a symmetric, positive definite matrix `A = U^T * U` where `U` is a upper triangular matrix.; - TDecompQRH: QR decomposition class.; - TDecompSVD: Single value decomposition class.; - TDecompSparse: Sparse symme",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:16249,Testability,test,test,16249,"return value is destroyed. So, the matrix constructor is; called 3 times and the destructor 2 times. For big matrices,; the cost of multiple constructing/copying/destroying of objects; may be very large. *Some* optimized compilers can cut down on 1; copying/destroying, but still it leaves at least two calls to; the constructor. Note, TMatrixDLazy (see below) can construct; TMatrixD m ""inplace"", with only a _single_ call to the; constructor. #### 2. Use ""two-address instructions"". ~~~ {.cpp}; void TMatrixD::operator += (const TMatrixD &B);; ~~~. as much as possible.; That is, to add two matrices, it's much more efficient to write. ~~~ {.cpp}; A += B;; ~~~. than. ~~~ {.cpp}; TMatrixD C = A + B;; ~~~. (if both operand should be preserved, `TMatrixD C = A; C += B;`; is still better). #### 3. Use glorified constructors when returning of an object seems inevitable:. ~~~ {.cpp}; TMatrixD A(TMatrixD::kTransposed,B);; TMatrixD C(A,TMatrixD::kTransposeMult,B);; ~~~. like in the following snippet (from `$ROOTSYS/test/vmatrix.cxx`); that verifies that for an orthogonal matrix T, T'T = TT' = E. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; TMatrixD unit(TMatrixD::kUnit,haar);; TMatrixD haar_t(TMatrixD::kTransposed,haar);; TMatrixD hth(haar,TMatrixD::kTransposeMult,haar);; TMatrixD hht(haar,TMatrixD::kMult,haar_t);; TMatrixD hht1 = haar; hht1 *= haar_t;; VerifyMatrixIdentity(unit,hth);; VerifyMatrixIdentity(unit,hht);; VerifyMatrixIdentity(unit,hht1);; ~~~. #### 4. Accessing row/col/diagonal of a matrix without much fuss. (and without moving a lot of stuff around):. ~~~ {.cpp}; TMatrixD m(n,n); TVectorD v(n); TMatrixDDiag(m) += 4;; v = TMatrixDRow(m,0);; TMatrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; ~~~. Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. #### 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. ~~~ {.cpp}; void foo(",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:18290,Testability,test,test,18290,"m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }; ~~~. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix element:. ~~~ {.cpp}; void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:17900,Usability,simpl,simple,17900,"atrixDColumn m1(m,1); m1(2) = 3; // the same as m(2,1)=3;; ~~~. Note, constructing of, say, TMatrixDDiag does *not* involve any; copying of any elements of the source matrix. #### 5. It's possible (and encouraged) to use ""nested"" functions; For example, creating of a Hilbert matrix can be done as follows:. ~~~ {.cpp}; void foo(const TMatrixD &m); {; TMatrixD m1(TMatrixD::kZero,m);; struct MakeHilbert : public TElementPosActionD {; void Operation(Double_t &element); { element = 1./(fI+fJ-1); }; };; m1.Apply(MakeHilbert());; }; ~~~. of course, using a special method THilbertMatrixD() is; still more optimal, but not by a whole lot. And that's right,; class MakeHilbert is declared *within* a function and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix element:. ~~~ {.cpp}; void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe an",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md:18616,Usability,simpl,simple,18616,"on and local to; that function. It means one can define another MakeHilbert class; (within another function or outside of any function, that is, in; the global scope), and it still will be OK. Note, this currently; is not yet supported by the interpreter CINT. Another example is applying of a simple function to each matrix element:. ~~~ {.cpp}; void foo(TMatrixD &m,TMatrixD &m1); {; typedef double (*dfunc_t)(double);; class ApplyFunction : public TElementActionD {; dfunc_t fFunc;; void Operation(Double_t &element); { element=fFunc(element); }; public:; ApplyFunction(dfunc_t func):fFunc(func) {}; };; ApplyFunction x(TMath::Sin);; m.Apply(x);; }; ~~~. Validation code `$ROOTSYS/test/vmatrix.cxx` and `vvector.cxx` contain; a few more examples of that kind. #### 6. Lazy matrices:. instead of returning an object return a ""recipe""; how to make it. The full matrix would be rolled out only when; and where it's needed:. ~~~ {.cpp}; TMatrixD haar = THaarMatrixD(5);; ~~~. THaarMatrixD() is a *class*, not a simple function. However; similar this looks to a returning of an object (see note #1; above), it's dramatically different. THaarMatrixD() constructs a; TMatrixDLazy, an object of just a few bytes long. A special; ""TMatrixD(const TMatrixDLazy &recipe)"" constructor follows the; recipe and makes the matrix haar() right in place. No matrix; element is moved whatsoever!. ### Acknowledgements. 1. Oleg E. Kiselyov; First implementations were based on the his code . We have diverged; quite a bit since then but the ideas/code for lazy matrix and; ""nested function"" are 100% his .; You can see him and his code in action at http://okmij.org/ftp; 2. Chris R. Birchenhall,; We adapted his idea of the implementation for the decomposition; classes instead of our messy installation of matrix inversion; His installation of matrix condition number, using an iterative; scheme using the Hage algorithm is worth looking at !; Chris has a nice writeup (matdoc.ps) on his matrix classes at; ftp://ftp.",MatchSource.DOCS,math/matrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/matrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit/doc/index.md:618,Availability,down,download,618,"\defgroup MinuitOld TMinuit; \ingroup Math; \brief The Minuit Minimization package.; \see Minuit2 for a newer version of this package. Direct C++ implementation of the Minuit minimization package. This package was originally written in Fortran by Fred James; and part of PACKLIB (patch D506). It has been converted to a C++ class, TMinuit, by R.Brun. See also:. - The main documentation is in the class TMinuit; - [The Chapter about Fitting Histogram in the Users Guide](https://root.cern/manual/fitting/#fitting-1-d-histograms-with-pre-defined-functions); - [The MINUIT documentation in CERNLIB](https://root.cern.ch/download/minuit.pdf); - [How to Fit Histograms](https://root-forum.cern.ch/t/how-to-fit-histograms-or-data-points/38870); - peaks.C How to Fit find peaks in histograms; ",MatchSource.DOCS,math/minuit/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit/doc/index.md:280,Deployability,patch,patch,280,"\defgroup MinuitOld TMinuit; \ingroup Math; \brief The Minuit Minimization package.; \see Minuit2 for a newer version of this package. Direct C++ implementation of the Minuit minimization package. This package was originally written in Fortran by Fred James; and part of PACKLIB (patch D506). It has been converted to a C++ class, TMinuit, by R.Brun. See also:. - The main documentation is in the class TMinuit; - [The Chapter about Fitting Histogram in the Users Guide](https://root.cern/manual/fitting/#fitting-1-d-histograms-with-pre-defined-functions); - [The MINUIT documentation in CERNLIB](https://root.cern.ch/download/minuit.pdf); - [How to Fit Histograms](https://root-forum.cern.ch/t/how-to-fit-histograms-or-data-points/38870); - peaks.C How to Fit find peaks in histograms; ",MatchSource.DOCS,math/minuit/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1067,Deployability,integrat,integrate,1067," new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1692,Deployability,install,installed,1692,"found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Errors in Minuit_ ([pdf](http://seal.cern.ch/documents/minuit/mnerror.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1871,Deployability,install,installing,1871,"found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Errors in Minuit_ ([pdf](http://seal.cern.ch/documents/minuit/mnerror.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1067,Integrability,integrat,integrate,1067," new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1197,Integrability,interface,interface,1197,"on provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https:/",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1397,Integrability,interface,interface,1397," limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1289,Modifiability,plug-in,plug-in,1289,"lent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT Use",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:310,Performance,perform,performances,310,"\page Minuit2Page Minuit2. The **Minuit2** library is a new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides a",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:464,Performance,optimiz,optimized,464,"\page Minuit2Page Minuit2. The **Minuit2** library is a new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides a",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:502,Testability,log,log,502,"\page Minuit2Page Minuit2. The **Minuit2** library is a new object-oriented implementation, written in C++,; of the popular MINUIT minimization package. These new version provides basically; all the functionality present in the old Fortran version, with almost equivalent; numerical accuracy and computational performances. Furthermore, it contains new; functionality, like the possibility to set single side parameter limits or the; FUMILI algorithm, which is an optimized method for least square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides a",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1485,Testability,test,test,1485,"square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1504,Testability,test,testMinimize,1504,"square and log likelihood; minimizations. The package has been originally developed by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1589,Testability,test,test,1589," by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Er",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1594,Testability,test,testMinimize,1594," by M. Winkler and F. James.; More information on the new C++ version can be found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Er",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:1961,Usability,guid,guides,1961,"found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Errors in Minuit_ ([pdf](http://seal.cern.ch/documents/minuit/mnerror.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:2317,Usability,guid,guides,2317,"found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Errors in Minuit_ ([pdf](http://seal.cern.ch/documents/minuit/mnerror.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md:2387,Usability,guid,guides,2387,"found on the; [MINUIT Web Site](http://www.cern.ch/minuit). Minuit2, originally developed in the SEAL project, is now distributed within %ROOT.; The API has been then changed in this new version to follow the %ROOT coding convention; (function names starting with capital letters) and the classes have been moved inside; the namespace _ROOT::Minuit2_. In addition, the %ROOT distribution contains classes; needed to integrate Minuit2 in the %ROOT framework. A new class has been introduced, ROOT::Minuit2::Minuit2Minimizer, which implements; the interface ROOT::Math::Minimizer. Within %ROOT, it can be instantiates also using; the %ROOT plug-in manager. This class provides a convenient entry point for using Minuit2\.; An example of using this interface is the %ROOT tutorial _tutorials/fit/NumericalMinimization.C_; or the Minuit2 test program; [<tt>testMinimize.cxx</tt>](https://github.com/cxx-hep/root-cern/blob/master/math/minuit2/test/testMinimize.cxx). A standalone version of Minuit2 (independent of %ROOT) can be easily built and installed using `CMake`. See this [`README`](https://github.com/root-project/root/blob/master/math/minuit2/README.md) for the instructions on how to get the sources, building and installing a stand-alone Minuit2. The [Minuit2 User Guide](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html); provides all the information needed for using directly (without add-on packages like %ROOT) Minuit2. ## References. 1. F. James, _Fortran MINUIT Reference Manual_ ([html](https://cern-tex.web.cern.ch/cern-tex/minuit/minmain.html));; 2. F. James and M. Winkler, _C++ MINUIT User's Guide_ ([html](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.html) and [pdf](https://root.cern/root/htmldoc/guides/minuit2/Minuit2.pdf));; 3. F. James, _Minuit Tutorial on Function Minimization_ ([pdf](http://seal.cern.ch/documents/minuit/mntutorial.pdf));; 4. F. James, _The Interpretation of Errors in Minuit_ ([pdf](http://seal.cern.ch/documents/minuit/mnerror.pdf));; ",MatchSource.DOCS,math/minuit2/doc/Minuit2.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/minuit2/doc/Minuit2.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:2469,Availability,down,downloaded,2469,"re, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMatrix - A high performance library for Vector/Matrix calculation and Vertexing_,; HERA-B Software Note 01-134, December 2, 2003 ([pdf](http://seal.web.cern.ch/seal/documents/mathlib/smatrix_herab.pdf)); 3. L. Moneta, %ROOT Math proposal for Linear Algebra, [presentation](http://seal.cern.ch/documents/mathlib/aa_matrix_nov05.pdf); at the LCG Application Area meeting, November 23, 2005. * * *. @authors the %ROOT Math Library Team, T. Glebe (original SMatrix author) and J. Palacios (LHCb); ",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:1409,Deployability,release,release,1409," used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float type",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:2528,Deployability,install,install,2528,"re, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMatrix - A high performance library for Vector/Matrix calculation and Vertexing_,; HERA-B Software Note 01-134, December 2, 2003 ([pdf](http://seal.web.cern.ch/seal/documents/mathlib/smatrix_herab.pdf)); 3. L. Moneta, %ROOT Math proposal for Linear Algebra, [presentation](http://seal.cern.ch/documents/mathlib/aa_matrix_nov05.pdf); at the LCG Application Area meeting, November 23, 2005. * * *. @authors the %ROOT Math Library Team, T. Glebe (original SMatrix author) and J. Palacios (LHCb); ",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:93,Performance,perform,performance,93,"\defgroup SMatrixGroup SMatrix Package; \ingroup Math. **SMatrix** is a C++ package for high performance vector and matrix computations. It can be; used only in problems when the size of the matrices is known at compile time, like in the; tracking reconstruction of HEP experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can be used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and d",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:370,Performance,optimiz,optimization,370,"\defgroup SMatrixGroup SMatrix Package; \ingroup Math. **SMatrix** is a C++ package for high performance vector and matrix computations. It can be; used only in problems when the size of the matrices is known at compile time, like in the; tracking reconstruction of HEP experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can be used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and d",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:558,Performance,optimiz,optimized,558,"\defgroup SMatrixGroup SMatrix Package; \ingroup Math. **SMatrix** is a C++ package for high performance vector and matrix computations. It can be; used only in problems when the size of the matrices is known at compile time, like in the; tracking reconstruction of HEP experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can be used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and d",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:935,Performance,perform,performant,935,"\defgroup SMatrixGroup SMatrix Package; \ingroup Math. **SMatrix** is a C++ package for high performance vector and matrix computations. It can be; used only in problems when the size of the matrices is known at compile time, like in the; tracking reconstruction of HEP experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can be used to implement; vector and matrix expressions such that these expressions can be transformed at compile time; to code which is equivalent to hand optimized code in a low-level language like FORTRAN or; C (see for example ref. 1). The SMatrix has been developed initially by T. Glebe of the Max-Planck-Institut, Heidelberg,; as part of the HeraB analysis framework. A subset of the original package has been now incorporated; in the %ROOT distribution, with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and d",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:1931,Performance,optimiz,optimized,1931,", with the aim to provide to the LHC experiments a stand-alone and; high performant matrix package for reconstruction. The API of the current package differs; from the original one, in order to be compliant to the %ROOT coding conventions. SMatrix contains generic \ref SMatrixSVector to describe matrix and vector of arbitrary; dimensions and of arbitrary type. The classes are templated on the scalar type and on the; size of the matrix (number of rows and columns) or the vector. Therefore, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMat",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:2875,Performance,perform,performance,2875,"re, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMatrix - A high performance library for Vector/Matrix calculation and Vertexing_,; HERA-B Software Note 01-134, December 2, 2003 ([pdf](http://seal.web.cern.ch/seal/documents/mathlib/smatrix_herab.pdf)); 3. L. Moneta, %ROOT Math proposal for Linear Algebra, [presentation](http://seal.cern.ch/documents/mathlib/aa_matrix_nov05.pdf); at the LCG Application Area meeting, November 23, 2005. * * *. @authors the %ROOT Math Library Team, T. Glebe (original SMatrix author) and J. Palacios (LHCb); ",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:2564,Testability,test,test,2564,"re, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMatrix - A high performance library for Vector/Matrix calculation and Vertexing_,; HERA-B Software Note 01-134, December 2, 2003 ([pdf](http://seal.web.cern.ch/seal/documents/mathlib/smatrix_herab.pdf)); 3. L. Moneta, %ROOT Math proposal for Linear Algebra, [presentation](http://seal.cern.ch/documents/mathlib/aa_matrix_nov05.pdf); at the LCG Application Area meeting, November 23, 2005. * * *. @authors the %ROOT Math Library Team, T. Glebe (original SMatrix author) and J. Palacios (LHCb); ",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md:2642,Testability,test,tests,2642,"re, the size has to; be known at compile time. Since the release 5.10, SMatrix supports symmetric matrices using; a storage class (ROOT::Math::MatRepSym) which contains only the N*(N+1)/2 independent element; of a NxN symmetric matrix.; It is not in the mandate of this package to provide a complete linear algebra functionality; for these classes. What is provided are basic \ref MatrixFunctions and \ref VectFunction,; such as the matrix-matrix, matrix-vector, vector-vector operations, plus some extra; functionality for square matrices, like inversion, which is based on the optimized Cramer; method for squared matrices of size up to 6x6, and determinant calculation.; For a more detailed descriptions and usage examples see:. * \ref SVectorDoc; * \ref SMatrixDoc; * \ref MatVecFunctions. The SMatrix package contains only header files. Normally one does not need to build any library.; In the %ROOT distribution a library, _libSmatrix_ is produced with the C++ dictionary information; for vectors, symmetric and squared matrices for double, float types up to dimension 7.; The current version of SMatrix can be downloaded from [here](../SMatrix.tar.gz). If you want; to install the header files or run the test _configure_ script and then _make install_ or; _make check_ to build the tests. No dictionary library is built in this case. ## References. 1. T. Veldhuizen, [_Expression Templates_](http://osl.iu.edu/~tveldhui/papers/Expression-Templates/exprtmpl.html),; C++ Report, 1995.; 2. T. Glebe, _SMatrix - A high performance library for Vector/Matrix calculation and Vertexing_,; HERA-B Software Note 01-134, December 2, 2003 ([pdf](http://seal.web.cern.ch/seal/documents/mathlib/smatrix_herab.pdf)); 3. L. Moneta, %ROOT Math proposal for Linear Algebra, [presentation](http://seal.cern.ch/documents/mathlib/aa_matrix_nov05.pdf); at the LCG Application Area meeting, November 23, 2005. * * *. @authors the %ROOT Math Library Team, T. Glebe (original SMatrix author) and J. Palacios (LHCb); ",MatchSource.DOCS,math/smatrix/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:1591,Availability,avail,available,1591,"of columns. Its; data member is an array T[nrows*ncols] containing the matrix data. The data are; stored in the row-major C convention. For example, for a matrix, M, of size 3x3,; the data \f$ \left[a_0,a_1,a_2,.......,a_7,a_8 \right] \f$ are stored in the following; order: \f[ M = \left( \begin{array}{ccc} a_0 & a_1 & a_2 \\ a_3 & a_4 & a_5 \\ a_6 & a_7 & a_8 \end{array} \right) \f]; 2. ROOT::Math::MatRepSym for a symmetric matrix of size NxN. This class is a template; on the contained type and on the symmetric matrix size, N. It has as data member an; array of type T of size N*(N+1)/2, containing the lower diagonal block of the matrix.; The order follows the lower diagonal block, still in a row-major convention. For; example for a symmetric 3x3 matrix the order of the 6 elements; \f$ \left[a_0,a_1.....a_5 \right]\f$ is: \f[ M = \left( \begin{array}{ccc} a_0 & a_1 & a_3 \\ a_1 & a_2 & a_4 \\ a_3 & a_4 & a_5 \end{array} \right) \f]. ### Creating a matrix. The following constructors are available to create a matrix:. * Default constructor for a zero matrix (all elements equal to zero).; * Constructor of an identity matrix.; * Copy constructor (and assignment) for a matrix with the same representation, or from a; different one when possible, for example from a symmetric to a general matrix.; * Constructor (and assignment) from a matrix expression, like D = A*B + C. Due to the; expression template technique, no temporary objects are created in this operation. In; the case of an operation like A = A*B + C, a temporary object is needed and it is created; automatically to store the intermediary result in order to preserve the validity of; this operation.; * Constructor from a generic STL-like iterator copying the data referred by the iterator,; following its order. It is both possible to specify the _begin_ and _end_ of the iterator; or the _begin_ and the size. In case of a symmetric matrix, it is required only the; triangular block and the user can specify whether givin",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:6305,Availability,error,error,6305,"ces, in contrast to the iterator access methods which behave; differently (it follows the data order). ~~~ {.cpp}; SMatrix33 m;; m(0,0) = 1; // set the element in first row and first column; *(m.begin()+1) = 2; // set the second element (0,1); double d[9]={1,2,3,4,5,6,7,8,9};; m.SetElements(d,d+9); // set the d[] values in m. double x = m(2,1); // return the element in third row and first column; x = m.apply(7); // return the 8-th element (row=2,col=1); x = *(m.begin()+7); // return the 8-th element (row=2,col=1); // symmetric matrices (note the difference in behavior between apply and the iterators); x = *(m.begin()+4) // return the element (row=2,col=1).; x = m.apply(7); // returns again the (row=2,col=1) element; ~~~. There are methods to place and/or retrieve ROOT::Math::SVector objects as rows or columns; in (from) a matrix. In addition one can put (get) a sub-matrix as another; ROOT::Math::SMatrix object in a matrix. If the size of the sub-vector or sub-matrix are; larger than the matrix size a static assert ( a compilation error) is produced. The non-const. ~~~ {.cpp}. SMatrix33 m;; SVector2 v2(1,2);; // place a vector of size 2 in the first row starting from element (0,1) : m(0,1) = v2[0]; m.Place_in_row(v2,0,1);; // place the vector in the second column from (0,1) : m(0,1) = v2[0]; m.Place in_col(v2,0,1);; SMatrix22 m2;; // place the sub-matrix m2 in m starting from the element (1,1) : m(1,1) = m2(0,0); m.Place_at(m2,1,1);; SVector3 v3(1,2,3);; // set v3 as the diagonal elements of m : m(i,i) = v3[i] for i=0,1,2; m.SetDiagonal(v3); ~~~. The const methods retrieving contents (getting slices of a matrix) are:. ~~~ {.cpp}; a = {1,2,3,4,5,6,7,8,9};; SMatrix33 m(a,a+9);; SVector3 irow = m.Row(0); // return as vector the first matrix row; SVector3 jcol = m.Col(1); // return as vector the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the sec",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:7813,Availability,avail,available,7813,",1,2; m.SetDiagonal(v3); ~~~. The const methods retrieving contents (getting slices of a matrix) are:. ~~~ {.cpp}; a = {1,2,3,4,5,6,7,8,9};; SMatrix33 m(a,a+9);; SVector3 irow = m.Row(0); // return as vector the first matrix row; SVector3 jcol = m.Col(1); // return as vector the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the second column from element (0,1) : c2[0] = m(0,1); c2[1] = m(1,1);; SVector2 c2 = m.SubCol<SVector2> (1,0);; // return a sub-matrix 2x2 with the upper left corner at the values (1,1); SMatrix22 subM = m.Sub<SMatrix22> (1,1);; // return the diagonal element in a SVector; SVector3 diag = m.Diagonal();; // return the upper(lower) block of the matrix m; SVector6 vub = m.UpperBlock(); // vub = [ 1, 2, 3, 5, 6, 9 ]; SVector6 vlb = m.LowerBlock(); // vlb = [ 1, 4, 5, 7, 8, 9 ]; ~~~. ### Linear Algebra Functions. Only limited linear algebra functionality is available for SMatrix. It is possible; for squared matrices NxN, to find the inverse or to calculate the determinant.; Different inversion algorithms are used if the matrix is smaller than 6x6 or if it; is symmetric. In the case of a small matrix, a faster direct inversion is used.; For a large (N > 6) symmetric matrix the Bunch-Kaufman diagonal pivoting method; is used while for a large (N > 6) general matrix an LU factorization is performed; using the same algorithm as in the CERNLIB routine; [dinv](https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/f010/top.html). ~~~ {.cpp}; // Invert a NxN matrix. The inverted matrix replace the existing one and returns if the result is successful; bool ret = m.Invert(); // return the inverse matrix of m. If the inversion fails ifail is different than zero; int ifail = 0;; mInv = m.Inverse(ifail);; ~~~. The determinant of a square matrix can be obtained as follows:. ~~~ {.cpp}; double det;; // calculate the determinant modifying the m",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:4862,Integrability,interface,interface,4862," create a matrix using the a[] data; // this will produce the 3x3 matrix; // ( 1 2 3; // 4 5 6; // 7 8 9 ); ~~~. Example to create a symmetric matrix from an _std::vector_:. ~~~ {.cpp}; std::vector<double> v(6);; for (int i = 0; i<6; ++i) v[i] = double(i+1);; SMatrixSym3 s(v.begin(),v.end()); // this will produce the symmetric matrix; // ( 1 2 4; // 2 3 5; // 4 5 6 ). // create a a general matrix from a symmetric matrix. The opposite will not compile; SMatrix33 m2 = s;; ~~~. Example to create a symmetric matrix from a ROOT::Math::SVector containing the lower/upper data block:. ~~~ {.cpp}; ROOT::Math::SVector<double, 6> v(1,2,3,4,5,6);; SMatrixSym3 s1(v); // lower block (default); // this will produce the symmetric matrix; // ( 1 2 4; // 2 3 5; // 4 5 6 ). SMatrixSym3 s2(v,false); // upper block; // this will produce the symmetric matrix; // ( 1 2 3; // 2 4 5; // 3 5 6 ); ~~~. ### Accessing and Setting Methods. The matrix elements can be set using the _operator()(irow,icol)_, where irow and icol are; the row and column indexes or by using the iterator interface. Notice that the indexes start; from zero and not from one as in FORTRAN. All the matrix elements can be set also by using; the ROOT::Math::SetElements function passing a generic iterator.; The elements can be accessed by these same methods and also by using the; ROOT::Math::SMatrix::apply function. The _apply(i)_ function has exactly the same behavior; for general and symmetric matrices, in contrast to the iterator access methods which behave; differently (it follows the data order). ~~~ {.cpp}; SMatrix33 m;; m(0,0) = 1; // set the element in first row and first column; *(m.begin()+1) = 2; // set the second element (0,1); double d[9]={1,2,3,4,5,6,7,8,9};; m.SetElements(d,d+9); // set the d[] values in m. double x = m(2,1); // return the element in third row and first column; x = m.apply(7); // return the 8-th element (row=2,col=1); x = *(m.begin()+7); // return the 8-th element (row=2,col=1); // symmetric mat",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:8304,Integrability,rout,routine,8304,"tor the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the second column from element (0,1) : c2[0] = m(0,1); c2[1] = m(1,1);; SVector2 c2 = m.SubCol<SVector2> (1,0);; // return a sub-matrix 2x2 with the upper left corner at the values (1,1); SMatrix22 subM = m.Sub<SMatrix22> (1,1);; // return the diagonal element in a SVector; SVector3 diag = m.Diagonal();; // return the upper(lower) block of the matrix m; SVector6 vub = m.UpperBlock(); // vub = [ 1, 2, 3, 5, 6, 9 ]; SVector6 vlb = m.LowerBlock(); // vlb = [ 1, 4, 5, 7, 8, 9 ]; ~~~. ### Linear Algebra Functions. Only limited linear algebra functionality is available for SMatrix. It is possible; for squared matrices NxN, to find the inverse or to calculate the determinant.; Different inversion algorithms are used if the matrix is smaller than 6x6 or if it; is symmetric. In the case of a small matrix, a faster direct inversion is used.; For a large (N > 6) symmetric matrix the Bunch-Kaufman diagonal pivoting method; is used while for a large (N > 6) general matrix an LU factorization is performed; using the same algorithm as in the CERNLIB routine; [dinv](https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/f010/top.html). ~~~ {.cpp}; // Invert a NxN matrix. The inverted matrix replace the existing one and returns if the result is successful; bool ret = m.Invert(); // return the inverse matrix of m. If the inversion fails ifail is different than zero; int ifail = 0;; mInv = m.Inverse(ifail);; ~~~. The determinant of a square matrix can be obtained as follows:. ~~~ {.cpp}; double det;; // calculate the determinant modifying the matrix content. Returns if the calculation was successful; bool ret = m.Det(det);; // calculate the determinant using a temporary matrix but preserving the matrix content; bool ret = n.Det2(det);; ~~~. For additional Matrix functionality see the \ref MatVecFunctions page. ",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:8250,Performance,perform,performed,8250,"tor the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the second column from element (0,1) : c2[0] = m(0,1); c2[1] = m(1,1);; SVector2 c2 = m.SubCol<SVector2> (1,0);; // return a sub-matrix 2x2 with the upper left corner at the values (1,1); SMatrix22 subM = m.Sub<SMatrix22> (1,1);; // return the diagonal element in a SVector; SVector3 diag = m.Diagonal();; // return the upper(lower) block of the matrix m; SVector6 vub = m.UpperBlock(); // vub = [ 1, 2, 3, 5, 6, 9 ]; SVector6 vlb = m.LowerBlock(); // vlb = [ 1, 4, 5, 7, 8, 9 ]; ~~~. ### Linear Algebra Functions. Only limited linear algebra functionality is available for SMatrix. It is possible; for squared matrices NxN, to find the inverse or to calculate the determinant.; Different inversion algorithms are used if the matrix is smaller than 6x6 or if it; is symmetric. In the case of a small matrix, a faster direct inversion is used.; For a large (N > 6) symmetric matrix the Bunch-Kaufman diagonal pivoting method; is used while for a large (N > 6) general matrix an LU factorization is performed; using the same algorithm as in the CERNLIB routine; [dinv](https://cern-tex.web.cern.ch/cern-tex/shortwrupsdir/f010/top.html). ~~~ {.cpp}; // Invert a NxN matrix. The inverted matrix replace the existing one and returns if the result is successful; bool ret = m.Invert(); // return the inverse matrix of m. If the inversion fails ifail is different than zero; int ifail = 0;; mInv = m.Inverse(ifail);; ~~~. The determinant of a square matrix can be obtained as follows:. ~~~ {.cpp}; double det;; // calculate the determinant modifying the matrix content. Returns if the calculation was successful; bool ret = m.Det(det);; // calculate the determinant using a temporary matrix but preserving the matrix content; bool ret = n.Det2(det);; ~~~. For additional Matrix functionality see the \ref MatVecFunctions page. ",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:2916,Safety,avoid,avoid,2916,"(and assignment) from a matrix expression, like D = A*B + C. Due to the; expression template technique, no temporary objects are created in this operation. In; the case of an operation like A = A*B + C, a temporary object is needed and it is created; automatically to store the intermediary result in order to preserve the validity of; this operation.; * Constructor from a generic STL-like iterator copying the data referred by the iterator,; following its order. It is both possible to specify the _begin_ and _end_ of the iterator; or the _begin_ and the size. In case of a symmetric matrix, it is required only the; triangular block and the user can specify whether giving a block representing the lower; (default case) or the upper diagonal part.; * Constructor of a symmetric matrix NxN passing a ROOT::Math::SVector with dimension; N*(N+1)/2 containing the lower (or upper) block data elements. Here are some examples on how to create a matrix. We use _typedef's_ in the following examples; to avoid the full C++ names for the matrix classes. Notice that for a general matrix the; representation has the default value, ROOT::Math::MatRepStd, and it is not needed to be; specified. Furthermore, for a general square matrix, the number of column may be as well omitted. ~~~ {.cpp}; // typedef definitions used in the following declarations; typedef ROOT::Math::SMatrix<double,3> SMatrix33;; typedef ROOT::Math::SMatrix<double,2> SMatrix22;; typedef ROOT::Math::SMatrix<double,3,3,ROOT::Math::MatRepSym<double,3> > SMatrixSym3;; typedef ROOT::Math::SVector<double,2> SVector2;; typedef ROOT::Math::SVector<double,3> SVector3;; typedef ROOT::Math::SVector<double,6> SVector6;. SMatrix33 m0; // create a zero 3x3 matrix; // create an 3x3 identity matrix; SMatrix33 i = ROOT::Math::SMatrixIdentity();; double a[9] = {1,2,3,4,5,6,7,8,9}; // input matrix data; SMatrix33 m(a,9); // create a matrix using the a[] data; // this will produce the 3x3 matrix; // ( 1 2 3; // 4 5 6; // 7 8 9 ); ~~~. Example",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:5082,Security,access,accessed,5082,"mmetric matrix; // ( 1 2 4; // 2 3 5; // 4 5 6 ). // create a a general matrix from a symmetric matrix. The opposite will not compile; SMatrix33 m2 = s;; ~~~. Example to create a symmetric matrix from a ROOT::Math::SVector containing the lower/upper data block:. ~~~ {.cpp}; ROOT::Math::SVector<double, 6> v(1,2,3,4,5,6);; SMatrixSym3 s1(v); // lower block (default); // this will produce the symmetric matrix; // ( 1 2 4; // 2 3 5; // 4 5 6 ). SMatrixSym3 s2(v,false); // upper block; // this will produce the symmetric matrix; // ( 1 2 3; // 2 4 5; // 3 5 6 ); ~~~. ### Accessing and Setting Methods. The matrix elements can be set using the _operator()(irow,icol)_, where irow and icol are; the row and column indexes or by using the iterator interface. Notice that the indexes start; from zero and not from one as in FORTRAN. All the matrix elements can be set also by using; the ROOT::Math::SetElements function passing a generic iterator.; The elements can be accessed by these same methods and also by using the; ROOT::Math::SMatrix::apply function. The _apply(i)_ function has exactly the same behavior; for general and symmetric matrices, in contrast to the iterator access methods which behave; differently (it follows the data order). ~~~ {.cpp}; SMatrix33 m;; m(0,0) = 1; // set the element in first row and first column; *(m.begin()+1) = 2; // set the second element (0,1); double d[9]={1,2,3,4,5,6,7,8,9};; m.SetElements(d,d+9); // set the d[] values in m. double x = m(2,1); // return the element in third row and first column; x = m.apply(7); // return the 8-th element (row=2,col=1); x = *(m.begin()+7); // return the 8-th element (row=2,col=1); // symmetric matrices (note the difference in behavior between apply and the iterators); x = *(m.begin()+4) // return the element (row=2,col=1).; x = m.apply(7); // returns again the (row=2,col=1) element; ~~~. There are methods to place and/or retrieve ROOT::Math::SVector objects as rows or columns; in (from) a matrix. In addition one",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:5292,Security,access,access,5292,"s;; ~~~. Example to create a symmetric matrix from a ROOT::Math::SVector containing the lower/upper data block:. ~~~ {.cpp}; ROOT::Math::SVector<double, 6> v(1,2,3,4,5,6);; SMatrixSym3 s1(v); // lower block (default); // this will produce the symmetric matrix; // ( 1 2 4; // 2 3 5; // 4 5 6 ). SMatrixSym3 s2(v,false); // upper block; // this will produce the symmetric matrix; // ( 1 2 3; // 2 4 5; // 3 5 6 ); ~~~. ### Accessing and Setting Methods. The matrix elements can be set using the _operator()(irow,icol)_, where irow and icol are; the row and column indexes or by using the iterator interface. Notice that the indexes start; from zero and not from one as in FORTRAN. All the matrix elements can be set also by using; the ROOT::Math::SetElements function passing a generic iterator.; The elements can be accessed by these same methods and also by using the; ROOT::Math::SMatrix::apply function. The _apply(i)_ function has exactly the same behavior; for general and symmetric matrices, in contrast to the iterator access methods which behave; differently (it follows the data order). ~~~ {.cpp}; SMatrix33 m;; m(0,0) = 1; // set the element in first row and first column; *(m.begin()+1) = 2; // set the second element (0,1); double d[9]={1,2,3,4,5,6,7,8,9};; m.SetElements(d,d+9); // set the d[] values in m. double x = m(2,1); // return the element in third row and first column; x = m.apply(7); // return the 8-th element (row=2,col=1); x = *(m.begin()+7); // return the 8-th element (row=2,col=1); // symmetric matrices (note the difference in behavior between apply and the iterators); x = *(m.begin()+4) // return the element (row=2,col=1).; x = m.apply(7); // returns again the (row=2,col=1) element; ~~~. There are methods to place and/or retrieve ROOT::Math::SVector objects as rows or columns; in (from) a matrix. In addition one can put (get) a sub-matrix as another; ROOT::Math::SMatrix object in a matrix. If the size of the sub-vector or sub-matrix are; larger than the matrix",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md:6282,Testability,assert,assert,6282,"ces, in contrast to the iterator access methods which behave; differently (it follows the data order). ~~~ {.cpp}; SMatrix33 m;; m(0,0) = 1; // set the element in first row and first column; *(m.begin()+1) = 2; // set the second element (0,1); double d[9]={1,2,3,4,5,6,7,8,9};; m.SetElements(d,d+9); // set the d[] values in m. double x = m(2,1); // return the element in third row and first column; x = m.apply(7); // return the 8-th element (row=2,col=1); x = *(m.begin()+7); // return the 8-th element (row=2,col=1); // symmetric matrices (note the difference in behavior between apply and the iterators); x = *(m.begin()+4) // return the element (row=2,col=1).; x = m.apply(7); // returns again the (row=2,col=1) element; ~~~. There are methods to place and/or retrieve ROOT::Math::SVector objects as rows or columns; in (from) a matrix. In addition one can put (get) a sub-matrix as another; ROOT::Math::SMatrix object in a matrix. If the size of the sub-vector or sub-matrix are; larger than the matrix size a static assert ( a compilation error) is produced. The non-const. ~~~ {.cpp}. SMatrix33 m;; SVector2 v2(1,2);; // place a vector of size 2 in the first row starting from element (0,1) : m(0,1) = v2[0]; m.Place_in_row(v2,0,1);; // place the vector in the second column from (0,1) : m(0,1) = v2[0]; m.Place in_col(v2,0,1);; SMatrix22 m2;; // place the sub-matrix m2 in m starting from the element (1,1) : m(1,1) = m2(0,0); m.Place_at(m2,1,1);; SVector3 v3(1,2,3);; // set v3 as the diagonal elements of m : m(i,i) = v3[i] for i=0,1,2; m.SetDiagonal(v3); ~~~. The const methods retrieving contents (getting slices of a matrix) are:. ~~~ {.cpp}; a = {1,2,3,4,5,6,7,8,9};; SMatrix33 m(a,a+9);; SVector3 irow = m.Row(0); // return as vector the first matrix row; SVector3 jcol = m.Col(1); // return as vector the second matrix column; // return a slice of the first row from element (0,1) : r2[0] = m(0,1); r2[1] = m(0,2); SVector2 r2 = m.SubRow<SVector2> (0,1);; // return a slice of the sec",MatchSource.DOCS,math/smatrix/doc/SMatrixClass.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SMatrixClass.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:310,Availability,avail,available,310,"\page SVectorDoc SVector Class Properties. The template ROOT::Math::SVector class has 2 template parameters which define, at compile; time, its properties. These are:. * type of the contained elements, for example _float_ or double.; * size of the vector. ### Creating a Vector. The following constructors are available to create a vector:. * Default constructor for a zero vector (all elements equal to zero); * Constructor (and assignment) from a vector expression, like v = p*q + w. Due to the; expression template technique, no temporary objects are created in this operation.; * Construct a vector passing directly the elements. This is possible only for vector up to size 10.; * Constructor from an iterator copying the data referred by the iterator. It is possible; to specify the _begin_ and _end_ of the iterator or the _begin_ and the size. Note that; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // se",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:2434,Availability,error,error,2434,"at; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element ioff, v[ioff + i] = w[i]; v.Place_at(w,ioff);; // return a sub-vector of size M starting from v[ioff]: w[i] = v[ioff + i]; w = v.Sub < SVector>double,M> > (ioff);; ~~~. For additional Vector functionality see the \ref MatVecFunctions page; ",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:2543,Availability,error,error,2543,"at; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element ioff, v[ioff + i] = w[i]; v.Place_at(w,ioff);; // return a sub-vector of size M starting from v[ioff]: w[i] = v[ioff + i]; w = v.Sub < SVector>double,M> > (ioff);; ~~~. For additional Vector functionality see the \ref MatVecFunctions page; ",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:1515,Integrability,interface,interface,1515,"n, like v = p*q + w. Due to the; expression template technique, no temporary objects are created in this operation.; * Construct a vector passing directly the elements. This is possible only for vector up to size 10.; * Constructor from an iterator copying the data referred by the iterator. It is possible; to specify the _begin_ and _end_ of the iterator or the _begin_ and the size. Note that; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; ",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:1615,Performance,perform,performed,1615,"he elements. This is possible only for vector up to size 10.; * Constructor from an iterator copying the data referred by the iterator. It is possible; to specify the _begin_ and _end_ of the iterator or the _begin_ and the size. Note that; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element iof",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:1798,Security,access,accessed,1798,"r or the _begin_ and the size. Note that; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element ioff, v[ioff + i] = w[i]; v.Place_at(w,ioff);; // return a sub-vector of size M starting from v[ioff]: w[i] = v[ioff + i]; w = v.Sub < SVector>double,M> > (ioff);; ~~~. For additional Vector functionalit",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md:2411,Testability,assert,assert,2411,"at; for the Vector the iterator is not generic and must be of type _T*,_ where T is the type; of the contained elements. Here are some examples on how to create a vector. In the following we assume that we are; using the namespace ROOT::Math. ~~~ {.cpp}; SVector<double,N> v; // create a vector of size N, v[i]=0; SVector<double,3> v(1,2,3); // create a vector of size 3, v[0]=1,v[1]=2,v[2]=3; double a[9] = {1,2,3,4,5,6,7,8,9}; // input data; SVector<double,9> v(a,9); // create a vector using the a[] data; ~~~. ### Accessing and Setting Methods. The single vector elements can be set or retrieved using the _operator[i]_ , _operator(i)_; or the iterator interface. Notice that the index starts from zero and not from one as in; FORTRAN. Also no check is performed on the passed index. Furthermore, all the matrix; elements can be set also by using the ROOT::SVector::SetElements function passing a generic; iterator. The elements can be accessed also by using the ROOT::Math::SVector::apply(i) function. ~~~ {.cpp}; v[0] = 1; // set the first element; v(1) = 2; // set the second element; *(v.begin()+3) = 3; // set the third element; // set vector elements from a std::vector<double>::iterator</double>; std::vector <double> w(3);; v.SetElements(w.begin(),w.end());. double x = m(i); // return the i-th element; x = m.apply(i); // return the i-th element; x = *(m.begin()+i); // return the i-th element; ~~~. In addition there are methods to place a sub-vector in a vector. If the size of the the; sub-vector is larger than the vector size a static assert ( a compilation error) is produced. ~~~ {.cpp}; SVector<double,N> v;; SVector<double,M> w; // M <= N otherwise a compilation error is obtained later; // place a vector of size M starting from element ioff, v[ioff + i] = w[i]; v.Place_at(w,ioff);; // return a sub-vector of size M starting from v[ioff]: w[i] = v[ioff + i]; w = v.Sub < SVector>double,M> > (ioff);; ~~~. For additional Vector functionality see the \ref MatVecFunctions page; ",MatchSource.DOCS,math/smatrix/doc/SVector.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/smatrix/doc/SVector.md
https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md:553,Availability,avail,available,553,"\defgroup Unuran Unuran; \ingroup Math; \brief Universal Non Uniform Random number generator for generating non uniform pseudo-random numbers. UNU.RAN, (Universal Non Uniform Random number generator for generating non uniform pseudo-random numbers); is an ANSI C library licensed under GPL.<br>; It contains universal (also called automatic or black-box) algorithms that can generate random numbers from; large classes of continuous or discrete distributions, and also from practically all standard distributions.; An extensive online documentation are available at the (UNU.RAN Web Site)[http://statistik.wu-wien.ac.at/unuran/]. New classes have been introduced to use the UNU.RAN C library from ROOT and C++ from ROOT and using C++ objects.; To use UNU.RAN one needs always an instance of the class **TUnuran**.; It can then be used in two distinct ways:; - using the UNU.RAN native string API for pre-defined distributions (see<a href=""http://statistik.wu-wien.ac.at/unuran/doc/unuran.html#StringAPI""> UNU.RAN documentation</a> for the string API):. ~~~{.cpp}; TUnuran unr;; //initialize unuran to generate normal random numbers using a ""arou"" method; unr.Init(""normal()"",""method=arou"");; //......; // sample distributions N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();. ~~~. - Using a distribution object. We have then the following cases depending on the dimension and the distribution object. - For 1D distribution the class **TUnuranContDist** must be used.; - A **TUnuranContDist** object can be created from a function; providing the pdf (probability density function) and optionally one providing the derivative of the pdf.; - If the derivative is not provided and the generation method requires it, then it is estimated numerically.; - The user can optionally provide the; - cdf (cumulative distribution function) via the **TUnuranContDist::SetCdf** function,; - the mode via **TUnuranContDist::SetMode**,; - the domain via **TUnuranContDist::",MatchSource.DOCS,math/unuran/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md:5525,Availability,avail,available,5525,"*TUnuranEmpDist** must be used.; In this case one can generate random numbers from a set of data (un-binned) in one or multi-dimension or; from a set of binned data in one dimension (similar to TH1::GetRandom() ).; - For unbin data the parent distribution is estimated by UNU.RAN using a gaussian kernel smoothing algorithm.; One can create the distribution class directly from a vector of data or from the buffer of TH1. ~~~~{.cpp}; // create distribution from a set of data 1D; // vdata is an std::vector containing the data; TUnuranEmpDist dist( vdata.begin(),vdata.end());; unr.Init(dist);; // sample N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();; ~~~~. - In the case of multi-dimension empirical distributions one needs to pass in addition to the iterators, the data dimension. It is assumed that the data are stored in the vector in this order : `(x0,y0,...),(x1,y1,....)`. - For binned data (only one dimensional data are supported) one uses directly the histogram. ~~~{.cpp}; // create an empirical distribution from an histogram; // if the histogram has a buffer one must use TUnuranEmpDist(h1,false); TH1 * h1 = ... // histogram pointer; TUnuranEmpDist binDist( h1);; unr.Init(binDist);; // sample N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();; ~~~. - This is equivalent to TH1::GetRandom(), but sampling is faster, therefore, since it requires some initialization time,; it becomes convenient when generating a large sample of random numbers. Functionality is also provided via the C++ classes for using a different random number generator by passing a; TRandom pointer when constructing the TUnuran class (by default the ROOT gRandom is passed to UNURAN). The (UNU.RAN documentation)[http://statistik.wu-wien.ac.at/unuran/doc/unuran.html#Top] provides a detailed; description of all the available methods and the possible options which one can pass to UNU.RAN for the various distributions.; ",MatchSource.DOCS,math/unuran/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md:422,Deployability,continuous,continuous,422,"\defgroup Unuran Unuran; \ingroup Math; \brief Universal Non Uniform Random number generator for generating non uniform pseudo-random numbers. UNU.RAN, (Universal Non Uniform Random number generator for generating non uniform pseudo-random numbers); is an ANSI C library licensed under GPL.<br>; It contains universal (also called automatic or black-box) algorithms that can generate random numbers from; large classes of continuous or discrete distributions, and also from practically all standard distributions.; An extensive online documentation are available at the (UNU.RAN Web Site)[http://statistik.wu-wien.ac.at/unuran/]. New classes have been introduced to use the UNU.RAN C library from ROOT and C++ from ROOT and using C++ objects.; To use UNU.RAN one needs always an instance of the class **TUnuran**.; It can then be used in two distinct ways:; - using the UNU.RAN native string API for pre-defined distributions (see<a href=""http://statistik.wu-wien.ac.at/unuran/doc/unuran.html#StringAPI""> UNU.RAN documentation</a> for the string API):. ~~~{.cpp}; TUnuran unr;; //initialize unuran to generate normal random numbers using a ""arou"" method; unr.Init(""normal()"",""method=arou"");; //......; // sample distributions N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();. ~~~. - Using a distribution object. We have then the following cases depending on the dimension and the distribution object. - For 1D distribution the class **TUnuranContDist** must be used.; - A **TUnuranContDist** object can be created from a function; providing the pdf (probability density function) and optionally one providing the derivative of the pdf.; - If the derivative is not provided and the generation method requires it, then it is estimated numerically.; - The user can optionally provide the; - cdf (cumulative distribution function) via the **TUnuranContDist::SetCdf** function,; - the mode via **TUnuranContDist::SetMode**,; - the domain via **TUnuranContDist::",MatchSource.DOCS,math/unuran/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md:1390,Integrability,depend,depending,1390,"rom; large classes of continuous or discrete distributions, and also from practically all standard distributions.; An extensive online documentation are available at the (UNU.RAN Web Site)[http://statistik.wu-wien.ac.at/unuran/]. New classes have been introduced to use the UNU.RAN C library from ROOT and C++ from ROOT and using C++ objects.; To use UNU.RAN one needs always an instance of the class **TUnuran**.; It can then be used in two distinct ways:; - using the UNU.RAN native string API for pre-defined distributions (see<a href=""http://statistik.wu-wien.ac.at/unuran/doc/unuran.html#StringAPI""> UNU.RAN documentation</a> for the string API):. ~~~{.cpp}; TUnuran unr;; //initialize unuran to generate normal random numbers using a ""arou"" method; unr.Init(""normal()"",""method=arou"");; //......; // sample distributions N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();. ~~~. - Using a distribution object. We have then the following cases depending on the dimension and the distribution object. - For 1D distribution the class **TUnuranContDist** must be used.; - A **TUnuranContDist** object can be created from a function; providing the pdf (probability density function) and optionally one providing the derivative of the pdf.; - If the derivative is not provided and the generation method requires it, then it is estimated numerically.; - The user can optionally provide the; - cdf (cumulative distribution function) via the **TUnuranContDist::SetCdf** function,; - the mode via **TUnuranContDist::SetMode**,; - the domain via **TUnuranContDist::SetDomain** for generating numbers in a restricted region,; - the area below the pdf via **TUnuranContDist::SetPdfArea**. Some of this information is required depending on the chosen UNURAN generation method. ~~~~{.cpp}; //1D case: create a distribution from two TF1 object pointers pdfFunc; TUnuranContDist dist( pdfFunc);; //initialize unuran passing the distribution and a string defining the meth",MatchSource.DOCS,math/unuran/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md:2160,Integrability,depend,depending,2160,"normal()"",""method=arou"");; //......; // sample distributions N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();. ~~~. - Using a distribution object. We have then the following cases depending on the dimension and the distribution object. - For 1D distribution the class **TUnuranContDist** must be used.; - A **TUnuranContDist** object can be created from a function; providing the pdf (probability density function) and optionally one providing the derivative of the pdf.; - If the derivative is not provided and the generation method requires it, then it is estimated numerically.; - The user can optionally provide the; - cdf (cumulative distribution function) via the **TUnuranContDist::SetCdf** function,; - the mode via **TUnuranContDist::SetMode**,; - the domain via **TUnuranContDist::SetDomain** for generating numbers in a restricted region,; - the area below the pdf via **TUnuranContDist::SetPdfArea**. Some of this information is required depending on the chosen UNURAN generation method. ~~~~{.cpp}; //1D case: create a distribution from two TF1 object pointers pdfFunc; TUnuranContDist dist( pdfFunc);; //initialize unuran passing the distribution and a string defining the method; unr.Init(dist, ""method=hinv"");; // sample distribution N times (generate N random numbers); for (int i = 0; i &lt; N; ++i); double x = unr.Sample();; ~~~~. - For multi-dimensional distribution the class **TUnuranMultiContDist** must be used.; In this case only the multi-dimensional pdf is required. ~~~~{.cpp}; //Multi-Dim case from a TF1 (or TF2 or TF3) object describing a multi-dimensional function; TUnuranMultiContDist dist( pdfFuncMulti);; // the recommended method for multi-dimensional function is ""hitro""; unr.Init(dist, ""method=hitro"");; // sample distribution N times (generate N random numbers); double x[NDIM];; for (int i = 0; i &lt; N; ++i); unr.SampleMulti(x);; ~~~~. - For discrete distribution the class **TUnuranDiscrDist** must be used.; Th",MatchSource.DOCS,math/unuran/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/eg/doc/index.md:65,Integrability,interface,interface,65,"\defgroup eg EG; \ingroup montecarlo; \brief Particle Data Group interface. These classes are interfaces to the Particle Data Group (PDG); data base, a static and dynamic particle class and a decay class framework. These classes are extensively used in the VMC (Virtual Monte Carlo).; See more details in the \ref montecarlo page.; ",MatchSource.DOCS,montecarlo/eg/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/eg/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/eg/doc/index.md:94,Integrability,interface,interfaces,94,"\defgroup eg EG; \ingroup montecarlo; \brief Particle Data Group interface. These classes are interfaces to the Particle Data Group (PDG); data base, a static and dynamic particle class and a decay class framework. These classes are extensively used in the VMC (Virtual Monte Carlo).; See more details in the \ref montecarlo page.; ",MatchSource.DOCS,montecarlo/eg/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/eg/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md:447,Availability,avail,available,447,"\defgroup pythia8 Pythia8; \ingroup montecarlo; \brief The Pythia8 interface. The pythia8 directory is an interface to the C++ version of Pythia 8.1 event generators, ; written by T.Sjostrand.; The user is assumed to be familiar with the Pythia8 package.; Only a basic interface to Pythia8 is provided. Because Pythia8 is; also written in C++, its functions/classes can be called directly from a; compiled C++ script. To call Pythia functions not available in this interface a dictionary must; be generated. See pythia8.C for an example of use from ROOT interpreter. See also the [complete Pythia8 documentation](http://home.thep.lu.se/~torbjorn/pythiaaux/recent.html); ",MatchSource.DOCS,montecarlo/pythia8/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md:67,Integrability,interface,interface,67,"\defgroup pythia8 Pythia8; \ingroup montecarlo; \brief The Pythia8 interface. The pythia8 directory is an interface to the C++ version of Pythia 8.1 event generators, ; written by T.Sjostrand.; The user is assumed to be familiar with the Pythia8 package.; Only a basic interface to Pythia8 is provided. Because Pythia8 is; also written in C++, its functions/classes can be called directly from a; compiled C++ script. To call Pythia functions not available in this interface a dictionary must; be generated. See pythia8.C for an example of use from ROOT interpreter. See also the [complete Pythia8 documentation](http://home.thep.lu.se/~torbjorn/pythiaaux/recent.html); ",MatchSource.DOCS,montecarlo/pythia8/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md:106,Integrability,interface,interface,106,"\defgroup pythia8 Pythia8; \ingroup montecarlo; \brief The Pythia8 interface. The pythia8 directory is an interface to the C++ version of Pythia 8.1 event generators, ; written by T.Sjostrand.; The user is assumed to be familiar with the Pythia8 package.; Only a basic interface to Pythia8 is provided. Because Pythia8 is; also written in C++, its functions/classes can be called directly from a; compiled C++ script. To call Pythia functions not available in this interface a dictionary must; be generated. See pythia8.C for an example of use from ROOT interpreter. See also the [complete Pythia8 documentation](http://home.thep.lu.se/~torbjorn/pythiaaux/recent.html); ",MatchSource.DOCS,montecarlo/pythia8/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md:269,Integrability,interface,interface,269,"\defgroup pythia8 Pythia8; \ingroup montecarlo; \brief The Pythia8 interface. The pythia8 directory is an interface to the C++ version of Pythia 8.1 event generators, ; written by T.Sjostrand.; The user is assumed to be familiar with the Pythia8 package.; Only a basic interface to Pythia8 is provided. Because Pythia8 is; also written in C++, its functions/classes can be called directly from a; compiled C++ script. To call Pythia functions not available in this interface a dictionary must; be generated. See pythia8.C for an example of use from ROOT interpreter. See also the [complete Pythia8 documentation](http://home.thep.lu.se/~torbjorn/pythiaaux/recent.html); ",MatchSource.DOCS,montecarlo/pythia8/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md:465,Integrability,interface,interface,465,"\defgroup pythia8 Pythia8; \ingroup montecarlo; \brief The Pythia8 interface. The pythia8 directory is an interface to the C++ version of Pythia 8.1 event generators, ; written by T.Sjostrand.; The user is assumed to be familiar with the Pythia8 package.; Only a basic interface to Pythia8 is provided. Because Pythia8 is; also written in C++, its functions/classes can be called directly from a; compiled C++ script. To call Pythia functions not available in this interface a dictionary must; be generated. See pythia8.C for an example of use from ROOT interpreter. See also the [complete Pythia8 documentation](http://home.thep.lu.se/~torbjorn/pythiaaux/recent.html); ",MatchSource.DOCS,montecarlo/pythia8/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/montecarlo/pythia8/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/index.md:79,Integrability,protocol,protocol,79,\defgroup http HTTP server; \brief THttpServer-related classes to provide HTTP protocol to ROOT application; ,MatchSource.DOCS,net/doc/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1902,Deployability,configurat,configuration,1902,"f specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:808",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3515,Deployability,continuous,continuously,3515,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3628,Deployability,update,updated,3628,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1554,Energy Efficiency,efficient,efficiently,1554,"erlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The id",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3557,Energy Efficiency,monitor,monitoring,3557,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:610,Integrability,protocol,protocol,610,"## Networking Libraries. A new class TS3WebFile has been introduced. The new class TS3WebFile is; an extension of TWebFile and belongs to the net module. The name; TS3WebFile reflects better the fact that this solution is intended to be; generic to several S3 servers and not limited to Amazon's, in addition; to the fact that it actually extends the capabilities of TWebFile. Compared to the current support of S3 in ROOT (basically the class; TAS3File), the modifications include the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:339,Modifiability,extend,extends,339,"## Networking Libraries. A new class TS3WebFile has been introduced. The new class TS3WebFile is; an extension of TWebFile and belongs to the net module. The name; TS3WebFile reflects better the fact that this solution is intended to be; generic to several S3 servers and not limited to Amazon's, in addition; to the fact that it actually extends the capabilities of TWebFile. Compared to the current support of S3 in ROOT (basically the class; TAS3File), the modifications include the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:756,Modifiability,extend,extend,756,"## Networking Libraries. A new class TS3WebFile has been introduced. The new class TS3WebFile is; an extension of TWebFile and belongs to the net module. The name; TS3WebFile reflects better the fact that this solution is intended to be; generic to several S3 servers and not limited to Amazon's, in addition; to the fact that it actually extends the capabilities of TWebFile. Compared to the current support of S3 in ROOT (basically the class; TAS3File), the modifications include the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1007,Modifiability,variab,variables,1007,"## Networking Libraries. A new class TS3WebFile has been introduced. The new class TS3WebFile is; an extension of TWebFile and belongs to the net module. The name; TS3WebFile reflects better the fact that this solution is intended to be; generic to several S3 servers and not limited to Amazon's, in addition; to the fact that it actually extends the capabilities of TWebFile. Compared to the current support of S3 in ROOT (basically the class; TAS3File), the modifications include the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1485,Modifiability,variab,variables,1485,"de the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plug",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1863,Modifiability,config,configuring,1863,"f specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:808",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1902,Modifiability,config,configuration,1902,"f specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:808",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:2003,Modifiability,config,configurable,2003,"f specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:808",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:2476,Modifiability,plugin,plugin,2476,"s.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If t",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1566,Safety,detect,detect,1566,"erlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The id",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:1356,Security,access,accessKey,1356,"bFile. Compared to the current support of S3 in ROOT (basically the class; TAS3File), the modifications include the improvements below:. - add support for using HTTPS : you can use different schemas for; specifying the underlying transport protocol to use ""s3:"",; ""s3http:"", ""s3https:"" [""s3"" uses HTTPS]. The current schema, namely; ""as3:"", is supported for backwards compatibility.; - extend support for other S3 service providers that do not offer the; virtual hosting functionality (currently only Amazon offers this).; - support the possibility of specifying user credentials on a per-file; basis or for all S3 files via environment variables.; - honor the ""NOPROXY"" option when specified in the constructor.; - exploit the capability of the S3 file server to provide partial; content responses to multi-range HTTP requests. Here are some examples of usages from the end user perspective:. ``` {.cpp}; TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"", ""AUTH=<accessKey>:<secretKey> NOPROXY""); TFile* f = TFile::Open(""s3://s3.amazonaws.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File clas",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:2459,Security,access,accessed,2459,"s.com/mybucket/path/to/my/file"") // Uses environmental variables for retrieving credentials; ```. Limitations:. - we cannot efficiently detect that a S3 server is able to respond to; multi-range HTTP GET requests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If t",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:2635,Security,access,access,2635,"equests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated.",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md:3147,Security,access,access,3147,"uests. Some servers, such as Amazon's,; respond to such kind of requests with the whole file contents. Other; servers, such as Huawei's, respond with the exact partial content; requested. Therefore, I added the possibility of configuring the; behavior via the ROOT configuration file: the identity of the; servers known to correctly support multi-range requests is; configurable. If the server is known to support this feature, ROOT; will send multi-range requests, otherwise it will issue multiple; single-range GET requests, which is also the default behavior.; - currently the virtual host syntax:; ""s3://mybucket.s3.amazonaws.com/path/to/my/file"" is not supported; but can be added if this is considered useful. The TAS3File class will be removed and should not have been used; directly by users anyway as it was only accessed via the plugin manager; in TFile::Open(). ### New HTTP Server package. A new HTTP Server package has been introduced. The idea behind such server is to provide direct access to the data from a running ROOT application. Any object can be streamed when requested and delivered to the browser. ##### Starting HTTP server. To start http server, at any time create instance; of the **`THttpServer`** class like:. ``` {.cpp}; serv = new THttpServer(""http:8080"");; ```. This will start civetweb-based http server on port 8080.; Then, one should be able to open address ""http://localhost:8080""; in any modern browser and browse objects created in application. By default, the server can access files, canvases and histograms via gROOT. All such objects can be displayed with JSRootIO graphics. At any time one could register other objects with the command:. ``` {.cpp}; TGraph* gr = new TGraph(10);; gr->SetName(""gr1"");; serv->Register(""graphs/subfolder"", gr);; ```. If the object content is changing in the application, like for example histograms being continuously filled, one could enable the monitoring flag in the browser, then the object view will be regularly updated. ",MatchSource.DOCS,net/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md:3491,Deployability,release,release,3491,"me; * Ponnuvel Palaniyappan; * qinch; * qinchao; * Radoslaw Zarzynski; * Red54; * Retallack Mark mark.retallack; * Richard Screene; * Rimas Misevi-ius; * Rinat Dobrokhotov; * ryankopf; * Sage Weil; * Sangwhan Moon; * Saumitra Vikram; * Scott Nations; * Sebastien Jodogne; * Sergey Linev; * sgmesservey; * shantanugadgil; * Sherwyn Sen; * shreyajaggi8; * Simon Hailes; * slidertom; * SpaceIm; * SpaceLord; * Stefan Codrescu; * sunfch; * suzukibitman; * Smal Rasmussen; * Tamotsu Kanoh; * thewaterymoon; * Thiago Macedo; * THILMANT, Bernard; * Thomas Davis; * Thomas Klausner; * Thorsten Horstmann; * Tim Gates; * Tim Hudson; * tnoho; * Tom Deblauwe; * Tomas Andrle; * Tomasz Gorochowik; * Toni Wilk; * Torben Jonas; * Uilian Ries; * Ulrich Hertlein; * Walt Steverson; * wangli28; * webxer; * William Greathouse; * Wolfram Rsler; * xeoshow; * xtne6f; * Yehuda Sadeh; * Yury Z; * zhen.wang. and others. # Mongoose Contributors; CivetWeb is based on the Mongoose code. The following users contributed to the original Mongoose release between 2010 and 2013. This list was generated from the Mongoose GIT logs. It does not contain contributions from the Mongoose mailing list. There is no record for contributors prior to 2010. * Sergey Lyubka; * Arnout Vandecappelle (Essensium/Mind); * Benot Amiaux; * Cody Hanson; * Colin Leitner; * Daniel Oaks; * Eric Bakan; * Erik Oomen; * Filipp Kovalev; * Ger Hobbelt; * Hendrik Polczynski; * Henrique Mendona; * Igor Okulist; * Jay; * Joe Mucchiello; * John Safranek; * Joseph Mainwaring; * Jos Miguel Gonalves; * KIU Shueng Chuan; * Katerina Blinova; * Konstantin Sorokin; * Marin Atanasov Nikolov; * Matt Healy; * Miguel Morales; * Mikhail Nikalyukin; * MikieMorales; * Mitch Hendrickson; * Nigel Stewart; * Pavel; * Pavel Khlebovich; * Rogerz Zhang; * Sebastian Reinhard; * Stefan Doehla; * Thileepan; * abadc0de; * arvidn; * bick; * ff.feng; * jmucchiello; * jwang; * lsm; * migal; * mlamb; * nullable.type; * shantanugadgil; * tayS; * test; * valenok; ",MatchSource.DOCS,net/http/civetweb/CREDITS.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md:3568,Testability,log,logs,3568,"me; * Ponnuvel Palaniyappan; * qinch; * qinchao; * Radoslaw Zarzynski; * Red54; * Retallack Mark mark.retallack; * Richard Screene; * Rimas Misevi-ius; * Rinat Dobrokhotov; * ryankopf; * Sage Weil; * Sangwhan Moon; * Saumitra Vikram; * Scott Nations; * Sebastien Jodogne; * Sergey Linev; * sgmesservey; * shantanugadgil; * Sherwyn Sen; * shreyajaggi8; * Simon Hailes; * slidertom; * SpaceIm; * SpaceLord; * Stefan Codrescu; * sunfch; * suzukibitman; * Smal Rasmussen; * Tamotsu Kanoh; * thewaterymoon; * Thiago Macedo; * THILMANT, Bernard; * Thomas Davis; * Thomas Klausner; * Thorsten Horstmann; * Tim Gates; * Tim Hudson; * tnoho; * Tom Deblauwe; * Tomas Andrle; * Tomasz Gorochowik; * Toni Wilk; * Torben Jonas; * Uilian Ries; * Ulrich Hertlein; * Walt Steverson; * wangli28; * webxer; * William Greathouse; * Wolfram Rsler; * xeoshow; * xtne6f; * Yehuda Sadeh; * Yury Z; * zhen.wang. and others. # Mongoose Contributors; CivetWeb is based on the Mongoose code. The following users contributed to the original Mongoose release between 2010 and 2013. This list was generated from the Mongoose GIT logs. It does not contain contributions from the Mongoose mailing list. There is no record for contributors prior to 2010. * Sergey Lyubka; * Arnout Vandecappelle (Essensium/Mind); * Benot Amiaux; * Cody Hanson; * Colin Leitner; * Daniel Oaks; * Eric Bakan; * Erik Oomen; * Filipp Kovalev; * Ger Hobbelt; * Hendrik Polczynski; * Henrique Mendona; * Igor Okulist; * Jay; * Joe Mucchiello; * John Safranek; * Joseph Mainwaring; * Jos Miguel Gonalves; * KIU Shueng Chuan; * Katerina Blinova; * Konstantin Sorokin; * Marin Atanasov Nikolov; * Matt Healy; * Miguel Morales; * Mikhail Nikalyukin; * MikieMorales; * Mitch Hendrickson; * Nigel Stewart; * Pavel; * Pavel Khlebovich; * Rogerz Zhang; * Sebastian Reinhard; * Stefan Doehla; * Thileepan; * abadc0de; * arvidn; * bick; * ff.feng; * jmucchiello; * jwang; * lsm; * migal; * mlamb; * nullable.type; * shantanugadgil; * tayS; * test; * valenok; ",MatchSource.DOCS,net/http/civetweb/CREDITS.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md:4449,Testability,test,test,4449,"me; * Ponnuvel Palaniyappan; * qinch; * qinchao; * Radoslaw Zarzynski; * Red54; * Retallack Mark mark.retallack; * Richard Screene; * Rimas Misevi-ius; * Rinat Dobrokhotov; * ryankopf; * Sage Weil; * Sangwhan Moon; * Saumitra Vikram; * Scott Nations; * Sebastien Jodogne; * Sergey Linev; * sgmesservey; * shantanugadgil; * Sherwyn Sen; * shreyajaggi8; * Simon Hailes; * slidertom; * SpaceIm; * SpaceLord; * Stefan Codrescu; * sunfch; * suzukibitman; * Smal Rasmussen; * Tamotsu Kanoh; * thewaterymoon; * Thiago Macedo; * THILMANT, Bernard; * Thomas Davis; * Thomas Klausner; * Thorsten Horstmann; * Tim Gates; * Tim Hudson; * tnoho; * Tom Deblauwe; * Tomas Andrle; * Tomasz Gorochowik; * Toni Wilk; * Torben Jonas; * Uilian Ries; * Ulrich Hertlein; * Walt Steverson; * wangli28; * webxer; * William Greathouse; * Wolfram Rsler; * xeoshow; * xtne6f; * Yehuda Sadeh; * Yury Z; * zhen.wang. and others. # Mongoose Contributors; CivetWeb is based on the Mongoose code. The following users contributed to the original Mongoose release between 2010 and 2013. This list was generated from the Mongoose GIT logs. It does not contain contributions from the Mongoose mailing list. There is no record for contributors prior to 2010. * Sergey Lyubka; * Arnout Vandecappelle (Essensium/Mind); * Benot Amiaux; * Cody Hanson; * Colin Leitner; * Daniel Oaks; * Eric Bakan; * Erik Oomen; * Filipp Kovalev; * Ger Hobbelt; * Hendrik Polczynski; * Henrique Mendona; * Igor Okulist; * Jay; * Joe Mucchiello; * John Safranek; * Joseph Mainwaring; * Jos Miguel Gonalves; * KIU Shueng Chuan; * Katerina Blinova; * Konstantin Sorokin; * Marin Atanasov Nikolov; * Matt Healy; * Miguel Morales; * Mikhail Nikalyukin; * MikieMorales; * Mitch Hendrickson; * Nigel Stewart; * Pavel; * Pavel Khlebovich; * Rogerz Zhang; * Sebastian Reinhard; * Stefan Doehla; * Thileepan; * abadc0de; * arvidn; * bick; * ff.feng; * jmucchiello; * jwang; * lsm; * migal; * mlamb; * nullable.type; * shantanugadgil; * tayS; * test; * valenok; ",MatchSource.DOCS,net/http/civetweb/CREDITS.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/CREDITS.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:549,Energy Efficiency,charge,charge,549,"ALL LICENSES; =====. This document includes several copyright licenses for different; aspects of the software. Not all licenses may apply depending; on the features chosen. Civetweb License; -----. ### Included with all features. > Copyright (c) 2013-2021 The CivetWeb developers ([CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md)); >; > Copyright (c) 2004-2013 Sergey Lyubka; >; > Copyright (c) 2013 No Face Press, LLC (Thomas Davis); >; > Copyright (c) 2013 F-Secure Corporation; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, pu",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:1767,Energy Efficiency,charge,charge,1767,"e shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. SQLite3 License; ------. ### Included only if built with Lua and SQLite support. http://www.sqlite.org/copyright.html. > 2001-09-15; >; > The author disclaims copyright to this source code. In place of; > a legal notice",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:3567,Energy Efficiency,charge,charge,3567," THE SOFTWARE. SQLite3 License; ------. ### Included only if built with Lua and SQLite support. http://www.sqlite.org/copyright.html. > 2001-09-15; >; > The author disclaims copyright to this source code. In place of; > a legal notice, here is a blessing:; >; > May you do good and not evil.; > May you find forgiveness for yourself and forgive others.; > May you share freely, never taking more than you give. lsqlite3 License; ------. ### Included only if built with Lua and SQLite support. > Copyright (C) 2002-2016 Tiago Dionizio, Doug Currie; > All rights reserved.; > Author : Tiago Dionizio <tiago.dionizio@ist.utl.pt>; > Author : Doug Currie <doug.currie@alum.mit.edu>; > Library : lsqlite3 - an SQLite 3 database binding for Lua 5; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua File System License; ------. ### Included only if built with Lua support. https://github.com/keplerproject/luafilesystem/blob/master/LICENSE. > Copyright  2003-2020 Kepler Project.;",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:4828,Energy Efficiency,charge,charge,4828,"tantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua File System License; ------. ### Included only if built with Lua support. https://github.com/keplerproject/luafilesystem/blob/master/LICENSE. > Copyright  2003-2020 Kepler Project.; >; > Permission is hereby granted, free of charge, to any person; > obtaining a copy of this software and associated documentation; > files (the ""Software""), to deal in the Software without; > restriction, including without limitation the rights to use, copy,; > modify, merge, publish, distribute, sublicense, and/or sell copies; > of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be; > included in all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,; > EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF; > MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND; > NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS; > BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN; > ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN; > CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; > SOFTWARE. LuaXML License; ------. ### Included only if built with Lua and LuaXML support. Version 1.8.0 (Lua 5.2), 2013-06-10 by Gerald Franz, eludi.net. Modified and extended 2015 by Bernhard Nortmann, https://github.com/n1t",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:6497,Energy Efficiency,charge,charge,6497," OTHERWISE, ARISING FROM, OUT OF OR IN; > CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; > SOFTWARE. LuaXML License; ------. ### Included only if built with Lua and LuaXML support. Version 1.8.0 (Lua 5.2), 2013-06-10 by Gerald Franz, eludi.net. Modified and extended 2015 by Bernhard Nortmann, https://github.com/n1tehawk/LuaXML  version 2.0.x, compatible with Lua 5.1 to 5.3 and LuaJIT. > LuaXML License; >; > LuaXml is licensed under the terms of the MIT license reproduced below,; > the same as Lua itself. This means that LuaXml is free software and can be; > used for both academic and commercial purposes at absolutely no cost.; >; > Copyright (C) 2007-2013 Gerald Franz, eludi.net; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Duktape License; ------. ### Included only if built with Duktape support. https://github.com/svaarala/duktape/blob/master/LICENSE.txt. > ===============; > Duktape license; > ===============; >; > (http://opensource.or",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:7873,Energy Efficiency,charge,charge,7873,"OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Duktape License; ------. ### Included only if built with Duktape support. https://github.com/svaarala/duktape/blob/master/LICENSE.txt. > ===============; > Duktape license; > ===============; >; > (http://opensource.org/licenses/MIT); >; > Copyright (c) 2013-2017 by Duktape authors (see AUTHORS.rst); >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. zlib License; ------. ### Included only if built with zlib support. https://www.zlib.net/zlib_license.html. > zlib.h -- interface of the 'zlib' general purpose compression library; > version 1.2.11, January 15th, 2017",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:138,Integrability,depend,depending,138,"ALL LICENSES; =====. This document includes several copyright licenses for different; aspects of the software. Not all licenses may apply depending; on the features chosen. Civetweb License; -----. ### Included with all features. > Copyright (c) 2013-2021 The CivetWeb developers ([CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md)); >; > Copyright (c) 2004-2013 Sergey Lyubka; >; > Copyright (c) 2013 No Face Press, LLC (Thomas Davis); >; > Copyright (c) 2013 F-Secure Corporation; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. Lua License; ------. ### Included only if built with Lua support. http://www.lua.org/license.html. > Copyright (C) 1994-2020 Lua.org, PUC-Rio.; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, pu",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:9024,Integrability,interface,interface,9024,"ion the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; > IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; > FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE; > AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER; > LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,; > OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN; > THE SOFTWARE. zlib License; ------. ### Included only if built with zlib support. https://www.zlib.net/zlib_license.html. > zlib.h -- interface of the 'zlib' general purpose compression library; > version 1.2.11, January 15th, 2017; >; > Copyright (C) 1995-2017 Jean-loup Gailly and Mark Adler; >; > This software is provided 'as-is', without any express or implied; > warranty. In no event will the authors be held liable for any damages; > arising from the use of this software.; >; > Permission is granted to anyone to use this software for any purpose,; > including commercial applications, and to alter it and redistribute it; > freely, subject to the following restrictions:; >; > 1. The origin of this software must not be misrepresented; you must not; > claim that you wrote the original software. If you use this software; > in a product, an acknowledgment in the product documentation would be; > appreciated but is not required.; > 2. Altered source versions must be plainly marked as such, and must not be; > misrepresented as being the original software.; > 3. This notice may not be removed or altered from any source distribution.; >; > Jean-loup Gailly",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md:6022,Modifiability,extend,extended,6022,"opy,; > modify, merge, publish, distribute, sublicense, and/or sell copies; > of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be; > included in all copies or substantial portions of the Software.; >; > THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,; > EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF; > MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND; > NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS; > BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN; > ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN; > CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; > SOFTWARE. LuaXML License; ------. ### Included only if built with Lua and LuaXML support. Version 1.8.0 (Lua 5.2), 2013-06-10 by Gerald Franz, eludi.net. Modified and extended 2015 by Bernhard Nortmann, https://github.com/n1tehawk/LuaXML  version 2.0.x, compatible with Lua 5.1 to 5.3 and LuaJIT. > LuaXML License; >; > LuaXml is licensed under the terms of the MIT license reproduced below,; > the same as Lua itself. This means that LuaXml is free software and can be; > used for both academic and commercial purposes at absolutely no cost.; >; > Copyright (C) 2007-2013 Gerald Franz, eludi.net; >; > Permission is hereby granted, free of charge, to any person obtaining a copy; > of this software and associated documentation files (the ""Software""), to deal; > in the Software without restriction, including without limitation the rights; > to use, copy, modify, merge, publish, distribute, sublicense, and/or sell; > copies of the Software, and to permit persons to whom the Software is; > furnished to do so, subject to the following conditions:; >; > The above copyright notice and this permission notice shall be included in; > all copies or substantial portions of the Software",MatchSource.DOCS,net/http/civetweb/LICENSE.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/LICENSE.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:2230,Availability,avail,available,2230,"ivetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/c",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:2379,Availability,down,download,2379,"io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [ht",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6333,Availability,down,download,6333,"a.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6699,Availability,avail,available,6699,"/github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.github",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:512,Deployability,integrat,integration,512,"![CivetWeb](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/civetweb_64x64.png ""CivetWeb"") CivetWeb; =======. **The official home of CivetWeb is [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb)**. [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT); [![GitHub contributors](https://img.shields.io/github/contributors/civetweb/civetweb.svg)](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). Continuous integration for Linux and macOS ([Travis CI](https://app.travis-ci.com/github/civetweb/civetweb)):. [![Travis Build Status](https://api.travis-ci.com/civetweb/civetweb.svg?branch=master)](https://app.travis-ci.com/github/civetweb/civetweb). Continuous integration for Windows ([AppVeyor](https://ci.appveyor.com/project/civetweb/civetweb)):. [![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate wit",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:764,Deployability,integrat,integration,764,"![CivetWeb](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/civetweb_64x64.png ""CivetWeb"") CivetWeb; =======. **The official home of CivetWeb is [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb)**. [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT); [![GitHub contributors](https://img.shields.io/github/contributors/civetweb/civetweb.svg)](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). Continuous integration for Linux and macOS ([Travis CI](https://app.travis-ci.com/github/civetweb/civetweb)):. [![Travis Build Status](https://api.travis-ci.com/civetweb/civetweb.svg?branch=master)](https://app.travis-ci.com/github/civetweb/civetweb). Continuous integration for Windows ([AppVeyor](https://ci.appveyor.com/project/civetweb/civetweb)):. [![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate wit",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:2265,Deployability,install,installation,2265,"ivetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/c",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:2408,Deployability,release,releases,2408,"io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [ht",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3008,Deployability,release,releases,3008,"e used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (fo",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3374,Deployability,release,releases,3374,eb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embed,MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3445,Deployability,release,releases,3445,urceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an ,MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3492,Deployability,release,releases,3492,//sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.,MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:8131,Deployability,install,install,8131,"leSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). Support; -------. This project is very easy to install and use.; Please read the [documentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the [examples](https://github.com/civetweb/civetweb/blob/master/examples/). Recent questions and discussions usually use [GitHub issues](https://github.com/civetweb/civetweb/issues).; Some old information may be found on the [mailing list](https://groups.google.com/d/forum/civetweb), ; but this information may be outdated. Feel free to create a GitHub issue for bugs, feature requests, questions, suggestions or if you want to share tips and tricks.; When creating an issues for a bug, add enough description to reproduce the issue - at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked conte",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:9710,Deployability,patch,patches,9710,"ng an issues for a bug, add enough description to reproduce the issue - at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked contents. Visit these pages and try the community support suggestions at your own risk.; Any link provided in this project (including source and documentation) is provided in the hope that this information will be helpful.; However, we cannot accept any responsibility for any content on an external page. Contributions; -------------. Contributions are welcome provided all contributions carry the MIT license. DO NOT APPLY fixes copied from Mongoose to this project to prevent GPL tainting.; Since 2013, CivetWeb and Mongoose are developed independently.; By now the code base differs, so patches cannot be safely transferred in either direction. Some guidelines can be found in [docs/Contribution.md](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md). Authors; -------. CivetWeb has been forked from the last MIT version of Mongoose in 2013.; Since then, CivetWeb has seen many improvements from various authors; (Copyright (c) 2013-2021 the CivetWeb developers, MIT license). A list of authors can be found in [CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). CivetWeb is based on the Mongoose project. The original author of Mongoose was; Sergey Lyubka (Copyright (c) 2004-2013 Sergey Lyubka, MIT license).; However, on August 16, 2013, the [license of Mongoose has been changed](https://groups.google.com/forum/#!topic/mongoose-users/aafbOnHonkI); after writing and distributing the original code this project is based on.; The license change and CivetWeb used to be mentioned on the Mongoose; [Wikipedia](https://en.wikipedia.org/wiki/Mongoose_(web_",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:1868,Energy Efficiency,power,powerful,1868,"//ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate without restrictions. CivetWeb can be used by developers as a library, to add web server functionality to an existing application. It can also be used by end users as a stand-alone web server running on a Windows or Linux PC. It is available as single executable, no installation is required. Where to find the official version?; -----------------------------------. End users can download CivetWeb binaries / releases from SourceForge; [https://sourceforge.net/projects/civetweb/](https://sourceforge.net/projects/civetweb/). Developers can contribute to CivetWeb via GitHub; [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb). Due to a [bug in Git for Windows V2.24](https://github.com/git-for-windows/git/issues/2435); CivetWeb must be used with an earlier or later version (see also [here](https://github.com/civetweb/civetweb/issues/812)). Trouble tickets sh",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6002,Energy Efficiency,power,powerful,6002," Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https:/",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:512,Integrability,integrat,integration,512,"![CivetWeb](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/civetweb_64x64.png ""CivetWeb"") CivetWeb; =======. **The official home of CivetWeb is [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb)**. [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT); [![GitHub contributors](https://img.shields.io/github/contributors/civetweb/civetweb.svg)](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). Continuous integration for Linux and macOS ([Travis CI](https://app.travis-ci.com/github/civetweb/civetweb)):. [![Travis Build Status](https://api.travis-ci.com/civetweb/civetweb.svg?branch=master)](https://app.travis-ci.com/github/civetweb/civetweb). Continuous integration for Windows ([AppVeyor](https://ci.appveyor.com/project/civetweb/civetweb)):. [![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate wit",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:764,Integrability,integrat,integration,764,"![CivetWeb](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/civetweb_64x64.png ""CivetWeb"") CivetWeb; =======. **The official home of CivetWeb is [https://github.com/civetweb/civetweb](https://github.com/civetweb/civetweb)**. [![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT); [![GitHub contributors](https://img.shields.io/github/contributors/civetweb/civetweb.svg)](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). Continuous integration for Linux and macOS ([Travis CI](https://app.travis-ci.com/github/civetweb/civetweb)):. [![Travis Build Status](https://api.travis-ci.com/civetweb/civetweb.svg?branch=master)](https://app.travis-ci.com/github/civetweb/civetweb). Continuous integration for Windows ([AppVeyor](https://ci.appveyor.com/project/civetweb/civetweb)):. [![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/civetweb/civetweb?svg=true)](https://ci.appveyor.com/project/civetweb/civetweb/branch/master). Test coverage check ([coveralls](https://coveralls.io/github/civetweb/civetweb), [codecov](https://codecov.io/gh/civetweb/civetweb/branch/master)) (using different tools/settings):. [![Coveralls](https://img.shields.io/coveralls/civetweb/civetweb.svg?maxAge=3600)](); [![Coverage Status](https://coveralls.io/repos/github/civetweb/civetweb/badge.svg?branch=master)](https://coveralls.io/github/civetweb/civetweb?branch=master). [![codecov](https://codecov.io/gh/civetweb/civetweb/branch/master/graph/badge.svg)](https://codecov.io/gh/civetweb/civetweb). Static source code analysis ([Coverity](https://scan.coverity.com/projects/5784)):. [![Coverity Scan Build Status](https://scan.coverity.com/projects/5784/badge.svg)](https://scan.coverity.com/projects/5784). Project Mission; -----------------. Project mission is to provide easy to use, powerful, C (C/C++) embeddable web server with optional CGI, SSL and Lua support.; CivetWeb has a MIT license so you can innovate wit",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:4753,Integrability,interface,interface,4753,"he following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.md](https://github.com/civetweb/civetweb/blob/master/docs/OpenSSL.md) - Adding HTTPS (SSL/TLS) support using OpenSSL.; - [API documentation](https://github.com/civetweb/civetweb/tree/master/docs/api) - Additional documentation on the civetweb application programming interface ([civetweb.h](https://github.com/civetweb/civetweb/blob/master/include/civetweb.h)).; - [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md) - Release Notes; - [SECURITY.md](https://github.com/civetweb/civetweb/blob/master/SECURITY.md) - Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civet",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6080,Integrability,depend,dependencies,6080," Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https:/",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:5613,Modifiability,enhance,enhancements,5613,".com/civetweb/civetweb/tree/master/docs/api) - Additional documentation on the civetweb application programming interface ([civetweb.h](https://github.com/civetweb/civetweb/blob/master/include/civetweb.h)).; - [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md) - Release Notes; - [SECURITY.md](https://github.com/civetweb/civetweb/blob/master/SECURITY.md) - Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrar",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6347,Modifiability,rewrite,rewrite,6347,"a.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:9201,Safety,risk,risk,9201,"ocumentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the [examples](https://github.com/civetweb/civetweb/blob/master/examples/). Recent questions and discussions usually use [GitHub issues](https://github.com/civetweb/civetweb/issues).; Some old information may be found on the [mailing list](https://groups.google.com/d/forum/civetweb), ; but this information may be outdated. Feel free to create a GitHub issue for bugs, feature requests, questions, suggestions or if you want to share tips and tricks.; When creating an issues for a bug, add enough description to reproduce the issue - at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked contents. Visit these pages and try the community support suggestions at your own risk.; Any link provided in this project (including source and documentation) is provided in the hope that this information will be helpful.; However, we cannot accept any responsibility for any content on an external page. Contributions; -------------. Contributions are welcome provided all contributions carry the MIT license. DO NOT APPLY fixes copied from Mongoose to this project to prevent GPL tainting.; Since 2013, CivetWeb and Mongoose are developed independently.; By now the code base differs, so patches cannot be safely transferred in either direction. Some guidelines can be found in [docs/Contribution.md](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md). Authors; -------. CivetWeb has been forked from the last MIT version of Mongoose in 2013.; Since then, CivetWeb has seen many improvements from various authors; (Copyright (c) 2013-2021 the CivetWeb developers, MIT license). A list of authors can be found in [CREDITS.md](",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:9728,Safety,safe,safely,9728,"ng an issues for a bug, add enough description to reproduce the issue - at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked contents. Visit these pages and try the community support suggestions at your own risk.; Any link provided in this project (including source and documentation) is provided in the hope that this information will be helpful.; However, we cannot accept any responsibility for any content on an external page. Contributions; -------------. Contributions are welcome provided all contributions carry the MIT license. DO NOT APPLY fixes copied from Mongoose to this project to prevent GPL tainting.; Since 2013, CivetWeb and Mongoose are developed independently.; By now the code base differs, so patches cannot be safely transferred in either direction. Some guidelines can be found in [docs/Contribution.md](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md). Authors; -------. CivetWeb has been forked from the last MIT version of Mongoose in 2013.; Since then, CivetWeb has seen many improvements from various authors; (Copyright (c) 2013-2021 the CivetWeb developers, MIT license). A list of authors can be found in [CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). CivetWeb is based on the Mongoose project. The original author of Mongoose was; Sergey Lyubka (Copyright (c) 2004-2013 Sergey Lyubka, MIT license).; However, on August 16, 2013, the [license of Mongoose has been changed](https://groups.google.com/forum/#!topic/mongoose-users/aafbOnHonkI); after writing and distributing the original code this project is based on.; The license change and CivetWeb used to be mentioned on the Mongoose; [Wikipedia](https://en.wikipedia.org/wiki/Mongoose_(web_",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6140,Security,authoriz,authorization,6140,"ight License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Lo",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6269,Security,authenticat,authentication,6269,". - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/l",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6308,Security,certificate,certificates,6308,"issive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](h",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6834,Testability,log,logo,6834,"ot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.gi",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:6962,Testability,log,logo,6962,"ipts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TL",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:7109,Testability,log,logo,7109,"dencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](https://www.openssl.org/).; - Optional support for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). S",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:7283,Testability,log,logo,7283,"ort for authentication using client side X.509 certificates.; - Resumed download, URL rewrite, file blacklist, IP-based ACL.; - May run as Windows service.; - Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). Support; -------. This project is very easy to install and use.; Please read the [documentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the ",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:7439,Testability,log,logo,7439,"- Download speed limit based on client subnet or URI pattern.; - Simple and clean embedding API.; - The source is in single file to make things easy.; - Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). Support; -------. This project is very easy to install and use.; Please read the [documentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the [examples](https://github.com/civetweb/civetweb/blob/master/examples/). Recent questions and discussions usually use [GitHub issues](https://github.com/civetw",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:7590,Testability,log,logo,7590,"- Embedding examples included.; - HTTP client capable of sending arbitrary HTTP/HTTPS requests.; - Websocket client functionality available (WS/WSS). ### Optionally included software. [![Lua](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/lua-logo.jpg ""Lua Logo"")](http://lua.org). [![Sqlite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/sqlite3-logo.jpg ""Sqlite3 Logo"")](http://sqlite.org). [![LuaFileSystem](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luafilesystem-logo.jpg ""LuaFileSystem Logo"")](http://keplerproject.github.io/luafilesystem/). [![LuaSQLite3](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luasqlite-logo.jpg ""LuaSQLite3 Logo"")](http://lua.sqlite.org/index.cgi/index). [![LuaXML](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/luaxml-logo.jpg ""LuaXML Logo"")](https://github.com/n1tehawk/LuaXML). [![Duktape](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/duktape-logo.png ""Duktape Logo"")](http://duktape.org). ### Optional depencencies. [![zlib](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/zlib3d-b1.png ""zlib Logo"")](https://zlib.net). [![OpenSSL](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/OpenSSL_logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). Support; -------. This project is very easy to install and use.; Please read the [documentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the [examples](https://github.com/civetweb/civetweb/blob/master/examples/). Recent questions and discussions usually use [GitHub issues](https://github.com/civetweb/civetweb/issues).; Some old information may be found on the [mailing list](https://groups.google.com/d/forum/civetweb), ; but this information may ",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:3808,Usability,simpl,simply,3808,com/civetweb/civetweb/issues/812)). Trouble tickets should be filed on GitHub; [https://github.com/civetweb/civetweb/issues](https://github.com/civetweb/civetweb/issues). New releases are announced at Google Groups; [https://groups.google.com/d/forum/civetweb](https://groups.google.com/d/forum/civetweb). Formerly some support question and discussion threads have been at [Google groups](https://groups.google.com/d/forum/civetweb).; Recent questions and discussions use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.md](https://github.com/civetweb/civetweb/blob/master/docs/OpenSSL.md) - Adding HTTPS (SSL/TLS) support using OpenSSL.; - [API documentation](https://github.com/civetweb/civetweb/tree/master/docs/api) - Additional documentation on the civetweb application programming interface ([civetweb.h](https://github.com/civetweb/civetweb/blob/master/include/,MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:4306,Usability,guid,guide,4306,"s use [GitHub issues](https://github.com/civetweb/civetweb/issues). Source releases can be found on GitHub; [https://github.com/civetweb/civetweb/releases](https://github.com/civetweb/civetweb/releases). A very brief overview can be found on GitHub Pages; [http://civetweb.github.io/civetweb/](http://civetweb.github.io/civetweb/). Getting The Source; ------------------; Download the source code by running the following code in your command prompt:. $ git clone https://github.com/civetweb/civetweb.git; or simply grab a copy of the source code as a ZIP or TGZ file. Quick start documentation; --------------------------. - [docs/Installing.md](https://github.com/civetweb/civetweb/blob/master/docs/Installing.md) - Install Guide (for end users using pre-built binaries); - [docs/UserManual.md](https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md) - End User Guide; - [docs/Building.md](https://github.com/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.md](https://github.com/civetweb/civetweb/blob/master/docs/OpenSSL.md) - Adding HTTPS (SSL/TLS) support using OpenSSL.; - [API documentation](https://github.com/civetweb/civetweb/tree/master/docs/api) - Additional documentation on the civetweb application programming interface ([civetweb.h](https://github.com/civetweb/civetweb/blob/master/include/civetweb.h)).; - [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md) - Release Notes; - [SECURITY.md](https://github.com/civetweb/civetweb/blob/master/SECURITY.md) - Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-fr",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:5222,Usability,simpl,simplicity,5222,"m/civetweb/civetweb/blob/master/docs/Building.md) - Building the Server (quick start guide); - [docs/Embedding.md](https://github.com/civetweb/civetweb/blob/master/docs/Embedding.md) - Embedding (how to add HTTP support to an existing application); - [docs/OpenSSL.md](https://github.com/civetweb/civetweb/blob/master/docs/OpenSSL.md) - Adding HTTPS (SSL/TLS) support using OpenSSL.; - [API documentation](https://github.com/civetweb/civetweb/tree/master/docs/api) - Additional documentation on the civetweb application programming interface ([civetweb.h](https://github.com/civetweb/civetweb/blob/master/include/civetweb.h)).; - [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md) - Release Notes; - [SECURITY.md](https://github.com/civetweb/civetweb/blob/master/SECURITY.md) - Security Policy; - [LICENSE.md](https://github.com/civetweb/civetweb/blob/master/LICENSE.md) - Copyright License. Overview; --------. CivetWeb keeps the balance between functionality and; simplicity by a carefully selected list of features:. - Liberal, commercial-friendly, permissive,; [MIT license](http://en.wikipedia.org/wiki/MIT_License); - Free from copy-left licenses, like GPL, because you should innovate without; restrictions.; - Forked from [Mongoose](https://code.google.com/p/mongoose/) in 2013, before; it changed the licence from MIT to commercial + GPL. A lot of enhancements; have been added since that time, see; [RELEASE_NOTES.md](https://github.com/civetweb/civetweb/blob/master/RELEASE_NOTES.md).; - Works on Windows, Mac, Linux, UNIX, iPhone, Android, Buildroot, and many; other platforms.; - Scripting and database support (CGI, SQLite database, Lua Server Pages,; Server side Lua scripts, Server side JavaScript).; This provides a ready to go, powerful web development platform in a one; single-click executable with **no dependencies**.0; - Support for CGI, SSI, HTTP digest (MD5) authorization, WebSocket,; WebDAV.; - HTTPS (SSL/TLS) support using [OpenSSL](htt",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:8866,Usability,guid,guidelines,8866,"logo.png ""OpenSSL Logo"")](https://www.openssl.org/). [![Mbed TLS](https://raw.githubusercontent.com/civetweb/civetweb/master/resources/mbedTLS_logo.png ""mbedTLS Logo"")](https://github.com/ARMmbed/mbedtls). Support; -------. This project is very easy to install and use.; Please read the [documentation](https://github.com/civetweb/civetweb/blob/master/docs/); and have a look at the [examples](https://github.com/civetweb/civetweb/blob/master/examples/). Recent questions and discussions usually use [GitHub issues](https://github.com/civetweb/civetweb/issues).; Some old information may be found on the [mailing list](https://groups.google.com/d/forum/civetweb), ; but this information may be outdated. Feel free to create a GitHub issue for bugs, feature requests, questions, suggestions or if you want to share tips and tricks.; When creating an issues for a bug, add enough description to reproduce the issue - at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked contents. Visit these pages and try the community support suggestions at your own risk.; Any link provided in this project (including source and documentation) is provided in the hope that this information will be helpful.; However, we cannot accept any responsibility for any content on an external page. Contributions; -------------. Contributions are welcome provided all contributions carry the MIT license. DO NOT APPLY fixes copied from Mongoose to this project to prevent GPL tainting.; Since 2013, CivetWeb and Mongoose are developed independently.; By now the code base differs, so patches cannot be safely transferred in either direction. Some guidelines can be found in [docs/Contribution.md](https://github.com/civetweb/civetweb/blob/master/docs/C",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md:9773,Usability,guid,guidelines,9773,"at least add CivetWeb version and operating system.; Please see also the guidelines for [Contributions](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md) and the [Security Policy](https://github.com/civetweb/civetweb/blob/master/SECURITY.md). Note: We do not take any liability or warranty for any linked contents. Visit these pages and try the community support suggestions at your own risk.; Any link provided in this project (including source and documentation) is provided in the hope that this information will be helpful.; However, we cannot accept any responsibility for any content on an external page. Contributions; -------------. Contributions are welcome provided all contributions carry the MIT license. DO NOT APPLY fixes copied from Mongoose to this project to prevent GPL tainting.; Since 2013, CivetWeb and Mongoose are developed independently.; By now the code base differs, so patches cannot be safely transferred in either direction. Some guidelines can be found in [docs/Contribution.md](https://github.com/civetweb/civetweb/blob/master/docs/Contribution.md). Authors; -------. CivetWeb has been forked from the last MIT version of Mongoose in 2013.; Since then, CivetWeb has seen many improvements from various authors; (Copyright (c) 2013-2021 the CivetWeb developers, MIT license). A list of authors can be found in [CREDITS.md](https://github.com/civetweb/civetweb/blob/master/CREDITS.md). CivetWeb is based on the Mongoose project. The original author of Mongoose was; Sergey Lyubka (Copyright (c) 2004-2013 Sergey Lyubka, MIT license).; However, on August 16, 2013, the [license of Mongoose has been changed](https://groups.google.com/forum/#!topic/mongoose-users/aafbOnHonkI); after writing and distributing the original code this project is based on.; The license change and CivetWeb used to be mentioned on the Mongoose; [Wikipedia](https://en.wikipedia.org/wiki/Mongoose_(web_server)); page as well, but it's getting deleted (and added again) there",MatchSource.DOCS,net/http/civetweb/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/http/civetweb/README.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4787,Availability,down,download,4787,"twork topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important t",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4820,Availability,down,download,4820,"ld be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5136,Availability,avail,available,5136,".5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on you",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5268,Availability,down,download,5268,"ewton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be pe",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5601,Availability,down,downloads,5601,"n Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall c",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5972,Availability,down,download,5972,"/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1082,Deployability,configurat,configuration,1082,"===============================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1887,Deployability,install,installed,1887," running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:2134,Deployability,install,install,2134,"ent system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:2188,Deployability,install,install,2188,"n run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:2749,Deployability,configurat,configuration,2749,"lt in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3385,Deployability,configurat,configuration,3385,"l` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; u",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3567,Deployability,configurat,configurations,3567,"d or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further i",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3682,Deployability,configurat,configuration,3682,".local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4456,Deployability,install,installing,4456,"d repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [B",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4502,Deployability,install,installation,4502,"Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make i",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5319,Deployability,install,installation,5319,"ewton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be pe",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5485,Deployability,install,install,5485,". Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your so",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5508,Deployability,install,install,5508,"ation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be se",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5525,Deployability,install,installing,5525,"ewton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts f",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5730,Deployability,install,installing,5730,"n Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall c",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5834,Deployability,install,installed,5834,"/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:5930,Deployability,install,installations,5930,"/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6123,Deployability,install,install,6123,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6241,Deployability,configurat,configuration,6241,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6371,Deployability,configurat,configuration,6371,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6421,Deployability,configurat,configuration,6421,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6571,Deployability,configurat,configuration,6571,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6665,Deployability,configurat,configuration,6665,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:668,Energy Efficiency,schedul,scheduling,668,"Setup a static PROOF cluster with PROOF on Demand; =================================================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:788,Energy Efficiency,schedul,scheduling,788,"Setup a static PROOF cluster with PROOF on Demand; =================================================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1365,Energy Efficiency,schedul,scheduling,1365,"t their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to you",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:2513,Integrability,depend,depends,2513,"de does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK;",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6486,Integrability,depend,dependencies,6486,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1082,Modifiability,config,configuration,1082,"===============================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:2749,Modifiability,config,configuration,2749,"lt in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3385,Modifiability,config,configuration,3385,"l` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; u",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3567,Modifiability,config,configurations,3567,"d or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further i",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3682,Modifiability,config,configuration,3682,".local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3743,Modifiability,flexible,flexible,3743,"ts:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > *",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6057,Modifiability,config,configure,6057,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6241,Modifiability,config,configuration,6241,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6371,Modifiability,config,configuration,6371,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6421,Modifiability,config,configuration,6421,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6571,Modifiability,config,configuration,6571,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6665,Modifiability,config,configuration,6665,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:804,Performance,concurren,concurrent,804,"Setup a static PROOF cluster with PROOF on Demand; =================================================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1420,Performance,queue,queue,1420,"t their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to you",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3366,Performance,cache,cache,3366,"em. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` service: how to to this depends on your operating; system. On Ubuntu using Upstart:. # restart autofs. On RHEL-based or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you w",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6261,Performance,perform,performed,6261,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4076,Security,authenticat,authentication,4076," tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4401,Security,certificate,certificate,4401,"d repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [B",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6806,Security,authenticat,authentication,6806,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6983,Security,authenticat,authentication,6983,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:7006,Security,access,access,7006,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:844,Usability,guid,guide,844,"Setup a static PROOF cluster with PROOF on Demand; =================================================. Introduction; ------------. Using PROOF on Demand is our current recommended way of running a PROOF; cluster. The usage of PoD is in particular helpful for the following; reasons:. - **Sandboxing.** Each user get their own personal PROOF cluster,; separated from the others: a problem occurring on one personal; cluster does not affect the workflow of other users. - **Easier administration and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:1504,Usability,guid,guide,1504,"n and self-servicing.** A user can restart their; personal PROOF cluster in case of troubles without waiting for a; system administrator's intervention. - **Efficient multiuser scheduling.** PROOF on Demand makes PROOF run on; top of an existing resource management system, moving the problem of; scheduling many concurrent users outside of PROOF. This guide particularly refers to the setup of a static PROOF cluster; running on physical hosts: the recommended setup is in practice the same; as the ready-to-go Virtual Analysis Facility. If you want to use PROOF; on the clouds there is no configuration to go through. Setup a resource management system; ----------------------------------. Although PROOF on Demand can run on a cluster of nodes without using a; resource management system (using `pod-ssh`), it is recommended to setup a; dedicated one to benefit from the scheduling in a multiuser environment, or a; dedicated queue on an existing one. As there's a variety of resource management systems, this guide does not cover; their setup. The RMS preconfigured for the Virtual Analysis Facility is; [HTCondor](http://research.cs.wisc.edu/htcondor/), which we recommend primarily; because it has dynamic addition of workers built in. Configuration steps for all nodes; ---------------------------------. ### Setup CernVM-FS. [CernVM-FS](http://cernvm.cern.ch/portal/filesystem) should be installed; on all machines as the preferred method for software distribution. > Configuration instructions for the latest CernVM-FS can be found; > [here](http://cernvm.cern.ch/portal/filesystem/techinformation). A brief step-by-step procedure to install CernVM-FS is hereby described. - Download and install the latest stable version from; [here](http://cernvm.cern.ch/portal/filesystem): pick one which is; appropriate to your operating system. You need the `cvmfs` package,; you *don't* need the `cvmfs-devel` or `cvmfs-server` ones. - As root user, run:. # cvmfs_config setup. - Start the `autofs` ser",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3662,Usability,guid,guide,3662,"d or older Ubuntus:. # service autofs restart. - Prepare a `/etc/cvmfs/default.local` file (create it if it does not; exists) with the following configuration bits:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further i",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:4516,Usability,guid,guide,4516,"Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > **Source code:** [PoD download page](http://pod.gsi.de/download.html); > and [Installation; > instructions](http://pod.gsi.de/doc/3.12/Installation.html). [PROOF on Demand](http://pod.gsi.de/) is required on the head node and on the; user's client. In case your experiment provides a version of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make i",MatchSource.DOCS,proof/doc/confman/ConfigProofPoD.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:2211,Availability,failure,failures,2211,"OF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4618,Availability,down,download,4618,"*n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4644,Availability,failure,failures,4644,"*n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:872,Deployability,install,install,872,"The Dataset Stager; ==================. Overview; --------. The [Dataset Stager (afdsmgrd)](http://afdsmgrd.googlecode.com/) is; a daemon that coordinates the transfer of data from a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:947,Deployability,configurat,configuration,947,"The Dataset Stager; ==================. Overview; --------. The [Dataset Stager (afdsmgrd)](http://afdsmgrd.googlecode.com/) is; a daemon that coordinates the transfer of data from a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1144,Deployability,configurat,configuration,1144,"m a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist,",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1351,Deployability,configurat,configuration,1351,"rogress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *rege",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1438,Deployability,configurat,configuration,1438,"rogress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *rege",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1695,Deployability,configurat,configuration,1695,"m ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5607,Deployability,configurat,configuration,5607," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:6041,Deployability,configurat,configuration,6041," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4742,Energy Efficiency,monitor,monitoring,4742,"t...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; yo",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4841,Energy Efficiency,monitor,monitoring,4841,"nd*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets inf",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4922,Energy Efficiency,monitor,monitoring,4922,"nd the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA m",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5260,Energy Efficiency,monitor,monitoring,5260,"smgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sle",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5569,Energy Efficiency,monitor,monitoring,5569," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5808,Energy Efficiency,monitor,monitoring,5808," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5899,Energy Efficiency,monitor,monitoring,5899," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:6020,Energy Efficiency,monitor,monitoring,6020," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:338,Integrability,protocol,protocol,338,"The Dataset Stager; ==================. Overview; --------. The [Dataset Stager (afdsmgrd)](http://afdsmgrd.googlecode.com/) is; a daemon that coordinates the transfer of data from a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:677,Modifiability,config,configuring,677,"The Dataset Stager; ==================. Overview; --------. The [Dataset Stager (afdsmgrd)](http://afdsmgrd.googlecode.com/) is; a daemon that coordinates the transfer of data from a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:947,Modifiability,config,configuration,947,"The Dataset Stager; ==================. Overview; --------. The [Dataset Stager (afdsmgrd)](http://afdsmgrd.googlecode.com/) is; a daemon that coordinates the transfer of data from a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1144,Modifiability,config,configuration,1144,"m a remote storage; to your local storage. For each file to transfer, a script is called. The script can be; customized to support your source and destination protocol. Staging requests are issued from the ROOT console, where you can also; control the progress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist,",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1351,Modifiability,config,configuration,1351,"rogress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *rege",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1438,Modifiability,config,configuration,1438,"rogress of your staging. Installation; ------------. The Dataset Stager is distributed both on a repository on its own and as; part of ROOT. The easiest way to compile it is to do it inside ROOT. Installing from ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *rege",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:1695,Modifiability,config,configuration,1695,"m ROOT; --------------------. When configuring the ROOT source, enable the Dataset Stager by adding; `--enable-afdsmgrd`. Check in the list of enabled features if you have; ""afdsmgrd"". After running `make` (and, optionally, `make install`) you'll find the; daemon in the same directory of `root.exe`. The configuration file and init.d startup script will be in; `$ROOTSYS/etc/proof`. The daemon can and **must** run as unprivileged; user. Configuration; -------------. The Dataset Stager can share its configuration file with PROOF, as; some directives are the same and unknown directives are just ignored. Directives are one per line and lines beginning with a pound sign (`#`); are used for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4753,Modifiability,plugin,plugin,4753,"t...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; yo",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4852,Modifiability,plugin,plugins,4852,"nd*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets inf",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4870,Modifiability,plugin,plugin,4870,"nd the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA m",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4933,Modifiability,plugin,plugin,4933,"nd the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA m",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5040,Modifiability,plugin,plugin,5040,"/path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5088,Modifiability,plugin,plugin,5088,"REENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; -----------------------",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5156,Modifiability,variab,variable,5156,"smgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sle",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5194,Modifiability,plugin,plugin,5194,"smgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sle",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5512,Modifiability,variab,variable,5512," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5541,Modifiability,plugin,plugin,5541," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5607,Modifiability,config,configuration,5607," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5621,Modifiability,variab,variable,5621," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5868,Modifiability,variab,variable,5868," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:6041,Modifiability,config,configuration,6041," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:2384,Performance,scalab,scalability,2384," for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; dsmgrd.sleepsecs *secs*; : Seconds to sleep between each loop. The dataset stager checks at; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:3584,Performance,concurren,concurrent,3584,"ntheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; dsmgrd.sleepsecs *secs*; : Seconds to sleep between each loop. The dataset stager checks at; each loop the status of the managed transfers. Defaults to **30; seconds**. dsmgrd.scandseveryloops *n*; : Every `n` loops, the dataset repository is checked for newly; incoming staging requests. Defaults to **10**. dsmgrd.parallelxfrs *n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corru",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5551,Performance,load,loaded,5551," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4305,Safety,timeout,timeout,4305,"; each loop the status of the managed transfers. Defaults to **30; seconds**. dsmgrd.scandseveryloops *n*; : Every `n` loops, the dataset repository is checked for newly; incoming staging requests. Defaults to **10**. dsmgrd.parallelxfrs *n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://h",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4462,Safety,timeout,timeout,4462,"he dataset repository is checked for newly; incoming staging requests. Defaults to **10**. dsmgrd.parallelxfrs *n*; : Number of concurrent transfers. Defaults to **8**. dsmgrd.stagecmd *shell\_command*; : Command to run in order to stage each file. It might be whatever you; want (executable, shell script...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5434,Security,password,password,5434," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,proof/doc/confman/DatasetStager.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:771,Availability,avail,available,771,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1058,Availability,avail,available,1058,"uction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Anal",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2330,Availability,avail,available,2330,"); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Si",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2599,Availability,avail,available,2599," VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API,",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3197,Availability,avail,available,3197,"for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptu",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:5269,Availability,down,downloaded,5269,".com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashboard page where you have previously; customized the contexts for your master and your slaves. Click on the rightmost button on the line of the desired context and; select **Get rendered context** from the dropdown: save the output to a; text file (such as `my_vaf_context.txt`, the name we will use in the; examples that follow). This file will be subsequently passed as the so; called ""user-data"" file to the cloud API. > Repeat the operation for both the master context and the slave; > context. ### OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrast",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:5595,Availability,down,downloaded,5595,"on on the line of the desired context and; select **Get rendered context** from the dropdown: save the output to a; text file (such as `my_vaf_context.txt`, the name we will use in the; examples that follow). This file will be subsequently passed as the so; called ""user-data"" file to the cloud API. > Repeat the operation for both the master context and the slave; > context. ### OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nod",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:5994,Availability,down,downloaded,5994,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:166,Deployability,deploy,deploy,166,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1122,Deployability,deploy,deployment,1122,"uction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Anal",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1317,Deployability,release,releases,1317," Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only av",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1446,Deployability,release,releases,1446,"OF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *A",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1631,Deployability,configurat,configuration,1631,"igured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts a",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1725,Deployability,configurat,configuration,1725,"certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specif",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3387,Deployability,configurat,configuration,3387,"e between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashbo",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:4183,Integrability,interface,interfaces,4183,"available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashboard page where you have previously; customized the contexts for your master and your slaves. Click on the rightmost button on the line of the desired context and; select **Get rendered context** from the dropdown: save the output to a; text file (such as `my_vaf_context.txt`, the name we will use in the; examples that follow). This file will be subsequently passed as the so; called ""user-data"" file to the cloud API. > Repeat the operation for both the master context and the slave; > context. ### OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:4347,Integrability,interface,interface,4347,"file for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashboard page where you have previously; customized the contexts for your master and your slaves. Click on the rightmost button on the line of the desired context and; select **Get rendered context** from the dropdown: save the output to a; text file (such as `my_vaf_context.txt`, the name we will use in the; examples that follow). This file will be subsequently passed as the so; called ""user-data"" file to the cloud API. > Repeat the operation for both the master context and the slave; > context. ### OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:307,Modifiability,config,configuring,307,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1631,Modifiability,config,configuration,1631,"igured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts a",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1725,Modifiability,config,configuration,1725,"certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specif",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2145,Modifiability,config,configure,2145," or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cer",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2271,Modifiability,config,configure,2271,"; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryp",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2345,Modifiability,config,configuring,2345,"); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Si",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3387,Modifiability,config,configuration,3387,"e between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashbo",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3401,Modifiability,variab,variables,3401,"e between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashbo",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:6259,Modifiability,config,configured,6259,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1792,Performance,perform,performed,1792,"rnVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empt",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:6374,Safety,safe,safely,6374,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:710,Security,certificate,certificate,710,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:722,Security,authenticat,authentication,722,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:1896,Security,access,accessible,1896," the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same clu",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2532,Security,authenticat,authenticating,2532,"); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:2974,Security,authenticat,authenticate,2974,"m-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following descriptio",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3014,Security,password,password,3014,"m-online.cern.ch/dashboard), click on the; **Create new context...** dropdown and select **Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following descriptio",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3032,Security,password,password,3032,"*Virtual Analysis Facility; node**. There's only a few parameters to configure. Context name; : A name for your context (such as *VAF Master for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN A",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3275,Security,encrypt,encryption,3275,"for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptu",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3286,Security,password,password,3286,"for ATLAS*). Any name; will work. Role; : Use this to configure either a *master* or a *slave*. VAF master (only available when configuring a slave); : IP address or FQDN of the Virtual Analysis Facility master. Auth method; : Choose between *ALICE LDAP* (useful only for ALICE users) or *Pool; accounts* (good for authenticating all the other Grid users). Num. pool accounts (only available when using pool accounts auth); : Number of pool accounts to create. Proxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptu",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:3598,Security,access,access,3598,"roxy for CVMFS; : An URL specifying the proxy server for CernVM-FS, such as; `http://ca-proxy.cern.ch:3128/`. If you leave it empty, proxy will; be automatically discovered. HTCondor shared secret; : VMs part of the same cluster should have the same value of this; field. It is used to mutually authenticate VMs and it is used like a; password. Context password; : Current profile will be saved on the [CernVM Online; repository](http://cernvm-online.cern.ch/). If you don't want the; information there to be publicly available to other users, type in; a value for protecting the context with an encryption password. You will have to create a profile for the **master** and the **slave**. Since; most of the configuration variables are the same (like the *HTCondor; shared secret*) you can create one, clone it and change only what's; needed to change. Deploy it on the cloud; ----------------------. Provided you have access to a certain cloud API, you'll need to; instantiate a certain number of CernVM batch images with proper; contextualization: one for the master, as many as you want as slaves. CernVM supports contextualization through the ""user data"" field; supported by all cloud infrastructures. Each cloud infrastructure has a different method of setting the ""user; data"". The following description will focus on:. - [OpenNebula](http://opennebula.org/). - OpenStack (such as the [CERN Agile; infrastructure](https://openstack.cern.ch/)). - [Amazon EC2](http://aws.amazon.com/ec2/)-compatible interfaces via; the open [Eucalyptus](http://www.eucalyptus.com/); [Euca2ools](http://www.eucalyptus.com/eucalyptus-cloud/tools): many popular; clouds support such interface and tools. ### Download the CernVM Online contextualizations. Go to the CernVM Online Dashboard page where you have previously; customized the contexts for your master and your slaves. Click on the rightmost button on the line of the desired context and; select **Get rendered context** from the dropdown: save the output ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:6110,Security,secur,security,6110,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:6219,Security,firewall,firewall,6219,"# OpenStack API: nova. Example of a CernVM instantiation using `nova`:. ``` {.bash}; nova boot \; --flavor m1.xlarge \; --image cernvm-batch-node-2.6.0-4-1-x86_64 \; --key-name my_default_keyparir \; --user-data my_vaf_context.txt \; Name-Of-My-New-VM; ```. The `--user-data` option requires the context file we've just; downloaded. ### EC2 API: euca-tools. Example of a CernVM instantiation using `euca-tools`:. ``` {.bash}; euca-run-instances \; --instance-type m1.xlarge \; --key my_default_keyparir \; --user-data-file my_vaf_context.txt \; cernvm-batch-node-2.6.0-4-1-x86_64; ```. The `--user-data-file` option is the context file we've just downloaded. ### OpenNebula. An example VM definition follows:. ``` {.ruby}; CONTEXT=[; EC2_USER_DATA=""<base64_encoded_string>"",; ]; CPU=""6""; VCPU=""6""; DISK=[; IMAGE=""cernvm-batch-node-2.6.0-4-1-x86_64"",; TARGET=""vda"" ]; MEMORY=""16000""; NAME=""CernVM-VAF-Node""; NIC=[; NETWORK=""My-OpenNebula-VNet"" ]; OS=[; ARCH=""x86_64"" ]; ```. The `<base64_encoded_string>` requires the base64 version of the whole; downloaded context definition. You can obtain it by running:. cat my_vaf_context.txt | base64 | tr -d '\n'. Network security groups; -----------------------. In order to make the Virtual Analysis Facility work properly, the; firewall of your infrastructure must be configured to allow some; connections. Some ports need to allow ""external"" connections while other ports might; be safely opened to allow only connections from other nodes of the; Virtual Analysis Facility. ### Ports to open on all nodes. HTCondor ports; : Allow **TCP and UDP range 9600-9700** only between nodes of the Virtual; Analysis Facility. Only HTCondor and PoD communication is needed between the nodes. No HTCondor; ports need to be opened to the world. ### Additional ports to open on the front end node. HTTPS; : Allow **TCP 443** from all. SSH; : Allow **TCP 22** from all. No other ports need to be opened from the outside. Your definition of; *allow from all* might vary.; ",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md:354,Usability,simpl,simply,354,"Deploying the Virtual Analysis Facility; =======================================. Introduction; ------------. Thanks to CernVM and PROOF on Demand, it is possible to deploy a ready; to use Virtual Analysis Facility on your cloud (either public, private; or even your desktop computer). On the server side, ""configuring"" the Virtual Analysis Facility is; simply a matter of starting a certain number of CernVM virtual machines; that will become part of your PROOF cluster. CernVM uses; contextualization to specialize each virtual machine to be either a head; node or a worker node. The Virtual Analysis Facility comes with many preconfigured things:. - a HTCondor cluster capable of running PROOF on Demand. - certificate authentication. - your experiment's software (if available on CernVM-FS). Obtain the CernVM image and contextualization; ---------------------------------------------. ### Download the CernVM bare image. The Virtual Analysis Facility currently works with *CernVM Batch 2.7.1; 64-bit*. This means that you need to have this CernVM image available; either on your local hard disk (in case of a desktop deployment) or in; your cloud's image repository. > For convenience we provide the direct link for the working versions:; >; > - [CernVM 2.7.1 batch 64-bit for; > **KVM**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.hdd.gz); >; > - [CernVM 2.7.1 batch 64-bit for; > **Xen**](https://cernvm.cern.ch/releases/19/cernvm-batch-node-2.7.1-2-3-x86_64.ext3.gz); >; > Images are gzipped. In most cases you'll need to gunzip them before; > registering to your image repository. ### Create VM configuration profiles. CernVM images are base images supporting boot-time customization via; configuration profiles called ""contexts"". Context creation can be; performed through the [CernVM Online](https://cernvm-online.cern.ch/); website. The site is immediately accessible if you have a CERN account. Go to your [CernVM Online; Dashboard](https://cernvm-online.cern.c",MatchSource.DOCS,proof/doc/confman/DeployVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DeployVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5770,Availability,echo,echo,5770,"`<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the remote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility clie",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5776,Availability,echo,echo,5776,"`<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the remote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility clie",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5972,Availability,echo,echo,5972," ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the remote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:6940,Availability,avail,available,6940,"t line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the remote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wid",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11001,Availability,avail,available,11001,"d it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections t",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11093,Availability,avail,available,11093,"ronment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 worke",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11425,Availability,avail,available,11425,"ironment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished usi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11556,Availability,avail,available,11556," cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case o",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11707,Availability,avail,available,11707,"rzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:12501,Availability,avail,available,12501,"/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request the; workers again at this point.; ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:12556,Availability,failure,failure,12556,"/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request the; workers again at this point.; ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:161,Deployability,install,installed,161,"Using the Virtual Analysis Facility; ===================================. Introduction; ------------. The Virtual Analysis Facility can be easily used by having installed on; your client the following software:. - [ROOT](http://root.cern.ch/). - [PROOF on Demand](http://pod.gsi.de/). - The VAF client *(see below)*: a convenience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1212,Deployability,configurat,configuration,1212,"n.ch/). - [PROOF on Demand](http://pod.gsi.de/). - The VAF client *(see below)*: a convenience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be cus",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1343,Deployability,configurat,configuration,1343,"nience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT ver",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1891,Deployability,configurat,configuration,1891,"de. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; confi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1947,Deployability,configurat,configuration,1947,"de. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; confi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2157,Deployability,configurat,configuration,2157,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2418,Deployability,install,installed,2418,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2457,Deployability,configurat,configuration,2457,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2526,Deployability,configurat,configuration,2526,"are). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocat",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2913,Deployability,configurat,configuration,2913,"on file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF mas",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3047,Deployability,configurat,configuration,3047,"s to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafCon",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3206,Deployability,install,installation,3206," or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible valu",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3392,Deployability,configurat,configuration,3392,"t; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3465,Deployability,install,installation,3465,"er's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3704,Deployability,install,installed,3704,"cation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configurat",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3876,Deployability,install,installation,3876,"ht be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.bef",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3955,Deployability,configurat,configuration,3955,"stem-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers sa",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4430,Deployability,configurat,configuration,4430,"calPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environme",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4595,Deployability,configurat,configuration,4595,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4665,Deployability,configurat,configuration,4665,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4714,Deployability,configurat,configuration,4714,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7313,Deployability,configurat,configuration,7313,"tory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PRO",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7394,Deployability,install,install,7394,"lly* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless S",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7941,Deployability,configurat,configuration,7941,"-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be p",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8004,Deployability,configurat,configuration,8004,"-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be p",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8772,Deployability,install,installed,8772,"e>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a rem",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9185,Deployability,configurat,configuration,9185,"--------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local com",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9270,Deployability,configurat,configuration,9270,"ent is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This she",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11129,Deployability,continuous,continuously,11129," a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11142,Deployability,update,update,11142," a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:11262,Energy Efficiency,monitor,monitoring,11262,"r local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1144,Integrability,depend,dependencies,1144,"=====================. Introduction; ------------. The Virtual Analysis Facility can be easily used by having installed on; your client the following software:. - [ROOT](http://root.cern.ch/). - [PROOF on Demand](http://pod.gsi.de/). - The VAF client *(see below)*: a convenience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot eve",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8250,Integrability,wrap,wrapper,8250,"f-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; confi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9298,Integrability,depend,depends,9298,"client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; -----------",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9784,Integrability,interface,interface,9784,"ficate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:536,Modifiability,config,configure,536,"Using the Virtual Analysis Facility; ===================================. Introduction; ------------. The Virtual Analysis Facility can be easily used by having installed on; your client the following software:. - [ROOT](http://root.cern.ch/). - [PROOF on Demand](http://pod.gsi.de/). - The VAF client *(see below)*: a convenience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1212,Modifiability,config,configuration,1212,"n.ch/). - [PROOF on Demand](http://pod.gsi.de/). - The VAF client *(see below)*: a convenience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be cus",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1343,Modifiability,config,configuration,1343,"nience tool that sets up the; environment for your experiment's software both on your client and; on the PROOF worker nodes. > If you are the end user, you'll probably might skip the part that; > concerns how to configure the VAF client: your system administrator; > has probably and conveniently set it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT ver",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1891,Modifiability,config,configuration,1891,"de. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; confi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1947,Modifiability,config,configuration,1947,"de. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; confi",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2157,Modifiability,config,configuration,2157,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2457,Modifiability,config,configuration,2457,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2526,Modifiability,config,configuration,2526,"are). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocat",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2913,Modifiability,config,configuration,2913,"on file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF mas",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3047,Modifiability,config,configuration,3047,"s to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafCon",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3307,Modifiability,variab,variables,3307,"ining the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3341,Modifiability,variab,variables,3341,"t; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3392,Modifiability,config,configuration,3392,"t; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3527,Modifiability,variab,variable,3527,"guration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via us",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3925,Modifiability,variab,variable,3925,"stem-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers sa",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3955,Modifiability,config,configuration,3955,"stem-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers sa",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4369,Modifiability,config,configured,4369,"e set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4430,Modifiability,config,configuration,4430,"calPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environme",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4595,Modifiability,config,configuration,4595,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4665,Modifiability,config,configuration,4665,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4714,Modifiability,config,configuration,4714,"`local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We n",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7313,Modifiability,config,configuration,7313,"tory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PRO",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7565,Modifiability,config,config-samples,7565,"d *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wa",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7745,Modifiability,config,config-samples,7745," data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate a",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7941,Modifiability,config,configuration,7941,"-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be p",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8004,Modifiability,config,configuration,8004,"-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be p",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8530,Modifiability,config,configured,8530,"ent and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9185,Modifiability,config,configuration,9185,"--------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local com",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9270,Modifiability,config,configuration,9270,"ent is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This she",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2577,Performance,load,loaded,2577,"tance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4331,Performance,queue,queue,4331,"e set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4519,Performance,load,loaded,4519,"VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not e",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2887,Safety,avoid,avoid,2887,"on file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF mas",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:4986,Safety,safe,safely,4986,"for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; ech",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:12287,Safety,detect,detecting,12287,"/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request the; workers again at this point.; ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1676,Security,access,accessing,1676,"et it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup f",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:1695,Security,authenticat,authenticated,1695,"et it up for you. The Virtual Analysis Facility client; ------------------------------------. The Virtual Analysis Facility client takes care of setting the; environment for the end user required by your software's experiment. The; environment will both be set on the client and on each PROOF node. Technically it is a Bash shell script which provides shortcuts for PROOF; on Demand commands and ensures local and remote environment consistency:; by executing it you enter a new clean environment where all your; software dependencies have already been set up. Local and remote environment configuration is split into a series of; files, which give the possibility to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup f",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5219,Security,authenticat,authentication,5219," the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5274,Security,authenticat,authenticate,5274," the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:5291,Security,access,access,5291," the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers safely; through the payload, see below. ### Payload: sending local files to the remote nodes. In many cases it is necessary to send some local data to the remote; workers: it is very common, for instance, to distribute a local Grid; authentication proxy on the remote workers to let them authenticate to; access a data storage. The `payload` file must be an executable generating some output that; will be prepended to the remote environment preparation. Differently; than the other environment scripts, it is not executed: instead, it is; first run, then *the output it produces will be executed*. Let's see a practical example to better understand how it works. We need; to send our Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:6677,Security,secur,secure,6677,"Grid proxy to the master node. This is our `payload` executable script:. ``` {.bash}; #!/bin/bash; echo ""echo '`cat /tmp/x509up_u$UID | base64 | tr -d '\r\n'`'"" \; ""| base64 -d > /tmp/x509up_u\$UID""; ```. This script will be executed locally, providing another ""script line"" as; output:. ``` {.bash}; echo 'VGhpcyBpcyB0aGUgZmFrZSBjb250ZW50IG9mIG91ciBHcmlkIHByb3h5IGZpbGUuCg==' | base64 -d > /tmp/x509up_u$UID; ```. This line will be prepended to the remote environment script and will be; executed before anything else on the remote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/des",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8384,Security,password,passwordless,8384,"o install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the exp",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8558,Security,authenticat,authentication,8558,"ent and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8743,Security,certificate,certificate,8743,"e>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a rem",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8941,Security,certificate,certificate,8941," configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:8967,Security,authenticat,authentication,8967," configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9053,Security,authenticat,authentication,9053," be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9951,Security,authenticat,authentication,9951,"ly be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember: you are still in a shell on your local computer!; pod://dberzano@cloud-gw-213.to.infn.it [~] >. This shell runs on your local computer and it has the environment; properly set up. PoD and PROOF workflow; ----------------------. > The following operations are valid inside the `vaf-enter` environment. ### Start your PoD server. With PROOF on Demand, each user has the control of its own personal; PROOF cluster. The first thing to do is to start the PoD server and the; PROOF master like this:. vafctl --start. A successful output will be similar to:. ** Starting remote PoD server on dberzano@cloud-gw-213.to.infn.it:/cvmfs/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request a",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2150,Usability,simpl,simple,2150,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7244,Usability,simpl,simply,7244,"emote node: it will effectively; decode the Base64 string back to the proxy file and write it into the; `/tmp` directory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; -------------------------------------------",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:9124,Usability,clear,clearly,9124,"cility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PROOF on Demand's `pod-remote`. The VAF; client takes care of setting up passwordless SSH from your client node; to the VAF master. ### Getting the credentials. > You can skip this paragraph if the remote server wasn't configured for; > HTTPS+SSH authentication. In our example we will assume that the remote server's name is; `cloud-gw-213.to.infn.it`: substitute it with your remote endpoint. First, check that you have your Grid certificate and private key; installed both in your browser and in the home directory of your; client. Point your browser to `https://cloud-gw-213.to.infn.it/auth/`: you'll; probably be asked for a certificate to choose for authentication. Pick; one and you'll be presented with the following web page:. ![Web authentication with sshcertauth](img/sshcertauth-web.png). The webpage clearly explains you what to do next. ### Customizing user's configuration. Before entering the VAF environment, you should customize the user's; configuration. How to do so depends on your experiment, but usually you; should essentially specify the version of the experiment's software you; need. For instance, in the CMS use case, only one file is needed:; `~/.vaf/common.before`, which contains something like:. ``` {.bash}; # Version of CMSSW (as reported by ""scram list""); export VafCmsswVersion='CMSSW_5_3_9_sherpa2beta2'; ```. ### Entering the VAF environment. Open a terminal on your client machine (can be either your local; computer or a remote user interface) and type:. vaf-enter <username>@cloud-gw-213.to.infn.it. You'll substitute `<username>` with the username that either your system; administrator or the web authentication (if you used it) provided you. You'll be presented with a neat shell which looks like the following:. Entering VAF environment: dberzano@cloud-gw-213.to.infn.it; Remember",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:12587,Usability,simpl,simply,12587,"/sft.cern.ch/lcg/external/PoD/3.12/x86_64-slc5-gcc41-python24-boost1.53; ** Server is started. Use ""pod-info -sd"" to check the status of the server. ### Request and wait for workers. Now the server is started but you don't have any worker available. To; request for `<n>` workers, do:. vafreq <n>. To check how many workers became available for use:. pod-info -n. To continuously update the check (`Ctrl-C` to terminate):. vafcount. Example of output:. Updating every 5 seconds. Press Ctrl-C to stop monitoring...; [20130411-172235] 0; [20130411-172240] 0; [20130411-172245] 12; [20130411-172250] 12; ... To execute a command after a certain number of workers is available (in; the example we wait for 5 workers then start ROOT):. vafwait 5 && root -l. > Workers take some time before becoming available. Also, it is possible; > that not all the requested workers will be satisfied. ### Start ROOT and use PROOF. When you are satisfied with the available number of active workers, you; may start your PROOF analysis. Start ROOT, and from its prompt connect; to PROOF like this:. root [0] TProof::Open(""pod://"");. Example of output:. Starting master: opening connection ...; Starting master: OK; Opening connections to workers: OK (12 workers); Setting up worker servers: OK (12 workers); PROOF set to parallel mode (12 workers). ### Stop or restart your PoD cluster. At the end of your session, remember to free the workers by stopping; your PoD server:. vafctl --stop. > PoD will stop the PROOF master and the workers after detecting they've; > been idle for a certain amount of time anyway, but it is a good habit; > to stop it for yourself when you're finished using it, so that you are; > immediately freeing resources and let them be available for other; > users. In case of a major PROOF failure (i.e., crash), you can simply restart; your personal PROOF cluster by running:. vafctl --start. PoD will stop and restart the PROOF master. You'll need to request the; workers again at this point.; ",MatchSource.DOCS,proof/doc/confman/UsingVirtualAnalysisFacility.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:109,Availability,avail,available,109,"## PROOF System. All the fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling.",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1715,Availability,ping,ping,1715,"ge of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1797,Availability,ping,ping,1797,"ge of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1854,Availability,ping,ping,1854,"ge of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2081,Availability,avail,available,2081,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:86,Deployability,release,release,86,"## PROOF System. All the fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling.",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2772,Deployability,patch,patch,2772,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2778,Deployability,release,release,2778,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2823,Deployability,install,install,2823,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2866,Deployability,patch,patch-release-notes,2866,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:362,Integrability,protocol,protocol,362,"## PROOF System. All the fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling.",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1043,Performance,cache,cache,1043," fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can b",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1175,Performance,scalab,scalability,1175,"a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:522,Security,hash,hash,522,"## PROOF System. All the fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling.",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2498,Security,access,access,2498,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1509,Testability,test,test,1509,"e for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more f",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1681,Testability,test,test,1681,"ge of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1696,Testability,test,test,1696,"ge of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2099,Testability,log,log,2099,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2630,Testability,test,tests,2630,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:2655,Testability,test,test,2655,"still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can be specified as option to TProof::Open and the output is available via the log viewer technology:. ``` {.cpp}; root[] p = TProof::Open(""master"", ""igprof-pp""); ```; - Miscellanea:; - Added functions [Getenv](http://root.cern.ch/root/htmldoc/TProof.html#TProof:Getenv) and [GetRC](http://root.cern.ch/root/htmldoc/TProof.html#TProof:GetRC); in TProof to retrieve environment information from the nodes, typically from the master.; - Add support unix secondary groups in group access control. This allows more flexibility in, for example, assigning group-shared credential files to the daemon.; - Several new tests and options in the test program _stressProof_. ### Bug fixes. Several consolidation fixes in several parts of the system (see the [5.34 patch release notes for details](https://root.cern/install/all_releases/root-version-v5-34-00-patch-release-notes/)). In particular, those for 'xproofd' were provided by B. Butler and M. Swiatlowski and greatly contributed to consolidate the daemon. ",MatchSource.DOCS,proof/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md:130,Deployability,release,release,130,"% ROOT Version ?.?? Release Notes; % 20??-??-??; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.??.00 is scheduled for release in ???. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHE",MatchSource.DOCS,README/ReleaseNotes/empty.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md:116,Energy Efficiency,schedul,scheduled,116,"% ROOT Version ?.?? Release Notes; % 20??-??-??; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.??.00 is scheduled for release in ???. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. Anton Alkin, Sungkyunkwan University\; Guilherme Amadio, CERN/IT,\; Abhigyan Acherjee, University of Cincinnati,\; Bertrand Bellenot, CERN/EP-SFT,\; Jakob Blomer, CERN/EP-SFT,\; Rene Brun,\; Carsten Burgard, DESY\; Will Buttinger, RAL,\; Philippe Canal, FNAL,\; Jolly Chen, CERN/EP-SFT,\; Olivier Couet, CERN/EP-SFT,\; Marta Czurylo, CERN/EP-SFT,\; Monica Dessole, CERN/EP-SFT,\; Mattias Ellert, Uppsala University,\; Gerri Ganis, CERN/EP-SFT,\; Florine de Geus, CERN/University of Twente,\; Andrei Gheata, CERN/EP-SFT,\; Bernhard Manfred Gruber,\; Enrico Guiraud,; Jonas Hahnfeld, CERN/Goethe University Frankfurt,\; Fernando Hueso Gonzalez, University of Valencia\; Attila Krasznahorkay, CERN/EP-ADP-OS,\; Wim Lavrijsen, LBL,\; Dennis Klein, GSI,\; Christoph Langenbruch, Heidelberg University/LHCb,\; Sergey Linev, GSI,\; Javier Lopez-Gomez,\; Pere Mato, CERN/EP-SFT,\; Alaettin Serhan Mete, Argonne,\; Thomas Madlener, DESY,\; Lorenzo Moneta, CERN/EP-SFT,\; Alja Mrak Tadel, UCSD/CMS,\; Axel Naumann, CERN/EP-SFT,\; Dante Niewenhuis, VU Amsterdam\; Luis Antonio Obis Aparicio, University of Zaragoza,; Ianna Osborne, Princeton University,\; Vincenzo Eduardo Padulano, CERN/EP-SFT,\; Danilo Piparo, CERN/EP-SFT,\; Fons Rademakers, CERN/IT,\; Jonas Rembser, CERN/EP-SFT,\; Andrea Rizzi, University of Pisa,\; Andre Sailer, CERN/EP-SFT,\; Garima Singh, ETH,\; Juraj Smiesko, CERN/RCS-PRJ-FC,; Pavlo Svirin, National Technical University of Ukraine,\; Maciej Szymanski, Argonne,\; Christian Tacke, Darmstadt University,\; Matevz Tadel, UCSD/CMS,\; Alvaro Tolosa Delgado, CERN/RCS-PRJ-FC,\; Devajith Valaparambil Sreeramaswamy, CERN/EP-SFT,\; Peter Van Gemmeren, Argonne,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHE",MatchSource.DOCS,README/ReleaseNotes/empty.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/empty.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11437,Availability,avail,available,11437,"cale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Ad",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14655,Availability,error,error,14655,"1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula cl",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:15598,Availability,avail,available,15598,"type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = (TFormula *) f1;; ```. **it is not valid anymore.**; The equivalent correct code is now. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = f1->GetFormula();; ```. ### TGraph2DPainter. - In some case and extra point was drawn in the center od the plot when a; `TGRaph2d`was drawn with `P`, `P0`, or `PCOL` options. ### THistPainter. - It was possible to interactively zoom outside the histograms' limits. Protec",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:15679,Availability,avail,available,15679,"e list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = (TFormula *) f1;; ```. **it is not valid anymore.**; The equivalent correct code is now. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = f1->GetFormula();; ```. ### TGraph2DPainter. - In some case and extra point was drawn in the center od the plot when a; `TGRaph2d`was drawn with `P`, `P0`, or `PCOL` options. ### THistPainter. - It was possible to interactively zoom outside the histograms' limits. Protections; have been added.; - When an histogram was drawn with the option `E0` and log scale along the Y axis,; some additional markers were dr",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:15751,Availability,avail,available,15751,"e list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = (TFormula *) f1;; ```. **it is not valid anymore.**; The equivalent correct code is now. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = f1->GetFormula();; ```. ### TGraph2DPainter. - In some case and extra point was drawn in the center od the plot when a; `TGRaph2d`was drawn with `P`, `P0`, or `PCOL` options. ### THistPainter. - It was possible to interactively zoom outside the histograms' limits. Protections; have been added.; - When an histogram was drawn with the option `E0` and log scale along the Y axis,; some additional markers were dr",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:21442,Availability,error,error,21442,"rowse/ROOT-6561); - Interactive update of `TText` position did not work in NDC mode.; (se https://sft.its.cern.ch/jira/browse/ROOT-7284). ### TLegend. - Use the new `TStyle` global attribute `gStyle->GetLegendTextSize()` to set the; legend item text size. If this value is 0 and if the text size directly set on; the `TLegend` object is also 0, then the text size is automatically computed to; fit the legend box. If `gStyle->GetLegendTextSize()` is non equal to 0 and if; text size directly set on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; - Fix an issue with transparent pads.; - Implement transparent colors using TiKZ ""opacity"".; - Implement `TStyle::SetLineScalePS()` to control le global basic line width.; - Offer 0 as line width option. Useful to make a line invisible. ### TPostScript. - Small fix for fill patterns 1, 2 and 3.; - With `TMathtext`, only the fonts really used are now loaded in the PostScript; file. Typically it reduces the file size by a factor 10 (compare to the previous; implementation) for normal plots with math formulae and greek characters.; - Offer 0 as line width option. Useful to make a line invisible. ### TPDF. - When a text size was equal or smaller than 0 the PDF file was corrupted.; - Small fix for fill patterns 1, 2 and 3.; - When printing a coloured 2D histograms (with option COLZ) into a PDF or PostScript; file, the preview on screen using many standard PDF previewer tools showed very; thin white lines between the bins as well as in the color palette.;",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:121,Deployability,release,released,121,"% ROOT Version 6.04/00 Release Notes; % 2 June 2015; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.04/00 was released on 2 June, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT,\; Maciej Zimnoch. ## Core Libraries. ### General. #### Platform support. ROOT now works on linuxarm64 / AArch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:7782,Deployability,update,updated,7782,"Solar](palette_100.png); ![SouthWest](palette_101.png); ![StarryNight](palette_102.png); ![Sunset](palette_103.png); ![TemperatureMap](palette_104.png); ![Thermometer](palette_105.png); ![Valentine](palette_106.png); ![VisibleSpectrum](palette_107.png); ![WaterMelon](palette_108.png); ![Cool](palette_109.png); ![Copper](palette_110.png); ![GistEart](palette_111.png). ### Interpreter Library. Many, many bugs have been fixed; thanks to everyone who has reported them!. #### Cling. Cling is now using a new just-in-time compilation engine called OrcJIT, a development based on MCJIT. It enables interpretation of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a Strea",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:7846,Deployability,release,release,7846,"ht](palette_102.png); ![Sunset](palette_103.png); ![TemperatureMap](palette_104.png); ![Thermometer](palette_105.png); ![Valentine](palette_106.png); ![VisibleSpectrum](palette_107.png); ![WaterMelon](palette_108.png); ![Cool](palette_109.png); ![Copper](palette_110.png); ![GistEart](palette_111.png). ### Interpreter Library. Many, many bugs have been fixed; thanks to everyone who has reported them!. #### Cling. Cling is now using a new just-in-time compilation engine called OrcJIT, a development based on MCJIT. It enables interpretation of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have bee",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:20474,Deployability,update,update,20474,"-4,4);; h1->FillRandom(""gaus"",20000);; h1->SetFillColor(kRed);; hs->Add(h1);. TH1F *h2 = new TH1F(""h2"",""h2"",10,-4,4);; h2->FillRandom(""gaus"",15000);; h2->SetFillColor(kBlue);; hs->Add(h2);. TH1F *h3 = new TH1F(""h3"",""h3"",10,-4,4);; h3->FillRandom(""gaus"",10000);; h3->SetFillColor(kGreen);; hs->Add(h3);. hs->Draw(""nostackb"");; return cst0;; }. ```; ![NOSTACKB plot example](nostackb.png ""NOSTACKB plot example""). ## GUI Libraries. ### TGTextViewostream. - A new `TGTextViewostream` class has been added. It is a text viewer widget and is a specialization of `TGTextView` and `std::ostream`. It uses a `TGTextViewStreamBuf`, which inherits from `std::streambuf`, allowing to stream text directly to the text view in a `cout` - like fashion. A new tutorial showing how to use the `TGTextViewostream` widget has also been added. ## 2D Graphics Libraries. ### TText. - The character position was not correct with the Cocoa backend.; (see https://sft.its.cern.ch/jira/browse/ROOT-6561); - Interactive update of `TText` position did not work in NDC mode.; (se https://sft.its.cern.ch/jira/browse/ROOT-7284). ### TLegend. - Use the new `TStyle` global attribute `gStyle->GetLegendTextSize()` to set the; legend item text size. If this value is 0 and if the text size directly set on; the `TLegend` object is also 0, then the text size is automatically computed to; fit the legend box. If `gStyle->GetLegendTextSize()` is non equal to 0 and if; text size directly set on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; -",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:24934,Deployability,configurat,configuration,24934," specify the delay between the last; image and the fist image in case of infinite loop. (Fernando Hueso Gonzlez; <f.gonzalez@hzdr.de>). ### TPadPainter; - Offer 0 as line width option. Useful to make a line invisible. ### TPad. - In `TPad::ShowGuidelines` the number of guide lines is limited to 15. Above; that they become useless.; - Print a warning if one of the pad limit is a NaN.; - Fix https://sft.its.cern.ch/jira/browse/ROOT-6703. ### TCanvas. - Make sure that ""/"" and ""."" are not part of the method name when a canvas is; saved as a .C file. ### TLatex. - With the Cocoa backend the PDF and PS output produced miss-aligned exponents; because the `GetTextExtend` method behaved differently in batch mode and ""screen""; mode. This is now fixed. See http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18883; - Improve the square-root drawing in case it is small.; - Better adjustment of the tilde accent position in case of Cocoa backend. ### TMathText. - `\mu` is now working for Postscript output.; - `\splitline` is now implemented. ### Cocoa backend. - Line width and line style were not applied on boxes. ## 3D Graphics Libraries. ### GL Viewer; - New option ""Rotate scene"" in the ""Extras"" tab of the GL Viewer. It allows to; do a real rotation instead of a wobbling when the ""Auto Rotator"" is launched.; - New methods from Jeremi Niedziela <jeremi.niedziela@cern.ch> to return the; image in memory. ## Tutorials. - New tutorial `textviewostream.C` showing how to use the TGTextViewostream widget. ## Build, Configuration and Testing Infrastructure. ### New functionalities. - Support ARM 64 bits architecture. - Partial support for PPC 64 bits Little Endian architecture. - Add ""Optimized"" CMAKE_BUILD_TYPE: allow highest level of optimisation of the GCC and Clang compilers (-Ofast). - Support ccache activation with cmake configuration switch. - Support link to jemalloc and tcmalloc allocators. - Careful suppression of known and understood warnings, e.g. coming from external packages.; ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8729,Energy Efficiency,schedul,scheduling,8729,"clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9943,Energy Efficiency,monitor,monitoring,9943,"en an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:10748,Energy Efficiency,monitor,monitor,10748,"d 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11989,Energy Efficiency,reduce,reduce,11989,"_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the d",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:21876,Energy Efficiency,reduce,reduces,21876," on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; - Fix an issue with transparent pads.; - Implement transparent colors using TiKZ ""opacity"".; - Implement `TStyle::SetLineScalePS()` to control le global basic line width.; - Offer 0 as line width option. Useful to make a line invisible. ### TPostScript. - Small fix for fill patterns 1, 2 and 3.; - With `TMathtext`, only the fonts really used are now loaded in the PostScript; file. Typically it reduces the file size by a factor 10 (compare to the previous; implementation) for normal plots with math formulae and greek characters.; - Offer 0 as line width option. Useful to make a line invisible. ### TPDF. - When a text size was equal or smaller than 0 the PDF file was corrupted.; - Small fix for fill patterns 1, 2 and 3.; - When printing a coloured 2D histograms (with option COLZ) into a PDF or PostScript; file, the preview on screen using many standard PDF previewer tools showed very; thin white lines between the bins as well as in the color palette.; This made very ugly the final output.; This problem is due to bad implementation of anti-aliasing in these previewers.; A way to bypass this issue was to turn off the anti-aliasing in the previewer; but then the rest of the document does not look nice. This problem is now bypassed; with a fix in both PDF and PostScript output.; - Offer 0 as line width option. Useful to make a line invisible. ### TSVG. - Use float numbers instead of integer to describe graphics paths to avoid; rounding prob",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2131,Integrability,interface,interfaces,2131,"Arch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2724,Integrability,interface,interface,2724,"iler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:3793,Modifiability,config,configuring,3793,"o the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new palettes with 255 colors. Names and colors' definitions have been taken from; [here](http://www.rcnp.osaka-u.ac.jp/~noji/colormap). Except for the `kBird` palette.; These palettes can be accessed with `gStyle->SetPalette(num)`. `num` can be taken; within the following enum:. * kDeepSea = 51; * kGreyScale = 52; * kDarkBodyRadiator = 53; * kBlueYellow = 54; * kRainBow = 55; * kInvertedDarkBodyRadiator = 56; * kBird = 57; * kCubehelix = 58; * kGreenRedViolet = 59; * kBlueRedYellow = 60; * kOcean = 61; * kColorPrintableOnGrey = 62; * kAlpine = 63; * kAquamarine = 64; * kArmy = 65; * kAtlantic = 66; * kAurora = 67; * kAvocado = 68; * kBeach = 69; * kBlackBody = 70; * kBlueGreenYellow = 71; * kBrownCyan = 72; * kCMYK = 73; * kCandy = 74; * kCherry = 75; * kCoffee = 76; * kDarkRainBow = 77; * kDarkTerrain = 78; * kFall = 79; * kFruitPunch = 80; * kFuchsia = 81; * kGreyYellow = 82; * kG",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:7990,Modifiability,variab,variable,7990,"Valentine](palette_106.png); ![VisibleSpectrum](palette_107.png); ![WaterMelon](palette_108.png); ![Cool](palette_109.png); ![Copper](palette_110.png); ![GistEart](palette_111.png). ### Interpreter Library. Many, many bugs have been fixed; thanks to everyone who has reported them!. #### Cling. Cling is now using a new just-in-time compilation engine called OrcJIT, a development based on MCJIT. It enables interpretation of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with t",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8399,Modifiability,portab,portability,8399,"on of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface;",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9640,Modifiability,config,configured,9640," the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provi",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9702,Modifiability,config,configure,9702,"yout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (vi",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9933,Modifiability,config,configure,9933,"en an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11956,Modifiability,extend,extend,11956," stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data th",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11981,Modifiability,extend,extend,11981,"_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the d",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13153,Modifiability,variab,variables,13153," in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In part",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13258,Modifiability,variab,variable,13258,"er classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE)",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13695,Modifiability,config,configured,13695,"of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there w",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13825,Modifiability,variab,variable,13825,", the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; Th",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13869,Modifiability,variab,variable,13869," off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14064,Modifiability,variab,variable,14064,"ehavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Chan",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:15092,Modifiability,variab,variables,15092,"FILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:15969,Modifiability,inherit,inheritance,15969,"se of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = (TFormula *) f1;; ```. **it is not valid anymore.**; The equivalent correct code is now. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = f1->GetFormula();; ```. ### TGraph2DPainter. - In some case and extra point was drawn in the center od the plot when a; `TGRaph2d`was drawn with `P`, `P0`, or `PCOL` options. ### THistPainter. - It was possible to interactively zoom outside the histograms' limits. Protections; have been added.; - When an histogram was drawn with the option `E0` and log scale along the Y axis,; some additional markers were drawn at the bottom line of the plot. This was; reported <a href=""http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18778"">here</a>.; - Implement the option `0` combined with the option `COL` as requested; <a href=""https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:20108,Modifiability,inherit,inherits,20108," histograms in the stack.; - New drawing option `NOSTACKB`. histograms are drawn next to each other as; bar charts. Example:. ``` {.cpp}; TCanvas* nostackb() {; TCanvas *cst0 = new TCanvas(""cst0"",""cst0"",600,400);; THStack *hs = new THStack(""hs"",""Stacked 1D histograms: option #font[82]{\""nostackb\""}"");. TH1F *h1 = new TH1F(""h1"",""h1"",10,-4,4);; h1->FillRandom(""gaus"",20000);; h1->SetFillColor(kRed);; hs->Add(h1);. TH1F *h2 = new TH1F(""h2"",""h2"",10,-4,4);; h2->FillRandom(""gaus"",15000);; h2->SetFillColor(kBlue);; hs->Add(h2);. TH1F *h3 = new TH1F(""h3"",""h3"",10,-4,4);; h3->FillRandom(""gaus"",10000);; h3->SetFillColor(kGreen);; hs->Add(h3);. hs->Draw(""nostackb"");; return cst0;; }. ```; ![NOSTACKB plot example](nostackb.png ""NOSTACKB plot example""). ## GUI Libraries. ### TGTextViewostream. - A new `TGTextViewostream` class has been added. It is a text viewer widget and is a specialization of `TGTextView` and `std::ostream`. It uses a `TGTextViewStreamBuf`, which inherits from `std::streambuf`, allowing to stream text directly to the text view in a `cout` - like fashion. A new tutorial showing how to use the `TGTextViewostream` widget has also been added. ## 2D Graphics Libraries. ### TText. - The character position was not correct with the Cocoa backend.; (see https://sft.its.cern.ch/jira/browse/ROOT-6561); - Interactive update of `TText` position did not work in NDC mode.; (se https://sft.its.cern.ch/jira/browse/ROOT-7284). ### TLegend. - Use the new `TStyle` global attribute `gStyle->GetLegendTextSize()` to set the; legend item text size. If this value is 0 and if the text size directly set on; the `TLegend` object is also 0, then the text size is automatically computed to; fit the legend box. If `gStyle->GetLegendTextSize()` is non equal to 0 and if; text size directly set on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTex",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:24934,Modifiability,config,configuration,24934," specify the delay between the last; image and the fist image in case of infinite loop. (Fernando Hueso Gonzlez; <f.gonzalez@hzdr.de>). ### TPadPainter; - Offer 0 as line width option. Useful to make a line invisible. ### TPad. - In `TPad::ShowGuidelines` the number of guide lines is limited to 15. Above; that they become useless.; - Print a warning if one of the pad limit is a NaN.; - Fix https://sft.its.cern.ch/jira/browse/ROOT-6703. ### TCanvas. - Make sure that ""/"" and ""."" are not part of the method name when a canvas is; saved as a .C file. ### TLatex. - With the Cocoa backend the PDF and PS output produced miss-aligned exponents; because the `GetTextExtend` method behaved differently in batch mode and ""screen""; mode. This is now fixed. See http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18883; - Improve the square-root drawing in case it is small.; - Better adjustment of the tilde accent position in case of Cocoa backend. ### TMathText. - `\mu` is now working for Postscript output.; - `\splitline` is now implemented. ### Cocoa backend. - Line width and line style were not applied on boxes. ## 3D Graphics Libraries. ### GL Viewer; - New option ""Rotate scene"" in the ""Extras"" tab of the GL Viewer. It allows to; do a real rotation instead of a wobbling when the ""Auto Rotator"" is launched.; - New methods from Jeremi Niedziela <jeremi.niedziela@cern.ch> to return the; image in memory. ## Tutorials. - New tutorial `textviewostream.C` showing how to use the TGTextViewostream widget. ## Build, Configuration and Testing Infrastructure. ### New functionalities. - Support ARM 64 bits architecture. - Partial support for PPC 64 bits Little Endian architecture. - Add ""Optimized"" CMAKE_BUILD_TYPE: allow highest level of optimisation of the GCC and Clang compilers (-Ofast). - Support ccache activation with cmake configuration switch. - Support link to jemalloc and tcmalloc allocators. - Careful suppression of known and understood warnings, e.g. coming from external packages.; ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2929,Performance,perform,performed,2929,"constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new pale",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2980,Performance,load,load,2980,"st element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new palettes with 255 colors. Names and colors' definitions have been ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9922,Performance,load,loaded,9922,"en an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:10405,Performance,load,loaded,10405,"ster an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; no",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11611,Performance,load,loaded,11611," devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TT",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13435,Performance,cache,cache,13435,"### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of defa",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13478,Performance,cache,cache,13478,"ction*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally sever",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13522,Performance,cache,cache,13522,"ction*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally sever",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13608,Performance,cache,cache,13608,"of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there w",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13675,Performance,cache,caches,13675,"of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there w",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13731,Performance,cache,cache,13731," when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:13769,Performance,cache,cache,13769," than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14334,Performance,cache,cache,14334,"e TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled u",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14389,Performance,cache,cache,14389,"e TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled u",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14468,Performance,cache,cache,14468,"e TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled u",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14547,Performance,cache,cache,14547,"1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula cl",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14739,Performance,cache,cached,14739,"; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFun",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14856,Performance,cache,cache,14856,"ECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14903,Performance,cache,cache,14903,"e default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormu",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:21831,Performance,load,loaded,21831,"ally computed to; fit the legend box. If `gStyle->GetLegendTextSize()` is non equal to 0 and if; text size directly set on the `TLegend` object is 0, then the `gStyle` value is; used to draw the legend text. If the text size directly set on the `TLegend`; object is not null, then it is used to draw the legend text. ### TTexDump. - The hollow fill style was not rendered correctly.; (see https://sft.its.cern.ch/jira/browse/ROOT-6841); - Better line width matching with screen and pdf output.; - Text color was ignored. It was always black.; - Text color was ignored. It was always black.; - The underscore `_` produced an error outside the TeX math context.; - Fix an issue with transparent pads.; - Implement transparent colors using TiKZ ""opacity"".; - Implement `TStyle::SetLineScalePS()` to control le global basic line width.; - Offer 0 as line width option. Useful to make a line invisible. ### TPostScript. - Small fix for fill patterns 1, 2 and 3.; - With `TMathtext`, only the fonts really used are now loaded in the PostScript; file. Typically it reduces the file size by a factor 10 (compare to the previous; implementation) for normal plots with math formulae and greek characters.; - Offer 0 as line width option. Useful to make a line invisible. ### TPDF. - When a text size was equal or smaller than 0 the PDF file was corrupted.; - Small fix for fill patterns 1, 2 and 3.; - When printing a coloured 2D histograms (with option COLZ) into a PDF or PostScript; file, the preview on screen using many standard PDF previewer tools showed very; thin white lines between the bins as well as in the color palette.; This made very ugly the final output.; This problem is due to bad implementation of anti-aliasing in these previewers.; A way to bypass this issue was to turn off the anti-aliasing in the previewer; but then the rest of the document does not look nice. This problem is now bypassed; with a fix in both PDF and PostScript output.; - Offer 0 as line width option. Useful to mak",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:1354,Safety,safe,safety,1354,"n, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/Alice,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Yue Shi Lai, MIT,\; Maciej Zimnoch. ## Core Libraries. ### General. #### Platform support. ROOT now works on linuxarm64 / AArch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::strin",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2066,Safety,avoid,avoid,2066,"Arch64 / ARMv8 64-bit - thanks, David Abdurachmanov!. ROOT supports GCC 5.0 (using the GCC4 ABI) and XCode 6.3, Mac OSX 10.10.3. #### Thread-Safety. A lot of effort went into improving the thread-safety of Core and Meta classes / functions. A special thanks to Chris Jones from CMS!. #### std::string_view. Introduce a preview of C++17's std::string_view. To take advantage of this new; class use:; ```{.cpp}; #include ""RStringView.h""; ```; The documentation of this can be found at `http://en.cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:8308,Safety,avoid,avoiding,8308," using a new just-in-time compilation engine called OrcJIT, a development based on MCJIT. It enables interpretation of inline assembly and exceptions; it will hopefully in the near future also support interpreting thread local storage (but doesn't at the moment). Thanks to the new JIT, cling also comes with debug symbols for interpreted code; you can enable them with "".debug"". #### Function evaluation. Function calls through TMethodCall etc have been accelerated. #### llvm / clang. llvm / clang were updated to r227800. This includes everything from the clang 3.6 release. ### Dictionary Generation. Detect usage of #pragma once for inlined headers. Turn on verbosity of genreflex if the VERBOSE environment variable is defined. Optimise forward declarations in rootmap files in order to make their interpretation faster. Propagate attributes specified in xml selection files to selected classes even when selected through typedefs. Optimise selection procedure caching selected declarations in the selection rules, therewith avoiding to query the AST twice. Include in the PCH all the STL and C headers to guarantee portability of binaries from SLC6 to CC7. ## I/O Libraries. ### I/O New functionalities. - Support for forward_list and I/O of unordered stl containers.; - Support for std::complex. ### I/O Behavior change. - The I/O now properly skip the content of base class onfile that have been removed from the in-memory class layout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest c",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:22917,Safety,avoid,avoid,22917,"ize by a factor 10 (compare to the previous; implementation) for normal plots with math formulae and greek characters.; - Offer 0 as line width option. Useful to make a line invisible. ### TPDF. - When a text size was equal or smaller than 0 the PDF file was corrupted.; - Small fix for fill patterns 1, 2 and 3.; - When printing a coloured 2D histograms (with option COLZ) into a PDF or PostScript; file, the preview on screen using many standard PDF previewer tools showed very; thin white lines between the bins as well as in the color palette.; This made very ugly the final output.; This problem is due to bad implementation of anti-aliasing in these previewers.; A way to bypass this issue was to turn off the anti-aliasing in the previewer; but then the rest of the document does not look nice. This problem is now bypassed; with a fix in both PDF and PostScript output.; - Offer 0 as line width option. Useful to make a line invisible. ### TSVG. - Use float numbers instead of integer to describe graphics paths to avoid; rounding problems.; - Implement missing math symbols.; - Offer 0 as line width option. Useful to make a line invisible. ### TASImage. - In the animated gif it is now possible to specify the delay between the last; image and the fist image in case of infinite loop. (Fernando Hueso Gonzlez; <f.gonzalez@hzdr.de>). ### TPadPainter; - Offer 0 as line width option. Useful to make a line invisible. ### TPad. - In `TPad::ShowGuidelines` the number of guide lines is limited to 15. Above; that they become useless.; - Print a warning if one of the pad limit is a NaN.; - Fix https://sft.its.cern.ch/jira/browse/ROOT-6703. ### TCanvas. - Make sure that ""/"" and ""."" are not part of the method name when a canvas is; saved as a .C file. ### TLatex. - With the Cocoa backend the PDF and PS output produced miss-aligned exponents; because the `GetTextExtend` method behaved differently in batch mode and ""screen""; mode. This is now fixed. See http://root.cern.ch/phpBB3/viewtopic.",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:2665,Security,access,accessible,2665,"cppreference.com/w/cpp/experimental/basic_string_view`; The implementation provided is extracted from libcxx. Whenever the current; compiler and standard library provide an implmentation, it is used. The type string_view describes an object that can refer to a constant contiguous sequence of char-like objects with the first element of the sequence at position zero. This type is used throughout the ROOT code to avoid copying strings when a; sub-string is needed and to extent interfaces that uses to take a const char*; to take a std::string_view as thus be able to be directly directly passed a; TString, a std::string or a std::string_view. Usage example:. ``` {.cpp}; // With SetName(std::string_view); std::string str; ; obj.SetName( str );; obj.SetName( {str.data()+pos, len} );; ```. ### Meta library. #### Backward Incompatibilities. TIsAProxy's constructor no longer take the optional and unused 2nd argument which was reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemente",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:3584,Security,checksum,checksum,3584,"as reserved for a 'context'. This context was unused in TIsAProxy itself and was not accessible from derived classes. #### Interpreter. The new interface `TInterpreter::Declare(const char* code)` will declare the; code to the interpreter with all interpreter extensions disabled, i.e. as; ""proper"" C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new palettes with 255 colors. Names and colors' definitions have been taken from; [here](http://www.rcnp.osaka-u.ac.jp/~noji/colormap). Except for the `kBird` palette.; These palettes can be accessed with `gStyle->SetPalette(num)`. `num` can be taken; within the following enum:. * kDeepSea = 51; * kGreyScale = 52; * kDarkBodyRadiator = 53; * kBlueYellow = 54; * kRainBow = 55; * kInvertedDarkBodyRadiator = 56; * kBird = 57; * kCubehelix = 58; * kGreenRedViolet = 59; * kBlueRedYellow = 60; * kOcean = 61; * kColorPrintableOnGrey = 62; * kAlpine = 63; * kAquamarine = 64; * kArmy = 65; * kAtlantic = 66; * kAurora = 67; * kAvocado = 68; * kBeach = 69; * kBlackBody = 70; * ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:3873,Security,access,access,3873,"C++ code. No autoloading or synamic lookup will be performed. A new R__LOAD_LIBRARY(libWhatever) will load libWhatever at parse time. This allows ROOT to resolve symbols from this library very early on. It is a work-around for the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new palettes with 255 colors. Names and colors' definitions have been taken from; [here](http://www.rcnp.osaka-u.ac.jp/~noji/colormap). Except for the `kBird` palette.; These palettes can be accessed with `gStyle->SetPalette(num)`. `num` can be taken; within the following enum:. * kDeepSea = 51; * kGreyScale = 52; * kDarkBodyRadiator = 53; * kBlueYellow = 54; * kRainBow = 55; * kInvertedDarkBodyRadiator = 56; * kBird = 57; * kCubehelix = 58; * kGreenRedViolet = 59; * kBlueRedYellow = 60; * kOcean = 61; * kColorPrintableOnGrey = 62; * kAlpine = 63; * kAquamarine = 64; * kArmy = 65; * kAtlantic = 66; * kAurora = 67; * kAvocado = 68; * kBeach = 69; * kBlackBody = 70; * kBlueGreenYellow = 71; * kBrownCyan = 72; * kCMYK = 73; * kCandy = 74; * kCherry = 75; * kCoffee = 76; * kDarkRainBow = 77; * kDarkTerrain = 78; * kFall = 79; * kFruitPunch = 80; * kFuchsia = 81; * kGreyYellow = 82; * kGreenBrownTerrain = 83; * kGreenPink = 84; * kIsland = 85; * kLake = 86; * kLigh",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:4096,Security,access,accessed,4096," the following code from ROOT 5:. ``` {.cpp}; // ROOT 5:; void func() {; gSystem->Load(""libEvent"");; Event* e = new Event;; }; ```. Instead, write:. ``` {.cpp}; // ROOT 6:; R__LOAD_LIBRARY(libEvent); #include ""Event.h"". void func() {; Event* e = new Event;; }; ```. #### TClass. Introduced new overload for calculating the TClass CheckSum:. ``` {.cpp}; UInt_t TClass::GetCheckSum(ECheckSum code, Bool_t &isvalid) const;; ```. which indicates via the 'isvalid' boolean whether the checksum could be; calculated correctly or not. ### TROOT. Implemented new gROOT->GetTutorialsDir() static method to return the actual location of the tutorials directory.; This is $ROOTSYS/tutorials when not configuring with --prefix or -Dgnuinstall for CMake. ### TColor. Add an enum to access the palette by name. Add new palettes with 255 colors. Names and colors' definitions have been taken from; [here](http://www.rcnp.osaka-u.ac.jp/~noji/colormap). Except for the `kBird` palette.; These palettes can be accessed with `gStyle->SetPalette(num)`. `num` can be taken; within the following enum:. * kDeepSea = 51; * kGreyScale = 52; * kDarkBodyRadiator = 53; * kBlueYellow = 54; * kRainBow = 55; * kInvertedDarkBodyRadiator = 56; * kBird = 57; * kCubehelix = 58; * kGreenRedViolet = 59; * kBlueRedYellow = 60; * kOcean = 61; * kColorPrintableOnGrey = 62; * kAlpine = 63; * kAquamarine = 64; * kArmy = 65; * kAtlantic = 66; * kAurora = 67; * kAvocado = 68; * kBeach = 69; * kBlackBody = 70; * kBlueGreenYellow = 71; * kBrownCyan = 72; * kCMYK = 73; * kCandy = 74; * kCherry = 75; * kCoffee = 76; * kDarkRainBow = 77; * kDarkTerrain = 78; * kFall = 79; * kFruitPunch = 80; * kFuchsia = 81; * kGreyYellow = 82; * kGreenBrownTerrain = 83; * kGreenPink = 84; * kIsland = 85; * kLake = 86; * kLightTemperature = 87; * kLightTerrain = 88; * kMint = 89; * kNeon = 90; * kPastel = 91; * kPearl = 92; * kPigeon = 93; * kPlum = 94; * kRedBlue = 95; * kRose = 96; * kRust = 97; * kSandyTerrain = 98; * kSienna = 99; * kSolar = 1",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9811,Security,access,access,9811,"oon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root f",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:18426,Security,access,access,18426,"or (Int_t i = 0; i < 25000; i++) {; gRandom->Rannor(px,py);; hcol21->Fill(px,5*py);; hcol22->Fill(px,5*py);; }; hcol21->SetBit(TH1::kNoStats);; hcol22->SetBit(TH1::kNoStats);; gStyle->SetPalette(1);; c1->cd(1); hcol21->Draw(""COLZ"");; c1->cd(2); hcol22->Draw(""COLZ0"");; hcol22->SetMaximum(100);; hcol22->SetMinimum(40);; return c1;; }; ```; ![COLZ0 plot example](colz0.png ""COLZ0 plot example""); - The parameter `gStyle->SetHistTopMargin()` was ignored when plotting a 2D histogram; using the option `E`. This can be seen plotting the histogram with `""LEGO E""`.; - `GetObjectInfo` did not display the right value form `""Sum""` for histograms plotted; with option `SAME` on top of an histogram displayed with a subrange. This was; reported in ROOT-7124.; - Use `GeyStdDev` instead of `GetRMS`. The stat box now shows `Std Dev` instead; of `RMS`.; - The Stats Format was ignored when painting the pave stats for 2D histograms. ### TGraph2D. - Change `GetHistogram()` in order to be able to access the returned histogram; before the 2D graph has been filled with points. That was not possible previously.; This problem was reported; <a href=""https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=19186"">here</a>.; - When a `TGraph2D` was entirely in the plane `Z=0` the 3D could not be defined.; This problem was reported; <a href=""https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=19517"">here</a>. ### TMultiGraph; - When a `TMultiGraph` contained only one `TGraph` the number of bins for the; internal histogram was not set correctly. This problem was reported; <a href=""https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=19603&p=83973#p83973"">here</a>. ### THStack. - Implement `GetNhists()` to return the number of histograms in the stack.; - New drawing option `NOSTACKB`. histograms are drawn next to each other as; bar charts. Example:. ``` {.cpp}; TCanvas* nostackb() {; TCanvas *cst0 = new TCanvas(""cst0"",""cst0"",600,400);; THStack *hs = new THStack(""hs"",""Stacked 1D histograms: option #font[82]{\""nostackb\""}",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:16654,Testability,log,log,16654,"tions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid in version 5 are still valid in TFormula version 6; - TFormula is not anymore a base class for TF1. ### TF1. - Change of its inheritance structure. `TF1` has not anymore `TFormula` as a base class, so this code. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = (TFormula *) f1;; ```. **it is not valid anymore.**; The equivalent correct code is now. ``` {.cpp}; TF1 * f1 = new TF1(""f1"",""f1"",""sin(x)"",0,10);; TFormula * formula = f1->GetFormula();; ```. ### TGraph2DPainter. - In some case and extra point was drawn in the center od the plot when a; `TGRaph2d`was drawn with `P`, `P0`, or `PCOL` options. ### THistPainter. - It was possible to interactively zoom outside the histograms' limits. Protections; have been added.; - When an histogram was drawn with the option `E0` and log scale along the Y axis,; some additional markers were drawn at the bottom line of the plot. This was; reported <a href=""http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18778"">here</a>.; - Implement the option `0` combined with the option `COL` as requested; <a href=""https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=19046"">here</a>.; When the minimum of the histogram is set to a greater value than the real minimum,; the bins having a value between the real minimum and the new minimum are not drawn; unless the option <tt>0</tt> is set. Example:. ``` {.cpp}; {; TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);; c1->Divide(1,2);; TH2F *hcol21 = new TH2F(""hcol21"",""Option COLZ"",40,-4,4,40,-20,20);; TH2F *hcol22 = new TH2F(""hcol22"",""Option COLZ0"",40,-4,4,40,-20,20);; Float_t px, py;; for (Int_t i = 0; i < 25000; i++) {; gRandom->Rannor(px,py);; hcol21->Fill(px,5*py);; hcol22->Fill(px,5*py);; }; hcol21->SetBit(TH1::kNoStats);; hcol22->SetBit(TH1::kNoStats);; gStyle->SetPalette(1);; c1->cd(1); hcol21->Draw(""COLZ"");;",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:10636,Usability,simpl,simple,10636,"d 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:12745,Usability,learn,learning,12745,"f .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TTreeCache; is the estimated size of a cluster size for the TTree. The TTreeCache; prefilling is also enabled by default; when in learning phase rather than; reading each requested branch individually, the TTreeCache will read all the; branches thus trading off the latencies inherent to multiple small reads for; the potential of requesting more data than needed by read from the disk or; server the baskets for too many branches. The default behavior can be changed by either updating one of the rootrc files; or by setting environment variables. The rootrc files, both the global and the; local ones, now support the following the resource variable TTreeCache.Size; which set the default size factor for auto sizing TTreeCache for TTrees. The; estimated cluster size for the TTree and this factor is used to give the cache; size. If option is set to zero auto cache creation is disabled and the default; cache size is the historical one (equivalent to factor 1.0). If set to; non zero auto cache creation is enabled and both auto created and; default sized caches will use the configured factor: 0.0 no automatic cache; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The reso",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14772,Usability,learn,learnt,14772,"; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFun",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14796,Usability,learn,learning,14796,"; and greater than 0.0 to enable cache. This value can be overridden by the; environment variable ROOT_TTREECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFun",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:14817,Usability,learn,learning,14817,"ECACHE_SIZE. The resource variable TTreeCache.Prefill sets the default TTreeCache prefilling; type. The prefill type may be: 0 for no prefilling and 1 to prefill all; the branches. It can be overridden by the environment variable ROOT_TTREECACHE_PREFILL. In particular the default can be set back to the same as in version 5 by; setting TTreeCache.Size (or ROOT_TTREECACHE_SIZE) and TTreeCache.Prefill; (or ROOT_TTREECACHE_PREFILL) both to zero. TTree methods which are expected to modify a cache, like AddBranchToCache, will; attempt to setup a cache of default size if one does not exist, irrespective of; whether the auto cache creation is enabled. Additionally several methods giving; control of the cache have changed return type from void to Int_t, to be able to; return a code to indicate if there was an error. Usually TTree::SetCacheSize will no longer reset the list of branches to be; cached (either set or previously learnt) nor restart the learning phase.; The learning phase is restarted when a new cache is created, e.g. after having; removed a cache with SetCacheSize(0). ### TSelectorDraw. The axis titles in case of a `x:y:z` plot with the option `COLZ` were not correct. ### TParallelCoordVar. Change the format used to print the variables limit for ||-Coord to `%g`. It was; `%6.4f` before. ## Histogram Libraries. ### TFormula. - New version of the TFormula class based on Cling. Formula expressions are now used to create functions which are passed to Cling to be Just In Time compiled.; The expression is therefore compiled using Clang/LLVVM which will give execution time as compiled code and in addition correctness of the result obtained.; - This class is not 100% backward compatible with the old TFormula class, which is still available in ROOT as =ROOT::v5::TFormula=.; Some of the TFormula member funtions available in version 5, such as =Analyze= and =AnalyzeFunction= are not available in the new TFormula class.; On the other hand formula expressions which were valid ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:23372,Usability,guid,guide,23372,"wed very; thin white lines between the bins as well as in the color palette.; This made very ugly the final output.; This problem is due to bad implementation of anti-aliasing in these previewers.; A way to bypass this issue was to turn off the anti-aliasing in the previewer; but then the rest of the document does not look nice. This problem is now bypassed; with a fix in both PDF and PostScript output.; - Offer 0 as line width option. Useful to make a line invisible. ### TSVG. - Use float numbers instead of integer to describe graphics paths to avoid; rounding problems.; - Implement missing math symbols.; - Offer 0 as line width option. Useful to make a line invisible. ### TASImage. - In the animated gif it is now possible to specify the delay between the last; image and the fist image in case of infinite loop. (Fernando Hueso Gonzlez; <f.gonzalez@hzdr.de>). ### TPadPainter; - Offer 0 as line width option. Useful to make a line invisible. ### TPad. - In `TPad::ShowGuidelines` the number of guide lines is limited to 15. Above; that they become useless.; - Print a warning if one of the pad limit is a NaN.; - Fix https://sft.its.cern.ch/jira/browse/ROOT-6703. ### TCanvas. - Make sure that ""/"" and ""."" are not part of the method name when a canvas is; saved as a .C file. ### TLatex. - With the Cocoa backend the PDF and PS output produced miss-aligned exponents; because the `GetTextExtend` method behaved differently in batch mode and ""screen""; mode. This is now fixed. See http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=18883; - Improve the square-root drawing in case it is small.; - Better adjustment of the tilde accent position in case of Cocoa backend. ### TMathText. - `\mu` is now working for Postscript output.; - `\splitline` is now implemented. ### Cocoa backend. - Line width and line style were not applied on boxes. ## 3D Graphics Libraries. ### GL Viewer; - New option ""Rotate scene"" in the ""Extras"" tab of the GL Viewer. It allows to; do a real rotation instead of ",MatchSource.DOCS,README/ReleaseNotes/v604/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:4798,Availability,down,down,4798," the object in the case where the original collection is marked as a owner. We resolved a memory leakage occuring as a consequence of repeated calls to `TClonesArray::AbsorbObjects` and `TClonesArray::Clear` [ROOT-6996]. A similar problem was affecting `TClonesArray::operator=`, `TClonesArray::Expand` and `TClonesArray::ExpandCreate` and was also solved. `TClonesArray` reliance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes.",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:4891,Availability,down,down,4891," the object in the case where the original collection is marked as a owner. We resolved a memory leakage occuring as a consequence of repeated calls to `TClonesArray::AbsorbObjects` and `TClonesArray::Clear` [ROOT-6996]. A similar problem was affecting `TClonesArray::operator=`, `TClonesArray::Expand` and `TClonesArray::ExpandCreate` and was also solved. `TClonesArray` reliance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes.",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:8191,Availability,avail,available,8191," input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; The command line utilities are:; - `rootbrowse`: to open the file in a TBrowser; - `rootcp`: to copy content from one file to another; - `rooteventselector`: to select a subset of the events in a tree contained in a file; - `rootls`: to list the content of a rootfile; - `rootmkdir`: to create a directory in a rootfile; - `rootmv`: to move content across files; - `rootprint`: to plot content (histograms, graphs) of files; - `rootrm`: to remove content from files; These utilities took inspiration from the well known *nix commands and all offer the `-h` switch which provides documentation for all options available and example invocation lines. ### TBufferFile. We updated TBuffer::Expand to properly shrink the buffer when requested, hence reducing memory usage in some cases. ### I/O New functionalities. We added support for template parameter packs in class name involved in the I/O. ## TTree Libraries. ### Improvement of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was onl",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:20749,Availability,error,error,20749,"IFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22008,Availability,avail,available,22008,"ng. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) comin",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22375,Availability,avail,available,22375," the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 e",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:25083,Availability,avail,available,25083,"ps://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks to Doxygen. They; are now part of the reference guide allowing nice cross-referencing with the; classes documentation. Here also a filter has been developed to generate; [the resulting picture](https://root.cern.ch/doc/master/ContourList_8C.html). ## Build, Configuration and Testing Infrastructure. ROOT uses the CMake cross-platform build-generator tool as a primary build system. CMake does not build the project, it generates the files needed by your build tool (GNU make, Ninja, Visual Studio, etc) for building ROOT. The classic build with configure/make is is still available but it will not be evolving with the new features of ROOT. We added full support for C++14. Minor changes in the build system:. - Renamed build option POSTGRESQL_LIBRARIES to POSTGRESQL_LIBRARY; - Added build option `builtin_openssl` to build OpenSSL internally. This is specially needed for the latest Mac OSX (El Capitan); ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:130,Deployability,release,release,130,"% ROOT Version 6.06 Release Notes; % 2015-12-08; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.06/00 is scheduled for release in November, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT, \; Burt Holzman, Fermilab, CMS,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http, JSROOT, \; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT/Openlab,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,CERN, LHCb\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter pa",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2312,Deployability,update,updated,2312,"his new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6541,Deployability,release,release,6541,"OOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; T",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:8251,Deployability,update,updated,8251,"t input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; The command line utilities are:; - `rootbrowse`: to open the file in a TBrowser; - `rootcp`: to copy content from one file to another; - `rooteventselector`: to select a subset of the events in a tree contained in a file; - `rootls`: to list the content of a rootfile; - `rootmkdir`: to create a directory in a rootfile; - `rootmv`: to move content across files; - `rootprint`: to plot content (histograms, graphs) of files; - `rootrm`: to remove content from files; These utilities took inspiration from the well known *nix commands and all offer the `-h` switch which provides documentation for all options available and example invocation lines. ### TBufferFile. We updated TBuffer::Expand to properly shrink the buffer when requested, hence reducing memory usage in some cases. ### I/O New functionalities. We added support for template parameter packs in class name involved in the I/O. ## TTree Libraries. ### Improvement of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::k",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:9448,Deployability,update,update,9448," of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::kBigNumber` is deprecated and its value has been changed to be equal; to `TTree::kMaxEntries`. ### MakeSelector. `TTree::MakeSelector` has been update to generate a code skeleton based on the `TTreeReader` rather than the old style relying on numeric data members replacements for the user objects. The main advantage is the lifting of the problem related to the fact that the old style was using fixed size array to represent variable size collection. `TTree::MakeSelector` takes an option parameter that can be used to specify the branches that will have a data member.; - If option is `""=legacy""`, a pre-ROOT6 selector will be generated (data members and branch pointers instead of TTreeReaders).; - If option is empty, readers will be generated for each leaf.; - If option is ""@"", readers will be generated for the topmost branches.; - Individual branches can also be picked by their name:; - ""X"" generates readers for leaves of X.; - ""@X"" generates a reader for X as a whole.; - ""@X;Y"" generates a reader for X as a whole and also readers for the; leaves of Y.; - For further examples see the figure below. \image html ttree_makeselector_option_examples.png. The generated code in selector.h includes",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17991,Deployability,configurat,configuration,17991,"st; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:18475,Deployability,configurat,configuration,18475," to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the cli",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:18521,Deployability,update,update,18521,"eetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22094,Deployability,integrat,integration,22094,"pired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and old",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22143,Deployability,integrat,integrating,22143,"pired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and old",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22724,Deployability,integrat,integration,22724,");; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:23465,Deployability,release,release,23465,"t easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are al",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:23512,Deployability,release,releases,23512,"ocally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks t",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:116,Energy Efficiency,schedul,scheduled,116,"% ROOT Version 6.06 Release Notes; % 2015-12-08; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.06/00 is scheduled for release in November, 2015. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT, \; Burt Holzman, Fermilab, CMS,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http, JSROOT, \; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT/Openlab,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,CERN, LHCb\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter pa",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2180,Energy Efficiency,reduce,reduced,2180,"eference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:4941,Energy Efficiency,allocate,allocated,4941,"[ROOT-6996]. A similar problem was affecting `TClonesArray::operator=`, `TClonesArray::Expand` and `TClonesArray::ExpandCreate` and was also solved. `TClonesArray` reliance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility require",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:5231,Energy Efficiency,allocate,allocated,5231,"liance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProcessCleanups, we now delete the objects held in TROOT's TDirectory part. If the libCling library is unloaded, this now induces an immediate tear down of the ROOT resources; consequently objects might be deleted sooner in the process tear down process on some platforms. TObject instances allocated as part of an array and made part of a collection, as for example the TCanvas instances into the global list of instances, are not longer deleted if the content of the collection is deleted. Technically the element of the array are now treated by collections as if they have been allocated on the stack. This fixes the issue described at [ROOT-7846]. ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2168,Integrability,wrap,wrapper,2168,"; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at des",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:8778,Integrability,rout,routine,8778,"n a file; - `rootls`: to list the content of a rootfile; - `rootmkdir`: to create a directory in a rootfile; - `rootmv`: to move content across files; - `rootprint`: to plot content (histograms, graphs) of files; - `rootrm`: to remove content from files; These utilities took inspiration from the well known *nix commands and all offer the `-h` switch which provides documentation for all options available and example invocation lines. ### TBufferFile. We updated TBuffer::Expand to properly shrink the buffer when requested, hence reducing memory usage in some cases. ### I/O New functionalities. We added support for template parameter packs in class name involved in the I/O. ## TTree Libraries. ### Improvement of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::kBigNumber` is deprecated and its value has been changed to be equal; to `TTree::kMaxEntries`. ### MakeSelector. `TTree::MakeSelector` has been update to generate a code skeleton based on the `TTreeReader` rather than the old style relying on numeric data members replacements for the user objects. The main advantage is the lifting of the problem related to the fact that the old style was using fixed size array to represent variable size collection. `TTree::MakeSelector` takes an option ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:8941,Integrability,rout,routines,8941,"cross files; - `rootprint`: to plot content (histograms, graphs) of files; - `rootrm`: to remove content from files; These utilities took inspiration from the well known *nix commands and all offer the `-h` switch which provides documentation for all options available and example invocation lines. ### TBufferFile. We updated TBuffer::Expand to properly shrink the buffer when requested, hence reducing memory usage in some cases. ### I/O New functionalities. We added support for template parameter packs in class name involved in the I/O. ## TTree Libraries. ### Improvement of handling of default number of entries. A new const expression value: `TTree::kMaxEntries` has been introduced to; express the largest possible entry number in a `TTree`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::kBigNumber` is deprecated and its value has been changed to be equal; to `TTree::kMaxEntries`. ### MakeSelector. `TTree::MakeSelector` has been update to generate a code skeleton based on the `TTreeReader` rather than the old style relying on numeric data members replacements for the user objects. The main advantage is the lifting of the problem related to the fact that the old style was using fixed size array to represent variable size collection. `TTree::MakeSelector` takes an option parameter that can be used to specify the branches that will have a data member.; - If option is `""=legacy""`, a pre-ROOT6 selector will be",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:13478,Integrability,interface,interface,13478,"484). ### TGraph2D. Add a new implementation for Delauney interpolation using the triangle code from Jonathan Shewchuk, see [[ http://www.cs.cmu.edu/~quake/triangle.html ]]. ; A new class for Delauney triangulator and interpolation has been added in the MathCore library ( `ROOT::Math::Delauney2D` ). ### Fitting. * Improve thread safety of TH1::Fit by making static member of TVirtualFitter and TMinuitMinimizer thread local. This fixes [ROOT-7791].; * Fix some bugs in TF1NormSum (to fit normalized sum of functions) and in TF1Convolution; * Add a new histogram fitting option, `WIDTH` to fit directly density. The bin content in this case is scaled by the histogram bin width. ### TFormula. * Fix several bugs in the new TFormula class.; * Add as new pre-defined functions: `crystalball`, `breitwigner` and `cheb0,cheb1,...cheb10` for the Chebyshev polynomials. . ## Math Libraries. ### Random numbers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Grap",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:13528,Integrability,interface,interfaces,13528,"Jonathan Shewchuk, see [[ http://www.cs.cmu.edu/~quake/triangle.html ]]. ; A new class for Delauney triangulator and interpolation has been added in the MathCore library ( `ROOT::Math::Delauney2D` ). ### Fitting. * Improve thread safety of TH1::Fit by making static member of TVirtualFitter and TMinuitMinimizer thread local. This fixes [ROOT-7791].; * Fix some bugs in TF1NormSum (to fit normalized sum of functions) and in TF1Convolution; * Add a new histogram fitting option, `WIDTH` to fit directly density. The bin content in this case is scaled by the histogram bin width. ### TFormula. * Fix several bugs in the new TFormula class.; * Add as new pre-defined functions: `crystalball`, `breitwigner` and `cheb0,cheb1,...cheb10` for the Chebyshev polynomials. . ## Math Libraries. ### Random numbers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:13897,Integrability,interface,interface,13897,"hread local. This fixes [ROOT-7791].; * Fix some bugs in TF1NormSum (to fit normalized sum of functions) and in TF1Convolution; * Add a new histogram fitting option, `WIDTH` to fit directly density. The bin content in this case is scaled by the histogram bin width. ### TFormula. * Fix several bugs in the new TFormula class.; * Add as new pre-defined functions: `crystalball`, `breitwigner` and `cheb0,cheb1,...cheb10` for the Chebyshev polynomials. . ## Math Libraries. ### Random numbers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used wit",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:15310,Integrability,wrap,wraps,15310," for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happen in the middle of real number constant; (ignored by latex) or even in the middle of latex command (producing incorrect file).; One solution would be to rewrite TTeXDump using only `PrintRaw` (that you can't mix; with `PrintStr/PrintFast/WriteReal`). The other would be to fix `PrintFast` to not; introduce forced newline. The third option is less intrusive and just adds additional; spaces to provide clues for the proper line wrapping (this is the one implemented in; this change). ### TLatex. Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:16007,Integrability,wrap,wrapping,16007,"DLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happen in the middle of real number constant; (ignored by latex) or even in the middle of latex command (producing incorrect file).; One solution would be to rewrite TTeXDump using only `PrintRaw` (that you can't mix; with `PrintStr/PrintFast/WriteReal`). The other would be to fix `PrintFast` to not; introduce forced newline. The third option is less intrusive and just adds additional; spaces to provide clues for the proper line wrapping (this is the one implemented in; this change). ### TLatex. Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, `#plus`,; `#mp`, `#hbar`, and `#backslash` were mis-aligned. The following macro demonstrate; the problem:. ``` {.cpp}; {; gStyle->SetTextAlign(22);; TLatex t(.5,.5,""#minus100 #mp100 #plus100 #hbar #backslash"");; t.Draw();; }; ```. The angle of a `TLatex` object was set to 0 if the `GetYsize` method was called. ### TColor. New palette `kViridis`. It was presented at SciPy2015 by Stfan van der Walt and; Nathaniel Smith. It is now matplotlib's current default color map. ![Viridis](palette_112.png). ### TMultiGraph. Ignore empty graphs when computing the multi-graph range at painting time. ### TASImage. A left click on a image produced a one pixel zoom. ### TCreatePrimitives. The ending of a polyline creation is based on the closeness of the two last; entered points.",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:20359,Integrability,interface,interfaces,20359,"cess to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or l",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:21156,Integrability,interface,interface,21156,"ption in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:21218,Integrability,interface,interface,21218,"HttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output a",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22094,Integrability,integrat,integration,22094,"pired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and old",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22143,Integrability,integrat,integrating,22143,"pired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and old",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22724,Integrability,integrat,integration,22724,");; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6406,Modifiability,variab,variable,6406,"tended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6744,Modifiability,extend,extended,6744,"Proxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; The command line utilities are:; - `rootbrowse`: to open the file in a TBrowser; - `rootcp`: to copy content from one file to another; - `rooteventselector`: to select a subset of the events in a tree contained i",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:9731,Modifiability,variab,variable,9731,"e`. This is used in; two main cases:. - as the default value for the requested number of entries a routine should be; applied to; for example this is used for `TTree::Draw` and `TTree::Process`.; Previously the default was only 1 billions entries, causing those routines to; end early in case of very large trees. - as the default value for the number of entries returned by TChain::GetEntriesFast.; The previous value was kBigNumber (set to 1234567890) and internally (but somewhat; inconsistently, see [ROOT-6885]) a larger value was used (named theBigNumber). Now; `TTree::kMaxEntries` is used throughout TChain. `TChain::kBigNumber` is deprecated and its value has been changed to be equal; to `TTree::kMaxEntries`. ### MakeSelector. `TTree::MakeSelector` has been update to generate a code skeleton based on the `TTreeReader` rather than the old style relying on numeric data members replacements for the user objects. The main advantage is the lifting of the problem related to the fact that the old style was using fixed size array to represent variable size collection. `TTree::MakeSelector` takes an option parameter that can be used to specify the branches that will have a data member.; - If option is `""=legacy""`, a pre-ROOT6 selector will be generated (data members and branch pointers instead of TTreeReaders).; - If option is empty, readers will be generated for each leaf.; - If option is ""@"", readers will be generated for the topmost branches.; - Individual branches can also be picked by their name:; - ""X"" generates readers for leaves of X.; - ""@X"" generates a reader for X as a whole.; - ""@X;Y"" generates a reader for X as a whole and also readers for the; leaves of Y.; - For further examples see the figure below. \image html ttree_makeselector_option_examples.png. The generated code in selector.h includes the following:; - Identification of the original Tree and Input file name; - Definition of selector class (data and functions); - The following class functions:; - const",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:14082,Modifiability,plug-in,plug-in,14082,"in this case is scaled by the histogram bin width. ### TFormula. * Fix several bugs in the new TFormula class.; * Add as new pre-defined functions: `crystalball`, `breitwigner` and `cheb0,cheb1,...cheb10` for the Chebyshev polynomials. . ## Math Libraries. ### Random numbers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:15732,Modifiability,rewrite,rewrite,15732,") are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happen in the middle of real number constant; (ignored by latex) or even in the middle of latex command (producing incorrect file).; One solution would be to rewrite TTeXDump using only `PrintRaw` (that you can't mix; with `PrintStr/PrintFast/WriteReal`). The other would be to fix `PrintFast` to not; introduce forced newline. The third option is less intrusive and just adds additional; spaces to provide clues for the proper line wrapping (this is the one implemented in; this change). ### TLatex. Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, `#plus`,; `#mp`, `#hbar`, and `#backslash` were mis-aligned. The following macro demonstrate; the problem:. ``` {.cpp}; {; gStyle->SetTextAlign(22);; TLatex t(.5,.5,""#minus100 #mp100 #plus100 #hbar #backslash"");; t.Draw();; }; ```. The angle of a `TLatex` object was set to 0 if the `GetYsize` method was called. ### TColor. New palette `kViridis`. It was presented at SciPy2015 by Stfan van der Walt and; Nathaniel Smith. It is now matplotlib's current default color map. ![Viridis](palette_112.png). ### TMultiGraph. Ignore empty graphs when computing the m",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17991,Modifiability,config,configuration,17991,"st; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:18475,Modifiability,config,configuration,18475," to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the cli",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19047,Modifiability,config,configure,19047,"uto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback ad",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19556,Modifiability,config,configured,19556," this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22243,Modifiability,enhance,enhanced,22243,"pired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and old",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:23270,Modifiability,rewrite,rewrite,23270,"ll. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:25056,Modifiability,config,configure,25056,"ps://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks to Doxygen. They; are now part of the reference guide allowing nice cross-referencing with the; classes documentation. Here also a filter has been developed to generate; [the resulting picture](https://root.cern.ch/doc/master/ContourList_8C.html). ## Build, Configuration and Testing Infrastructure. ROOT uses the CMake cross-platform build-generator tool as a primary build system. CMake does not build the project, it generates the files needed by your build tool (GNU make, Ninja, Visual Studio, etc) for building ROOT. The classic build with configure/make is is still available but it will not be evolving with the new features of ROOT. We added full support for C++14. Minor changes in the build system:. - Renamed build option POSTGRESQL_LIBRARIES to POSTGRESQL_LIBRARY; - Added build option `builtin_openssl` to build OpenSSL internally. This is specially needed for the latest Mac OSX (El Capitan); ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2471,Performance,multi-thread,multi-threaded,2471,"ndex.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null pointer;; previously it was interpreting a null pointer as a request to *not* change the current; directo",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6619,Performance,perform,performance,6619,"OOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; T",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:7504,Performance,perform,performed,7504,"See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We added command line utilities to streamline very common operations performed on root files, like listing their content or creating directories.; The command line utilities are:; - `rootbrowse`: to open the file in a TBrowser; - `rootcp`: to copy content from one file to another; - `rooteventselector`: to select a subset of the events in a tree contained in a file; - `rootls`: to list the content of a rootfile; - `rootmkdir`: to create a directory in a rootfile; - `rootmv`: to move content across files; - `rootprint`: to plot content (histograms, graphs) of files; - `rootrm`: to remove content from files; These utilities took inspiration from the well known *nix commands and all offer the `-h` switch which provides documentation for all options available and example invocation lines. ### TBufferFile. We updated TBuffer::Expand to properly shrink the buffer when requested, hence reducing memory usage in some cases. ### I/O New functionalities. We added support for template parameter packs in class name involved in the I/O. ## TTree Libraries. ### Improveme",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:15339,Performance,optimiz,optimized,15339,"learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happen in the middle of real number constant; (ignored by latex) or even in the middle of latex command (producing incorrect file).; One solution would be to rewrite TTeXDump using only `PrintRaw` (that you can't mix; with `PrintStr/PrintFast/WriteReal`). The other would be to fix `PrintFast` to not; introduce forced newline. The third option is less intrusive and just adds additional; spaces to provide clues for the proper line wrapping (this is the one implemented in; this change). ### TLatex. Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, `#plus`,; `#mp`, `#hbar`, and `#backslash` were mis-aligned. The following macro demonstrate; the problem:. ``` {.cpp}; {; gStyle->SetTextAlign(22);; TLatex t(.5,.5,""#minus100 #",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19729,Performance,optimiz,optimize,19729,", ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an er",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:21293,Performance,perform,perform,21293,"HttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new interface, implemented in the class TProcPool, provides the possibility to perform in parallel a very generic set of tasks, described by macros, functions or lambdas. This illustrates the usage of lambdas:. ``` {.cpp}; {; TProcPool pool;; auto ten = pool.MapReduce([]() { return 1; }, 10, [](std::vector<int> v) { return std::accumulate(v.begin(), v.end(), 0); }); }; ```. And this how it can be used to generate ten histos and merge them:. ``` {.cpp}; {; TObject *CreateAndFillHists(); {. TH1F *h = new TH1F(""h"", """", 100, -3., 3.);; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output a",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2051,Safety,safe,safety,2051,"assil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TCo",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2354,Safety,avoid,avoid,2354,"his new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2830,Safety,safe,safe,2830,"] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null pointer;; previously it was interpreting a null pointer as a request to *not* change the current; directory - this behavior is now implement by the default constructor. ### Collections. In THashList and THashTable, GetListForObject now returns a pointer to const as modifying the returned list (in particular adding to it) can break invariant of THashTable so we need to clearly mark the list as not being allowed to be modified. In TSeqCollection::Merge, ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6312,Safety,avoid,avoid,6312,". ### Code Cleanups. Several definition where moved from the global or ROOT namespace to the ROOT::Internal namespace as they are not intended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:12824,Safety,safe,safety,12824,"problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7766).; * Change `TGraph::ComputeRange`: in case of log scale the minimum along X and; Y axis are now set to the lowest positive values of the graph. Previously a % of the; maximum was used which may hide some points like in the following example; ``` {.cpp}; {; TGraph * gr = new TGraph(10);; for (int i = 0;i<10;i++) gr->SetPoint(i,i,TMath::Exp(-10.0*i));; for (int i = 5;i<10;i++) gr->SetPoint(i,i,0.);; gr->Draw(""apl"");; gr->SetMarkerStyle(20);; gPad->SetLogy(true);; }; ```; The problem was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20484). ### TGraph2D. Add a new implementation for Delauney interpolation using the triangle code from Jonathan Shewchuk, see [[ http://www.cs.cmu.edu/~quake/triangle.html ]]. ; A new class for Delauney triangulator and interpolation has been added in the MathCore library ( `ROOT::Math::Delauney2D` ). ### Fitting. * Improve thread safety of TH1::Fit by making static member of TVirtualFitter and TMinuitMinimizer thread local. This fixes [ROOT-7791].; * Fix some bugs in TF1NormSum (to fit normalized sum of functions) and in TF1Convolution; * Add a new histogram fitting option, `WIDTH` to fit directly density. The bin content in this case is scaled by the histogram bin width. ### TFormula. * Fix several bugs in the new TFormula class.; * Add as new pre-defined functions: `crystalball`, `breitwigner` and `cheb0,cheb1,...cheb10` for the Chebyshev polynomials. . ## Math Libraries. ### Random numbers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17066,Safety,avoid,avoid,17066,"Make sure the line width used to draw `#sqrt` is always >= 1. When a global text alignment was set the `TLatex`characters `#minus`, `#plus`,; `#mp`, `#hbar`, and `#backslash` were mis-aligned. The following macro demonstrate; the problem:. ``` {.cpp}; {; gStyle->SetTextAlign(22);; TLatex t(.5,.5,""#minus100 #mp100 #plus100 #hbar #backslash"");; t.Draw();; }; ```. The angle of a `TLatex` object was set to 0 if the `GetYsize` method was called. ### TColor. New palette `kViridis`. It was presented at SciPy2015 by Stfan van der Walt and; Nathaniel Smith. It is now matplotlib's current default color map. ![Viridis](palette_112.png). ### TMultiGraph. Ignore empty graphs when computing the multi-graph range at painting time. ### TASImage. A left click on a image produced a one pixel zoom. ### TCreatePrimitives. The ending of a polyline creation is based on the closeness of the two last; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17614,Safety,detect,detect,17614,"t and; Nathaniel Smith. It is now matplotlib's current default color map. ![Viridis](palette_112.png). ### TMultiGraph. Ignore empty graphs when computing the multi-graph range at painting time. ### TASImage. A left click on a image produced a one pixel zoom. ### TCreatePrimitives. The ending of a polyline creation is based on the closeness of the two last; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphic",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:2145,Security,access,access,2145,"; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly avoid costly checks (extra RecursiveRemove and lock). We removed the need to create a TThread object per thread in a multi-threaded application. Now ROOT can be used with any threading model (e.g. OpenMP, STL threads, TBB) transparently. All the internal synchronisation mechanisms of ROOT are activated by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at des",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6475,Security,access,access,6475,"tended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:18931,Security,access,accessible,18931,"ionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.jso",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19194,Security,access,access,19194,"d to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19338,Security,access,accessible,19338,"erwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; ne",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19374,Security,access,access,19374,"de `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; n",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19538,Security,authenticat,authentication,19538," this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19829,Security,expose,expose,19829," exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19870,Security,expose,exposed,19870," exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:20074,Security,access,access,20074,"uld be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:11983,Testability,log,log,11983," this function:. - connect your Tree file (eg: `TFile f(""myfile.root"");`); - `T->MakeSelector(""myselect"");`. where T is the name of the Tree in file myfile.root; and myselect.h, myselect.C the name of the files created by this function.; In a ROOT session, you can do:; ``` {.cpp}; root > T->Process(""myselect.C""); ```. ### Other improvements. We fixed the handling of the case when an object, stored in a TTree, used to have a defaulted Streamer and when the TTree is being read, the object now has a custom Streamer that we must use. ## Histogram Libraries. ### TH1. * Fix a bug in using the buffer with weights different than one; * Remove the `kCanRebin` bit, that it was not used anymore. Its functionality is replaced by the `TH1::SetCanExtend` function. ### TGraph. * `TGraph::GetHistogram()` was resetting the TimeDisplay attribute of axis.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7766).; * Change `TGraph::ComputeRange`: in case of log scale the minimum along X and; Y axis are now set to the lowest positive values of the graph. Previously a % of the; maximum was used which may hide some points like in the following example; ``` {.cpp}; {; TGraph * gr = new TGraph(10);; for (int i = 0;i<10;i++) gr->SetPoint(i,i,TMath::Exp(-10.0*i));; for (int i = 5;i<10;i++) gr->SetPoint(i,i,0.);; gr->Draw(""apl"");; gr->SetMarkerStyle(20);; gPad->SetLogy(true);; }; ```; The problem was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20484). ### TGraph2D. Add a new implementation for Delauney interpolation using the triangle code from Jonathan Shewchuk, see [[ http://www.cs.cmu.edu/~quake/triangle.html ]]. ; A new class for Delauney triangulator and interpolation has been added in the MathCore library ( `ROOT::Math::Delauney2D` ). ### Fitting. * Improve thread safety of TH1::Fit by making static member of TVirtualFitter and TMinuitMinimizer thread local. This fixes [ROOT-7791].; * Fix some bugs in TF1NormSum (to fit normalized sum of function",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:14590,Testability,log,log,14590,"andom engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot of space characters that are used for newline; placement. Current `TTeXDump::DrawPolyMarker` would often produce a long contiguous lines; that trigger a forceful linewrap that can happe",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17663,Testability,test,tested,17663,"ridis](palette_112.png). ### TMultiGraph. Ignore empty graphs when computing the multi-graph range at painting time. ### TASImage. A left click on a image produced a one pixel zoom. ### TCreatePrimitives. The ending of a polyline creation is based on the closeness of the two last; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Librar",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:23997,Testability,log,logical,23997,"from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks to Doxygen. They; are now part of the reference guide allowing nice cross-referencing with the; classes documentation. Here also a filter has been developed to generate; [the resulting picture](https://root.cern.ch/doc/master/ContourList_8C.html). ## Build, Configuration and Testing Infrastructure. ROOT uses the CMake cross-platform build-generator tool as a primary build system. CMake does not build the project, it generates the files needed by your build tool (GNU make, Ninja, ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:1337,Usability,guid,guide,1337," Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Kyle Cranmer, NYU, RooStats,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT, \; Burt Holzman, Fermilab, CMS,\; Lukasz Janyst, CERN/IT,\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http, JSROOT, \; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT/Openlab,\; Enric Tejedor Saavedra, CERN/SFT,\; Liza Sakellari, CERN/SFT,\; Manuel Tobias Schiller,CERN, LHCb\; David Smith, CERN/IT,\; Matevz Tadel, UCSD/CMS, Eve, \; Vassil Vassilev, CERN/SFT \; Wouter Verkerke, NIKHEF/Atlas, RooFit, \; Omar, Zapata, Medellin, Columbia \; Maciej Zimnoch, GSoC, Poland. ## ROOT reference manual. The ROOT reference manual has been moved into Doxygen. Still some work and; polish has to be done but the reference guide in this new format is now online; and can be seen from the [ROOT home page](https://root.cern.ch/doc/master/index.html). ## Core Libraries. ### Dictionary generation. Fixed the dictionary generation in the case of class inside a namespace; marked inlined. Added mechanisms to stop the dictionary generation while parsing the XML and while selecting in presence of duplicates. Fix [ROOT-7760] : fully allow the usage of the dylib extension on OSx. Fix [ROOT-7723] : allow IOCtors to have as argument a ref to a type called __void__. We added a dictionary for map<string,string> as part of the default STL dictionary. We added support for template parameter packs in class name involved in the I/O. ### Thread safety and thread awareness. We added the function `TMethodCall::GetCallFunc` to allow direct access to the function wrapper. We reduced thread serialization in `TClass::GetCheckSum`, `TClass::GetBaseClassOffset` and `TClass::Property`. `TObjArray::Delete` was updated to allow its caller to explicitly ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:3719,Usability,clear,clearly,3719,"ed by a single call: `ROOT::EnableThreadSafety()` which is the successor of the existing `TThread::Initialize`. This call must take place if ROOT needs to be used in a thread safe manner. The implementation of TSemaphore was redone based on C++11 thread primitive in order to prevent cases where some of request post were lost. ### TDirectory::TContext. We added a default constructor to `TDirectory::TContext` which record the current directory; and will restore it at destruction time and does not change the current directory. The constructor for `TDirectory::TContext` that takes a single TDirectory pointer as; an argument was changed to set `gDirectory` to zero when being passed a null pointer;; previously it was interpreting a null pointer as a request to *not* change the current; directory - this behavior is now implement by the default constructor. ### Collections. In THashList and THashTable, GetListForObject now returns a pointer to const as modifying the returned list (in particular adding to it) can break invariant of THashTable so we need to clearly mark the list as not being allowed to be modified. In TSeqCollection::Merge, we no longer delete the object in the case where the original collection is marked as a owner. We resolved a memory leakage occuring as a consequence of repeated calls to `TClonesArray::AbsorbObjects` and `TClonesArray::Clear` [ROOT-6996]. A similar problem was affecting `TClonesArray::operator=`, `TClonesArray::Expand` and `TClonesArray::ExpandCreate` and was also solved. `TClonesArray` reliance on global state during the destruction of the elements was decreased (removing use of `TObject::SetDtorOnly`). ### Global resources. Several tweaks to if and when, resources held by the global ROOT object (TROOT, TApplication) are deleted. When the default TApplication is replaced by a user provide TApplication, do not call EndOfProcessCleanups and co. and thus do not delete TFiles, TSockets or TColors that have already been created. In EndOfProce",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:14383,Usability,learn,learning,14383,"bers. * Move from MathMore to MathCore the class `ROOT::Math::Random`. Make it a new interface class for random number generation. Add interfaces for standard; ROOT random engines, GSL random engines and random engines provided by the C++ standard library (`std::random`).; * Add a new randomengine, `MIXMAX` based on matrix-recursive random number generator from Kostas and George Savvidy. See this [paper](http://dx.doi.org/10.1016/j.cpc.2015.06.003). ## R Interface. Apply several improvements in the interface to R, allowing to use R functions within ROOT.; See more at the [ROOT-R User Guide](http://oproject.org/tiki-index.php?page=ROOT%20R%20Users%20Guide). . ## TMVA. Add new TMVA plug-in based on R and Python (using Scikit-Learn) ; * See the [RMVA Web page](http://oproject.org/tiki-index.php?page=RMVA) for a detailed description of the new TMVA method based on R; * See the [PyMVA Web page](http://oproject.org/tiki-index.php?page=PyMVA) for detailed description of the machine learning methods added in TMVA and based on the Python Scikit-Learn package. ## RooFit Libraries; . ## 2D Graphics Libraries. ### THistPainter. Improve the algorithm to compute the lower limit of an axis in log scale when its; real lower limit is 0. The problem was reported in ROOT-7414. Using the `COL` option with histograms having some negative bins; the empty bins; (containing 0) are drawn. In some cases one wants to not draw empty bins; (containing 0) of histograms having a negative minimum. The option `1`, used with; the option `COL`, allows to do that. Implement the Log option for `CANDLE` plots as requested; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20225&p=87006#p87006). ### TTeXDump. From Dmitry Kalinkin (via github): Fix file corruption in `TTeXDump::DrawPolyMarker`; The current implementation of `TTeXDump` uses `TVirtualPS::PrintFast` based methods; to output TeX markup with automatic line-wraps. Yet these methods are optimized for; PostScript format where there are a lot",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:20223,Usability,clear,clear,20223,"r::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback address.; This restrict access to http server only from localhost.; One could either specify 'loopback' option in constructor:; new THttpServer(""http:8080?loopback""); or in clear text specify IP address to which http socket should be bind:; new THttpServer(""http:127.0.0.1:8080""); If host has several network interfaces, one could select one for binding:; new THttpServer(""http:192.168.1.17:8080""). ### TNetXNGFileStager; Fixed ROOT-7703. This restores the behavior of Locate() to that found with; TXNetFileStager: Rather than return only the xrootd server's reply, the endpoint; hostname is looked up and Locate() returns the full url, including the path. ### TWebFile; Fixed ROOT-7809. Returns an error for a redirect which does not specify the new; URI, rather than going into a loop. Fixed ROOT-7817. Avoid a crash under some circumstances when trying to open an; invalid path. ## GUI Libraries. ## Montecarlo Libraries. ## Multi-processing. With this version we introduce a new module, core/multiproc, for multi-processing on multi-core machines. This module is based on fork technology and offers an interface inspired from Python multiprocessor module. The new",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:22695,Usability,simpl,simplest,22695,");; h->SetDirectory(0);; h->FillRandom(""gaus"", 1000);; return h;; }. TProcPool pool;; auto hist = pool.MapReduce(CreateAndFillHists, 10, PoolUtils::ReduceObjects);; hist->DrawClone();; }; ```. Tutorials illustrating other usages of the new class TProcPool are available under tutorials/multicore. ## Language Bindings. ### Notebooks; We provided integration of ROOT with the Jupyter technology, integrating ROOT with Python Notebooks and providing a ROOT Kernel like functionality - de facto an enhanced C++ web based shell. Tab completion, output and graphics inlining have been added. These functionalities are automatically available upon import of the ROOT module in a Notebook or at startup of a ROOT prompt kernel.; We made it easier to use ROOT notebooks locally, by providing a 'root --notebook' command option to start a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:23577,Usability,guid,guide,23577,"a local notebook server customised with all the ROOT features. New tutorials and code examples have been provided. The simplest example showing the integration of ROOT with the notebook technology can be found [here](https://root.cern.ch/notebooks/HowTos/HowTo_ROOT-Notebooks.html) and many more snippets [here](https://root.cern.ch/code-examples#notebooks). Support for capturing large outputs (stderr/stdout) coming from C++ libraries has been added. ## JavaScript ROOT. - support registered in THttpServer commands with arguments.; - provide workaround for websites using require.js and older jquery-ui; - support custom requests to remote objects, demonstrated in httptextlog.C tutorial; - rewrite draw.htm (page for individual object drawing) to support all custom features as main gui does; - See also the [JSRoot 3.9 examples page](https://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks to Doxygen. They; are now part of the reference guide allowing nice",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:24558,Usability,guid,guide,24558,"ps://root.cern.ch/js/3.9/) and the [JSRoot 3.9 release notes](https://github.com/linev/jsroot/releases/tag/3.9). ## Class Reference Guide. The ROOT [reference guide](https://root.cern.ch/doc/master/index.html) is moving; to the Doxygen system. Doxygen is the de-facto standard for code documentation. It offers; many nice features we are now exploring and trying to get the best of them. Having; [MathJax rendered math formula](https://root.cern.ch/doc/master/classTSpectrum2.html#a482a7f144b9cc1b0405d0ac0d8cc9bbb); is one of them. The documentation can be structured in a more logical way; [using groups](https://root.cern.ch/doc/master/modules.html). Still there is a lot; to do but big progresses have been done. We developed also a Doxygen filter allowing; to execute macros given as examples in the documentation and show the; [resulting picture directly in the documentation](https://root.cern.ch/doc/master/classTHistPainter.html#HP16). ## Tutorials. [The tutorials](https://root.cern.ch/doc/master/group__Tutorials.html) in; `$ROOTSYS/tutorials` are also presented on the web thanks to Doxygen. They; are now part of the reference guide allowing nice cross-referencing with the; classes documentation. Here also a filter has been developed to generate; [the resulting picture](https://root.cern.ch/doc/master/ContourList_8C.html). ## Build, Configuration and Testing Infrastructure. ROOT uses the CMake cross-platform build-generator tool as a primary build system. CMake does not build the project, it generates the files needed by your build tool (GNU make, Ninja, Visual Studio, etc) for building ROOT. The classic build with configure/make is is still available but it will not be evolving with the new features of ROOT. We added full support for C++14. Minor changes in the build system:. - Renamed build option POSTGRESQL_LIBRARIES to POSTGRESQL_LIBRARY; - Added build option `builtin_openssl` to build OpenSSL internally. This is specially needed for the latest Mac OSX (El Capitan); ",MatchSource.DOCS,README/ReleaseNotes/v606/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:2836,Availability,error,errors,2836,"tem: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_info` from Rtypeinfo.h, `type_info` should be spelled; `std::type_info`. Also:. * `TPluginManager` was made thread-safe [ROOT-7927].; * On MacOSX, backtraces are now generated without external tools [ROOT-6667].; * The set of include paths considered by the interpreter has been reduced to the bare minimum. ### Containers. * A pseudo-container (generator) was created, `ROOT::TSeq<T>`. This template is inspired by the xrange built-in function of Python. See the example [here](https://root.cern.ch/doc/master/cnt001__basictseq_8C.html). ### Meta Library. Add a new mode for `TClass::SetCanSplit` (2) which indicates that this class and any derived class should not be split. This included a rework the mechanism checking the base classes. Instead of using `InheritsFrom`, which lead in some cases, including the case where the class derived from an STL collection, to spurrious autoparsing (to look at the base class of the collection!",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8237,Availability,error,errors,8237,"o process the entries of a TTree in parallel. The user provides a function that receives one parameter, a TTreeReader, that can be used to iterate over a subrange of entries. Each subrange corresponds to a cluster in the TTree and is processed by a task, which can potentially be run in parallel with other tasks.; * Add a new implementation of a RW lock, `ROOT::TRWSpinLock`, which is based on a `ROOT::TSpinMutex`. `TRWSpinLock` tries to make faster the scenario when readers come and go but there is no writer, while still preventing starvation of writers. ## I/O Libraries. * Support I/O of `std::unique_ptr`s and STL collections thereof.; * Support I/O of `std::array`.; * Support I/O of `std::tuple`. The dictionary for those is never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the opti",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9251,Availability,error,errors,9251,"to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually call",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:12452,Availability,down,downloded,12452,"d the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new ker",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:12663,Availability,avail,available,12663,"fined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13496,Availability,avail,available,13496,"ltin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at th",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13598,Availability,avail,available,13598,"tion. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be nec",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14083,Availability,down,down,14083,"DA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to select an histogram on a canvas by clicking on the vertical; lines of the bins boundaries.; This",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:19639,Availability,avail,available,19639,"rn where surrounded by a solid line.; * Support custom line styles in `TTeXDump` as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8215); * `TColor::GetFreeColorIndex()` allows to make sure the new color is created with an; unused color index.; * In `TLegend::SetHeader` the new option `C` allows to center the title.; * New method `ChangeLabel` in `TGaxis` and `TAxis`allowing to a fine tuning of; individual labels attributes. All the attributes can be changed and even the; label text itself. Example:; ``` {.cpp}; {; c1 = new TCanvas(""c1"",""Examples of Gaxis"",10,10,900,500);; c1->Range(-6,-0.1,6,0.1);; TGaxis *axis1 = new TGaxis(-5.5,0.,5.5,0.,0.0,100,510,"""");; axis1->SetName(""axis1"");; axis1->SetTitle(""Axis Title"");; axis1->SetTitleSize(0.05);; axis1->SetTitleColor(kBlue);; axis1->SetTitleFont(42);; axis1->ChangeLabel(1,-1,-1,-1,2);; axis1->ChangeLabel(3,-1,0.);; axis1->ChangeLabel(5,30.,-1,0);; axis1->ChangeLabel(6,-1,-1,-1,3,-1,""6th label"");; axis1->Draw();; }; ```; Being available in `TAxis`, this method allow to change a label on and histogram; plot like:; ``` {.cpp}; hpx->Draw();; hpx->GetXaxis()->ChangeLabel(5,-1,-1,-1,kRed,-1,""Zero"");; ```; * New class `TAxisModLab`: a TAxis helper class used to store the modified labels.; * `TPie` the format parameter set by `SetPercentFormat` was ignored.; (reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8294)); * Improvements in the histogram plotting option `TEXT`: In case several histograms; are drawn on top ot each other (using option `SAME`), the text can be shifted; using `SetBarOffset()`. It specifies an offset for the text position in each; cell, in percentage of the bin width.; * `TGaxis::PaintAxis()` might caused a correctness problem in multithreaded; context when handling optionTime with `%F`. This was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8309). The fixed was suggested; by Philippe Gras (philippe.gras@cea.fr).; * `TGaxis::PaintAxis()` misplaced the `x10` at the end of the ax",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23890,Availability,avail,available,23890," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24141,Availability,avail,available,24141,"imitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the pa",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27140,Availability,error,errors,27140," volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28050,Availability,avail,available,28050,"es; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config th",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28722,Availability,avail,available,28722,"ROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias E",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:130,Deployability,release,release,130,"% ROOT Version 6.08 Release Notes; % 2015-11-12; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.08/00 is scheduled for release in October, 2016. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Adrian Bevan, Queen Mary University of London, ATLAS,\; Attila Bagoly, GSoC,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, Fermilab,\; Andrew Carnes, University of Florida, CMS, \; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Paul Gessinger, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Luca Giommi, CERN/SFT,\; Sergei Gleyzer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:1647,Deployability,update,update,1647,"zer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, alo",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5163,Deployability,update,updated,5163,"to forbid dictionaries to remember include paths expressed in the command line invocation.; * Genreflex and rootcling cannot generate capability files anymore.; * Fix [ROOT-7760]: Fully allow the usage of the dylib extension on OSx.; * Fix [ROOT-7879]: Prevent LinkDef files to be listed in a rootmap file and use (as the user actually expects) the header files #included in the linkdef file, if any, as the top level headers.; * Add the *noIncludePaths* switch both for rootcling and genreflex to allow to loose track of the include paths in input to the dictionary generator.; * Fix handling of template parameter pack in the forward declaration printer. [ROOT-8096]; * Do not autoparse headers for classes in the pch.; * Avoid autoparse on IsForeign() if possible.; * Check for new-style empty pcm with key named ""EMPTY"" created since commit 90047b0cba6fd295f5c5722749a0d043fbc11ea5.; * Do not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the ma",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8487,Deployability,update,updated,8487,"run in parallel with other tasks.; * Add a new implementation of a RW lock, `ROOT::TRWSpinLock`, which is based on a `ROOT::TSpinMutex`. `TRWSpinLock` tries to make faster the scenario when readers come and go but there is no writer, while still preventing starvation of writers. ## I/O Libraries. * Support I/O of `std::unique_ptr`s and STL collections thereof.; * Support I/O of `std::array`.; * Support I/O of `std::tuple`. The dictionary for those is never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We ad",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9771,Deployability,update,update,9771,"hout any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on crea",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9954,Deployability,update,update,9954,"ke sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implic",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:11579,Deployability,integrat,integrate,11579,"ll deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13062,Deployability,configurat,configuration,13062,"while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14750,Deployability,continuous,continuous,14750,"ll methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to select an histogram on a canvas by clicking on the vertical; lines of the bins boundaries.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-6649).; * When using time format in axis, `TGaxis::PaintAxis()` may in some cases call; `strftime()` with invalid parameter causing a crash.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7689).; * Having ""X11.UseXft: yes"" activated in .rootrc file and running; [this](https://sft.its.cern.ch/jira/browse/ROOT-7985) little program,; resulted in a crash.; * Ease the setting of the appearance of joining lines for PostScript and PDF; output. `TPostScript::SetLineJoin`; allowed to set the line joining style for PostScript files. But the setting this; parameter implie",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14953,Deployability,continuous,continuous,14953,"as been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to select an histogram on a canvas by clicking on the vertical; lines of the bins boundaries.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-6649).; * When using time format in axis, `TGaxis::PaintAxis()` may in some cases call; `strftime()` with invalid parameter causing a crash.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7689).; * Having ""X11.UseXft: yes"" activated in .rootrc file and running; [this](https://sft.its.cern.ch/jira/browse/ROOT-7985) little program,; resulted in a crash.; * Ease the setting of the appearance of joining lines for PostScript and PDF; output. `TPostScript::SetLineJoin`; allowed to set the line joining style for PostScript files. But the setting this; parameter implied to create a `TPostScript` object. Now a `TStyle` setting has been; implemented and it is enough to do:; ``` {.cpp}; gStyle->SetLineJoinPS(2);; ```; Also this setting is now active for P",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24080,Deployability,install,installation,24080,"ced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24111,Deployability,install,installation,24111,"imitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the pa",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24188,Deployability,install,installation,24188,"the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command argu",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24815,Deployability,configurat,configuration,24815,"onvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syn",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25246,Deployability,configurat,configuration,25246,"ies ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibil",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25581,Deployability,integrat,integration,25581,"atabase Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TG",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25623,Deployability,integrat,integration,25623,"` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offloa",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28927,Deployability,install,installed,28927,"tion; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'c",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29928,Deployability,install,installations,29928," section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'cuda' option to enable looking for CUDA in the system. ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:116,Energy Efficiency,schedul,scheduled,116,"% ROOT Version 6.08 Release Notes; % 2015-11-12; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.08/00 is scheduled for release in October, 2016. For more information, see:. [http://root.cern](http://root.cern). The following people have contributed to this new version:. David Abdurachmanov, CERN, CMS,\; Adrian Bevan, Queen Mary University of London, ATLAS,\; Attila Bagoly, GSoC,\; Bertrand Bellenot, CERN/SFT,\; Rene Brun, CERN/SFT,\; Philippe Canal, Fermilab,\; Andrew Carnes, University of Florida, CMS, \; Cristina Cristescu, CERN/SFT,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Paul Gessinger, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Luca Giommi, CERN/SFT,\; Sergei Gleyzer, University of Florida, CMS\; Christopher Jones, Fermilab, CMS,\; Wim Lavrijsen, LBNL, PyRoot,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Abhinav Moudgil, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:3168,Energy Efficiency,reduce,reduced,3168,"l). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_info` from Rtypeinfo.h, `type_info` should be spelled; `std::type_info`. Also:. * `TPluginManager` was made thread-safe [ROOT-7927].; * On MacOSX, backtraces are now generated without external tools [ROOT-6667].; * The set of include paths considered by the interpreter has been reduced to the bare minimum. ### Containers. * A pseudo-container (generator) was created, `ROOT::TSeq<T>`. This template is inspired by the xrange built-in function of Python. See the example [here](https://root.cern.ch/doc/master/cnt001__basictseq_8C.html). ### Meta Library. Add a new mode for `TClass::SetCanSplit` (2) which indicates that this class and any derived class should not be split. This included a rework the mechanism checking the base classes. Instead of using `InheritsFrom`, which lead in some cases, including the case where the class derived from an STL collection, to spurrious autoparsing (to look at the base class of the collection!), we use a custom walk through the tree of base classes that checks their value of `fCanSplit`. This also has the side-effect of allowing the extension of the concept 'base class that prevent its derived class from being split' to any user class. This fixes [ROOT-7972]. ### Dictionaries. * Add the -excludePath option to",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5953,Energy Efficiency,reduce,reduce,5953,"o not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant wi",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9568,Energy Efficiency,reduce,reduce,9568,"OT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonethe",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23592,Energy Efficiency,adapt,adapter,23592,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24050,Energy Efficiency,adapt,adapter,24050," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:1853,Integrability,interface,interfaces,1853,"il, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_i",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:1954,Integrability,interface,interface,1954,"il, GSoC, \; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh, GSoC, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Timur Pocheptsov, CERN/SFT,\; Fons Rademakers, CERN/IT,\; Paul Russo, Fermilab,\; Enric Tejedor Saavedra, CERN/SFT,\; George Troska, Dortmund Univ.,\; Liza Sakellari, CERN/SFT,\; Alex Saperstein, ANL,\; Manuel Tobias Schiller, CERN/LHCb,\; David Smith, CERN/IT,\; Peter Speckmayer,\; Tom Stevenson, Queen Mary University of London, ATLAS\; Matevz Tadel, UCSD/CMS, Eve,\; Peter van Gemmeren, ANL, ATLAS,\; Xavier Valls, CERN/SFT, \; Vassil Vassilev, Fermilab/CMS,\; Stefan Wunsch, KIT, CMS\; Omar Zapata, University of Antioquia, CERN/SFT.; . <a name=""core-libs""></a>. ## General. * Remove many instances of new warnings issued by gcc 6.1; * Significant update of the valgrind suppression file to hide intentional lack; of delete of some entities at the end of the process.; * Resolved several memory leaks.; * Added deprecation system: when compiling against interfaces marked R__DEPRECATED, the compiler will issue a warning showing the ROOT version when the interface will be removed.; * From this version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_i",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:6277,Integrability,interface,interface,6277,"tions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant with C++11 requirements.; * Add a new Implicit Multi-Threading (IMT) use case, incarnated in method `TTreeProcessor::Process`. `TTProcessor::Process` allows to process the entries of a TTree",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:6365,Integrability,interface,interface,6365,"to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant with C++11 requirements.; * Add a new Implicit Multi-Threading (IMT) use case, incarnated in method `TTreeProcessor::Process`. `TTProcessor::Process` allows to process the entries of a TTree in parallel. The user provides a function that receives one parameter, a TTreeReader, that can be used to iterate over a subrange of e",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9719,Integrability,interface,interfaces,9719," data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is mu",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:10323,Integrability,rout,routine,10323,"aking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## His",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:11579,Integrability,integrat,integrate,11579,"ll deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13467,Integrability,interface,interface,13467,"ltin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at th",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:21973,Integrability,depend,depends,21973,"d.; Painting it produced a dot with the X11 backend.; * New class `TRatioPlot` implemented by Paul Gessinger <hello@paulgessinger.com>.; Class for displaying ratios, differences and fit residuals. `TRatioPlot` has two constructors, one which accepts two histograms, and is responsible; for setting up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Je",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23355,Integrability,depend,depending,23355,"ll render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this RO",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23592,Integrability,adapter,adapter,23592,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24050,Integrability,adapter,adapter,24050," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24279,Integrability,depend,depends,24279,"the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command argu",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25581,Integrability,integrat,integration,25581,"atabase Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TG",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25623,Integrability,integrat,integration,25623,"` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offloa",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28375,Integrability,interface,interfaces,28375,"OT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29571,Integrability,wrap,wrapper,29571," section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'cuda' option to enable looking for CUDA in the system. ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29871,Integrability,depend,dependent,29871," section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'cuda' option to enable looking for CUDA in the system. ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:6425,Modifiability,inherit,inherit,6425,"to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant with C++11 requirements.; * Add a new Implicit Multi-Threading (IMT) use case, incarnated in method `TTreeProcessor::Process`. `TTProcessor::Process` allows to process the entries of a TTree in parallel. The user provides a function that receives one parameter, a TTreeReader, that can be used to iterate over a subrange of e",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8257,Modifiability,plugin,plugins,8257,"o process the entries of a TTree in parallel. The user provides a function that receives one parameter, a TTreeReader, that can be used to iterate over a subrange of entries. Each subrange corresponds to a cluster in the TTree and is processed by a task, which can potentially be run in parallel with other tasks.; * Add a new implementation of a RW lock, `ROOT::TRWSpinLock`, which is based on a `ROOT::TSpinMutex`. `TRWSpinLock` tries to make faster the scenario when readers come and go but there is no writer, while still preventing starvation of writers. ## I/O Libraries. * Support I/O of `std::unique_ptr`s and STL collections thereof.; * Support I/O of `std::array`.; * Support I/O of `std::tuple`. The dictionary for those is never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the opti",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9072,Modifiability,variab,variables,9072,"late instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-caches",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9141,Modifiability,variab,variables,9141," to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:12573,Modifiability,variab,variable,12573,"om `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13062,Modifiability,config,configuration,13062,"while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13631,Modifiability,variab,variable,13631,"tion. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be nec",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:15960,Modifiability,enhance,enhancement,15960,"ble to select an histogram on a canvas by clicking on the vertical; lines of the bins boundaries.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-6649).; * When using time format in axis, `TGaxis::PaintAxis()` may in some cases call; `strftime()` with invalid parameter causing a crash.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7689).; * Having ""X11.UseXft: yes"" activated in .rootrc file and running; [this](https://sft.its.cern.ch/jira/browse/ROOT-7985) little program,; resulted in a crash.; * Ease the setting of the appearance of joining lines for PostScript and PDF; output. `TPostScript::SetLineJoin`; allowed to set the line joining style for PostScript files. But the setting this; parameter implied to create a `TPostScript` object. Now a `TStyle` setting has been; implemented and it is enough to do:; ``` {.cpp}; gStyle->SetLineJoinPS(2);; ```; Also this setting is now active for PDF output.; This enhancement was triggered by [this forum question](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=21077).; * Make sure the palette axis title is correct after a histogram cloning. This; problem was mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8007).; * `TASImage` When the first or last point of a wide line is exactly on the; window limit the line is drawn vertically or horizontally.; This problem was mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8021); * Make sure that `TLatex` text strings containing ""\\"" (ie: rendered using `TMathText`); produce an output in PDF et SVG files.; * In TLatex, with the Cocoa backend on Mac the Angstroem characters did not render correctly.; This problem was mentioned [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=21321); * New version of libpng (1.2.55) as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8045).; * Enhancement of the CANDLE drawing option (implemented by Georg Troska georg.troska@tu-dortmund.de).; This option has been comple",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23420,Modifiability,plug-in,plug-in,23420,"ll render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this RO",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23592,Modifiability,adapt,adapter,23592,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24050,Modifiability,adapt,adapter,24050," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24415,Modifiability,config,configure,24415,"the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command argu",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24815,Modifiability,config,configuration,24815,"onvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syn",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:25246,Modifiability,config,configuration,25246,"ies ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syntax ""%%"", for example ""%%cpp"".; * The methods ""toCpp"" and ""toPython"" have been removed.; * Factorise output capturing and execution in an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibil",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27895,Modifiability,variab,variables,27895," support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdf",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28227,Modifiability,config,config,28227,"y context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*;",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29012,Modifiability,config,config,29012,"tion; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'c",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29037,Modifiability,config,configure,29037,"tion; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'c",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29389,Modifiability,config,configure,29389," section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'cuda' option to enable looking for CUDA in the system. ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5689,Performance,multi-thread,multi-threading,5689,"ry generator.; * Fix handling of template parameter pack in the forward declaration printer. [ROOT-8096]; * Do not autoparse headers for classes in the pch.; * Avoid autoparse on IsForeign() if possible.; * Check for new-style empty pcm with key named ""EMPTY"" created since commit 90047b0cba6fd295f5c5722749a0d043fbc11ea5.; * Do not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreaded",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:5891,Performance,multi-thread,multi-threading,5891,"n the pch.; * Avoid autoparse on IsForeign() if possible.; * Check for new-style empty pcm with key named ""EMPTY"" created since commit 90047b0cba6fd295f5c5722749a0d043fbc11ea5.; * Do not insert macro definition of `__ROOTCLING__` into the pch. ### Interpreter Library. * llvm / clang have been updated to r274612.; * The GCC5 ABI is now supported [ROOT-7947].; * Exceptions are now caught in the interactive ROOT session, instead of terminating ROOT.; * A ValuePrinter for tuple and pair has been added to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessEx",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8944,Performance,cache,cache,8944," never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesi",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9328,Performance,optimiz,optimization,9328,"to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually call",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9493,Performance,cache,cache,9493,"OT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonethe",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9739,Performance,cache,cache,9739,"hout any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on crea",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9794,Performance,cache,cache,9794,"hout any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on crea",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9934,Performance,cache,cachesize,9934,"; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In add",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9977,Performance,cache,cache,9977,"ke sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implic",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:10040,Performance,cache,cachesize,10040,"ke sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implic",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:10242,Performance,cache,cache,10242,"dle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fix",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:11006,Performance,multi-thread,multi-threading,11006," use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard libr",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:11101,Performance,multi-thread,multi-threading,11101," use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually called for each input file even those containing `TTree` objects with no entries.; * Repair setting the branch address of a leaflist style branch taking directly the address of the struct. (Note that leaflist is nonetheless still deprecated and declaring the struct to the interpreter and passing the object directly to create the branch is much better).; * Provide an implicitly parallel implementation of `TTree::GetEntry`. The approach is based on creating a task per top-level branch in order to do the reading, unzipping and deserialisation in parallel. In addition, a getter and a setter methods are provided to check the status and enable/disable implicit multi-threading for that tree (see Parallelisation section for more information about implicit multi-threading).; * Properly support `std::cin` (and other stream that can not be rewound) in `TTree::ReadStream`. This fixes [ROOT-7588].; * Prevent `TTreeCloner::CopyStreamerInfos()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard libr",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:12947,Performance,optimiz,optimized,12947,"N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradie",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:21852,Performance,perform,performance,21852,"lues; specified by `SetMaximum()` and `SetMinimum()`.; * In `TMarker3DBox` when a box marker has a size equal to zero it is not painted.; Painting it produced a dot with the X11 backend.; * New class `TRatioPlot` implemented by Paul Gessinger <hello@paulgessinger.com>.; Class for displaying ratios, differences and fit residuals. `TRatioPlot` has two constructors, one which accepts two histograms, and is responsible; for setting up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns th",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:21919,Performance,perform,performance,21919,"d.; Painting it produced a dot with the X11 backend.; * New class `TRatioPlot` implemented by Paul Gessinger <hello@paulgessinger.com>.; Class for displaying ratios, differences and fit residuals. `TRatioPlot` has two constructors, one which accepts two histograms, and is responsible; for setting up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Je",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22314,Performance,perform,performance,22314,"ing up the calculation of ratios and differences. This calculation is in part; delegated to `TEfficiency`. A single option can be given as a parameter, that is; used to determine which procedure is chosen. The remaining option string is then; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used f",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22493,Performance,perform,performance,22493,"n; passed through to the calculation, if applicable. Several examples illustrate how to use this class. See:; `$ROOTSYS/tutorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversio",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:22605,Performance,optimiz,optimized,22605,"utorials/hist/ratioplot?.C`. * New option ""I"" allowing to draw TGraph with invisible axis (used by `TRatioPlot`);. ## New histogram drawing options. ### COL2; COL2 is a new rendering technique providing potential performance improvements; compared to the standard COL option. The performance comparison of the COL2 to; the COL option depends on the histogram and the size of the rendering region in; the current pad. In general, a small (approx. less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navi",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23164,Performance,perform,performance,23164,"than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23398,Performance,load,loaded,23398,"ll render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this RO",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23556,Performance,load,loaded,23556,"ng rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheat",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23703,Performance,load,loading,23703,"n replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested range",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23994,Performance,perform,performance,23994," of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebF",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:26946,Performance,perform,performance,26946," an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automa",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27443,Performance,perform,performance,27443," volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:3004,Safety,safe,safe,3004,"version on, building ROOT with CMake requires CMake &gt;= 3.4.3. ## Core Libraries. ROOT prepares for [cxx modules](http://clang.llvm.org/docs/Modules.html). One of; the first requirements is its header files to be self-contained (section ""Missing; Includes""). ROOT header files were cleaned up from extra includes and the missing; includes were added. This could be considered as backward incompatibility (for good however). User; code may need to add extra includes, which were previously resolved indirectly; by including a ROOT header. For example:. * TBuffer.h - TObject.h doesn't include TBuffer.h anymore. Third party code,; replying on the definition of TBufer will need to include TBuffer.h, along; with TObject.h.; * TSystem.h - for some uses of gSystem.; * GeneticMinimizer.h; * ... Other improvements, which may cause compilation errors in third party code:. * If you get `std::type_info` from Rtypeinfo.h, `type_info` should be spelled; `std::type_info`. Also:. * `TPluginManager` was made thread-safe [ROOT-7927].; * On MacOSX, backtraces are now generated without external tools [ROOT-6667].; * The set of include paths considered by the interpreter has been reduced to the bare minimum. ### Containers. * A pseudo-container (generator) was created, `ROOT::TSeq<T>`. This template is inspired by the xrange built-in function of Python. See the example [here](https://root.cern.ch/doc/master/cnt001__basictseq_8C.html). ### Meta Library. Add a new mode for `TClass::SetCanSplit` (2) which indicates that this class and any derived class should not be split. This included a rework the mechanism checking the base classes. Instead of using `InheritsFrom`, which lead in some cases, including the case where the class derived from an STL collection, to spurrious autoparsing (to look at the base class of the collection!), we use a custom walk through the tree of base classes that checks their value of `fCanSplit`. This also has the side-effect of allowing the extension of the concept '",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:9238,Safety,detect,detection,9238,"to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesize=SIZE"". To update the size of the cache or disable it from `hadd`, use the command line option `-cachesize SIZE`. `SIZE` shouyld be given in number bytes and can be expressed in 'human readable form' (number followed by size unit like MB, MiB, GB or GiB, etc. or SIZE can be set zero to disable the cache. ### Other Changes. * Update `TChain::LoadTree` so that the user call back routine is actually call",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:12248,Safety,safe,safety,12248,"s()` from causing an autoparse on an abstract base class. ## Histogram Libraries. * TH2Poly has a functional Merge method.; * Implemented the `TGraphAsymmErrors` constructor directly from an ASCII file. ## Math Libraries. * New template class `TRandomGen<Engine>` which derives from `TRandom` and integrate new random generator engines as TRandom classes.; * New TRandom specific types have been defined for these following generators:; * `TRandomMixMax` - recommended MIXMAX generator with N=240; * `TRandomMixMax17` - MIXMAX generator with smaller state (N=17) and faster seeding time; * `TRandomMixMax256` - old version of MIXMAX generator (N=256); * `TRandomMT64` - 64 bit Mersenenne Twister generator from the standard library (based on `std::mt19937_64`). This generates 64 bit random numbers, while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14000,Safety,avoid,avoiding,14000,"* `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to selec",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:14566,Safety,avoid,avoid,14566,"riable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is now drawn using a continuous line.; * It is now possible to select an histogram on a canvas by clicking on the vertical; lines of the bins boundaries.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-6649).; * When using time format in axis, `TGaxis::PaintAxis()` may in some cases call; `strftime()` with invalid parameter causing a crash.; This problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-7689).; * Having ""X11.UseXft: yes"" activated in .rootrc file and running; [this](https://sft.its.cern.ch/jira/browse/ROOT-7985) little program,; resulted in a crash.; * Ease the setting of the appearance of joining lines for PostScript and PDF; output. `TPo",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8325,Security,secur,security,8325,"terate over a subrange of entries. Each subrange corresponds to a cluster in the TTree and is processed by a task, which can potentially be run in parallel with other tasks.; * Add a new implementation of a RW lock, `ROOT::TRWSpinLock`, which is based on a `ROOT::TSpinMutex`. `TRWSpinLock` tries to make faster the scenario when readers come and go but there is no writer, while still preventing starvation of writers. ## I/O Libraries. * Support I/O of `std::unique_ptr`s and STL collections thereof.; * Support I/O of `std::array`.; * Support I/O of `std::tuple`. The dictionary for those is never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by ta",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8376,Security,secur,security,8376,"terate over a subrange of entries. Each subrange corresponds to a cluster in the TTree and is processed by a task, which can potentially be run in parallel with other tasks.; * Add a new implementation of a RW lock, `ROOT::TRWSpinLock`, which is based on a `ROOT::TSpinMutex`. `TRWSpinLock` tries to make faster the scenario when readers come and go but there is no writer, while still preventing starvation of writers. ## I/O Libraries. * Support I/O of `std::unique_ptr`s and STL collections thereof.; * Support I/O of `std::array`.; * Support I/O of `std::tuple`. The dictionary for those is never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by ta",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:23108,Security,access,access,23108," less than 100 bins per axis),; sparsely populated TH2 will render faster with the COL option. However, for larger histograms (approx. more than 100 bins per axis) that are; not sparse, the COL2 option will provide up to 20 times performance improvements.; For example, a 1000x1000 bin TH2 that is not sparse will render an order of; magnitude faster with the COL2 option. The COL2 option will also scale its performance based on the size of the pixmap; the histogram image is being rendered into. It also is much better optimized for; sessions where the user is forwarding X11 windows through an `ssh` connection. For the most part, the COL2 and COLZ2 options are a drop in replacement to the COL; and COLZ options. There is one major difference and that concerns the treatment of; bins with zero content. The COL2 and COLZ2 options color these bins the color of zero. This has been implemented by Jeromy Tompkins <Tompkins@nscl.msu.edu>. ## Geometry Libraries; A new module geom/vecgeom was introduced to give transparent access to VecGeom ; solid primitives. VecGeom is a high performance geometry package (link) providing ; SIMD vectorization for the CPU-intensive geometry algorithms used for geometry; navigation. The module creates a new library libConverterVG.so depending on the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: inst",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27152,Testability,log,logx,27152," volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:27638,Testability,log,log,27638,"nteractivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; -",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13951,Usability,simpl,simplified,13951,"for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be necessary to increase the chunks' size using the new function:; `TGraphPainter::SetMaxPointsPerLine(20000)`.; * When using line styles different from 1 (continuous line), the behavior of TArrow; was suboptimal. The problem was that the line style is also applied to the arrow; head, which is usually not what one wants.; The arrow tip is ",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:17078,Usability,guid,guide,17078,"he palette axis title is correct after a histogram cloning. This; problem was mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8007).; * `TASImage` When the first or last point of a wide line is exactly on the; window limit the line is drawn vertically or horizontally.; This problem was mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8021); * Make sure that `TLatex` text strings containing ""\\"" (ie: rendered using `TMathText`); produce an output in PDF et SVG files.; * In TLatex, with the Cocoa backend on Mac the Angstroem characters did not render correctly.; This problem was mentioned [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=21321); * New version of libpng (1.2.55) as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8045).; * Enhancement of the CANDLE drawing option (implemented by Georg Troska georg.troska@tu-dortmund.de).; This option has been completely rewritten and offers a wide range of possibilities.; See the THistPainter reference guide for all the details and examples.; * Fix `TText` copy constructor as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8116).; New example to check this fix.; * SVG boxes were not correct when `x2<1` (reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8126)).; * In TASImage there was no protection against graphics being drawn outside the assigned; memory. That may generate some crashes like described [here](https://sft.its.cern.ch/jira/browse/ROOT-8123).; * In TASImage: transparent rectangles did not work when png files were created in batch mode.; * In TASImage: implement transparent text for png files created in batch mode.; * TCanvas title was not set correctly when a TCanvas was read from a TFile.; (reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=21540&p=94053#p93981)).; * The text generated by `TSVG` has now the `xml:space=""preserve""` attribute in order; to be editable later on using external softwares like ""inkscape"". This improvement; was suggest",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24775,Usability,simpl,simply,24775,"onvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command arguments. To disable processing the rootlogon do the following; before any other command that will trigger initialization:; ```; >>> import ROOT; >>> ROOT.PyConfig.DisableRootLogon = True; >>> ...; ```. ### Notebook integration. * Refactoring of the Jupyter integration layer into the new package JupyROOT.; * Added ROOT [Jupyter Kernel for ROOT](https://root.cern.ch/root-has-its-jupyter-kernel); * Magics are now invoked with standard syn",MatchSource.DOCS,README/ReleaseNotes/v608/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1382,Availability,avail,available,1382,"ivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1872,Availability,repair,repaired,1872,"have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:5612,Availability,avail,available,5612,"of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxis(1)->SetRangeUser(0.1, 0.2);. TH1* projection = chain->Projection(0); ```. ## Math Libraries. * Improve thread friendliness of the TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is misleading; please use `TTreePlayer::SetEntriesRange()` instead.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of c",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:9692,Availability,error,error,9692,"aph2D` were not drawn (option `P`).; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8447).; - New options for automatic coloring of graphs and histograms. When several; histograms or graphs are painted in the same canvas thanks to the option ""SAME""; via a `THStack` or `TMultigraph` it might be useful to have an easy and automatic; way to choose their color. The simplest way is to pick colors in the current active color; palette. Palette coloring for histogram is activated thanks to the options `PFC`; (Palette Fill Color), `PLC` (Palette Line Color) and `AMC` (Palette Marker Color).; When one of these options is given to `TH1::Draw` the histogram get its color; from the current color palette defined by `gStyle->SetPalette()`. The color; is determined according to the number of objects having palette coloring in; the current pad.; - The line width and line style can be change on 2d histograms painted with; option `ARR`.; - When the angle of a TGraphPolar was not in radian, the error bars were misplaced.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8476).; - In `TASimage::DrawLineInternal` the case of a line with 0 pixel along X and 0; pixel along Y was not treated properly. An horizontal line was drawn instead.; - In `TGraphPainter::PaintGrapHist`: Decouple the `P` option (histogram drawn with; a simple polymarker) from the `L` option (Histogram drawn as a simple polyline). This; improved (in some cases some extra markers were drawn) and simplified the code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:11180,Availability,error,error,11180,"e code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations of presets and individual options for VIOLIN-charts; * Implementation of VIOLIN-charts in THStack - can be combined with CANDLE; * Update of the docs (THistPainter and THStack); * New tutorials; - In various places in TGraph the underlying histogram was deleted when the graph; range should be recomputed. This has the side effect that some graph parameters; (like the axis titles) were also deleted. This now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8092).; - Improve the error bars drawing in TLegend to match the plot's error; drawing. This improvement was requested [here](https://sft.its.cern.ch/jira/browse/ROOT-5468).; - Implement text clipping in TASImage as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-4538).; Also the text size in batch mode for png (gif jpeg) files better matches the; size on screen and pdf.; - `TMathText` and `TTeXDump` implement the `TLatex` character `\bar`.; - In the following example, `TPad::WaitPrimitive` was not stoping the macro; execution after each plot :; ~~~ {.cpp}; {; TCanvas c1(""c1"");; TFile f(""hsimple.root"");; hpx->Draw(); gPad->WaitPrimitive();; hpxpy->Draw(); gPad->WaitPrimitive();; hprof->Draw();; ~~~; this was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=22957).; - New flag `Cocoa.EnableFillAreaAntiAliasing` in `system.rootrc` to enable the; anti-aliasing for filled area for the Cocoa backend. Default is `no`.; - The ""BOX"" option, to draw 3D histograms, has been reimplemented by Evgueni Tcherniaev; The fo",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:11230,Availability,error,error,11230,"e code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations of presets and individual options for VIOLIN-charts; * Implementation of VIOLIN-charts in THStack - can be combined with CANDLE; * Update of the docs (THistPainter and THStack); * New tutorials; - In various places in TGraph the underlying histogram was deleted when the graph; range should be recomputed. This has the side effect that some graph parameters; (like the axis titles) were also deleted. This now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8092).; - Improve the error bars drawing in TLegend to match the plot's error; drawing. This improvement was requested [here](https://sft.its.cern.ch/jira/browse/ROOT-5468).; - Implement text clipping in TASImage as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-4538).; Also the text size in batch mode for png (gif jpeg) files better matches the; size on screen and pdf.; - `TMathText` and `TTeXDump` implement the `TLatex` character `\bar`.; - In the following example, `TPad::WaitPrimitive` was not stoping the macro; execution after each plot :; ~~~ {.cpp}; {; TCanvas c1(""c1"");; TFile f(""hsimple.root"");; hpx->Draw(); gPad->WaitPrimitive();; hpxpy->Draw(); gPad->WaitPrimitive();; hprof->Draw();; ~~~; this was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=22957).; - New flag `Cocoa.EnableFillAreaAntiAliasing` in `system.rootrc` to enable the; anti-aliasing for filled area for the Cocoa backend. Default is `no`.; - The ""BOX"" option, to draw 3D histograms, has been reimplemented by Evgueni Tcherniaev; The fo",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:12728,Availability,down,down,12728," macro; execution after each plot :; ~~~ {.cpp}; {; TCanvas c1(""c1"");; TFile f(""hsimple.root"");; hpx->Draw(); gPad->WaitPrimitive();; hpxpy->Draw(); gPad->WaitPrimitive();; hprof->Draw();; ~~~; this was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=22957).; - New flag `Cocoa.EnableFillAreaAntiAliasing` in `system.rootrc` to enable the; anti-aliasing for filled area for the Cocoa backend. Default is `no`.; - The ""BOX"" option, to draw 3D histograms, has been reimplemented by Evgueni Tcherniaev; The following picture show the old and new version. ![New box option for 3D histograms](NewBoxOption.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [h",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:12791,Availability,error,error,12791,"imple.root"");; hpx->Draw(); gPad->WaitPrimitive();; hpxpy->Draw(); gPad->WaitPrimitive();; hprof->Draw();; ~~~; this was reported [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=22957).; - New flag `Cocoa.EnableFillAreaAntiAliasing` in `system.rootrc` to enable the; anti-aliasing for filled area for the Cocoa backend. Default is `no`.; - The ""BOX"" option, to draw 3D histograms, has been reimplemented by Evgueni Tcherniaev; The following picture show the old and new version. ![New box option for 3D histograms](NewBoxOption.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the mark",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13207,Availability,avail,available,13207,"eni Tcherniaev; The following picture show the old and new version. ![New box option for 3D histograms](NewBoxOption.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance with `SetPoint`); after the `TMultiGraph` was drawn, the `TMultiGraph` range was not recomputed.; This issue was discovered thanks to",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13277,Availability,avail,available,13277,"ion.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance with `SetPoint`); after the `TMultiGraph` was drawn, the `TMultiGraph` range was not recomputed.; This issue was discovered thanks to [this forum post](https://root-forum.cern.ch/t/multi-layer-perceptron/24561/2).; - When a TGraph is drawn, the X",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:15367,Availability,error,error,15367,"d `RY` allow to; change this order. The option `RX` allows to draw the X-axis with increasing values; from right to left and the `RY` option allows to draw the Y-axis with increasing; values from top to bottom.; ~~~ {.cpp}; g->Draw(""APL"");; g->Draw(""A RX RY PL"");; ~~~. ![New box option for 3D histograms](ReverseAxis.png). ## 3D Graphics Libraries; - In `TMarker3DBox::PaintH3` the boxes' sizes was not correct.; - The option `BOX`and `GLBOX` now draw boxes with a volume proportional to the; bin content to be conform to the 2D case where the surface of the boxes is; proportional to the bin content. ## Geometry Libraries. ## Dictionaries; - Stop dictionary generation early, during AST scanning, if a union is selected for I/O as this is not supported (triggered by [ROOT-8492](https://sft.its.cern.ch/jira/browse/ROOT-8492)); - Allow inclusion of headers in linkdef files [ROOT-7765](https://sft.its.cern.ch/jira/browse/ROOT-7765); - More expressive error messages when trying to directly select std::arrays; - rootcling now `#define`s `__PIC__` when parsing input headers [ROOT-8719]. ## I/O Libraries; - [[ROOT-8478](https://sft.its.cern.ch/jira/browse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:15593,Availability,error,error,15593," ![New box option for 3D histograms](ReverseAxis.png). ## 3D Graphics Libraries; - In `TMarker3DBox::PaintH3` the boxes' sizes was not correct.; - The option `BOX`and `GLBOX` now draw boxes with a volume proportional to the; bin content to be conform to the 2D case where the surface of the boxes is; proportional to the bin content. ## Geometry Libraries. ## Dictionaries; - Stop dictionary generation early, during AST scanning, if a union is selected for I/O as this is not supported (triggered by [ROOT-8492](https://sft.its.cern.ch/jira/browse/ROOT-8492)); - Allow inclusion of headers in linkdef files [ROOT-7765](https://sft.its.cern.ch/jira/browse/ROOT-7765); - More expressive error messages when trying to directly select std::arrays; - rootcling now `#define`s `__PIC__` when parsing input headers [ROOT-8719]. ## I/O Libraries; - [[ROOT-8478](https://sft.its.cern.ch/jira/browse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writing to a single; output file. Its purpose is similar to TParallelMergingFile,; but instead of using processes that connect to a network; socket, TBufferMerger uses threads that each write to a; TBufferMergerFile, which in turn push data into a queue; managed by the TBu",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:15719,Availability,error,error,15719," ![New box option for 3D histograms](ReverseAxis.png). ## 3D Graphics Libraries; - In `TMarker3DBox::PaintH3` the boxes' sizes was not correct.; - The option `BOX`and `GLBOX` now draw boxes with a volume proportional to the; bin content to be conform to the 2D case where the surface of the boxes is; proportional to the bin content. ## Geometry Libraries. ## Dictionaries; - Stop dictionary generation early, during AST scanning, if a union is selected for I/O as this is not supported (triggered by [ROOT-8492](https://sft.its.cern.ch/jira/browse/ROOT-8492)); - Allow inclusion of headers in linkdef files [ROOT-7765](https://sft.its.cern.ch/jira/browse/ROOT-7765); - More expressive error messages when trying to directly select std::arrays; - rootcling now `#define`s `__PIC__` when parsing input headers [ROOT-8719]. ## I/O Libraries; - [[ROOT-8478](https://sft.its.cern.ch/jira/browse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writing to a single; output file. Its purpose is similar to TParallelMergingFile,; but instead of using processes that connect to a network; socket, TBufferMerger uses threads that each write to a; TBufferMergerFile, which in turn push data into a queue; managed by the TBu",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:15866,Availability,error,error,15866," with a volume proportional to the; bin content to be conform to the 2D case where the surface of the boxes is; proportional to the bin content. ## Geometry Libraries. ## Dictionaries; - Stop dictionary generation early, during AST scanning, if a union is selected for I/O as this is not supported (triggered by [ROOT-8492](https://sft.its.cern.ch/jira/browse/ROOT-8492)); - Allow inclusion of headers in linkdef files [ROOT-7765](https://sft.its.cern.ch/jira/browse/ROOT-7765); - More expressive error messages when trying to directly select std::arrays; - rootcling now `#define`s `__PIC__` when parsing input headers [ROOT-8719]. ## I/O Libraries; - [[ROOT-8478](https://sft.its.cern.ch/jira/browse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writing to a single; output file. Its purpose is similar to TParallelMergingFile,; but instead of using processes that connect to a network; socket, TBufferMerger uses threads that each write to a; TBufferMergerFile, which in turn push data into a queue; managed by the TBufferMerger. An excerpt of the; [tutorial](https://github.com/root-project/root/blob/master/tutorials/multicore/mt103_fillNtuples.C); is shown below.; ```{.cpp}; // Create the TBufferMerger;",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:130,Deployability,release,release,130,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:116,Energy Efficiency,schedul,scheduled,116,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:743,Integrability,interface,interfaces,743,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:769,Integrability,interface,interfaces,769,"% ROOT Version 6.10 Release Notes; % 2016-09-30; <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.10/00 is scheduled for release in 2017. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Bertrand Bellenot, CERN/SFT,\; Georgios Bitzes, CERN/IT,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cl",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:2890,Integrability,inject,injected,2890,"tion going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceA",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:3168,Integrability,interface,interface,3168,"thodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `C",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:3225,Integrability,interface,interface,3225,"me()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `CopyString()` which clearly indicates that it involves a temporary. ## Histogram Libraries. - New class `THnChain` w",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:3754,Integrability,interface,interface,3754,"he `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `CopyString()` which clearly indicates that it involves a temporary. ## Histogram Libraries. - New class `THnChain` was added to provide a `TChain`-like experience when; working with `THnBase`'ed histograms (currently `THn` and `THnSparse`) from; many files, see [here](https://sft.its.cern.ch/jira/browse/ROOT-4515). This; allows to e.g., interactively adjust axis parameters before performing; projections from high-dimensional histograms,. ```{.cpp}; // Create a chain of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxi",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13531,Integrability,depend,depending,13531," ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance with `SetPoint`); after the `TMultiGraph` was drawn, the `TMultiGraph` range was not recomputed.; This issue was discovered thanks to [this forum post](https://root-forum.cern.ch/t/multi-layer-perceptron/24561/2).; - When a TGraph is drawn, the X-axis is drawn with increasing values from left to; right and the Y-axis from bottom to top. The two options `RX` and `RY` allow to; change this order. The option `RX` allows to draw the X-axis with increasing values; from right to left and the `RY` op",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:15373,Integrability,message,messages,15373,"d `RY` allow to; change this order. The option `RX` allows to draw the X-axis with increasing values; from right to left and the `RY` option allows to draw the Y-axis with increasing; values from top to bottom.; ~~~ {.cpp}; g->Draw(""APL"");; g->Draw(""A RX RY PL"");; ~~~. ![New box option for 3D histograms](ReverseAxis.png). ## 3D Graphics Libraries; - In `TMarker3DBox::PaintH3` the boxes' sizes was not correct.; - The option `BOX`and `GLBOX` now draw boxes with a volume proportional to the; bin content to be conform to the 2D case where the surface of the boxes is; proportional to the bin content. ## Geometry Libraries. ## Dictionaries; - Stop dictionary generation early, during AST scanning, if a union is selected for I/O as this is not supported (triggered by [ROOT-8492](https://sft.its.cern.ch/jira/browse/ROOT-8492)); - Allow inclusion of headers in linkdef files [ROOT-7765](https://sft.its.cern.ch/jira/browse/ROOT-7765); - More expressive error messages when trying to directly select std::arrays; - rootcling now `#define`s `__PIC__` when parsing input headers [ROOT-8719]. ## I/O Libraries; - [[ROOT-8478](https://sft.its.cern.ch/jira/browse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:18744,Integrability,depend,depend,18744,"r.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; - Added the CMake exported ROOT libraries into the ROOT:: namespace. In this way, projects based on CMake using ROOT can avoid; conflicts in library target names. As an example, this is the way to build a project consisting of one library and one; executable using ROOT.; ```; find_package(ROOT REQUIRED); include(${ROOT_USE_FILE}). include_directories(${CMAKE_SOURCE_DIR} ${ROOT_INCLUDE_DIRS}); add_definitions(${ROOT_CXX_FLAGS}). ROOT_GENERATE_DICTIONARY(G__Event Event.h LINKDEF EventLinkDef.h). add_library(Event SHARED Event.cxx G__Event.cxx); target_link_libraries(Event ROOT::Hist ROOT::Tree). add_executable(Main MainEvent.cxx); target_link_libraries(Main Event); ```; - Added option `builtin_all` to enable all the built in options.; - For rootcling_stage1 (formerly known as rootcling_tmp), the package structure was changed to enable homogenous visibility; settings across object files. See core/README for an overview.; - Several non-public headers are not copied into include/ anymore; they reside in the PACKAGE/res/ subdirectory in the source tree.; - The IMT switch is set to on by default.; - A new library is now created, libImt. It contains all classes which depend on TBB. Those classes were previously part of libThread. As a consequence rootcling/genreflex do not depend anymore from TBB even in presence of imt builds.; - Refactoring of several math tests to avoid exact comparisons of floating point numbers; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:18852,Integrability,depend,depend,18852,"r.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; - Added the CMake exported ROOT libraries into the ROOT:: namespace. In this way, projects based on CMake using ROOT can avoid; conflicts in library target names. As an example, this is the way to build a project consisting of one library and one; executable using ROOT.; ```; find_package(ROOT REQUIRED); include(${ROOT_USE_FILE}). include_directories(${CMAKE_SOURCE_DIR} ${ROOT_INCLUDE_DIRS}); add_definitions(${ROOT_CXX_FLAGS}). ROOT_GENERATE_DICTIONARY(G__Event Event.h LINKDEF EventLinkDef.h). add_library(Event SHARED Event.cxx G__Event.cxx); target_link_libraries(Event ROOT::Hist ROOT::Tree). add_executable(Main MainEvent.cxx); target_link_libraries(Main Event); ```; - Added option `builtin_all` to enable all the built in options.; - For rootcling_stage1 (formerly known as rootcling_tmp), the package structure was changed to enable homogenous visibility; settings across object files. See core/README for an overview.; - Several non-public headers are not copied into include/ anymore; they reside in the PACKAGE/res/ subdirectory in the source tree.; - The IMT switch is set to on by default.; - A new library is now created, libImt. It contains all classes which depend on TBB. Those classes were previously part of libThread. As a consequence rootcling/genreflex do not depend anymore from TBB even in presence of imt builds.; - Refactoring of several math tests to avoid exact comparisons of floating point numbers; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1340,Modifiability,variab,variables,1340,"ene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructur",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1529,Modifiability,variab,variables,1529,"RN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modi",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1909,Performance,optimiz,optimized,1909,", `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1959,Performance,optimiz,optimization,1959,"RTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjS",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:2005,Performance,optimiz,optimize,2005,"RTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjS",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:4527,Performance,perform,performing,4527,"TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `CopyString()` which clearly indicates that it involves a temporary. ## Histogram Libraries. - New class `THnChain` was added to provide a `TChain`-like experience when; working with `THnBase`'ed histograms (currently `THn` and `THnSparse`) from; many files, see [here](https://sft.its.cern.ch/jira/browse/ROOT-4515). This; allows to e.g., interactively adjust axis parameters before performing; projections from high-dimensional histograms,. ```{.cpp}; // Create a chain of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxis(1)->SetRangeUser(0.1, 0.2);. TH1* projection = chain->Projection(0); ```. ## Math Libraries. * Improve thread friendliness of the TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is misleading; please use `TTreePlayer::SetEntriesRange()` instead.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precisio",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:6260,Performance,perform,perform,6260,"d.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for an input TTree; - Snapshot on a rootfile the dataset after cuts and after augmentation with columns created by the user; - Run analyses expressed as chains of actions in parallel in a transparent way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFram",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:6341,Performance,multi-thread,multi-threading,6341,"/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for an input TTree; - Snapshot on a rootfile the dataset after cuts and after augmentation with columns created by the user; - Run analyses expressed as chains of actions in parallel in a transparent way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFrame.html) for more details. ## 2D Graphics Libraries; - If one used ""col2"" or ""colz2"", the value of `TH1::fMaximum` got modified.; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:16656,Performance,queue,queue,16656,"rowse/ROOT-8478)] - Prompt error when building streamer info and a data member is a vector<T> w/o dictionary; - Fix ROOT-8686 and ROOT-8595 which led to error when persistifying classes which featured std::arrays as data members in TTrees.; - TDavixFile: Added support for bucket name in path; - Fix error sometimes prompted when trying to write std::array column-wise. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism and PROOF; - Add ROOT::GetImplicitMTPoolSize function to get the size of the pool used to enable implicit multi threading; - Add the TThreadExecutor::Foreach method for parallelising functions featuring void return type; - Add TBufferMerger and TBufferMergerFile classes. TBufferMerger is a class to facilitate writing data in; parallel from multiple threads, while writing to a single; output file. Its purpose is similar to TParallelMergingFile,; but instead of using processes that connect to a network; socket, TBufferMerger uses threads that each write to a; TBufferMergerFile, which in turn push data into a queue; managed by the TBufferMerger. An excerpt of the; [tutorial](https://github.com/root-project/root/blob/master/tutorials/multicore/mt103_fillNtuples.C); is shown below.; ```{.cpp}; // Create the TBufferMerger; TBufferMerger merger(""mp103_fillNtuple.root"");. // Define what each worker will do; auto work_function = [&]() {; auto f = merger.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; -",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1684,Safety,avoid,avoiding,1684,"have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:5472,Safety,avoid,avoid,5472," allows to e.g., interactively adjust axis parameters before performing; projections from high-dimensional histograms,. ```{.cpp}; // Create a chain of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxis(1)->SetRangeUser(0.1, 0.2);. TH1* projection = chain->Projection(0); ```. ## Math Libraries. * Improve thread friendliness of the TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is misleading; please use `TTreePlayer::SetEntriesRange()` instead.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:5872,Safety,safe,safely,5872,"he TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is misleading; please use `TTreePlayer::SetEntriesRange()` instead.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13058,Safety,avoid,avoid,13058,"ng for filled area for the Cocoa backend. Default is `no`.; - The ""BOX"" option, to draw 3D histograms, has been reimplemented by Evgueni Tcherniaev; The following picture show the old and new version. ![New box option for 3D histograms](NewBoxOption.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance w",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:17687,Safety,avoid,avoid,17687,"fferMerger. An excerpt of the; [tutorial](https://github.com/root-project/root/blob/master/tutorials/multicore/mt103_fillNtuples.C); is shown below.; ```{.cpp}; // Create the TBufferMerger; TBufferMerger merger(""mp103_fillNtuple.root"");. // Define what each worker will do; auto work_function = [&]() {; auto f = merger.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; - Added the CMake exported ROOT libraries into the ROOT:: namespace. In this way, projects based on CMake using ROOT can avoid; conflicts in library target names. As an example, this is the way to build a project consisting of one library and one; executable using ROOT.; ```; find_package(ROOT REQUIRED); include(${ROOT_USE_FILE}). include_directories(${CMAKE_SOURCE_DIR} ${ROOT_INCLUDE_DIRS}); add_definitions(${ROOT_CXX_FLAGS}). ROOT_GENERATE_DICTIONARY(G__Event Event.h LINKDEF EventLinkDef.h). add_library(Event SHARED Event.cxx G__Event.cxx); target_link_libraries(Event ROOT::Hist ROOT::Tree). add_executable(Main MainEvent.cxx); target_link_libraries(Main Event); ```; - Added option `builtin_all` to enable all the built in options.; - For rootcling_stage1 (formerly known as rootcling_tmp), the package structure was changed to enable homogenous visibility; settings across object files. See core/README for an overview.; - Several non-public headers are not copied into include/ anymore; they reside in the PACKAGE/res/ subdirectory in the source tree.; - The IMT switch is set to on by default.; - A new",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:18948,Safety,avoid,avoid,18948,"r.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; - Added the CMake exported ROOT libraries into the ROOT:: namespace. In this way, projects based on CMake using ROOT can avoid; conflicts in library target names. As an example, this is the way to build a project consisting of one library and one; executable using ROOT.; ```; find_package(ROOT REQUIRED); include(${ROOT_USE_FILE}). include_directories(${CMAKE_SOURCE_DIR} ${ROOT_INCLUDE_DIRS}); add_definitions(${ROOT_CXX_FLAGS}). ROOT_GENERATE_DICTIONARY(G__Event Event.h LINKDEF EventLinkDef.h). add_library(Event SHARED Event.cxx G__Event.cxx); target_link_libraries(Event ROOT::Hist ROOT::Tree). add_executable(Main MainEvent.cxx); target_link_libraries(Main Event); ```; - Added option `builtin_all` to enable all the built in options.; - For rootcling_stage1 (formerly known as rootcling_tmp), the package structure was changed to enable homogenous visibility; settings across object files. See core/README for an overview.; - Several non-public headers are not copied into include/ anymore; they reside in the PACKAGE/res/ subdirectory in the source tree.; - The IMT switch is set to on by default.; - A new library is now created, libImt. It contains all classes which depend on TBB. Those classes were previously part of libThread. As a consequence rootcling/genreflex do not depend anymore from TBB even in presence of imt builds.; - Refactoring of several math tests to avoid exact comparisons of floating point numbers; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:2890,Security,inject,injected,2890,"tion going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceA",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:3257,Security,access,accesses,3257,"me()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.; - Add support for std::array_view also for C++11 builds. The implementation has been modified to work before C++14.; - Added TCollection::Notify to allow notifying more than one object.; ```{.cpp}; TList formulas;; // Add several TTreeFormula to the list;; chain.SetNotify(&formulas);; ```; - For classes that need the `ClassDef` support, `ClassDefInline(ClassName, Version)` now provides it without the need for a dictionary source: all members injected by this `ClassDef` flavor are generated by the interpreter. ### `TObjString` to `TString`. `TObjString::GetString()` now returns a `const TString&` to the `TString` inside the `TObjString`, instead of copying it.; This is to prevent very common misunderstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `CopyString()` which clearly indicates that it involves a temporary. ## Histogram Libraries. - New class `THnChain` w",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:6299,Security,access,accessible,6299,"/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for an input TTree; - Snapshot on a rootfile the dataset after cuts and after augmentation with columns created by the user; - Run analyses expressed as chains of actions in parallel in a transparent way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFrame.html) for more details. ## 2D Graphics Libraries; - If one used ""col2"" or ""colz2"", the value of `TH1::fMaximum` got modified.; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:8101,Testability,log,log,8101," way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFrame.html) for more details. ## 2D Graphics Libraries; - If one used ""col2"" or ""colz2"", the value of `TH1::fMaximum` got modified.; This deviated from the behavior of ""col"" or ""colz"". This is now fixed as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8389).; - When the option SAME (or ""SAMES"") is used with the option COL, the boxes' color; are computing taking the previous plots into account. The range along the Z axis; is imposed by the first plot (the one without option SAME); therefore the order; in which the plots are done is relevant.; - With option BOX on 2D histos with negative content:; - do not draw the empty bins as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8385).; - fix the issue mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-*402).; - When several histogram were drawn on top of each other with the option; `BOX SAME` and if the log scale along Z was on, the plot showed only the; first histogram. This can be reproduce by using the documentation example; illustrating `BOX SAME`and turning the canvas into log scale along Z.; - In TLatex:; - Do not paint the text when the text size is <= 0. This fixes; the problem mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8305); - Do not paint text if the text string is empty.; - From: Sergey Linev: In `TPad::SaveAs` method json file extension is now handled; - Because of some precision issue some data points exactly on the plot limits of; a `TGraph2D` were not drawn (option `P`).; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8447).; - New options for automatic coloring of graphs and histograms. When several; histograms or graphs are painted in the same canvas thanks to the option ""SAME""; via a `THStack` or `TMultigraph` it might be useful to have an easy and automatic; way to choose their color. The simplest way is to pi",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:8279,Testability,log,log,8279,"ails. ## 2D Graphics Libraries; - If one used ""col2"" or ""colz2"", the value of `TH1::fMaximum` got modified.; This deviated from the behavior of ""col"" or ""colz"". This is now fixed as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8389).; - When the option SAME (or ""SAMES"") is used with the option COL, the boxes' color; are computing taking the previous plots into account. The range along the Z axis; is imposed by the first plot (the one without option SAME); therefore the order; in which the plots are done is relevant.; - With option BOX on 2D histos with negative content:; - do not draw the empty bins as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8385).; - fix the issue mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-*402).; - When several histogram were drawn on top of each other with the option; `BOX SAME` and if the log scale along Z was on, the plot showed only the; first histogram. This can be reproduce by using the documentation example; illustrating `BOX SAME`and turning the canvas into log scale along Z.; - In TLatex:; - Do not paint the text when the text size is <= 0. This fixes; the problem mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8305); - Do not paint text if the text string is empty.; - From: Sergey Linev: In `TPad::SaveAs` method json file extension is now handled; - Because of some precision issue some data points exactly on the plot limits of; a `TGraph2D` were not drawn (option `P`).; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8447).; - New options for automatic coloring of graphs and histograms. When several; histograms or graphs are painted in the same canvas thanks to the option ""SAME""; via a `THStack` or `TMultigraph` it might be useful to have an easy and automatic; way to choose their color. The simplest way is to pick colors in the current active color; palette. Palette coloring for histogram is activated thanks to the options `PFC`; (Palette Fill Color), `PLC",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:13291,Testability,log,log,13291,"ion.png). - Implement options ""BOX1"", ""BOX2"" and ""BOX3"" for TH3 equivalent of ""LEGO1"", ""LEGO2"" and ""LEGO3""for TH2.; - When a 2d histogram was drawn with option `LEGO1` and white colored, the dark side; of the lego was red instead of gray.; - New option ""0"" to draw TH2Poly. When used with any `COL` options, the empty; bins are not drawn.; - Fix a long pending problem with Z axis drawing when a lego or a surface was drawn; upside-down.; - Add a protection in TLatex when a string has a syntax error. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-7424).; - Implement the automatic placement of the Y axis title. If the title offset is; set to 0:; ~~~ {.cpp}; h->GetYaxis()->SetTitleOffset(0.);; ~~~; the axis title is automatically placed to avoid overlaps with the axis labels.; - Implement the automatic placement of the `TLegend`. A new constructor not; specifying the legend position is available. Only width and height are defined.; - `ChangeLabel` is now available for log axis as well as requested [here](https://sft.its.cern.ch/jira/browse/ROOT-8537).; - The `TGraph` copy constructor also copy the underlying `TH1F` if it exists (it; holds the axis titles).; - `TGraph` axis range was computed differently depending on the order of SetLog[x|y]""; This issue was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8751); - Add the new markers suggested [here](https://root-forum.cern.ch/t/adding-custom-markers/24506).; Improve the marker style for the OpenGl backend (some where wrong or missing). ![New markers](NewMarkers.png). - Remove a large memory leak in TFITSHDU's GetArrayRow, GetArrayColumn and GetTabRealVectorColumn member functions.; - When `TGraph`s belonging to a `TMultiGraph` were changed (for instance with `SetPoint`); after the `TMultiGraph` was drawn, the `TMultiGraph` range was not recomputed.; This issue was discovered thanks to [this forum post](https://root-forum.cern.ch/t/multi-layer-perceptron/24561/2).; - When a TGraph is drawn, the X",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:18939,Testability,test,tests,18939,"r.GetFile();; TNtuple ntrand(""ntrand"", ""Random Numbers"", ""r"");; fill(ntrand, nEventsPerWorker);; ntrand.Write();; f->Write();; };; ```. ## Language Bindings. - Add in PyROOT the converter for std::string_view; - Fix ROOT-8811: pickling of ROOT.Long now works; - Fix ROOT-8809: push_back on a vector of pointers; - Fix ROOT-8805: itemsize was not set on buffers returned by PyROOT functions. ## JavaScript ROOT. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - rlibmap has been removed; it was deprecated for three years.; - Added the CMake exported ROOT libraries into the ROOT:: namespace. In this way, projects based on CMake using ROOT can avoid; conflicts in library target names. As an example, this is the way to build a project consisting of one library and one; executable using ROOT.; ```; find_package(ROOT REQUIRED); include(${ROOT_USE_FILE}). include_directories(${CMAKE_SOURCE_DIR} ${ROOT_INCLUDE_DIRS}); add_definitions(${ROOT_CXX_FLAGS}). ROOT_GENERATE_DICTIONARY(G__Event Event.h LINKDEF EventLinkDef.h). add_library(Event SHARED Event.cxx G__Event.cxx); target_link_libraries(Event ROOT::Hist ROOT::Tree). add_executable(Main MainEvent.cxx); target_link_libraries(Main Event); ```; - Added option `builtin_all` to enable all the built in options.; - For rootcling_stage1 (formerly known as rootcling_tmp), the package structure was changed to enable homogenous visibility; settings across object files. See core/README for an overview.; - Several non-public headers are not copied into include/ anymore; they reside in the PACKAGE/res/ subdirectory in the source tree.; - The IMT switch is set to on by default.; - A new library is now created, libImt. It contains all classes which depend on TBB. Those classes were previously part of libThread. As a consequence rootcling/genreflex do not depend anymore from TBB even in presence of imt builds.; - Refactoring of several math tests to avoid exact comparisons of floating point numbers; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:1462,Usability,simpl,simply,1462,"i Gheata, CERN/SFT,\; Sergey Linev, GSI, http,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Vassil Vassilev, Fermilab/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.08. ### CINT remnants, dysfunctional for ROOT 6. - `TInterpreter`'s `Getgvp()`, `Getp2f2funcname(void*)`, `Setgvp(Long_t)`, `SetRTLD_NOW()`, `SetRTLD_LAZY()`.; - `SetFCN(void*)` from TVirtualFitter, TFitter, TBackCompFitter, TMinuit; - `TFoam::SetRhoInt(void*)`. ### Core. - The enum constant `TRef::kNotComputed`, `TLink::kObjIsParent` were never used and have been removed.; - The enum constant `TClonesArray::kNoSplit` has not been used since v2.26 and has been removed. ## Interpreter. - Automatic declaration of variables (`h = new TH1F(...)`) is *only* available at the prompt. The side-effects of relying on this in source files is simply too grave. Due to a bug (ROOT-8538), automatically declared variables must currently reside on the top-most scope, i.e. not inside an `if` block etc.; - Improved the stack frame information generated by the JIT. By avoiding interleaving of the memory associated to multiple JIT module, the generation of stack trace involving jitted code and the catching of exception going through jitted code has been repaired.; - Interpreted code is now optimized; `.O 0/1/2/3` can be used to change the optimization level, as well as `#pragma cling optimize`.; - The prompt colors are now much more visible, both on terminals with light and dark background.; - Significant speedup of `TMethodCall`.; - One can now run `.x 12file-with@funny=name.C`; it will expect a function called `_12file_with_funny_name()`. ## Core Libraries. - See ""Build, Configuration and Testing Infrastructure"" below for changes in the directory structure.; - libCling now exports only a minimal set of symbols.;",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:4164,Usability,clear,clearly,4164,"rstanding of the interface. In several cases, the misunderstanding of the interface caused invalid memory accesses to the already destructed; temporary `TString` returned by `GetString()`, e.g. `objStr->GetString().Data()`. This will be fixed automatically by the; new return type. In rare cases, the caller expected `GetString()` to return a (non-const) reference to the embedded `TString`, e.g.; `objString->GetString().ReplaceAll(""a"", ""b""); // WRONG!` This will now fail to compile, instead of not doing what the author of the; code expected. Please fix that code by using the `TObjString::String()` interface, which returns a non-const `TString&`:; `objString->String().ReplaceAll(""a"", ""b"");`. In extremely rare cases, this change breaks a valid use where the temporary `TString` was modified and then captured in a new `TString`; object before the destruction of the temporary: `TString str = objStr->GetString().ReplaceAll(""a"", ""b"");`. In these rare cases,; please use the new function `CopyString()` which clearly indicates that it involves a temporary. ## Histogram Libraries. - New class `THnChain` was added to provide a `TChain`-like experience when; working with `THnBase`'ed histograms (currently `THn` and `THnSparse`) from; many files, see [here](https://sft.its.cern.ch/jira/browse/ROOT-4515). This; allows to e.g., interactively adjust axis parameters before performing; projections from high-dimensional histograms,. ```{.cpp}; // Create a chain of histograms called `h`.; THnChain chain(""h"");. // Add files containing histograms `h` to `chain`.; chain->AddFile(""file1.root"");. chain->GetXaxis(1)->SetRangeUser(0.1, 0.2);. TH1* projection = chain->Projection(0); ```. ## Math Libraries. * Improve thread friendliness of the TMinuit class. ## RooFit Libraries. - Remove deprecated `RooComplex` superseded by `std::complex`. ## TTree Libraries. - `TTreeReader` now supports `TEntryList`s, `Double32_t` / `Float16_t`.; - `TTreeReader::SetLastEntry()` has been deprecated. Its name is mi",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:6234,Usability,intuit,intuitive,6234,"d.; - `TTree::Branch()` now complains for wrong leaf list strings, e.g. ""value/F[4]"" (which should really be spelled as ""value[4]/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for an input TTree; - Snapshot on a rootfile the dataset after cuts and after augmentation with columns created by the user; - Run analyses expressed as chains of actions in parallel in a transparent way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFram",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:6310,Usability,simpl,simply,6310,"/F"").; - Allow reading of older version of TTreePerfStats (ROOT-8520); - In `TTree::OptimizeBaskets()` do not call GetBasket(0) to avoid disc reads; - It is now possible to define the precision of the default histogram created; by `TTree::Draw`. Three new parameters are available in `$ROOTSYS/etcsystem.rootrc`; ```{.cpp}; Hist.Precision.1D: float; Hist.Precision.2D: float; Hist.Precision.3D: float; ```; the default values are `float`. They can be set to `double`.; - Fix ROOT-8742: TTree::SetBranchAddress could not be invoked safely even when dealing with the same tree obtained from the same file opened in different threads.; - TTree::Branch() now complains if a ""name[size]/F"" branch specification is passed wrongly (e.g. as ""name/F[size]""). ### TDataFrame; - Creation of the TDataFrame class. The TDataFrame allows to interact with data; stored in columnar format in a functional and intuitive way in order to perform; data analysis. Parallelism is accessible simply by activating implicit; multi-threading with the ROOT::EnableImplicitMT() function.; In a nutshell, the functionality provided is:; - Create and fill histograms with one single method invocation; - Express filtering of entries with strings, lambdas or functions; - Easy creation of efficiencies of cut-flows; - Possibility to run on ranges of entries; - Creating columns not present in the original dataset; - Chain multiple actions to be executed on the same event loop; - Creation of events on-the-fly (e.g. via Pythia or user-define generator functors), with no need for an input TTree; - Snapshot on a rootfile the dataset after cuts and after augmentation with columns created by the user; - Run analyses expressed as chains of actions in parallel in a transparent way for the user; See [the online documentation](https://root.cern.ch/doc/master/classROOT_1_1Experimental_1_1TDF_1_1TDataFrame.html) for more details. ## 2D Graphics Libraries; - If one used ""col2"" or ""colz2"", the value of `TH1::fMaximum` got modified.; ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:9065,Usability,simpl,simplest,9065," the log scale along Z was on, the plot showed only the; first histogram. This can be reproduce by using the documentation example; illustrating `BOX SAME`and turning the canvas into log scale along Z.; - In TLatex:; - Do not paint the text when the text size is <= 0. This fixes; the problem mentioned [here](https://sft.its.cern.ch/jira/browse/ROOT-8305); - Do not paint text if the text string is empty.; - From: Sergey Linev: In `TPad::SaveAs` method json file extension is now handled; - Because of some precision issue some data points exactly on the plot limits of; a `TGraph2D` were not drawn (option `P`).; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8447).; - New options for automatic coloring of graphs and histograms. When several; histograms or graphs are painted in the same canvas thanks to the option ""SAME""; via a `THStack` or `TMultigraph` it might be useful to have an easy and automatic; way to choose their color. The simplest way is to pick colors in the current active color; palette. Palette coloring for histogram is activated thanks to the options `PFC`; (Palette Fill Color), `PLC` (Palette Line Color) and `AMC` (Palette Marker Color).; When one of these options is given to `TH1::Draw` the histogram get its color; from the current color palette defined by `gStyle->SetPalette()`. The color; is determined according to the number of objects having palette coloring in; the current pad.; - The line width and line style can be change on 2d histograms painted with; option `ARR`.; - When the angle of a TGraphPolar was not in radian, the error bars were misplaced.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8476).; - In `TASimage::DrawLineInternal` the case of a line with 0 pixel along X and 0; pixel along Y was not treated properly. An horizontal line was drawn instead.; - In `TGraphPainter::PaintGrapHist`: Decouple the `P` option (histogram drawn with; a simple polymarker) from the `L` option (Histogram ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:10047,Usability,simpl,simple,10047,"hoose their color. The simplest way is to pick colors in the current active color; palette. Palette coloring for histogram is activated thanks to the options `PFC`; (Palette Fill Color), `PLC` (Palette Line Color) and `AMC` (Palette Marker Color).; When one of these options is given to `TH1::Draw` the histogram get its color; from the current color palette defined by `gStyle->SetPalette()`. The color; is determined according to the number of objects having palette coloring in; the current pad.; - The line width and line style can be change on 2d histograms painted with; option `ARR`.; - When the angle of a TGraphPolar was not in radian, the error bars were misplaced.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8476).; - In `TASimage::DrawLineInternal` the case of a line with 0 pixel along X and 0; pixel along Y was not treated properly. An horizontal line was drawn instead.; - In `TGraphPainter::PaintGrapHist`: Decouple the `P` option (histogram drawn with; a simple polymarker) from the `L` option (Histogram drawn as a simple polyline). This; improved (in some cases some extra markers were drawn) and simplified the code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations of presets and individual options for VIOLIN-charts; * Implementation of VIOLIN-charts in THStack - can be combined with CANDLE; * Update of the docs (THistPainter and THStack); * New tutorials; - In various places in TGraph the underlying histogram was deleted when the graph; range should be recomputed. This has the side effect that some graph parameters; (like t",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:10108,Usability,simpl,simple,10108,"hoose their color. The simplest way is to pick colors in the current active color; palette. Palette coloring for histogram is activated thanks to the options `PFC`; (Palette Fill Color), `PLC` (Palette Line Color) and `AMC` (Palette Marker Color).; When one of these options is given to `TH1::Draw` the histogram get its color; from the current color palette defined by `gStyle->SetPalette()`. The color; is determined according to the number of objects having palette coloring in; the current pad.; - The line width and line style can be change on 2d histograms painted with; option `ARR`.; - When the angle of a TGraphPolar was not in radian, the error bars were misplaced.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8476).; - In `TASimage::DrawLineInternal` the case of a line with 0 pixel along X and 0; pixel along Y was not treated properly. An horizontal line was drawn instead.; - In `TGraphPainter::PaintGrapHist`: Decouple the `P` option (histogram drawn with; a simple polymarker) from the `L` option (Histogram drawn as a simple polyline). This; improved (in some cases some extra markers were drawn) and simplified the code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations of presets and individual options for VIOLIN-charts; * Implementation of VIOLIN-charts in THStack - can be combined with CANDLE; * Update of the docs (THistPainter and THStack); * New tutorials; - In various places in TGraph the underlying histogram was deleted when the graph; range should be recomputed. This has the side effect that some graph parameters; (like t",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md:10191,Usability,simpl,simplified,10191,"activated thanks to the options `PFC`; (Palette Fill Color), `PLC` (Palette Line Color) and `AMC` (Palette Marker Color).; When one of these options is given to `TH1::Draw` the histogram get its color; from the current color palette defined by `gStyle->SetPalette()`. The color; is determined according to the number of objects having palette coloring in; the current pad.; - The line width and line style can be change on 2d histograms painted with; option `ARR`.; - When the angle of a TGraphPolar was not in radian, the error bars were misplaced.; The problem was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-8476).; - In `TASimage::DrawLineInternal` the case of a line with 0 pixel along X and 0; pixel along Y was not treated properly. An horizontal line was drawn instead.; - In `TGraphPainter::PaintGrapHist`: Decouple the `P` option (histogram drawn with; a simple polymarker) from the `L` option (Histogram drawn as a simple polyline). This; improved (in some cases some extra markers were drawn) and simplified the code.; - Candle plot improvements:; * Rearragement of TCandle-code - split into calculate and paint; * Implementation for a ""raw-data candle"" inside TCandle - to be used from TTreeViewer in the future; * Implementation of 1D histograms along each candle (left, right and violin) - to be used for violin-charts; * Implementation of a zero indicator line for TCandle - to be used for violin-charts; * Reimplementation if THistPainter draw option VIOLIN; * Implementations of presets and individual options for VIOLIN-charts; * Implementation of VIOLIN-charts in THStack - can be combined with CANDLE; * Update of the docs (THistPainter and THStack); * New tutorials; - In various places in TGraph the underlying histogram was deleted when the graph; range should be recomputed. This has the side effect that some graph parameters; (like the axis titles) were also deleted. This now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8092).; - ",MatchSource.DOCS,README/ReleaseNotes/v610/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v610/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4204,Availability,avail,available,4204,"ne needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentra",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7343,Availability,avail,available,7343,"n the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7655,Availability,error,error,7655,"); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by set",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8019,Availability,error,error,8019,"rr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8474,Availability,error,error,8474," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8614,Availability,recover,recover,8614," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8731,Availability,redundant,redundant,8731,"T6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirect",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:11644,Availability,avail,available,11644,"features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows t",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18178,Availability,avail,available,18178," objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class cla",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:21981,Availability,error,error,21981,"ces a filled polygon and a line plot.; - `TH1::SetOption()` method didn't work when called from `TH3D` instance.; - With the Cocoa backend on Mac the png image were truncated when ROOT was running; in a small screen attached to the Mac with the graphics window on the Mac; display. It was reported; [here](https://root-forum.cern.ch/t/tcanvas-print-png-outputs-fraction-of-figure-when-canvas-size-is-declared/26011/44).; - Fix an issue with `TGraph2D` drawn as lines (reported [here](https://sft.its.cern.ch/jira/browse/ROOT-9046)).; - ROOT Cocoa: fix rendering into bitmaps on high-dpi display. With retina display; the rendering of polylines was slow.; - Fix a precision issue in `TGraph2D`. It was reported [here](https://root-forum.cern.ch/t/tgraph2d-plotting-issues/26562); - New method `TGraph::InsertPointBefore(Int_t ipoint, Double_t x, Double_t y)`; to insert a new point with coordinates (x,y) before the point number `ipoint`.; - When a 2D histogram was drawn with error bars and has a function in its list; it was impossible to rotate it interactively. This problem was reported; [here](https://root-forum.cern.ch/t/2d-histogram-fit-draws-to-wrong-scale/26369).; - As more and more people are using `TGraph2D` for random cloud of points, the default; drawing option implying Delaunay triangulation was not appropriate. The default; drawing option is now change to `P0`.; - It is now possible to set the value of `MaxDigits` on individual axis as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-35).; For example, to accept 6 digits number like 900000 on the X axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiat",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:30283,Availability,error,error,30283,"; - Use correct painter to check range; - Change proper axis attributes in context menu; - Correctly show axis labels on 3D plot; - Correctly handle circle (marker kind 24) as marker kind; - Correct circle drawing with coordinates rounding; - TLatex #frac and #splitline, adjust vertical position; - Workaround for y range when fMinimum==fMaximum!=-1111; - Correct tooltips for graph with marker drawing; - Support pow(x,n) function in formula; - Use pad.fFillColor for frame when fFrameFillColor==0; - Correctly identify horizontal TGaxis with reverse scale; - Correctly handle negative line width in exclusion; - Tooltips handling for TF1; - Potential mix-up in marker attributes handling; - Unzomming of log scale https://root-forum.cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data read by `TDataFrame`.; - dataframe/tdf013_InspectAnalysis.C shows how to display incremental snapshots of `TDataFrame` analysis results in a `TBrowser`; - dataframe/tdf014_CSVDataSource.C shows reading text-data (comma separated) using a `TDataFrame`; - dataframe/tdf012_DefinesAndFiltersAsStrings.C shows how to use jitted defines and filters by calculating pi; from checking how many randomly generated ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:30351,Availability,error,errors,30351,"; - Use correct painter to check range; - Change proper axis attributes in context menu; - Correctly show axis labels on 3D plot; - Correctly handle circle (marker kind 24) as marker kind; - Correct circle drawing with coordinates rounding; - TLatex #frac and #splitline, adjust vertical position; - Workaround for y range when fMinimum==fMaximum!=-1111; - Correct tooltips for graph with marker drawing; - Support pow(x,n) function in formula; - Use pad.fFillColor for frame when fFrameFillColor==0; - Correctly identify horizontal TGaxis with reverse scale; - Correctly handle negative line width in exclusion; - Tooltips handling for TF1; - Potential mix-up in marker attributes handling; - Unzomming of log scale https://root-forum.cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data read by `TDataFrame`.; - dataframe/tdf013_InspectAnalysis.C shows how to display incremental snapshots of `TDataFrame` analysis results in a `TBrowser`; - dataframe/tdf014_CSVDataSource.C shows reading text-data (comma separated) using a `TDataFrame`; - dataframe/tdf012_DefinesAndFiltersAsStrings.C shows how to use jitted defines and filters by calculating pi; from checking how many randomly generated ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:130,Deployability,release,release,130,"% ROOT Version 6.12 Release Notes; % 2017-05-18. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.12/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dic",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1101,Deployability,release,release,1101,"n 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overload",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1251,Deployability,release,release,1251,"ntributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Oth",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4179,Deployability,update,updated,4179,"ne needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentra",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:5352,Deployability,release,releases,5352,"lved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significa",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6069,Deployability,upgrade,upgraded,6069,"laim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same objec",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6111,Deployability,patch,patches,6111,"ders, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray a",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6861,Deployability,update,update,6861,"n needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7129,Deployability,update,update,7129,"d.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (0000000000000000000000",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7732,Deployability,release,releases,7732,"ile(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12094,Deployability,update,update,12094,"sed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create th",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18686,Deployability,update,updated,18686,"ch uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2D Graphics Libraries; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:32012,Deployability,release,release,32012,"cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data read by `TDataFrame`.; - dataframe/tdf013_InspectAnalysis.C shows how to display incremental snapshots of `TDataFrame` analysis results in a `TBrowser`; - dataframe/tdf014_CSVDataSource.C shows reading text-data (comma separated) using a `TDataFrame`; - dataframe/tdf012_DefinesAndFiltersAsStrings.C shows how to use jitted defines and filters by calculating pi; from checking how many randomly generated points in the unit square fall inside a unit circle; - most `TDataFrame` tutorials are now provided both in C++ and python. ## Command line tools; - `rootls` has been extended.; - option `-l` displays the year; - option `-t` displays all details of 'THnSparse'; - `rootcp` bug fixes ([ROOT-8528](https://sft.its.cern.ch/jira/browse/ROOT-8528)); - Now copies only the latest version of each object instead of copying all; versions in wrong order. ## Class Reference Guide; - The list of libraries needed by each class is displayed as a diagram. ## Build, Configuration and Testing Infrastructure. This is the last release with the configure/make-based build system. It will; be removed; please migrate to the CMake-based build system.; ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:116,Energy Efficiency,schedul,scheduled,116,"% ROOT Version 6.12 Release Notes; % 2017-05-18. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.12/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dic",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6252,Energy Efficiency,reduce,reduces,6252,"OOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* re",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:9157,Energy Efficiency,reduce,reduce,9157,"The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters wi",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12845,Energy Efficiency,adapt,adaptor,12845,"of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17661,Energy Efficiency,power,power-,17661,"ed; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats class",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17682,Energy Efficiency,power,power,17682,"ed; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats class",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17907,Energy Efficiency,power,power-,17907," a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18148,Energy Efficiency,power,power-,18148," objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class cla",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:22954,Energy Efficiency,adapt,adapted,22954,"he point number `ipoint`.; - When a 2D histogram was drawn with error bars and has a function in its list; it was impossible to rotate it interactively. This problem was reported; [here](https://root-forum.cern.ch/t/2d-histogram-fit-draws-to-wrong-scale/26369).; - As more and more people are using `TGraph2D` for random cloud of points, the default; drawing option implying Delaunay triangulation was not appropriate. The default; drawing option is now change to `P0`.; - It is now possible to set the value of `MaxDigits` on individual axis as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-35).; For example, to accept 6 digits number like 900000 on the X axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiation length and nuclear interaction length for mixtures as in Geant4 to have; numeric matching of average properties.; - Added support for reading region definition and production cuts for e+, e-, gamma, p; from GDML files; - Added support for reading/writing parts of the geometry tree to GDML (Markus Frank). ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism; - Fix issue which prevented nested TBB task execution without race conditions, e.g. in TDataFrame; - Fix race condition in TTreeProcessorMT due to TBB nested task execution; - The TTaskGroup class has been added to the ROOT::Experimental namespace. It allows to submit to the runtime; item of work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1345,Integrability,interface,interfaces,1345,"llenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the tra",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1371,Integrability,interface,interfaces,1371,"ne Brun, CERN/SFT,\; Philippe Canal, FNAL,\; David Clark, ANL (SULI),\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Sergey Linev, GSI,\; Timur Pocheptsov, CERN/SFT,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Simon Pfreundschuh,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the transversal of THashList and THashTable container",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4544,Integrability,synchroniz,synchronize,4544,"cts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6443,Integrability,wrap,wrapper,6443,"R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7661,Integrability,message,message,7661,"); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by set",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8025,Integrability,message,message,8025,"rr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8480,Integrability,message,message,8480," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12428,Integrability,interface,interface,12428,"ing slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm,",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12779,Integrability,interface,interface,12779,"of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12914,Integrability,interface,interface,12914,"of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15896,Integrability,interface,interfaces,15896," with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function or an expression. Example: `gaus(x, [A], [m0]*y+[m1], [sigma])`.; - Support for function composition in `TFormula`, i.e. a function can be composed from another function, Again, an example: `gaus( f1(x), [A],[Mean],[Sigma])`, where `f1` is a function defined; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will crea",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17874,Integrability,synchroniz,synchronization,17874,"UM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Libr",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1787,Modifiability,config,configured,1787," Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the transversal of THashList and THashTable containers will; will have to be done without call Hash (and hence be linear rather than; logarithmic complexity). You will also see warnings like; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::H",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:3870,Modifiability,enhance,enhanced,3870,"tead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when reade",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4483,Modifiability,config,configurable,4483,"cts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4532,Modifiability,variab,variable,4532,"cts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:10420,Modifiability,variab,variable,10420,"o launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading s",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12845,Modifiability,adapt,adaptor,12845,"of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:13298,Modifiability,config,configure,13298,"ce interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create histograms with the same parameters of their constructors, for example; ```c++; auto myHisto = myTdf.Histo1D({""histName"", ""histTitle"", 64, 0, 128}, ""myColumn"");; ```; or; ```c++; auto myHistoCustomBinning = myTdf.Histo1D({""histName"", ""histTitle"", 64, binEdges}, ""myColumn"");; ```; Models can be created as stand alone objects:; ```c++; TDF::TH1DModel myModel {""histName"", ""histTitle"", 64, binEdges};; auto myHistoCustomBinning = myTdf.Histo1D(myModel, ""myColumn"");; ```; - pyROOT users can now easily specify parameters for the TDF histograms and profiles thanks to the newly intr",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15335,Modifiability,enhance,enhanced,15335,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:16369,Modifiability,variab,variables,16369,"e; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function or an expression. Example: `gaus(x, [A], [m0]*y+[m1], [sigma])`.; - Support for function composition in `TFormula`, i.e. a function can be composed from another function, Again, an example: `gaus( f1(x), [A],[Mean],[Sigma])`, where `f1` is a function defined; previously.; - Facilitate using Normalized sums of TF1 objects and convolutions, by adding the `NSUM` and `CONV` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:22954,Modifiability,adapt,adapted,22954,"he point number `ipoint`.; - When a 2D histogram was drawn with error bars and has a function in its list; it was impossible to rotate it interactively. This problem was reported; [here](https://root-forum.cern.ch/t/2d-histogram-fit-draws-to-wrong-scale/26369).; - As more and more people are using `TGraph2D` for random cloud of points, the default; drawing option implying Delaunay triangulation was not appropriate. The default; drawing option is now change to `P0`.; - It is now possible to set the value of `MaxDigits` on individual axis as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-35).; For example, to accept 6 digits number like 900000 on the X axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiation length and nuclear interaction length for mixtures as in Geant4 to have; numeric matching of average properties.; - Added support for reading region definition and production cuts for e+, e-, gamma, p; from GDML files; - Added support for reading/writing parts of the geometry tree to GDML (Markus Frank). ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism; - Fix issue which prevented nested TBB task execution without race conditions, e.g. in TDataFrame; - Fix race condition in TTreeProcessorMT due to TBB nested task execution; - The TTaskGroup class has been added to the ROOT::Experimental namespace. It allows to submit to the runtime; item of work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:31566,Modifiability,extend,extended,31566,"cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data read by `TDataFrame`.; - dataframe/tdf013_InspectAnalysis.C shows how to display incremental snapshots of `TDataFrame` analysis results in a `TBrowser`; - dataframe/tdf014_CSVDataSource.C shows reading text-data (comma separated) using a `TDataFrame`; - dataframe/tdf012_DefinesAndFiltersAsStrings.C shows how to use jitted defines and filters by calculating pi; from checking how many randomly generated points in the unit square fall inside a unit circle; - most `TDataFrame` tutorials are now provided both in C++ and python. ## Command line tools; - `rootls` has been extended.; - option `-l` displays the year; - option `-t` displays all details of 'THnSparse'; - `rootcp` bug fixes ([ROOT-8528](https://sft.its.cern.ch/jira/browse/ROOT-8528)); - Now copies only the latest version of each object instead of copying all; versions in wrong order. ## Class Reference Guide; - The list of libraries needed by each class is displayed as a diagram. ## Build, Configuration and Testing Infrastructure. This is the last release with the configure/make-based build system. It will; be removed; please migrate to the CMake-based build system.; ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:32029,Modifiability,config,configure,32029,"cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data read by `TDataFrame`.; - dataframe/tdf013_InspectAnalysis.C shows how to display incremental snapshots of `TDataFrame` analysis results in a `TBrowser`; - dataframe/tdf014_CSVDataSource.C shows reading text-data (comma separated) using a `TDataFrame`; - dataframe/tdf012_DefinesAndFiltersAsStrings.C shows how to use jitted defines and filters by calculating pi; from checking how many randomly generated points in the unit square fall inside a unit circle; - most `TDataFrame` tutorials are now provided both in C++ and python. ## Command line tools; - `rootls` has been extended.; - option `-l` displays the year; - option `-t` displays all details of 'THnSparse'; - `rootcp` bug fixes ([ROOT-8528](https://sft.its.cern.ch/jira/browse/ROOT-8528)); - Now copies only the latest version of each object instead of copying all; versions in wrong order. ## Class Reference Guide; - The list of libraries needed by each class is displayed as a diagram. ## Build, Configuration and Testing Infrastructure. This is the last release with the configure/make-based build system. It will; be removed; please migrate to the CMake-based build system.; ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4314,Performance,race condition,race conditions,4314,"ase classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6333,Performance,concurren,concurrency,6333,"d may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. Thi",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:9364,Performance,queue,queue,9364,"ilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize in",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:9862,Performance,multi-thread,multi-threaded,9862,"eatures;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") -->",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:10110,Performance,load,loaded,10110,"o accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirectory*` that the tree should be constructed in.; Defaults to `gDirectory`, i.e. the default behavior did not change.; - To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced.; This change will prevent additional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allo",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:10978,Performance,cache,cache,10978,"tional reads from occurring when reading events out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:11036,Performance,cache,cached,11036,"out of sequence.; By setting TTree::SetClusterPrefetch(), an entire clusters will be loaded into memory, rather than single baskets.; By setting the MaxVirtualSize of the tree to a negative value, previous clusters will be retained; (the absolute value of MaxVirtualSize indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:11329,Performance,cache,cached,11329,"Size indicates how many additional clusters will be kept in memory).; - Added ```TBranchProxy::GetEntries``` to support leaflist variable size array and added ```TBranchProxy::GetArrayLength```.; - In ```TBranch::Streamer``` insured that we never steam already basket already written to disk. ### TDataFrame. #### New features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See th",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:11405,Performance,multi-thread,multi-threading,11405,"features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows t",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:11530,Performance,multi-thread,multi-threading,11530,"features; - Add `Alias`, a facility to specify an alternative name for a given column: `auto histo = mytdf.Alias(""myAlias"", ""myColumn"").Histo1D(""myAlias"");`. Especially useful for pyROOT users to deal with column names that are not valid C++ identifiers (e.g. `Filter(""1branch > 0"") --> Alias(""1branch"", ""branch1"").Filter(""branch1 > 0"")`.; - Add `Cache`, a facility to cache `TDataFrame`s in memory. All or some columns can be cached. Two versions of the method are proposed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows t",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12032,Performance,multi-thread,multi-thread,12032,"sed: one which allows to explicitly list the types of the columns and another one allowing to let the system infer them (the same mechanism of the `Snapshot` method). Only columns containing instances of classes which have a copy constructor can be cached.; - Add `DefineSlot`, a `Define` transformation that is aware of the multi-threading slot where the workload is executed; - Add `DefineSlotEntry`, a `Define` transformation that is aware of the multi-threading slot and of the current entry number; - Add `GetColumnsNames`: users can now get the names of the available columns coming from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create th",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:13483,Performance,multi-thread,multi-threading,13483,"ce interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create histograms with the same parameters of their constructors, for example; ```c++; auto myHisto = myTdf.Histo1D({""histName"", ""histTitle"", 64, 0, 128}, ""myColumn"");; ```; or; ```c++; auto myHistoCustomBinning = myTdf.Histo1D({""histName"", ""histTitle"", 64, binEdges}, ""myColumn"");; ```; Models can be created as stand alone objects:; ```c++; TDF::TH1DModel myModel {""histName"", ""histTitle"", 64, binEdges};; auto myHistoCustomBinning = myTdf.Histo1D(myModel, ""myColumn"");; ```; - pyROOT users can now easily specify parameters for the TDF histograms and profiles thanks to the newly intr",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:14728,Performance,race condition,race condition,14728,"f their constructors, for example; ```c++; auto myHisto = myTdf.Histo1D({""histName"", ""histTitle"", 64, 0, 128}, ""myColumn"");; ```; or; ```c++; auto myHistoCustomBinning = myTdf.Histo1D({""histName"", ""histTitle"", 64, binEdges}, ""myColumn"");; ```; Models can be created as stand alone objects:; ```c++; TDF::TH1DModel myModel {""histName"", ""histTitle"", 64, binEdges};; auto myHistoCustomBinning = myTdf.Histo1D(myModel, ""myColumn"");; ```; - pyROOT users can now easily specify parameters for the TDF histograms and profiles thanks to the newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histog",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:14744,Performance,concurren,concurrent,14744,"f their constructors, for example; ```c++; auto myHisto = myTdf.Histo1D({""histName"", ""histTitle"", 64, 0, 128}, ""myColumn"");; ```; or; ```c++; auto myHistoCustomBinning = myTdf.Histo1D({""histName"", ""histTitle"", 64, binEdges}, ""myColumn"");; ```; Models can be created as stand alone objects:; ```c++; TDF::TH1DModel myModel {""histName"", ""histTitle"", 64, binEdges};; auto myHistoCustomBinning = myTdf.Histo1D(myModel, ""myColumn"");; ```; - pyROOT users can now easily specify parameters for the TDF histograms and profiles thanks to the newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histog",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15124,Performance,perform,performing,15124,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15356,Performance,perform,performance,15356,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:17808,Performance,multi-thread,multi-thread,17808,"` operators for TF1 objects built with formula expressions; - `TF1(""model"", ""NSUM(gaus , expo)"", xmin, xmax)` will create a function composed of a normalized sum of a gaussian and an exponential.; - `TF1(""voigt"", ""CONV(breitwigner, gausn) , -15, 15)` will create a TF1 object made of a convolution between a Breit-Wigner and a Gaussian. ; - `TFormula` supports vectorization. All the `TF1` objected created with a formula expression can have a vectorized signature using `ROOT::Double_v`: `TF1::EvalPar( ROOT::Double_v * x,; double * p)`. The vectorization can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and repla",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18355,Performance,load,loading,18355,"tion can then be used to speed-up fitting. It is not enabled by default, but it can be enabled by callig `TF1::SetVectorized(true)` or using the `""VEC""` option in the; constructor of TF1, when ROOT has been built with VecCore and one vectorization library such as Vc. ; - Added new auto-binning algorithm, referred to as `power-2`, which uses power of 2 bin widths to create bins; that are mergeable. The target use-case is support for auto-binning in multi-process or multi-thread execution,; e.g. `TDataFrame`, without the need of a synchronization point.; The new `power-2` algorithm is activated by setting the new `TH1::kAutoBinPTwo` status bit on the histogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:23485,Performance,race condition,race conditions,23485,"axis as; requested [here](https://sft.its.cern.ch/jira/browse/ROOT-35).; For example, to accept 6 digits number like 900000 on the X axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiation length and nuclear interaction length for mixtures as in Geant4 to have; numeric matching of average properties.; - Added support for reading region definition and production cuts for e+, e-, gamma, p; from GDML files; - Added support for reading/writing parts of the geometry tree to GDML (Markus Frank). ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism; - Fix issue which prevented nested TBB task execution without race conditions, e.g. in TDataFrame; - Fix race condition in TTreeProcessorMT due to TBB nested task execution; - The TTaskGroup class has been added to the ROOT::Experimental namespace. It allows to submit to the runtime; item of work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of specifying the execution policy and without creating a thread but; directly submitting the work to the runtime in order to use the same pool as any other item of work spawned by ROOT.; - The TFuture template has been added to the ROOT::Experimental namespace. It represents a future and is compatible; with the ROOT::Experimental::Async function. It has the same properties of an STL future and can be initialised by; one of these classes. For example, *TFuture<int> = std::async(myfunc,a,b,c);*; - Reintroduced greedy reduction in TProc",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:23528,Performance,race condition,race condition,23528,"axis of the; histogram `h` call:; ```{.cpp}; h->GetXaxis()->SetMaxDigits(6);; ```; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries; - Added system of units and physical constants matching the CLHEP port to Geant4, adapted to ROOT by Marko Petric.; - Computing radiation length and nuclear interaction length for mixtures as in Geant4 to have; numeric matching of average properties.; - Added support for reading region definition and production cuts for e+, e-, gamma, p; from GDML files; - Added support for reading/writing parts of the geometry tree to GDML (Markus Frank). ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## Parallelism; - Fix issue which prevented nested TBB task execution without race conditions, e.g. in TDataFrame; - Fix race condition in TTreeProcessorMT due to TBB nested task execution; - The TTaskGroup class has been added to the ROOT::Experimental namespace. It allows to submit to the runtime; item of work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of specifying the execution policy and without creating a thread but; directly submitting the work to the runtime in order to use the same pool as any other item of work spawned by ROOT.; - The TFuture template has been added to the ROOT::Experimental namespace. It represents a future and is compatible; with the ROOT::Experimental::Async function. It has the same properties of an STL future and can be initialised by; one of these classes. For example, *TFuture<int> = std::async(myfunc,a,b,c);*; - Reintroduced greedy reduction in TProcessExecutor.; - Fix empty chunks in the result vector of TThreadExecutor::Map. If the integer partition of the data in nChunks causes ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:1771,Safety,safe,safety,1771," Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Arthur Tsang, CERN/SFT, \; Peter van Gemmeren, ANL,\; Vassil Vassilev, Princeton Univ./CMS,\; Xavier Valls Pla, CERN/UJI, \; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, KIT,\; Omar Zapata. ## General News. This release now supports building with C++17 enabled using either libstdc++ or; libc++. This requires Clang >= 5.0, or GCC >= 7.3.0. At the date of this; release, GCC 7.2.0 still does not provide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the transversal of THashList and THashTable containers will; will have to be done without call Hash (and hence be linear rather than; logarithmic complexity). You will also see warnings like; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::H",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:3387,Safety,avoid,avoid,3387,"thout call Hash (and hence be linear rather than; logarithmic complexity). You will also see warnings like; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::Hash and RecursiveRemove, for example THashTable, the container uses ```TObject::CheckedHash()``` instead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock`",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:3524,Safety,safe,safe,3524,"; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::Hash and RecursiveRemove, for example THashTable, the container uses ```TObject::CheckedHash()``` instead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condit",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:4293,Safety,safe,safety,4293,"ssingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInt",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:5670,Safety,safe,safe,5670,"s the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when readers come and go but there is no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:5779,Safety,safe,safe,5779,"s no writer. In that case, readers will not pay the price of taking the internal lock.; Moreover, this RW lock tries to be fair with writers, giving them the possibility to claim the lock and wait for only the remaining readers, thus preventing starvation. - Switched the ROOT global to be a ```ROOT::TReentrantRWLock``` and renamed it ROOT::gCoreMutex. The old name ```gROOTMutex``` and ```gInterpreterMutex``` are deprecated and may be removed in future releases.; - Added ```TReadLockGuard```,```TWriteLockGuard```, ```R__READ_LOCKGUARD``` and```R__WRITE_LOCKGUARD``` to take advantage of the new lock. The legacy ```TLockGuard``` and ```R__LOCKGUARD``` use the write lock.; - Improved scaling of TROOT::RecursiveRemove in the case of large collection.; - Added a thread safe mode for the following ROOT collections: THashList, THashTable, TList and TObjArray. When ROOT's thread safe mode is enabled and the collection is set to use internal locks by calling:; ```; collection->UseRWLock();; ```; all operations on the collection will take the read or write lock when needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:6997,Safety,detect,detected,6997,"n needed, currently they shared the global lock (ROOT::gCoreMutex). ### Interpreter. - cling's LLVM is upgraded to version 5.0; - All of cling's patches to llvm have been upstreamed.; - The interpreter-related lock is now locking only the compilation step, not the execution step. This reduces the scope for lock contention. Most significantly, it enables the use of concurrency on the prompt!. ## I/O Libraries. - Introduce TKey::ReadObject<typeName>. This is a user friendly wrapper around ReadObjectAny. For example; ```; auto h1 = key->ReadObject<TH1>; ```; after which h1 will either be null if the key contains something that is not a TH1 (or derived class); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8614,Safety,recover,recover,8614," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8731,Safety,redund,redundant,8731,"T6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolved O(N^2) scaling problem in ```TTree::Draw()``` observed when a branch that contains a; large TClonesArray where each element contains another small vector container.; - `TTree::TTree()` now takes the `TDirect",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15117,Safety,avoid,avoids,15117,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:24714,Safety,avoid,avoid,24714,"work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of specifying the execution policy and without creating a thread but; directly submitting the work to the runtime in order to use the same pool as any other item of work spawned by ROOT.; - The TFuture template has been added to the ROOT::Experimental namespace. It represents a future and is compatible; with the ROOT::Experimental::Async function. It has the same properties of an STL future and can be initialised by; one of these classes. For example, *TFuture<int> = std::async(myfunc,a,b,c);*; - Reintroduced greedy reduction in TProcessExecutor.; - Fix empty chunks in the result vector of TThreadExecutor::Map. If the integer partition of the data in nChunks causes the existence of empty chunks (e.g therounded updivision of 12 elements in 5 chunks), the number of chunks is decreased to avoid empty chunks and, as a consequence, accesses to uninitialized memory in the reduction step. ## Language Bindings; - PyROOT now supports list initialisation with tuples. For example, suppose to have a function `void f(const TH1F& h)`. In C++, this can be invoked with this syntax: `f({""name"", ""title"", 64, -4, 4})`. In PyROOT this translates too `f(('name', 'title', 64, -4, 4))`. ## JavaScript ROOT. Upgrade JSROOT to v5.3.1. Following new features implemented:. - New supported classes:; - TGraphPolar; - TGraphTime; - TSpline3; - TSpline5; - TPolyLine3D; - TPolyMarker; - TEfficiency; - TH1K; - New supported options:; * ""PFC"" - auto fill color (histograms and graphs); * ""PLC"" - auto line color; * ""PMC"" - auto marker color; * ""A"" - fully disables axes drawing for histograms painters; * ""TEXT"" - for TH2Poly; * ""SAMES"" - draw stat box for superimposed histograms; * ""NOCOL"" - ignore stored in the TCanvas colors list; * ""NOPAL"" - ignore stored in the TCanvas color palette; - Improvements in e",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:13476,Security,access,access,13476,"ce interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings containing multiple C++ expressions, e.g. ""static int a = 0; return ++a"". Especially useful for pyROOT users.; - Histograms can be initialised by *models*, which allow to create histograms with the same parameters of their constructors, for example; ```c++; auto myHisto = myTdf.Histo1D({""histName"", ""histTitle"", 64, 0, 128}, ""myColumn"");; ```; or; ```c++; auto myHistoCustomBinning = myTdf.Histo1D({""histName"", ""histTitle"", 64, binEdges}, ""myColumn"");; ```; Models can be created as stand alone objects:; ```c++; TDF::TH1DModel myModel {""histName"", ""histTitle"", 64, binEdges};; auto myHistoCustomBinning = myTdf.Histo1D(myModel, ""myColumn"");; ```; - pyROOT users can now easily specify parameters for the TDF histograms and profiles thanks to the newly intr",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:18997,Security,validat,validation,18997,istogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2D Graphics Libraries; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to retrieve a color.; - Improvements in candle plots:; - LogZ for violins; - scaling of candles and violins with respect to each other; - static functions for WhiskerRange and BoxRange; - In some case it was not possible to zoom a 1D histogram using the mouse; on the X axis. This was described; [here](https://root-forum.cer,MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:24756,Security,access,accesses,24756,"work which are dealt with in parallel;; - The Async template function has been added the ROOT::Experimental namespace. The template function is analogous; to *std::async* but without the possibility of specifying the execution policy and without creating a thread but; directly submitting the work to the runtime in order to use the same pool as any other item of work spawned by ROOT.; - The TFuture template has been added to the ROOT::Experimental namespace. It represents a future and is compatible; with the ROOT::Experimental::Async function. It has the same properties of an STL future and can be initialised by; one of these classes. For example, *TFuture<int> = std::async(myfunc,a,b,c);*; - Reintroduced greedy reduction in TProcessExecutor.; - Fix empty chunks in the result vector of TThreadExecutor::Map. If the integer partition of the data in nChunks causes the existence of empty chunks (e.g therounded updivision of 12 elements in 5 chunks), the number of chunks is decreased to avoid empty chunks and, as a consequence, accesses to uninitialized memory in the reduction step. ## Language Bindings; - PyROOT now supports list initialisation with tuples. For example, suppose to have a function `void f(const TH1F& h)`. In C++, this can be invoked with this syntax: `f({""name"", ""title"", 64, -4, 4})`. In PyROOT this translates too `f(('name', 'title', 64, -4, 4))`. ## JavaScript ROOT. Upgrade JSROOT to v5.3.1. Following new features implemented:. - New supported classes:; - TGraphPolar; - TGraphTime; - TSpline3; - TSpline5; - TPolyLine3D; - TPolyMarker; - TEfficiency; - TH1K; - New supported options:; * ""PFC"" - auto fill color (histograms and graphs); * ""PLC"" - auto line color; * ""PMC"" - auto marker color; * ""A"" - fully disables axes drawing for histograms painters; * ""TEXT"" - for TH2Poly; * ""SAMES"" - draw stat box for superimposed histograms; * ""NOCOL"" - ignore stored in the TCanvas colors list; * ""NOPAL"" - ignore stored in the TCanvas color palette; - Improvements in e",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:2472,Testability,log,logarithmic,2472,"rovide full support to compile ROOT with C++17. ## Removed interfaces. The following interfaces have been removed, after deprecation in v6.10. - Remove the deprecated `TSelectorCint.h` and `TSelectorCint.cxx`.; - Remove the deprecated `Riosfwd.h` and `Rtypeinfo.h`.; - `TTreeReader::SetLastEntry()` was replaced by `TTreeReader::SetEntriesRange()`. ## Core Libraries. - Added support for XCode 9 and MacOS High Sierra.; - When invoking root with the ""-t"" argument, ROOT enables thread-safety and,; if configured, implicit multithreading within ROOT.; - `NULL` is not defined by `Rtypes.h` anymore. Instead, its definition is expected to be; provided by `Rtype.h`'s `#include` of `stddef.h`.; - ROOT now supports dictionaries, autoload and autoparse for classes with template parameter packs.; - std::make_unique has been backported; - If a class overloads TObject::Hash, this derived class should also add; ```; ROOT::CallRecursiveRemoveIfNeeded(*this); ```; Otherwise, when RecursiveRemove is called (by ~TObject or example) for this; type of object, the transversal of THashList and THashTable containers will; will have to be done without call Hash (and hence be linear rather than; logarithmic complexity). You will also see warnings like; ```; Error in <ROOT::Internal::TCheckHashRecursiveRemoveConsistency::CheckRecursiveRemove>: The class SomeName overrides TObject::Hash but does not call TROOT::RecursiveRemove in its destructor.; ```; - When a container relies on TObject::Hash and RecursiveRemove, for example THashTable, the container uses ```TObject::CheckedHash()``` instead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::Ge",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:8442,Testability,log,logic,8442," version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by setting it to zero; ```. - Added an experimental feature that allows the IO libraries to skip writing out redundant information for some split classes, resulting in disk space savings. This is disabled by default and may be enabled by setting:. ```; ROOT::TIOFeatures features;; features.Set(ROOT::Experimental::EIOFeatures::kGenerateOffsetMap);; ttree_ref.SetIOFeatures(features);; ```; - Added `GetAutoSave()` and `SetAutoSave()` methods to `TBufferMerger`, to allow; it to accumulate several buffers in memory before merging, to reduce the; amount of compression work done due to `TTree` metadata. - Added a non-blocking callback mechanism to `TBufferMerger` to allow users to; control the rate at which data is pushed into the merging queue. The callback; mechanism can be used, for example, to launch tasks asynchronously whenever a; buffer is done processing. ## TTree Libraries. - Resolv",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12716,Testability,test,testing,12716," from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:15455,Testability,test,tests,15455,"newly introduced tuple-initialization; ```python; myHisto = myTdf.Histo1D(('histName', 'histTitle', 64, 0, 128), 'myColumn'); ```; - Add support for friend trees and chains. Just add the friends before passing the tree/chain to TDataFrame's constructor and refer to friend branches as usual. #### Fixes; - Fixed race condition: concurrent deletion of TTreeReader/TTreeReaderValue; - Fixed reading of c-style arrays from jitted transformations and actions; - Fixed writing of c-style arrays with `Snapshot`; - Improved checks for column name validity (throw if column does not exist and if `Define`d column overrides an already existing column). #### Other changes; - Improved documentation; - TDF now avoids performing virtual calls for parts of the analysis that are not jitted; - Removed ""custom column"" nodes from the internal functional graph therewith optimising its traversal; - Improvements in Cling drastically enhanced scaling and performance of TDF jitted code; - Test coverage has been increased with the introduction of google tests; - Interface change: users must now use TDF::TArrayBranch rather than std::array\_view to specify that the column being read is a c-style array TTree branch; - Interface change: `Min` and `Max` now return results as the same type specified as template parameter, or double if no template parameter was specified. ## Histogram Libraries; - Histogram-based fits are implicitly parallelized.; - Added new options to the histogram fitting interfaces to support explicit parallelization of the fit as well.; - `TF1` gradient evaluation supports vectorization.; - Refactor of `TF1` constructors, default initialization of its data members and fixed ambiguous TF1::operator().; - Extend `TFormula` parsing capabilities.; - The parsing of arguments for defining parametric function is improved. For example a Gaussian function in y can be defined as `gaus( y , [A], [Mean], [Sigma])`.; - One can define the function variables or parameters using another function o",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:19045,Testability,test,test,19045,istogram.; The tutorial `tutorials/multicore/mt304_fillHistos.C` gives an example of how to use the functionality with; `TThreadedObject<TH1D>` . The `power-2` binning is currently available only for 1D histograms. ## Math Libraries; - The Fitting functions now support vectorization and parallelization.; - Added padding in the fit data classes for correct loading of SIMD arrays. ## RooFit Libraries. - Apply several fixes from the ATLAS Higgs combination branch of RooFit. These fixes include; - fix for computing the contraint normalization. This requires now the option GlobalObservables when creating the NLL.; - All the `RooAbsPdf::createNLL` used in The RooStats classes have been updated to include the `GlobalObservables` option.; - Remove the `Roo1DMomentMorphFunction` and replace it with `RooMomentMorphFunction` and `RooMomentMorphFunctionND`. ## TMVA Library. - Improvement and fixes in ROCCurve class.; - Add support for event weights in the DNN; - Add in the DNN the option to use a validation data set independent of the training/test set used for training the DNN.; - Add option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2D Graphics Libraries; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to retrieve a color.; - Improvements in candle plots:; - LogZ for violins; - scaling of candles and violins with respect to each other; - static functions for WhiskerRange and BoxRange; - In some case it was not possible to zoom a 1D histogram using the mouse; on the X axis. This was described; [here](https://root-forum.cer,MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:20107,Testability,log,log,20107,"d option to suppress correlation outputs; - Improvements in the support for multi-class classification.; - Improvements in the Gradient Boostig Trees; - Deprecate the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2D Graphics Libraries; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to retrieve a color.; - Improvements in candle plots:; - LogZ for violins; - scaling of candles and violins with respect to each other; - static functions for WhiskerRange and BoxRange; - In some case it was not possible to zoom a 1D histogram using the mouse; on the X axis. This was described; [here](https://root-forum.cern.ch/t/axis-blocked-when-overlaying-two-histograms/25326); - When drawing an histogram with option ""BOX"" with log scale along the Z axis; the bins were not visible in some case. This was described; [here](https://root-forum.cern.ch/t/set-logscale-on-z-axis-in-2d-histo/25385).; - When a TGraph2D was plotted with the option ""PCOLZ"" with a log scale along the; Z axis, there was a mismatch between the markers' colors and the color palette; displayed. It is now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8200).; - It is now possible to set the titles and the axis ranges of a TMultiGraph drawn as 3D lines.; - Implement the option ""Z"" (to draw the palette) for 3D histograms drawn with; the option ""BOX2"".; - With the option `HBAR` the histogram grid was painted over the stat box.; - The `TGraph`'s options ""F"" and ""L"" respectively draw a filled polygon and; a line plot. They can be combined when calling `TGraph::Draw`. Doing that; produced a filled polygon only. Now it produces a filled polygon and a line plot.; - `TH1::SetOption()` method didn't work whe",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:20235,Testability,log,logscale-on-z-axis-in-,20235,"the TMVA DNN Reference Implementation. Support now only CPU and GPU implementations. . ## 2D Graphics Libraries; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to retrieve a color.; - Improvements in candle plots:; - LogZ for violins; - scaling of candles and violins with respect to each other; - static functions for WhiskerRange and BoxRange; - In some case it was not possible to zoom a 1D histogram using the mouse; on the X axis. This was described; [here](https://root-forum.cern.ch/t/axis-blocked-when-overlaying-two-histograms/25326); - When drawing an histogram with option ""BOX"" with log scale along the Z axis; the bins were not visible in some case. This was described; [here](https://root-forum.cern.ch/t/set-logscale-on-z-axis-in-2d-histo/25385).; - When a TGraph2D was plotted with the option ""PCOLZ"" with a log scale along the; Z axis, there was a mismatch between the markers' colors and the color palette; displayed. It is now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8200).; - It is now possible to set the titles and the axis ranges of a TMultiGraph drawn as 3D lines.; - Implement the option ""Z"" (to draw the palette) for 3D histograms drawn with; the option ""BOX2"".; - With the option `HBAR` the histogram grid was painted over the stat box.; - The `TGraph`'s options ""F"" and ""L"" respectively draw a filled polygon and; a line plot. They can be combined when calling `TGraph::Draw`. Doing that; produced a filled polygon only. Now it produces a filled polygon and a line plot.; - `TH1::SetOption()` method didn't work when called from `TH3D` instance.; - With the Cocoa backend on Mac the png image were truncated when ROOT was running; in a small screen attached to the Mac with the ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:20336,Testability,log,log,20336,"; - The method TColor::InvertPalette inverts the current palette. The top color becomes; bottom and vice versa. This was [suggested by Karl Smith](https://root-forum.cern.ch/t/inverted-color-palettes/24826/2).; - New method `TColor::SetColorThreshold(Float_t t)` to specify the color; threshold used by GetColor to retrieve a color.; - Improvements in candle plots:; - LogZ for violins; - scaling of candles and violins with respect to each other; - static functions for WhiskerRange and BoxRange; - In some case it was not possible to zoom a 1D histogram using the mouse; on the X axis. This was described; [here](https://root-forum.cern.ch/t/axis-blocked-when-overlaying-two-histograms/25326); - When drawing an histogram with option ""BOX"" with log scale along the Z axis; the bins were not visible in some case. This was described; [here](https://root-forum.cern.ch/t/set-logscale-on-z-axis-in-2d-histo/25385).; - When a TGraph2D was plotted with the option ""PCOLZ"" with a log scale along the; Z axis, there was a mismatch between the markers' colors and the color palette; displayed. It is now fixed. It was reported; [here](https://sft.its.cern.ch/jira/browse/ROOT-8200).; - It is now possible to set the titles and the axis ranges of a TMultiGraph drawn as 3D lines.; - Implement the option ""Z"" (to draw the palette) for 3D histograms drawn with; the option ""BOX2"".; - With the option `HBAR` the histogram grid was painted over the stat box.; - The `TGraph`'s options ""F"" and ""L"" respectively draw a filled polygon and; a line plot. They can be combined when calling `TGraph::Draw`. Doing that; produced a filled polygon only. Now it produces a filled polygon and a line plot.; - `TH1::SetOption()` method didn't work when called from `TH3D` instance.; - With the Cocoa backend on Mac the png image were truncated when ROOT was running; in a small screen attached to the Mac with the graphics window on the Mac; display. It was reported; [here](https://root-forum.cern.ch/t/tcanvas-print-png-ou",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:30105,Testability,log,log,30105,"tly faster.; - When creating image in SVG format, correctly convert url(""#id"") references. Bugfixes:; - Show TH2 projections also when tooltip is disabled; - use z_handle to format Z-axis labels; - Support labels on TH3 Z axis; - TH1 zooming in 3D mode; - Suppress empty {} in TLatex; - Add several math symbols for TLatex; - Font kind 1 is italic times roman; - Do not let expand parent item in hierarchy; - Use correct painter to check range; - Change proper axis attributes in context menu; - Correctly show axis labels on 3D plot; - Correctly handle circle (marker kind 24) as marker kind; - Correct circle drawing with coordinates rounding; - TLatex #frac and #splitline, adjust vertical position; - Workaround for y range when fMinimum==fMaximum!=-1111; - Correct tooltips for graph with marker drawing; - Support pow(x,n) function in formula; - Use pad.fFillColor for frame when fFrameFillColor==0; - Correctly identify horizontal TGaxis with reverse scale; - Correctly handle negative line width in exclusion; - Tooltips handling for TF1; - Potential mix-up in marker attributes handling; - Unzomming of log scale https://root-forum.cern.ch/t/25889; - Ignore not-supported options in TMultiGraph https://root-forum.cern.ch/t/25888; - Correctly use fGridColor from TStyle; - Prevent error when TPaveText includes TLine or TBox in list of lines; - Bin errors calculations in TProfile; - Correctly handle new TF1 parameter coding convention (jsroot#132); - Check if pad name can be used as element id (jsroot#133); - Adjust title position for vertical axis with fTitleOffset==0. ## Tutorials. - xml/xmlreadfile.C shows how to read and parse any xml file, supported by TXMLEngine class.; - fit/fitNormSum.C shows building of vectorized function and fitting with TF1.; - multicore/mt303_AsyncSimple.C explains uses of `Async()` and `TFuture`.; - multicore/mt304_fillHistos.C shows the new auto-binning mechanism.; - graphs/timeSeriesFromCSV_TDF.C illustrates a time axis on a TGraph with text-data ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:7649,Usability,clear,clear,7649,"); or will be set to the address of the histogram read from the file.; - Add the ability to store the 'same' object several time (assumingly with different data) in a single buffer. Instead of. ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer << arr;; }; ```; which would only really stream the array at the first iteration because it will be detected has having the same address and thus assumed to be the same object. We can now do:; ```; while(...) {; TObjArray arr;; ... update the content of ""arr""; buffer.WriteObject(&arr, kFALSE);; }; ```; where the last argument of WriteObject tells the buffer do *not* remember this object's address and to always stream it. This feature is also available via WriteObjectAny. - Added a new mechanism for providing clean forward-compatibility breaks in a ``TTree`` (i.e., a newer version of ROOT writes a ``TTree`` an older version cannot read). When future versions of ROOT utilize an IO feature that this version does not support, ROOT will provide a clear error message instead of crashing or returning garbage data. In future ROOT6 releases, forward-compatibility breaks will only be allowed if a non-default feature is enabled via the ``ROOT::Experimental`` namespace; it is expected ROOT7 will enable forward-compatibility breaks by default. - When a file using an unsupported file format feature is encountered, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fIOBits (00000000000000000000000001111110) contains unknown flags (supported flags are 00000000000000000000000000000001), indicating this was written with a newer version of ROOT utilizing critical IO features this version of ROOT does not support. Refusing to deserialize.; ```; - When an older version of ROOT, without this logic, encounters the file, the error message will be similar to the following:; ```; Error in <TBasket::Streamer>: The value of fNevBufSize is incorrect (-72) ; trying to recover by set",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:12686,Usability,simpl,simple,12686," from trees, data sources or `Define`d columns; - Add `OnPartialResult` and `OnPartialResultSlot`: users can now register one or more functions to be executed on partial results of TDF actions during the event loop.; This mechanism is meant to be used to inspect partial results of the analysis or print useful debug information.; For example, both in single- and multi-thread event loops, one can draw a result histogram and update the canvas every 100 entries like this:; ```c++; auto h = tdf.Histo1D(""x"");; TCanvas c(""c"",""x hist"");; h.OnPartialResult(100, [&c](TH1D &h_) { c.cd(); h_.Draw(); c.Update(); });; ```; See the tutorials for more examples.; - Add `Sum`, an action that sums all values of a column for the processed entries; - The new TDataSource interface allows developers to pipe any kind of columnar data format into TDataFrame. Two example data sources have been provided: the TRootDS and the TTrivialDS. The former allows to read via the novel data source mechanism ROOT data, while the latter is a simple generator, created for testing and didactic purposes. It is therefore now possible to interface *any* kind of dataset/data format to ROOT as long as an adaptor which implements the pure virtual methods of the TDataSource interface can be written in C++.; - TDF can now read CSV files through a specialized TDataSource. Just create the TDF with `MakeCsvDataFrame(""f.csv"")`. Just create the TDF with MakeCsvDataFrame(""f.csv""). The data types of the CSV columns are automatically inferred. You can also specify if you want to use a different delimiter or if your file does not have headers.; - Users can now configure Snapshot to use different file open modes (""RECREATE"" or ""UPDATE""), compression level, compression algorithm, TTree split-level and autoflush settings; - Users can now access multi-threading slot and entry number as pre-defined columns ""tdfslot_"" and ""tdfentry_"". Especially useful for pyROOT users.; - Users can now specify filters and definitions as strings ",MatchSource.DOCS,README/ReleaseNotes/v612/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1755,Availability,redundant,redundant,1755,"kers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialExecutor in ROOT, sharing the interfaces of TExecutor.This should improve code economy when providing a fallback for TThreadExecutor/TProcessExecutor. ### Thread safety; - Resolved several race conditions, dead-locks, performance and order of initialization/destruction issues still lingering because of or despite the new read-write lock mechanism. ## Interpreter. - Enabled use of multi-thre",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:4632,Availability,robust,robustness,4632," ratio comparing to ZLIB); - If two or more files have an identical streamer info record, this is only treated once therewith avoiding to take the global lock.; - Allow writing temporary objects (with same address) in the same TBuffer(s). A new flag to TBuffer*::WriteObject allows to skip the mechanism that prevent the 2nd streaming of an object. This allows the (re)use of temporary objects to store different data in the same buffer.; - Reuse branch proxies internally used by TTreeReader{Value,Array} therewith increasing performance when having multiple readers pointing to the same branch.; - Implement reading of objects data from JSON; - Provide TBufferJSON::ToJSON() and TBufferJSON::FromJSON() methods; - Provide TBufferXML::ToXML() and TBufferXML::FromXML() methods; - Converts NaN and Infinity values into null in JSON, there are no other direct equivalent. ## TTree Libraries; - Enable the TTreeCache by default of `TTree::Draw`, `TTreeReader` and `RDataFrame`; - Significant enhancement in the `TTreeCache` filling algorithm to increase robustness in case of oddly clustered `TTree` and under provisioned cache size. See the [merge request](https://github.com/root-project/root/pull/1960) for more details.; - Proxies are now properly re-used when multiple TTreeReader{Value,Array}s are associated to a single branch. Deserialisation is therefore performed once. This is an advantage for complex TDataFrame graphs.; - Add TBranch::BackFill to allow the addition of new branches to an existing tree and keep the new basket clustered in the same way as the rest of the TTree. Use with the following pattern,; make sure to to call BackFill for the same entry for all the branches consecutively:; ```; for(auto e = 0; e < tree->GetEntries(); ++e) { // loop over entries.; for(auto branch : branchCollection) {; ... Make change to the data associated with the branch ...; branch->BackFill();; }; }; ```; Since we loop over all the branches for each new entry all the baskets for a cluster ar",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:7819,Availability,avail,available,7819,"f`.; - Histograms and profiles returned by RDataFrame (e.g. by a Histo1D action) are now not associated to a ROOT directory (their fDirectory is a nullptr).; The following still works as expected:; ```; auto h = tdf.Histo1D(""x"");; TFile f(fname, ""RECREATE"");; h->Write(); // event loop is run here and h is written to the TFile f; ```. #### New features; - The TDataSource interface changed. The `TDataSource::SetEntry` method now returns a boolean. If true the entry is processed within the event loop managed by the tdf, skipped otherwise.; - The TLazyDS data source has been added. It allows to create a source starting from ResultProxies to vectors.; - `TDataFrameInterface<T>::Report` returns a `TCutflowReport` object which can be inspected programmatically.; - Add `Aggregate` action and implement `Reduce` in terms of it.; - Add support for a more general leafname syntax that includes pathnames with multiple dots, such as ""myBranch.mySubBranch.myLeaf"". This is available both for jitted expressions and for lists of column names.; - The CSV data source (TCsvDS) can now be constructed with a chunk size parameter, and as a result the CSV file will be read progressively, in chunks of the specified size. This can be used to prevent the whole CSV file from being read into memory at once, thus reducing the memory footprint of this data source.; - Add the `ROOT::Experimental::TAdoptAllocator<T>`, an allocator which allows to adopt existing memory. If memory is adopted, upon allocation a copy is performed in the new, potentially more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and ",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:9108,Availability,avail,available,9108,"f this data source.; - Add the `ROOT::Experimental::TAdoptAllocator<T>`, an allocator which allows to adopt existing memory. If memory is adopted, upon allocation a copy is performed in the new, potentially more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and scalars and TVecs are supported. Most popular math functions which act on TVecs are provided. Helpers to calculate basic quantities such as sum, mean, variance or standard deviation of TVecs are provided.; A powerful and concise syntax for expressing cuts is available:; ```; // mu_pts_tvec and mu_etas_tvec are two equally sized TVecs holding kinematic properties of muons; // a filter on muons pseudorapidities is applied considering a range in pseudo rapidity.; filtered_mu_pts_tvec = mu_pts_tvec[abs(mu_etas_tvec) < 2)];; ```; - The `TArrayBranch` class has been removed and replaced by the more powerful `TVec`.; - Columns on disk stored as C arrays should be read as `TVec`s, `std::vector` columns can be read as `TVec`s if requested. Jitted transformations and actions consider `std::vector` columns as well as C array columns `TVec`s.; - In jitted transformations and actions, `std::vector` and C array columns are read as `TVec`s.; - When snapshotting, columns read from trees which are of type `std::vector` or C array and read as TVecs are persistified on disk as a `std::vector` or C arrays respectively - no transformation happens. `TVec` columns, for example coming from `Define`s, are written as `std::vector<T, TAdoptAllocator<T>>`. #### Fixes; - Do not alphabetically order columns before snapshotting to avoid issues",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:12799,Availability,error,errors,12799,"luding support for Multi-Process cross-validation running. . ## 2D Graphics Libraries; - `TMultiGraph::GetHistogram` now works even if the multigraph is not drawn. Make sure; it never returns a null pointer.; - X11 line `width = 0` doesn't work on OpenSuSE Thumbleweed for non solid lines. Now fixed.; - TCanvas::SetWindowsSize has been changed to get the same window size in interactive modeand batch mode.; - Change the `TGraph` default fill color to white to avoid black box in legend; when `gPad->BuildLegend()` is called.; - Auto-coloring for TF1 (drawing options PFC, PLC and PMC) is implemented.; - Auto-coloring for TH1::DrawCopy (drawing options PFC, PLC and PMC) is implemented.; - Improve the option management in `TF1::Draw` to allow to combine the option; `SAME` with other drawing options.; - `TGraph::Draw(""AB"")` was malfunctioning when using `TAxis::SetRangeUser`.; It was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-9144).; - The errors end-caps size in `TLegend` follows the value set by `gStyle->SetEndErrorSize()`.; For instance setting it to 0 allows to remove the end-caps both on the graph and the legend.; It was requested [here](https://sft.its.cern.ch/jira/browse/ROOT-9184); - New color palette ""cividis"" implemented by Sven Augustin.; This colormap aims to solve problems that people with color vision deficiency have; with the common colormaps. For more details see:; Nuez J, Anderton C, and Renslow R. Optimizing colormaps with consideration; for color vision deficiency to enable accurate interpretation of scientific data.; See the article [here](https://arxiv.org/abs/1712.01662); - New graphics style ""ATLAS"" from M.Sutton.; - In `TGraphPainter` the fit parameters were painted too early. [In some cases graph's; error bars overlapped the stat box](https://root-forum.cern.ch/t/hide-error-bars-behind-tpavestats/27996).; - Implement the possibility to generate high definition bitmap pictures in `TImageDump`.; This done via `gStyle->SetImageScaling(x)",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:13600,Availability,error,error,13600,"with other drawing options.; - `TGraph::Draw(""AB"")` was malfunctioning when using `TAxis::SetRangeUser`.; It was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-9144).; - The errors end-caps size in `TLegend` follows the value set by `gStyle->SetEndErrorSize()`.; For instance setting it to 0 allows to remove the end-caps both on the graph and the legend.; It was requested [here](https://sft.its.cern.ch/jira/browse/ROOT-9184); - New color palette ""cividis"" implemented by Sven Augustin.; This colormap aims to solve problems that people with color vision deficiency have; with the common colormaps. For more details see:; Nuez J, Anderton C, and Renslow R. Optimizing colormaps with consideration; for color vision deficiency to enable accurate interpretation of scientific data.; See the article [here](https://arxiv.org/abs/1712.01662); - New graphics style ""ATLAS"" from M.Sutton.; - In `TGraphPainter` the fit parameters were painted too early. [In some cases graph's; error bars overlapped the stat box](https://root-forum.cern.ch/t/hide-error-bars-behind-tpavestats/27996).; - Implement the possibility to generate high definition bitmap pictures in `TImageDump`.; This done via `gStyle->SetImageScaling(x);` `x` being a multiplication factor.; This new feature is now used to generate the reference guide with `x=3`.; Pictures in the reference guide are now much shaper and in particular the text. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries. ## Database Libraries; - Fix issue related to time stamps manipulation done by `TPgSQLStatement` as suggested [here](https://root-forum.cern.ch/t/please-correct-bug-reading-date-time-from-postgresql-tpgsqlstatement). ## Networking Libraries; - New THttpWSHandler class should be used to work with websockets. It includes all necessary methods to handle multiple connections correctly. See in tutorials/http/ws.C how it can be used.; - Interface of THttpWSEn",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:13670,Availability,error,error-bars-behind-tpavestats,13670,"ng when using `TAxis::SetRangeUser`.; It was reported [here](https://sft.its.cern.ch/jira/browse/ROOT-9144).; - The errors end-caps size in `TLegend` follows the value set by `gStyle->SetEndErrorSize()`.; For instance setting it to 0 allows to remove the end-caps both on the graph and the legend.; It was requested [here](https://sft.its.cern.ch/jira/browse/ROOT-9184); - New color palette ""cividis"" implemented by Sven Augustin.; This colormap aims to solve problems that people with color vision deficiency have; with the common colormaps. For more details see:; Nuez J, Anderton C, and Renslow R. Optimizing colormaps with consideration; for color vision deficiency to enable accurate interpretation of scientific data.; See the article [here](https://arxiv.org/abs/1712.01662); - New graphics style ""ATLAS"" from M.Sutton.; - In `TGraphPainter` the fit parameters were painted too early. [In some cases graph's; error bars overlapped the stat box](https://root-forum.cern.ch/t/hide-error-bars-behind-tpavestats/27996).; - Implement the possibility to generate high definition bitmap pictures in `TImageDump`.; This done via `gStyle->SetImageScaling(x);` `x` being a multiplication factor.; This new feature is now used to generate the reference guide with `x=3`.; Pictures in the reference guide are now much shaper and in particular the text. ## 3D Graphics Libraries; - When a LEGO plot was drawn with Theta=90, the X and Y axis were misplaced. ## Geometry Libraries. ## Database Libraries; - Fix issue related to time stamps manipulation done by `TPgSQLStatement` as suggested [here](https://root-forum.cern.ch/t/please-correct-bug-reading-date-time-from-postgresql-tpgsqlstatement). ## Networking Libraries; - New THttpWSHandler class should be used to work with websockets. It includes all necessary methods to handle multiple connections correctly. See in tutorials/http/ws.C how it can be used.; - Interface of THttpWSEngine class was changed, all its instances handled internally in THtt",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:130,Deployability,release,release,130,"% ROOT Version 6.14 Release Notes; % 2017-11-19. <a name=""TopOfPage""></a>. ## Introduction. ROOT version 6.14/00 is scheduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN/EP-ADP-OS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1117,Deployability,update,updated,1117,"eduled for release in 2018. For more information, see:. [http://root.cern.ch](http://root.cern.ch). The following people have contributed to this new version:. Kim Albertsson, CERN/EP-ADP-OS,\; Guilherme Amadio, CERN/SFT,\; Bertrand Bellenot, CERN/SFT,\; Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RString",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1411,Deployability,release,release,1411," Brian Bockelman, UNL,\; Rene Brun, CERN/SFT,\; Philippe Canal, FNAL,\; Olivier Couet, CERN/SFT,\; Gerri Ganis, CERN/SFT,\; Andrei Gheata, CERN/SFT,\; Enrico Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialEx",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1475,Deployability,patch,patch,1475,"co Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialExecutor in ROOT, sharing the interfaces of TExecutor.This should improve code economy when providing a fallback for TThreadExecutor/TProcessExecutor. ### Th",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1502,Deployability,release,releases,1502,"co Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialExecutor in ROOT, sharing the interfaces of TExecutor.This should improve code economy when providing a fallback for TThreadExecutor/TProcessExecutor. ### Th",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:1545,Deployability,release,release,1545,"co Guiraud, CERN/SFT,\; Raphael Isemann, Chalmers Univ. of Tech.,\; Vladimir Ilievski, GSOC 2017,\; Sergey Linev, GSI,\; Pere Mato, CERN/SFT,\; Lorenzo Moneta, CERN/SFT,\; Axel Naumann, CERN/SFT,\; Danilo Piparo, CERN/SFT,\; Fons Rademakers, CERN/SFT,\; Enric Tejedor Saavedra, CERN/SFT,\; Oksana Shadura, UNL,\; Saurav Shekhar, GSOC 2017,\; Xavier Valls Pla, UJI, CERN/SFT,\; Vassil Vassilev, Princeton/CMS,\; Wouter Verkerke, NIKHEF/Atlas, RooFit,\; Stefan Wunsch, CERN/SFT, \; Zhe Zhang, UNL. ## Important Notice. The default compression algorithm used when writing ROOT files has been updated to use LZ4 in particular to improve read (decompression) performance. You can change this default for each file through (for example) the `TFile constructor` or `TFile::SetCompressionAlgorithm`. It should be noted that ROOT files written with LZ4 compression can not be read with older release of ROOT. Support for LZ4 was however back-ported to the patch branches of previous releases and the following tags (and later release in the same patch series) can read ROOT files written with LZ4 compression:. * v5.34/38; * v6.08/06 [not yet released]; * v6.10/08; * v6.12/02. ## Removed interfaces. ## Core Libraries; - Optimize away redundant deserialization of template specializations. This reduces the memory footprint for hsimple by around 30% while improving the runtime performance for various cases by around 15%.; - When ROOT is signaled with a SIGUSR2 (i.e. on Linux and MacOS X) it will now print a backtrace.; - Move RStringView.h to ROOT/RStringView.hxx and always include ROOT/RStringView.hxx instead of RStringView.h for backward compatibility; - In `TClingCallFunc`, support r-value reference parameters. This paves the way for the corresponding support in PyROOT (implemented now in the latest Cppyy).; - Included the new TSequentialExecutor in ROOT, sharing the interfaces of TExecutor.This should improve code economy when providing a fallback for TThreadExecutor/TProcessExecutor. ### Th",MatchSource.DOCS,README/ReleaseNotes/v614/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md
