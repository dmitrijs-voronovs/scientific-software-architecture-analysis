id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:205,Availability,error,error,205,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665
https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:301,Availability,error,error,301,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665
https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:579,Availability,error,error,579,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665
https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:936,Deployability,patch,patch,936,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665
https://github.com/scverse/scanpy/issues/388#issuecomment-444661453:237,Deployability,update,update,237,"mmmm #2...; The previous email regarding decorator issue, may have been a problem from; namespace shadowing in a jupyter notebook. I think the previous pull; request works--but suggest testing with and without vmin vmax arguments.; I'll update you as I do more testing myself.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/388#issuecomment-444388428>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACez5ZEF7goRe3PYEixKaLT4f0cNthGks5u13gdgaJpZM4ZB23Z>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444661453
https://github.com/scverse/scanpy/issues/388#issuecomment-444661453:523,Deployability,patch,patch,523,"mmmm #2...; The previous email regarding decorator issue, may have been a problem from; namespace shadowing in a jupyter notebook. I think the previous pull; request works--but suggest testing with and without vmin vmax arguments.; I'll update you as I do more testing myself.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/388#issuecomment-444388428>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACez5ZEF7goRe3PYEixKaLT4f0cNthGks5u13gdgaJpZM4ZB23Z>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444661453
https://github.com/scverse/scanpy/issues/388#issuecomment-444661453:185,Testability,test,testing,185,"mmmm #2...; The previous email regarding decorator issue, may have been a problem from; namespace shadowing in a jupyter notebook. I think the previous pull; request works--but suggest testing with and without vmin vmax arguments.; I'll update you as I do more testing myself.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/388#issuecomment-444388428>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACez5ZEF7goRe3PYEixKaLT4f0cNthGks5u13gdgaJpZM4ZB23Z>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444661453
https://github.com/scverse/scanpy/issues/388#issuecomment-444661453:261,Testability,test,testing,261,"mmmm #2...; The previous email regarding decorator issue, may have been a problem from; namespace shadowing in a jupyter notebook. I think the previous pull; request works--but suggest testing with and without vmin vmax arguments.; I'll update you as I do more testing myself.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/388#issuecomment-444388428>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACez5ZEF7goRe3PYEixKaLT4f0cNthGks5u13gdgaJpZM4ZB23Z>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444661453
https://github.com/scverse/scanpy/issues/389#issuecomment-444820105:45,Testability,test,testing,45,"It is working fine for me and is part of the testing. Which version do you; have? maybe you need to use `n_panels_per_row`. On Thu, Dec 6, 2018 at 3:55 AM Alex Wolf <notifications@github.com> wrote:. > Hm, the code; > <https://github.com/theislab/scanpy/blob/21adc0c9a31fb1eebb16579aa4f41700bc939aa2/scanpy/plotting/tools/__init__.py#L180-L188>; > for this looks fine: do you have less than 5 groups?; >; > n_panels_x = min(n_panels_per_row, len(group_names)); >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/389#issuecomment-444730523>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1du-PES9h_EXgZVonUcbuvlvFKdWks5u2IcsgaJpZM4ZCXJs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/389#issuecomment-444820105
https://github.com/scverse/scanpy/pull/390#issuecomment-446061532:256,Testability,test,tests,256,"I submitted both the exact changes suggested by @flying-sheep and . normalize = matplotlib.colors.Normalize(vmin=kwds.get('vmin'), vmax=kwds.get('vmax')); colors = [cmap(normalize(value)) for value in mean_flat]. as a second submission, trying to pass the tests. But it looks like the tests are failing for some other reason outside of the anndata.py file (only file modified in my commit). . I don't think the tests are failing from the changes made here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532
https://github.com/scverse/scanpy/pull/390#issuecomment-446061532:285,Testability,test,tests,285,"I submitted both the exact changes suggested by @flying-sheep and . normalize = matplotlib.colors.Normalize(vmin=kwds.get('vmin'), vmax=kwds.get('vmax')); colors = [cmap(normalize(value)) for value in mean_flat]. as a second submission, trying to pass the tests. But it looks like the tests are failing for some other reason outside of the anndata.py file (only file modified in my commit). . I don't think the tests are failing from the changes made here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532
https://github.com/scverse/scanpy/pull/390#issuecomment-446061532:411,Testability,test,tests,411,"I submitted both the exact changes suggested by @flying-sheep and . normalize = matplotlib.colors.Normalize(vmin=kwds.get('vmin'), vmax=kwds.get('vmax')); colors = [cmap(normalize(value)) for value in mean_flat]. as a second submission, trying to pass the tests. But it looks like the tests are failing for some other reason outside of the anndata.py file (only file modified in my commit). . I don't think the tests are failing from the changes made here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446061532
https://github.com/scverse/scanpy/pull/390#issuecomment-446104893:13,Availability,error,error,13,"Exactly, the error was introduced by some third party update or so. Therefore there was no need for 6e797fa, and it even is is wrong, the second line *needs* to be. ```py; colors = cmap(normalize(mean_flat)); ```. It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`. And when you call it with `normalize(mean_flat[0])` (what happens in the list comprehension), vmin gets set to `min(mean_flat[0]) == mean_flat[0]` instead of `min(mean_flat)`. please do. ```sh; git reset --hard a4b3ccd88f0412461813838d5435ce0cc0b10883; git push -f; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893
https://github.com/scverse/scanpy/pull/390#issuecomment-446104893:54,Deployability,update,update,54,"Exactly, the error was introduced by some third party update or so. Therefore there was no need for 6e797fa, and it even is is wrong, the second line *needs* to be. ```py; colors = cmap(normalize(mean_flat)); ```. It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`. And when you call it with `normalize(mean_flat[0])` (what happens in the list comprehension), vmin gets set to `min(mean_flat[0]) == mean_flat[0]` instead of `min(mean_flat)`. please do. ```sh; git reset --hard a4b3ccd88f0412461813838d5435ce0cc0b10883; git push -f; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893
https://github.com/scverse/scanpy/pull/390#issuecomment-446335721:19,Availability,error,errors,19,"OK great. The same errors as on master happen, so this didn’t introduce any failures. Thank you very much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721
https://github.com/scverse/scanpy/pull/390#issuecomment-446335721:76,Availability,failure,failures,76,"OK great. The same errors as on master happen, so this didn’t introduce any failures. Thank you very much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721
https://github.com/scverse/scanpy/issues/391#issuecomment-444950693:309,Availability,error,error,309,"It looks like your adata object is corrupted. You should be able to type; `adata.X` to get the matrix. How are you generating the adata object?. On Thu, Dec 6, 2018 at 5:56 PM ltosti <notifications@github.com> wrote:. > Hi there,; >; > When running sc.pp.highly_variable_genes(adata.X) I get the following; > error:; >; > AttributeError: X not found; >; > I then ran sc.pp.highly_variable_genes(adata) and got the following:; >; > ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf,; > inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]).; > You can drop duplicate edges by setting the duplicates kwarg; >; > The older sc.pp.filter_genes_dispersion(adata.X) works fine.; >; > Do you know how to fix this?; >; > Thank you!; >; > *Info*: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0; > pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > louvain==0.6.1; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/391>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RPErIznAoUd0DwpbdlEjkOUyjTdks5u2Uw4gaJpZM4ZG6Jw>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693
https://github.com/scverse/scanpy/issues/391#issuecomment-444950693:864,Usability,learn,learn,864,"It looks like your adata object is corrupted. You should be able to type; `adata.X` to get the matrix. How are you generating the adata object?. On Thu, Dec 6, 2018 at 5:56 PM ltosti <notifications@github.com> wrote:. > Hi there,; >; > When running sc.pp.highly_variable_genes(adata.X) I get the following; > error:; >; > AttributeError: X not found; >; > I then ran sc.pp.highly_variable_genes(adata) and got the following:; >; > ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf,; > inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]).; > You can drop duplicate edges by setting the duplicates kwarg; >; > The older sc.pp.filter_genes_dispersion(adata.X) works fine.; >; > Do you know how to fix this?; >; > Thank you!; >; > *Info*: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0; > pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > louvain==0.6.1; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/391>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RPErIznAoUd0DwpbdlEjkOUyjTdks5u2Uw4gaJpZM4ZG6Jw>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693
https://github.com/scverse/scanpy/issues/391#issuecomment-445038953:127,Testability,log,logarithmized,127,"Hi,; could you please try ; ```; sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata); ```; As highly_variable_genes expects logarithmized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445038953
https://github.com/scverse/scanpy/issues/391#issuecomment-445151260:177,Availability,error,error,177,"Hi @Koncopd, my data are indeed already normalised. @fidelram I generated the data merging a few datasets using ```bbknn```. But when I tried on a single sample, I got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445151260
https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:294,Availability,error,error,294,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304
https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:469,Deployability,update,updated,469,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304
https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:300,Integrability,message,message,300,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304
https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:288,Usability,clear,clear,288,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:664,Availability,error,error,664,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:3217,Availability,avail,available,3217,"on); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 90 df['dispersions'] = dispersion; 91 if flavor == 'seurat':; ---> 92 df['mean_bin'] = pd.cut(df['means'], bins=n_bins); 93 disp_grouped = df.groupby('mean_bin')['dispersions']; 94 disp_mean_bin = disp_grouped.mean(). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/pandas/core/reshape/tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates); 226 # GH 24314; 227 raise ValueError(; --> 228 ""cannot specify integer `bins` when input data contains infinity""; 229 ); 230 elif mn == mx: # adjust end points before binning. ValueError: cannot specify integer `bins` when input data contains infinity; ```. I am assuming its something wrong with the dataset (it's a publicly available one which I needed to convert from a Seurat Object), but I can't figure out what. . I have checked if there are any Inf values included in adata.X or adata.raw.X but there are not. Also both adata.X and adata.raw.X are sparse matrices. Any ideas would be greatly appreciated. . ![Screen Shot 2020-03-13 at 6 09 35 PM](https://user-images.githubusercontent.com/15019107/76643678-d6e24500-6555-11ea-88c0-c16f097432e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:343,Testability,log,log,343,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:1416,Testability,log,log,1416,"0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:1437,Testability,log,log,1437,"sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:1613,Testability,log,log,1613,"le_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 90 df['dispersions'] = dispersion; 91 if flavor == 'seurat':; ---> 92 df['mean_bin'] = pd.cut(df",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:1634,Testability,log,log,1634,"ning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 90 df['dispersions'] = dispersion; 91 if flavor == 'seurat':; ---> 92 df['mean_bin'] = pd.cut(df['means'], bins=n_bins); 93 disp_grouped = df.groupby('mean_bin')['dispersions']; 94 disp_mean_bin = disp_grouped.mean(). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-pack",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026
https://github.com/scverse/scanpy/issues/391#issuecomment-598855980:120,Testability,log,logarithmized,120,"Hi! ; Sorry, I don't really have the time to get into this atm, but I have an idea... I think the default for expecting logarithmized data vs non-logarithmized data changed between the two functions for the `method='seurat'` case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980
https://github.com/scverse/scanpy/issues/391#issuecomment-598855980:146,Testability,log,logarithmized,146,"Hi! ; Sorry, I don't really have the time to get into this atm, but I have an idea... I think the default for expecting logarithmized data vs non-logarithmized data changed between the two functions for the `method='seurat'` case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598855980
https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:22,Availability,error,error,22,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561
https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:300,Deployability,Update,Update,300,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561
https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:74,Testability,log,log,74,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561
https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:95,Testability,log,log,95,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561
https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:222,Testability,log,log,222,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561
https://github.com/scverse/scanpy/issues/391#issuecomment-718318538:115,Availability,error,error,115,"FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error. . I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538
https://github.com/scverse/scanpy/issues/391#issuecomment-718318538:318,Availability,down,downstream,318,"FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error. . I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538
https://github.com/scverse/scanpy/issues/391#issuecomment-718667650:16,Deployability,update,update,16,"Thanks for your update @rpeys, I will try to convert to scipy csr sparse matrix :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718667650
https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:315,Availability,error,error,315,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201
https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:394,Availability,error,error,394,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201
https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:649,Availability,error,error,649,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201
https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:94,Testability,log,log,94,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201
https://github.com/scverse/scanpy/issues/391#issuecomment-870384617:188,Availability,error,error,188,"For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-870384617
https://github.com/scverse/scanpy/issues/391#issuecomment-1149904076:18,Deployability,update,update,18,"> Thanks for your update @rpeys, I will try to convert to scipy csr sparse matrix :). Hello, Massonix, was the problem resolved?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149904076
https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:117,Availability,error,error,117,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935
https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:325,Availability,down,downstream,325,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935
https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:489,Modifiability,variab,variables,489,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935
https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:558,Modifiability,variab,variable,558,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935
https://github.com/scverse/scanpy/issues/392#issuecomment-445515498:249,Availability,fault,fault,249,"Both of these modules are not in the docs and not referenced in any tutorial and I never considered them mature code... I always planned on fixing these... but my bandwidth for this is limited... I should not have merged them into master, that's my fault... Won't happen again...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/392#issuecomment-445515498
https://github.com/scverse/scanpy/issues/393#issuecomment-445972448:309,Usability,learn,learn,309,"For pca of sparse matrices i think it should work this way; 1) Create class for lazy evaluation of X - mean, i.e store X, mean separately and implement multiplication by some dense B as `sparse.csr_matrix.dot(X, B) - mean.dot(B)`.; 2) Pass instance of this class to [randomized_svd](https://github.com/scikit-learn/scikit-learn/blob/7fe3413475bf50683f821d296c2ca6cb525a7714/sklearn/utils/extmath.py#L233)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-445972448
https://github.com/scverse/scanpy/issues/393#issuecomment-445972448:322,Usability,learn,learn,322,"For pca of sparse matrices i think it should work this way; 1) Create class for lazy evaluation of X - mean, i.e store X, mean separately and implement multiplication by some dense B as `sparse.csr_matrix.dot(X, B) - mean.dot(B)`.; 2) Pass instance of this class to [randomized_svd](https://github.com/scikit-learn/scikit-learn/blob/7fe3413475bf50683f821d296c2ca6cb525a7714/sklearn/utils/extmath.py#L233)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-445972448
https://github.com/scverse/scanpy/issues/393#issuecomment-446368749:587,Energy Efficiency,efficient,efficiently,587,"**Most importantly**: Other than stated in the docs, the default for `zero_center` is `True` and has been `True` since I believe, July 2017 (very early Scanpy, maybe 0.2..). @VolkerBergen: I concur. One should obtain the same representation independent of the data type and that's what the default behavior of the function should give you. @Koncopd: One can also talk about a proper implementation of PCA for sparse data, which I thought would require quite some custom code. Your solution seems like a really good solution if randomiced_svd is able to treat that lazy evaluation object efficiently. @VolkerBergen: I've viewed `TruncatedSVD` as an alternative way of compressing the data. Of course, the first SVD component will then store all the information about the means. From component two on this alternative way should be similar to what you get from PCA, but yes, it's not equivalent... As I eventually didn't run into memory problems I never really investigated further... But I'm pretty sure that PCA is just one of 100 ways of compressing the data in a somewhat meaningful manner giving you somewhat meaningful results. That's already evident from the fact that all the autoencoder based latent space representations don't give you completely different results than PCA. My impression is that, in fact, the results are highly similar.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446368749
https://github.com/scverse/scanpy/issues/393#issuecomment-446371088:132,Usability,simpl,simple,132,"And, you're right: [line 486](https://github.com/theislab/scanpy/blob/17141d02ad19ad10aedd8361633be3cd670b3001/scanpy/preprocessing/simple.py#L486) could be a bug. It should be `zero_center is None` and not `zero_center is not None`. Hm, @Koncopd, could it be that the function does the opposite as wished? Did this happen when introducing the `chunked` version a couple of months ago or was it present from the beginning? It would be quite a serious bug... And @VolkerBergen would be right in this observation... Damn.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446371088
https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:428,Availability,fault,fault,428,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971
https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:382,Deployability,release,release,382,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971
https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:459,Testability,test,test,459,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971
https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:510,Testability,test,test,510,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971
https://github.com/scverse/scanpy/issues/393#issuecomment-446373823:135,Deployability,release,release,135,I fixed the bug: https://github.com/theislab/scanpy/commit/15593d532fbaa696bf1ea328d1991d31b334e175. . And I'll immediately make a new release and put a warning on the webpage... @Koncopd: Thank you for adding the tests!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823
https://github.com/scverse/scanpy/issues/393#issuecomment-446373823:214,Testability,test,tests,214,I fixed the bug: https://github.com/theislab/scanpy/commit/15593d532fbaa696bf1ea328d1991d31b334e175. . And I'll immediately make a new release and put a warning on the webpage... @Koncopd: Thank you for adding the tests!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446373823
https://github.com/scverse/scanpy/issues/393#issuecomment-446377138:10,Deployability,release,release,10,Done with release 1.3.6 and the warning: https://github.com/theislab/scanpy/commit/35030d28bb4e1e4559449bfe41238523bee0e616,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446377138
https://github.com/scverse/scanpy/issues/393#issuecomment-446377673:234,Modifiability,inherit,inherits,234,"As for `randomized_svd`, looking at [this](https://github.com/scikit-learn/scikit-learn/blob/7fe3413475bf50683f821d296c2ca6cb525a7714/sklearn/utils/extmath.py#L120) it seems that is should work properly if a class for lazy evaluation inherits from standard sparse class and implements \_\_mul\_\_ and \_\_rmul\_\_.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446377673
https://github.com/scverse/scanpy/issues/393#issuecomment-446377673:69,Usability,learn,learn,69,"As for `randomized_svd`, looking at [this](https://github.com/scikit-learn/scikit-learn/blob/7fe3413475bf50683f821d296c2ca6cb525a7714/sklearn/utils/extmath.py#L120) it seems that is should work properly if a class for lazy evaluation inherits from standard sparse class and implements \_\_mul\_\_ and \_\_rmul\_\_.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446377673
https://github.com/scverse/scanpy/issues/393#issuecomment-446377673:82,Usability,learn,learn,82,"As for `randomized_svd`, looking at [this](https://github.com/scikit-learn/scikit-learn/blob/7fe3413475bf50683f821d296c2ca6cb525a7714/sklearn/utils/extmath.py#L120) it seems that is should work properly if a class for lazy evaluation inherits from standard sparse class and implements \_\_mul\_\_ and \_\_rmul\_\_.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446377673
https://github.com/scverse/scanpy/issues/393#issuecomment-446396916:57,Usability,simpl,simply,57,"Following @Koncopd 's idea, wouldn't it be sufficient to simply have line 340 in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py changed to ; ```; mu = M.mean(1).A1 if issparse(M) else M.mean(1); B = safe_sparse_dot(Q.T, M) - safe_sparse_dot(Q.T, mu[:, None]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446396916
https://github.com/scverse/scanpy/issues/393#issuecomment-446396916:107,Usability,learn,learn,107,"Following @Koncopd 's idea, wouldn't it be sufficient to simply have line 340 in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py changed to ; ```; mu = M.mean(1).A1 if issparse(M) else M.mean(1); B = safe_sparse_dot(Q.T, M) - safe_sparse_dot(Q.T, mu[:, None]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446396916
https://github.com/scverse/scanpy/issues/393#issuecomment-446396916:120,Usability,learn,learn,120,"Following @Koncopd 's idea, wouldn't it be sufficient to simply have line 340 in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py changed to ; ```; mu = M.mean(1).A1 if issparse(M) else M.mean(1); B = safe_sparse_dot(Q.T, M) - safe_sparse_dot(Q.T, mu[:, None]); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446396916
https://github.com/scverse/scanpy/issues/393#issuecomment-446527430:114,Usability,learn,learn,114,"@VolkerBergen ; No, similar lines also should be changed in [`randomized_range_finder`](https://github.com/scikit-learn/scikit-learn/blob/3a884c5ee507f735e2df384727340c72c5219a8e/sklearn/utils/extmath.py#L148), which is used by `randomized_svd` function. Or the whole `safe_sparse_dot` function. But copying the file extmath.py (or the part of it related to svd) and changing this lines would be sufficient, yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446527430
https://github.com/scverse/scanpy/issues/393#issuecomment-446527430:127,Usability,learn,learn,127,"@VolkerBergen ; No, similar lines also should be changed in [`randomized_range_finder`](https://github.com/scikit-learn/scikit-learn/blob/3a884c5ee507f735e2df384727340c72c5219a8e/sklearn/utils/extmath.py#L148), which is used by `randomized_svd` function. Or the whole `safe_sparse_dot` function. But copying the file extmath.py (or the part of it related to svd) and changing this lines would be sufficient, yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446527430
https://github.com/scverse/scanpy/issues/393#issuecomment-446532755:376,Testability,test,test,376,"> which did the expected thing, @flying-sheep introduced the bug 22 days ago in ce10d02. damn, the only thing I could have done wrong there…. It went into that commit because the previous code was too convoluted to understand, and I needed to understand that line to improve the docs! I ended up understanding it it but rewrote the line incorrectly. I’m sorry!. Did you add a test after 15593d5?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446532755
https://github.com/scverse/scanpy/issues/393#issuecomment-446612573:47,Energy Efficiency,power,power,47,"@VolkerBergen ; Also appropriately implemented power method (last section of [this](http://www.cs.yale.edu/homes/el327/datamining2013aFiles/07_singular_value_decomposition.pdf), for example) for svd should be fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446612573
https://github.com/scverse/scanpy/issues/393#issuecomment-447614569:160,Deployability,update,updated,160,"@flying-sheep no worries! We'll steadily increase test coverage. I assume that almost no one should have run into the bug in the past 22 days. Among those that updated their version, only very few will have run the PCA with sparse data... @Koncopd, I'm very happy if you move forward with a proper sparse implementation of PCA! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569
https://github.com/scverse/scanpy/issues/393#issuecomment-447614569:50,Testability,test,test,50,"@flying-sheep no worries! We'll steadily increase test coverage. I assume that almost no one should have run into the bug in the past 22 days. Among those that updated their version, only very few will have run the PCA with sparse data... @Koncopd, I'm very happy if you move forward with a proper sparse implementation of PCA! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-447614569
https://github.com/scverse/scanpy/issues/396#issuecomment-447898456:24,Usability,clear,clearer,24,"Thanks, now is becoming clearer. Can you specify the maximum percentage; value or this is taken from the data?. What would be a nice name for a parameter to add to the function?; `max_fraction` ?. I would not be able to work on this for the next days but at least we can; throw some ideas. The change is the code is probably quite simple. On Fri, Dec 14, 2018 at 7:14 PM a-munoz-rojas <notifications@github.com>; wrote:. > Sure - this is an output from a Seurat analysis. You can see that the; > scale of the dot size goes from 10% to 60%, such that the group with 60%; > expressing cells is scaled to the max dot size:; >; > [image: pastedgraphic-3]; > <https://user-images.githubusercontent.com/37122760/50017697-d9dd3700-ff9a-11e8-8c28-fb6cd7f064e7.png>; >; > As a comparison, this is a (different) output from scanpy that; > automatically scales to 100% and causes the dots to be too small:; > [image: dotplotex]; > <https://user-images.githubusercontent.com/37122760/50019765-df8a4b00-ffa1-11e8-9b49-30d5057898bb.png>; >; > Please let me know if this makes sense!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/396#issuecomment-447408166>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Xirz8yk_WM-3MJPaKKrbq2rm19Bks5u4-qegaJpZM4ZSMYu>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396#issuecomment-447898456
https://github.com/scverse/scanpy/issues/396#issuecomment-447898456:331,Usability,simpl,simple,331,"Thanks, now is becoming clearer. Can you specify the maximum percentage; value or this is taken from the data?. What would be a nice name for a parameter to add to the function?; `max_fraction` ?. I would not be able to work on this for the next days but at least we can; throw some ideas. The change is the code is probably quite simple. On Fri, Dec 14, 2018 at 7:14 PM a-munoz-rojas <notifications@github.com>; wrote:. > Sure - this is an output from a Seurat analysis. You can see that the; > scale of the dot size goes from 10% to 60%, such that the group with 60%; > expressing cells is scaled to the max dot size:; >; > [image: pastedgraphic-3]; > <https://user-images.githubusercontent.com/37122760/50017697-d9dd3700-ff9a-11e8-8c28-fb6cd7f064e7.png>; >; > As a comparison, this is a (different) output from scanpy that; > automatically scales to 100% and causes the dots to be too small:; > [image: dotplotex]; > <https://user-images.githubusercontent.com/37122760/50019765-df8a4b00-ffa1-11e8-9b49-30d5057898bb.png>; >; > Please let me know if this makes sense!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/396#issuecomment-447408166>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Xirz8yk_WM-3MJPaKKrbq2rm19Bks5u4-qegaJpZM4ZSMYu>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/396#issuecomment-447898456
https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:483,Availability,down,down-regulated,483,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:40,Modifiability,variab,variable,40,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:123,Modifiability,variab,variable,123,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:77,Performance,perform,perform,77,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:660,Testability,test,test,660,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464
https://github.com/scverse/scanpy/issues/397#issuecomment-447417086:170,Testability,test,testing,170,"Hi,. Thank you so much for the prompt response. I was able to make the comparisons following your method. As you suggested, I am going to try using MAST or limma for DEG testing in the future. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447417086
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:653,Energy Efficiency,power,powerful,653,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:478,Performance,perform,performs,478,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:1034,Safety,detect,detection,1034,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:238,Testability,test,test,238,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:379,Testability,test,test,379,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:754,Testability,test,test,754,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447598981:129,Usability,simpl,simple,129,"Thank you so much for fielding so many of the issues, @LuckyMD! :smile:. Can we elaborate a bit further on this one, though? For simple two-group comparisons, `rank_genes_groups` with `method='wilcoxon'` (Wilcoxon-Rank-Sum/Mann-Whitney U test) should be a legit choice, shouldn't it? It's used in many of this year's Nature, Cell and Science single-cell papers, it's the default test of Seurat (https://satijalab.org/seurat/de_vignette.html) and several people reported that it performs well in [Sonison & Robinson, Nat Meth (2018)](https://doi.org/10.1038/nmeth.4612). So, I don't think one needs to encourage people to immediately go to the great and powerful MAST, limma and DESeq2. Can you point me to a reference that shows that a Wilcoxon-Rank-Sum test is less _sensitive_? How is this even a useful statement if you don't talk about the false positives you buy in? We should look at an AUC that scans different p-values, right? A bit more than a year ago, @tcallies and I had a full paper draft discussing AUCs for marker gene detection formulated as a classification problem, but we never finished it. In the general setting, it's not at all straightforward to make the evaluation a well-defined problem and other people will for sure have done a better job. Unfortunately, I have never fully caught up with the literature, I fear...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447598981
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1019,Modifiability,variab,variability,1019,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:216,Performance,perform,perform,216,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:736,Performance,perform,performs,736,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1227,Performance,perform,perform,1227,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1383,Safety,detect,detection,1383,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:123,Testability,test,tests,123,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:286,Testability,test,test,286,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:329,Testability,log,log,329,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:406,Testability,test,test,406,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:686,Testability,test,testing,686,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:884,Testability,test,test,884,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1140,Testability,test,tests,1140,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1167,Testability,test,tests,1167,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1734,Testability,test,tests,1734,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:1761,Testability,test,tests,1761,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447865088:587,Usability,simpl,simple,587,"@falexwolf I try to answer where I can. I should probably have clarified a bit above. I would argue that most real data DE tests benefit from accounting for technical covariates. For example, you should probably not perform batch correction on your data and then do a wilcoxon rank sum test, but instead take the normalized (and log transformed) data or the raw counts and include a batch covariate in the test. This also holds for technical covariates that describe the complexity of the data (such as size factors or n_genes). Often these factors are not sufficiently accounted for by simple normalization techniques (especially for plate-based data), and are thus included in the DE testing framework. This is done in MAST (and MAST performs better with this `detRate` covariate in the Soneson & Robinson paper you cite above), and it is also done in a recent negative binomial DE test from [Mayer et al, Nature 2018](http://www.nature.com/doifinder/10.1038/nature25999). When you are not able to fit the background variability in your model, you will have a lower sensitivity. Accounting for covariates is obviously not possible with t-tests or wilcoxon rank sum tests. Hence my statement about lower sensitivity. They did perform comparatively well in the DE method comparison, which is why I'd argue that they're useful for first pass exploratory applications (and marker gene detection when you don't want to use more fancy approaches like [this](https://www.biorxiv.org/content/early/2018/11/05/463265)). However, if you can account for technical covariates, that's probably a good approach to use. Also, according to the comparison paper you mention, there are not more false positives when using MAST or limma compared to t-tests or Wilcoxon rank sum tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447865088
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:158,Energy Efficiency,power,power,158,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:635,Energy Efficiency,power,power,635,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:1040,Performance,perform,performing,1040,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:131,Testability,test,tests,131,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:171,Testability,test,tests,171,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:285,Testability,test,test-,285,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:501,Testability,test,test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl,501,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:778,Testability,test,test,778,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:899,Testability,test,tests,899,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:1158,Testability,test,test,1158,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-447874358:852,Usability,Intuit,Intuitively,852,"I agree with @LuckyMD about the points regarding covariates. . With respect to two group comparisons without confounding, rank-sum tests have less statitical power than t-tests (https://stats.stackexchange.com/questions/130562/why-is-the-asymptotic-relative-efficiency-of-the-wilcoxon-test-3-pi-compared), disclaimer I haven't checked this proof, I think this is a standard statistics result though, this is also discussed here https://stats.stackexchange.com/questions/121852/how-to-choose-between-t-test-or-non-parametric-test-e-g-wilcoxon-in-small-sampl. I havent run simulations to check how big the influence of the difference in power is on the kind of data we encounter. However, as also pointed out by the second link, violations of the distributional assumptions for t-test impact these results and these violations will be major on scRNAseq. Intuitively I would therefore tend to rank-sum tests. With respect to [diffxpy](https://github.com/theislab/diffxpy): We can account for other noise models in the two-group comparisons by performing model fitting, tutorial [here](https://github.com/theislab/diffxpy_tutorials/blob/master/diffxpy_tutorials/test/single/wald_test.ipynb). The bioarxiv will hopefully be up in the next few weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447874358
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:683,Energy Efficiency,adapt,adapt,683,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:683,Modifiability,adapt,adapt,683,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:145,Safety,detect,detection,145,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:105,Testability,test,test,105,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:125,Testability,test,test,125,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:588,Testability,test,test-overestimate-var,588,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-449358857:708,Testability,test,test-overestimate-var,708,"Also, I just found time to read the links you posted @davidsebfischer. Shouldn't we always use a welch t-test instead of a t-test in marker gene detection according to your second stackexchange link? They state that If you don't have a good reason to assume equal variances in the groups, then use the Welch correction... if we have a `group` vs `rest` type of setup as we do in `rank_genes_groups()` at the moment, then we would definitely not expect a single cluster to have an equal variance to the combination of all other cells in other clusters. I think the default is currently `t-test-overestimate-var`... being oblivious to exactly how that works, might it not be better to adapt that to a `welch-t-test-overestimate-var` or something like that @falexwolf?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-449358857
https://github.com/scverse/scanpy/issues/397#issuecomment-450025261:132,Energy Efficiency,adapt,adaption,132,@LuckyMD . Thank you for the whole in-depth discussion. It makes a lot of sense! :smile:. To your question: Scanpy has used Welch's adaption of Student's t-test from the very beginning. @davidsebfischer . Thank you! I guess it would be nice to have a single-cell tutorial in diffxpy that shows higher sensitivity by accounting for technical covariates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261
https://github.com/scverse/scanpy/issues/397#issuecomment-450025261:132,Modifiability,adapt,adaption,132,@LuckyMD . Thank you for the whole in-depth discussion. It makes a lot of sense! :smile:. To your question: Scanpy has used Welch's adaption of Student's t-test from the very beginning. @davidsebfischer . Thank you! I guess it would be nice to have a single-cell tutorial in diffxpy that shows higher sensitivity by accounting for technical covariates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261
https://github.com/scverse/scanpy/issues/397#issuecomment-450025261:156,Testability,test,test,156,@LuckyMD . Thank you for the whole in-depth discussion. It makes a lot of sense! :smile:. To your question: Scanpy has used Welch's adaption of Student's t-test from the very beginning. @davidsebfischer . Thank you! I guess it would be nice to have a single-cell tutorial in diffxpy that shows higher sensitivity by accounting for technical covariates.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-450025261
https://github.com/scverse/scanpy/issues/397#issuecomment-462890590:97,Usability,learn,learn,97,Any news when diffxpy will be up on biorxiv? The package looks super interesting and I'd like to learn more about the background to the methods you implemented.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-462890590
https://github.com/scverse/scanpy/issues/397#issuecomment-529105173:11,Performance,perform,performs,11,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.1 = ""CD14+ Mono"", ident.2 = ""FCGR3A+ Mono"", test.use = ""MAST""). So I hope that Scanpy could interated more methods too, such as diffxpy in this way:; sc.tl.rank_gene_groups(adata, method='diffxpy' or 'MAST'). Here is the hyperlink of DE analysis in Seurat:. https://satijalab.org/seurat/v3.0/de_vignette.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173
https://github.com/scverse/scanpy/issues/397#issuecomment-529105173:50,Testability,test,tests,50,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.1 = ""CD14+ Mono"", ident.2 = ""FCGR3A+ Mono"", test.use = ""MAST""). So I hope that Scanpy could interated more methods too, such as diffxpy in this way:; sc.tl.rank_gene_groups(adata, method='diffxpy' or 'MAST'). Here is the hyperlink of DE analysis in Seurat:. https://satijalab.org/seurat/v3.0/de_vignette.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173
https://github.com/scverse/scanpy/issues/397#issuecomment-529105173:178,Testability,test,test,178,"Now seurat performs DE analysis using alternative tests including MAST and DESeq2 in a convinent way, such as FindMarkers(pbmc, ident.1 = ""CD14+ Mono"", ident.2 = ""FCGR3A+ Mono"", test.use = ""MAST""). So I hope that Scanpy could interated more methods too, such as diffxpy in this way:; sc.tl.rank_gene_groups(adata, method='diffxpy' or 'MAST'). Here is the hyperlink of DE analysis in Seurat:. https://satijalab.org/seurat/v3.0/de_vignette.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-529105173
https://github.com/scverse/scanpy/issues/397#issuecomment-551411475:115,Energy Efficiency,power,powerful,115,"This field is developing very fast, more and more advanced DE test methos are emerging, it's better to adopt these powerful methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551411475
https://github.com/scverse/scanpy/issues/397#issuecomment-551411475:62,Testability,test,test,62,"This field is developing very fast, more and more advanced DE test methos are emerging, it's better to adopt these powerful methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551411475
https://github.com/scverse/scanpy/issues/397#issuecomment-551419621:47,Testability,test,testing,47,"One of the shortcomings of scanpy's default DE testing is that p-values (or FDR) of a few genes are very significant (equal 0 or approximately 0 in some datasets), then it's impossible to execute -log transformation, even there is only one 0. The volcano plot will be not beautiful because of the high significance.; @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621
https://github.com/scverse/scanpy/issues/397#issuecomment-551419621:197,Testability,log,log,197,"One of the shortcomings of scanpy's default DE testing is that p-values (or FDR) of a few genes are very significant (equal 0 or approximately 0 in some datasets), then it's impossible to execute -log transformation, even there is only one 0. The volcano plot will be not beautiful because of the high significance.; @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-551419621
https://github.com/scverse/scanpy/issues/397#issuecomment-635495778:114,Testability,test,testing,114,Thanks all for the interesting discussion- did a consensus emerge on the 'best' way to do differential expression testing in scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635495778
https://github.com/scverse/scanpy/issues/397#issuecomment-635821693:267,Testability,test,tests,267,"Thank you @LuckyMD. Naive question, but what is the advantage of `diffxpy` over `sc.tl.rank_genes_groups`? I read comments above about noise models and technical covariates, but I don't fully understand the model fitting aspect and both methods seem to offer similar tests like T-tests and Wilcoxon rank-sum.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635821693
https://github.com/scverse/scanpy/issues/397#issuecomment-635821693:280,Testability,test,tests,280,"Thank you @LuckyMD. Naive question, but what is the advantage of `diffxpy` over `sc.tl.rank_genes_groups`? I read comments above about noise models and technical covariates, but I don't fully understand the model fitting aspect and both methods seem to offer similar tests like T-tests and Wilcoxon rank-sum.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635821693
https://github.com/scverse/scanpy/issues/397#issuecomment-635895430:44,Testability,test,test,44,"`sc.tl.rank_genes_groups` offers only the T-test (including a second version of this) and Wilcoxon rank-sum test. These tests are also in `diffxpy`, but there are fare more sophisticated parametric models which you can (and probably should) use to test for differential expression in different setups. Ideally, to run a DE test you would want to model raw count data as a negative binomial and then add covariates to the model (like size factors, sample, condition, etc.). This is only possible in `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635895430
https://github.com/scverse/scanpy/issues/397#issuecomment-635895430:108,Testability,test,test,108,"`sc.tl.rank_genes_groups` offers only the T-test (including a second version of this) and Wilcoxon rank-sum test. These tests are also in `diffxpy`, but there are fare more sophisticated parametric models which you can (and probably should) use to test for differential expression in different setups. Ideally, to run a DE test you would want to model raw count data as a negative binomial and then add covariates to the model (like size factors, sample, condition, etc.). This is only possible in `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635895430
https://github.com/scverse/scanpy/issues/397#issuecomment-635895430:120,Testability,test,tests,120,"`sc.tl.rank_genes_groups` offers only the T-test (including a second version of this) and Wilcoxon rank-sum test. These tests are also in `diffxpy`, but there are fare more sophisticated parametric models which you can (and probably should) use to test for differential expression in different setups. Ideally, to run a DE test you would want to model raw count data as a negative binomial and then add covariates to the model (like size factors, sample, condition, etc.). This is only possible in `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635895430
https://github.com/scverse/scanpy/issues/397#issuecomment-635895430:248,Testability,test,test,248,"`sc.tl.rank_genes_groups` offers only the T-test (including a second version of this) and Wilcoxon rank-sum test. These tests are also in `diffxpy`, but there are fare more sophisticated parametric models which you can (and probably should) use to test for differential expression in different setups. Ideally, to run a DE test you would want to model raw count data as a negative binomial and then add covariates to the model (like size factors, sample, condition, etc.). This is only possible in `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635895430
https://github.com/scverse/scanpy/issues/397#issuecomment-635895430:323,Testability,test,test,323,"`sc.tl.rank_genes_groups` offers only the T-test (including a second version of this) and Wilcoxon rank-sum test. These tests are also in `diffxpy`, but there are fare more sophisticated parametric models which you can (and probably should) use to test for differential expression in different setups. Ideally, to run a DE test you would want to model raw count data as a negative binomial and then add covariates to the model (like size factors, sample, condition, etc.). This is only possible in `diffxpy`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-635895430
https://github.com/scverse/scanpy/pull/398#issuecomment-447896676:101,Deployability,integrat,integrated,101,"I second this initiative. I had used the code from Brent and works quite; well. Naturally, having it integrated into Scanpy would be great. On Mon, Dec 17, 2018 at 2:18 PM Marius Lange <notifications@github.com>; wrote:. > *@Marius1311* commented on this pull request.; > ------------------------------; >; > In scanpy/preprocessing/combat.py; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>:; >; > > @@ -0,0 +1,161 @@; > +import numpy as np; > +from scipy.sparse import issparse; > +import pandas as pd; > +import sys; > +from numpy import linalg as la; > +import patsy; > +; > +def design_mat(mod, batch_levels):; > + # require levels to make sure they are in the same order as we use in the; > + # rest of the script.; > + design = patsy.dmatrix(""~ 0 + C(batch, levels=%s)"" % str(batch_levels),; >; > thanks, did that!; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1fZSO-j8m0NwemluQp-0wNEGDHJ9ks5u55mlgaJpZM4ZTmeq>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-447896676
https://github.com/scverse/scanpy/pull/398#issuecomment-447896676:101,Integrability,integrat,integrated,101,"I second this initiative. I had used the code from Brent and works quite; well. Naturally, having it integrated into Scanpy would be great. On Mon, Dec 17, 2018 at 2:18 PM Marius Lange <notifications@github.com>; wrote:. > *@Marius1311* commented on this pull request.; > ------------------------------; >; > In scanpy/preprocessing/combat.py; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>:; >; > > @@ -0,0 +1,161 @@; > +import numpy as np; > +from scipy.sparse import issparse; > +import pandas as pd; > +import sys; > +from numpy import linalg as la; > +import patsy; > +; > +def design_mat(mod, batch_levels):; > + # require levels to make sure they are in the same order as we use in the; > + # rest of the script.; > + design = patsy.dmatrix(""~ 0 + C(batch, levels=%s)"" % str(batch_levels),; >; > thanks, did that!; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/398#discussion_r242142511>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1fZSO-j8m0NwemluQp-0wNEGDHJ9ks5u55mlgaJpZM4ZTmeq>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-447896676
https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:173,Deployability,integrat,integration,173,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646
https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:173,Integrability,integrat,integration,173,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646
https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:195,Testability,test,tests,195,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646
https://github.com/scverse/scanpy/pull/398#issuecomment-448304646:30,Usability,feedback,feedback,30,"Hey everyone, thanks for your feedback! In the latest commit, I have tried to include all of your comments, including the more stylistic comments, the references, the numba integration, the unit tests and so on. Have a look and see what you think. I won't be able to work on this any more this year because I am going on holidays. Merry Christmas everyone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-448304646
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:62,Energy Efficiency,adapt,adapting,62,"Thank you very much! I merged this via the command line after adapting to the private module design. I still get a to me cryptic AttributeError from patsy on my Mac, but the tests are fine and on the Linux server it also runs fine:; ```; preprocessing/_combat.py:150: in combat; s_data, design, var_pooled, stand_mean = stand_data(model, data); preprocessing/_combat.py:78: in stand_data; design = design_mat(model, batch_levels); preprocessing/_combat.py:32: in design_mat; model, return_type=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:62,Modifiability,adapt,adapting,62,"Thank you very much! I merged this via the command line after adapting to the private module design. I still get a to me cryptic AttributeError from patsy on my Mac, but the tests are fine and on the Linux server it also runs fine:; ```; preprocessing/_combat.py:150: in combat; s_data, design, var_pooled, stand_mean = stand_data(model, data); preprocessing/_combat.py:78: in stand_data; design = design_mat(model, batch_levels); preprocessing/_combat.py:32: in design_mat; model, return_type=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:2068,Safety,avoid,avoid,2068,"ype=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully contain newlines, we'll just remove all; # the newlines up front to avoid any complications:; code = code.replace(""\n"", "" "").strip(); it = tokenize.generate_tokens(StringIO(code).readline); try:; for (pytype, string, (_, start), (_, end), code) in it:; if pytype == tokenize.ENDMARKER:; break; origin = Origin(code, start, end); > assert pytype not in (tokenize.NL, tokenize.NEWLINE); E AssertionError. ../../../miniconda3/lib/python3.6/site-packages/patsy/tokens.py:35: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:174,Testability,test,tests,174,"Thank you very much! I merged this via the command line after adapting to the private module design. I still get a to me cryptic AttributeError from patsy on my Mac, but the tests are fine and on the Linux server it also runs fine:; ```; preprocessing/_combat.py:150: in combat; s_data, design, var_pooled, stand_mean = stand_data(model, data); preprocessing/_combat.py:78: in stand_data; design = design_mat(model, batch_levels); preprocessing/_combat.py:32: in design_mat; model, return_type=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:2331,Testability,assert,assert,2331,"ype=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully contain newlines, we'll just remove all; # the newlines up front to avoid any complications:; code = code.replace(""\n"", "" "").strip(); it = tokenize.generate_tokens(StringIO(code).readline); try:; for (pytype, string, (_, start), (_, end), code) in it:; if pytype == tokenize.ENDMARKER:; break; origin = Origin(code, start, end); > assert pytype not in (tokenize.NL, tokenize.NEWLINE); E AssertionError. ../../../miniconda3/lib/python3.6/site-packages/patsy/tokens.py:35: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:2387,Testability,Assert,AssertionError,2387,"ype=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully contain newlines, we'll just remove all; # the newlines up front to avoid any complications:; code = code.replace(""\n"", "" "").strip(); it = tokenize.generate_tokens(StringIO(code).readline); try:; for (pytype, string, (_, start), (_, end), code) in it:; if pytype == tokenize.ENDMARKER:; break; origin = Origin(code, start, end); > assert pytype not in (tokenize.NL, tokenize.NEWLINE); E AssertionError. ../../../miniconda3/lib/python3.6/site-packages/patsy/tokens.py:35: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451762530:2471,Testability,Assert,AssertionError,2471,"ype=""dataframe""); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:291: in dmatrix; NA_action, return_type); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:165: in _do_highlevel_design; NA_action); ../../../miniconda3/lib/python3.6/site-packages/patsy/highlevel.py:62: in _try_incr_builders; formula_like = ModelDesc.from_formula(formula_like); ../../../miniconda3/lib/python3.6/site-packages/patsy/desc.py:164: in from_formula; tree = parse_formula(tree_or_string); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:148: in parse_formula; _atomic_token_types); ../../../miniconda3/lib/python3.6/site-packages/patsy/infix_parser.py:210: in infix_parse; for token in token_source:; ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:94: in _tokenize_formula; yield _read_python_expr(it, end_tokens); ../../../miniconda3/lib/python3.6/site-packages/patsy/parse_formula.py:44: in _read_python_expr; for pytype, token_string, origin in it:; ../../../miniconda3/lib/python3.6/site-packages/patsy/util.py:332: in next; return six.advance_iterator(self._it); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . code = ''. def python_tokenize(code):; # Since formulas can only contain Python expressions, and Python; # expressions cannot meaningfully contain newlines, we'll just remove all; # the newlines up front to avoid any complications:; code = code.replace(""\n"", "" "").strip(); it = tokenize.generate_tokens(StringIO(code).readline); try:; for (pytype, string, (_, start), (_, end), code) in it:; if pytype == tokenize.ENDMARKER:; break; origin = Origin(code, start, end); > assert pytype not in (tokenize.NL, tokenize.NEWLINE); E AssertionError. ../../../miniconda3/lib/python3.6/site-packages/patsy/tokens.py:35: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451762530
https://github.com/scverse/scanpy/pull/398#issuecomment-451888324:100,Availability,error,error,100,"Thanks Alex! That's great, thanks also for adding me to the authors list. I haven't seen that patsy error on my Ubuntu machine either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451888324
https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:154,Availability,recover,recover,154,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340
https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:154,Safety,recover,recover,154,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340
https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:390,Safety,safe,safely,390,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340
https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:350,Security,secur,security,350,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340
https://github.com/scverse/scanpy/issues/399#issuecomment-448102220:95,Performance,load,load,95,"From a gene matrix, tsne and cluster .csv files obtained from cell ranger output I was able to load these into scanpy and display a tsne plot that look exactly like the output of cellranger cloupe file. This is great thanks!. ![screen shot 2018-12-18 at 14 32 39](https://user-images.githubusercontent.com/39877296/50134113-eaaae700-02d1-11e9-96db-8c2a3393724b.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-448102220
https://github.com/scverse/scanpy/pull/403#issuecomment-450026681:52,Testability,benchmark,benchmarks,52,"This is nice! Thank you!. It appears to me that the benchmarks show that this only becomes relevant for *very* large data. So we need to be mindful to not break backward compatibility for all the small and medium-size datasets that people use (which we do by introducing the tiny difference). Don't you think that in the light of this, it would be better to leave the default as is (densifying) and have an option `sparse_pca` or something similar?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450026681
https://github.com/scverse/scanpy/pull/403#issuecomment-450029072:27,Testability,benchmark,benchmarks,27,">It appears to me that the benchmarks show that this only becomes relevant for very large data. Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450029072
https://github.com/scverse/scanpy/pull/403#issuecomment-450220968:355,Availability,avail,available,355,"> Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?. Yes, it's definitely large and it's awesome that you solved this problem! I just meant that it's not hitting people's computational resources limits: your example is 60K x 2K, so quite big already, if you densify you need 800MB, which is easily available even on a laptop. That's what I meant. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450220968
https://github.com/scverse/scanpy/pull/403#issuecomment-453966774:22,Testability,test,test,22,Not sure what kind of test to add for this...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-453966774
https://github.com/scverse/scanpy/pull/403#issuecomment-456032298:35,Deployability,integrat,integrate,35,"As discussed, @Koncopd will try to integrate this into scikit-learn itself and not into Scanpy. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-456032298
https://github.com/scverse/scanpy/pull/403#issuecomment-456032298:35,Integrability,integrat,integrate,35,"As discussed, @Koncopd will try to integrate this into scikit-learn itself and not into Scanpy. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-456032298
https://github.com/scverse/scanpy/pull/403#issuecomment-456032298:62,Usability,learn,learn,62,"As discussed, @Koncopd will try to integrate this into scikit-learn itself and not into Scanpy. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-456032298
https://github.com/scverse/scanpy/pull/403#issuecomment-460239298:75,Usability,learn,learn,75,Similar pull request exists already in sklearn.; https://github.com/scikit-learn/scikit-learn/pull/12841; Will watch.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-460239298
https://github.com/scverse/scanpy/pull/403#issuecomment-460239298:88,Usability,learn,learn,88,Similar pull request exists already in sklearn.; https://github.com/scikit-learn/scikit-learn/pull/12841; Will watch.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-460239298
https://github.com/scverse/scanpy/pull/403#issuecomment-573320770:83,Usability,learn,learn,83,"Hm, it was decided to suspend this pr earlier.; There is an analogous pr in scikit-learn, but i'm not sure it will got forward.; I'm not sure what to do with this pr...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-573320770
https://github.com/scverse/scanpy/pull/403#issuecomment-577471793:179,Usability,learn,learn,179,"That's still the case (at least for randomized PCA @Koncopd linked above), though it looks like there may be a another path forward using other solvers: https://github.com/scikit-learn/scikit-learn/issues/12794. Still needs an implementation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-577471793
https://github.com/scverse/scanpy/pull/403#issuecomment-577471793:192,Usability,learn,learn,192,"That's still the case (at least for randomized PCA @Koncopd linked above), though it looks like there may be a another path forward using other solvers: https://github.com/scikit-learn/scikit-learn/issues/12794. Still needs an implementation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-577471793
https://github.com/scverse/scanpy/pull/403#issuecomment-581727727:1634,Energy Efficiency,efficient,efficient,1634,"You could just add a `sparse` argument to `pca`. If True, just call this function instead of scikit-learn's PCA:. ```; def sparse_pca(X,npcs,mu = None):; # X -- scipy sparse data matrix; # npcs -- number of principal components; # mu -- precomputed feature means. if None, calculates them from X. # compute mean of data features; if mu is None: ; mu = X.mean(0).A.flatten()[None,:]. # dot product operator for the means; mmat = mdot = mu.dot ; # dot product operator for the transposed means; mhmat = mhdot = mu.T.dot ; # dot product operator for the data; Xmat = Xdot = X.dot ; # dot product operator for the transposed data; XHmat = XHdot = X.T.conj().dot ; # dot product operator for a vector of ones; ones = np.ones(X.shape[0])[None,:].dot . # modify the matrix/vector dot products to subtract the means; def matvec(x): ; return Xdot(x) - mdot(x); def matmat(x): ; return Xmat(x) - mmat(x); def rmatvec(x): ; return XHdot(x) - mhdot(ones(x)); def rmatmat(x): ; return XHmat(x) - mhmat(ones(x)); ; # construct the LinearOperator; XL = sp.sparse.linalg.LinearOperator(matvec = matvec, dtype = X.dtype,; matmat = matmat,; shape = X.shape,; rmatvec = rmatvec, rmatmat = rmatmat); ; u,s,v = sp.sparse.linalg.svds(XL,solver='arpack',k=npcs); ; # i like my eigenvalues sorted in decreasing order; idx = np.argsort(-s); S = np.diag(s[idx]); # principal components; pcs = u[:,idx].dot(S) ; # equivalent to PCA.components_ in sklearn ; components_ = v[idx,:] ; return pcs,components_; ```. This only works for the `arpack` solver. It's a bit slower than PCA on dense matrices (since arpack is slower than randomized), but it's super memory efficient.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-581727727
https://github.com/scverse/scanpy/pull/403#issuecomment-581727727:100,Usability,learn,learn,100,"You could just add a `sparse` argument to `pca`. If True, just call this function instead of scikit-learn's PCA:. ```; def sparse_pca(X,npcs,mu = None):; # X -- scipy sparse data matrix; # npcs -- number of principal components; # mu -- precomputed feature means. if None, calculates them from X. # compute mean of data features; if mu is None: ; mu = X.mean(0).A.flatten()[None,:]. # dot product operator for the means; mmat = mdot = mu.dot ; # dot product operator for the transposed means; mhmat = mhdot = mu.T.dot ; # dot product operator for the data; Xmat = Xdot = X.dot ; # dot product operator for the transposed data; XHmat = XHdot = X.T.conj().dot ; # dot product operator for a vector of ones; ones = np.ones(X.shape[0])[None,:].dot . # modify the matrix/vector dot products to subtract the means; def matvec(x): ; return Xdot(x) - mdot(x); def matmat(x): ; return Xmat(x) - mmat(x); def rmatvec(x): ; return XHdot(x) - mhdot(ones(x)); def rmatmat(x): ; return XHmat(x) - mhmat(ones(x)); ; # construct the LinearOperator; XL = sp.sparse.linalg.LinearOperator(matvec = matvec, dtype = X.dtype,; matmat = matmat,; shape = X.shape,; rmatvec = rmatvec, rmatmat = rmatmat); ; u,s,v = sp.sparse.linalg.svds(XL,solver='arpack',k=npcs); ; # i like my eigenvalues sorted in decreasing order; idx = np.argsort(-s); S = np.diag(s[idx]); # principal components; pcs = u[:,idx].dot(S) ; # equivalent to PCA.components_ in sklearn ; components_ = v[idx,:] ; return pcs,components_; ```. This only works for the `arpack` solver. It's a bit slower than PCA on dense matrices (since arpack is slower than randomized), but it's super memory efficient.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-581727727
https://github.com/scverse/scanpy/issues/405#issuecomment-470943686:1658,Availability,error,error,1658,"> Hi, no worries! I tried that but by explicitly stating ‘use_raw=True’ but it did not change the outcome. From: Fidel Ramirez <notifications@github.com> Reply-To: theislab/scanpy <reply@reply.github.com> Date: Monday, January 7, 2019 at 11:16 AM To: theislab/scanpy <scanpy@noreply.github.com> Cc: ""Heymann, Jurgen (NIH/NIDDK) [E]"" <heymannj@niddk.nih.gov>, Author <author@noreply.github.com> Subject: Re: [theislab/scanpy] sc.pl.stacked_violin: IndexError, list index out of range (#405) Hi, sorry for the late reply. Given that the function works for some mg genes but not for other, this usually indicates that the gene may not be in the matrix. Can you try to set `use_raw=True` just to check if this is the issue (although use_raw should be True by default). Still, very suspicious that it works with with other functions like matrixplot.; > On Thu, Dec 27, 2018 at 9:07 PM Alex Wolf ***@***.***> wrote: @fidelram <https://github.com/fidelram> Could it be that stacked_violin doesn't fully account for .raw? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-450221575)>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEu_1ftSP-OSKeDQYWV8Eu0-oRt6aXBAks5u9Sh_gaJpZM4ZiTv5> .; > — You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-451988385)>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AioIiKYX4lsLgg91sMNygZWO1ALRDzsqks5vA3KmgaJpZM4ZiTv5>. Same error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470943686
https://github.com/scverse/scanpy/issues/405#issuecomment-470945339:222,Availability,error,error,222,> @fidelram Thank you for your suggestions! The example data in Scanpy worked without flaw. I will go over my code again!. Actually I solved this problem by adding more markers in the marker gene list. ; Alternatively The error will be gone if I `swap_axes=True`; Interesting,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470945339
https://github.com/scverse/scanpy/issues/405#issuecomment-471151481:27,Availability,error,error,27,"I'm also getting this list error, but @brianpenghe 's suggestion of using `swap_axes=True` also seems to have fixed the problem. At least it shows a plot now, although not sure if its correct yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471151481
https://github.com/scverse/scanpy/issues/405#issuecomment-471159340:51,Availability,error,error,51,@outlace Did you try adding more marker genes? The error is gone if you have a large number of marker genes to plot in my case.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471159340
https://github.com/scverse/scanpy/issues/405#issuecomment-471238684:92,Modifiability,variab,variable,92,Just made a pull request that fixes this issue. @brianpenghe . I did some debugging and the variable `num_rows` was incorrectly calculated only when `swap_axes==False` on line 880 of `_anndata.py`. Instead of `num_rows = len(categories)` it should be `num_rows = len(var_names)` . If you make that small change in your _anndata.py in `~/anaconda3/lib/site-packages/scanpy/plotting/_anndata.py` then recompile the packages using `python -m compileall .` and restart python it should work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471238684
https://github.com/scverse/scanpy/pull/406#issuecomment-450268629:249,Usability,simpl,simply,249,"@fidelram FYI, this defines an explicit plotting submodule in `plotting/__init__.py`, which also contains the docs for it. There is no need to reexport to `api/pl.py` anymore. Everything is backwards compat and if you want to use new functionality, simply `import scanpy` instead of `import scanpy.api`...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450268629
https://github.com/scverse/scanpy/pull/406#issuecomment-450485020:16,Security,access,access,16,can you give me access to https://icb-scanpy.readthedocs-hosted.com?. I just have access to the public readthedocs.org,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450485020
https://github.com/scverse/scanpy/pull/406#issuecomment-450485020:82,Security,access,access,82,can you give me access to https://icb-scanpy.readthedocs-hosted.com?. I just have access to the public readthedocs.org,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450485020
https://github.com/scverse/scanpy/pull/406#issuecomment-450768851:5,Testability,test,tested,5,"I've tested this quite a bit in the past 5 days and am merging it into master. In essence, it's a superficial change.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450768851
https://github.com/scverse/scanpy/pull/406#issuecomment-450818246:476,Deployability,update,update,476,"> I sent you an invitation for readthedocs.com about 2 months ago already - I just resent it. :). Well, doesn’t seem like it worked in the past: What I got now was not an invitation that I needed to click, but simply a notification that I’m now member of the team on rtd.com (which I wasn’t before). The changes look good! I would however prefer to do things via `.. include::` instead of duplicating code for the `scanpy` and `scanpy.api` sections. Except if you plan to not update the `scanpy.api` module and docs section.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246
https://github.com/scverse/scanpy/pull/406#issuecomment-450818246:210,Usability,simpl,simply,210,"> I sent you an invitation for readthedocs.com about 2 months ago already - I just resent it. :). Well, doesn’t seem like it worked in the past: What I got now was not an invitation that I needed to click, but simply a notification that I’m now member of the team on rtd.com (which I wasn’t before). The changes look good! I would however prefer to do things via `.. include::` instead of duplicating code for the `scanpy` and `scanpy.api` sections. Except if you plan to not update the `scanpy.api` module and docs section.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246
https://github.com/scverse/scanpy/pull/406#issuecomment-450877926:28,Deployability,update,update,28,"> Except if you plan to not update the scanpy.api module and docs section. Yes, that's the plan. `scanpy.api` is completely phased out an simply there for backwards compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926
https://github.com/scverse/scanpy/pull/406#issuecomment-450877926:138,Usability,simpl,simply,138,"> Except if you plan to not update the scanpy.api module and docs section. Yes, that's the plan. `scanpy.api` is completely phased out an simply there for backwards compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926
https://github.com/scverse/scanpy/issues/407#issuecomment-451494959:179,Usability,feedback,feedback,179,"This should be fixed via: https://github.com/theislab/scanpy/issues/407. We're super happy if you check out the new: https://scanpy.readthedocs.io/en/latest/api/ and give us your feedback! We know that we still have an issue with the return sections, which was introduced in the past couple of months as we changed the docs generator. We're working on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407#issuecomment-451494959
https://github.com/scverse/scanpy/issues/407#issuecomment-451605378:109,Usability,responsiv,responsive,109,The new documentation index looks great! It's exactly what I was thinking about! Thanks so much for being so responsive!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/407#issuecomment-451605378
https://github.com/scverse/scanpy/issues/408#issuecomment-450882561:4,Usability,simpl,simply,4,"Hm, simply removing `.. automodule:: scanpy` is not possible in the case of `scanpy/plotting/__init__.py` as then sphinx doesn't seem to know anymore where all the `pl.*` functions come from. Also, `docs/api/index.rst` renders completely fine: https://scanpy.readthedocs.io/en/latest/api/index.html. The problem is with `scanpy/api/__init__.py` (which doesn't contain `..automodule::`, as we're just documenting the functions defined in that directory) and `scanpy/plotting/__init__.py` (which does contain it, as we're documenting 'scanpy-level' functions).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408#issuecomment-450882561
https://github.com/scverse/scanpy/issues/408#issuecomment-450887824:545,Usability,simpl,simply,545,"I see! OK, so `.. automodule` [doesn’t by default include the members](http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html), and we don’t have [`autodoc_default_options`](http://www.sphinx-doc.org/en/master/usage/extensions/autodoc.html#confval-autodoc_default_options) set. > All three directives [(`automodule` and so on)] will by default only insert the docstring of the object itself. However I don’t understand what you mean by. > as then sphinx doesn't seem to know anymore where all the pl.* functions come from. So will it simply not link them? Because that can have other reasons as well…",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/408#issuecomment-450887824
https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:136,Availability,error,error,136,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:1600,Availability,error,error,1600,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:1879,Availability,error,error,1879,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:1627,Deployability,Update,Update,1627,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:1717,Performance,perform,performing,1717,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140
https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729:115,Availability,error,error,115,@falexwolf This issue still persists in version 1.9.1. and the work around suggested by @Xparx results in the same error that @haskankaya has reported. Any advice on how to get around this or a potential fix?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729
https://github.com/scverse/scanpy/issues/415#issuecomment-452283384:89,Testability,test,test,89,"These appear to be consistent, simple changes and I assume they would be covered by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_highly_variable_genes.py. If you have any doubts about this, let's discuss before making a PR. Otherwise, I'm happy if you move forward with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415#issuecomment-452283384
https://github.com/scverse/scanpy/issues/415#issuecomment-452283384:149,Testability,test,tests,149,"These appear to be consistent, simple changes and I assume they would be covered by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_highly_variable_genes.py. If you have any doubts about this, let's discuss before making a PR. Otherwise, I'm happy if you move forward with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415#issuecomment-452283384
https://github.com/scverse/scanpy/issues/415#issuecomment-452283384:31,Usability,simpl,simple,31,"These appear to be consistent, simple changes and I assume they would be covered by this test: https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_highly_variable_genes.py. If you have any doubts about this, let's discuss before making a PR. Otherwise, I'm happy if you move forward with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/415#issuecomment-452283384
https://github.com/scverse/scanpy/issues/418#issuecomment-453006714:275,Testability,test,test,275,"@Xparx Thanks for reporting the problem an a potential solution. . Each plotting function has a save parameter which does:; ```; pl.savefig(filename, dpi=dpi, bbox_inches='tight'); ```; So, instead of calling `fig.savefig()`, what you can do in your example is to add `save='test.png'`:. ```; sc.pl.matrixplot(adata, save='test.png', var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714
https://github.com/scverse/scanpy/issues/418#issuecomment-453006714:323,Testability,test,test,323,"@Xparx Thanks for reporting the problem an a potential solution. . Each plotting function has a save parameter which does:; ```; pl.savefig(filename, dpi=dpi, bbox_inches='tight'); ```; So, instead of calling `fig.savefig()`, what you can do in your example is to add `save='test.png'`:. ```; sc.pl.matrixplot(adata, save='test.png', var_names=genes_ranked_by_loading_in_PC[:topg], groupby='hpf', use_raw=None, cmap='RdBu_r', swap_axes=True); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/418#issuecomment-453006714
https://github.com/scverse/scanpy/issues/419#issuecomment-453012463:224,Testability,test,testing,224,"All plotting functions should return an ax or an ax list if `show=False`. `_rank_genes_groups_plot` returns whatever the internally called function returns (which could be tracksplot or heatmap etc). However, I don't recall testing this output in all cases. . Can you provide a non working example using the test data? Here you can see how to use one of the test datasets: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. I think that @falexwolf can comment on the original reason to set `show=False` to return the axes. . I agree with @Xparx that is more standard to always return the axes as you usually don't dig into the parameter list for this functionality. However, changing this behaviour now could break some code so I don't know if the benefits are greater than the drawbacks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463
https://github.com/scverse/scanpy/issues/419#issuecomment-453012463:308,Testability,test,test,308,"All plotting functions should return an ax or an ax list if `show=False`. `_rank_genes_groups_plot` returns whatever the internally called function returns (which could be tracksplot or heatmap etc). However, I don't recall testing this output in all cases. . Can you provide a non working example using the test data? Here you can see how to use one of the test datasets: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. I think that @falexwolf can comment on the original reason to set `show=False` to return the axes. . I agree with @Xparx that is more standard to always return the axes as you usually don't dig into the parameter list for this functionality. However, changing this behaviour now could break some code so I don't know if the benefits are greater than the drawbacks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463
https://github.com/scverse/scanpy/issues/419#issuecomment-453012463:358,Testability,test,test,358,"All plotting functions should return an ax or an ax list if `show=False`. `_rank_genes_groups_plot` returns whatever the internally called function returns (which could be tracksplot or heatmap etc). However, I don't recall testing this output in all cases. . Can you provide a non working example using the test data? Here you can see how to use one of the test datasets: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. I think that @falexwolf can comment on the original reason to set `show=False` to return the axes. . I agree with @Xparx that is more standard to always return the axes as you usually don't dig into the parameter list for this functionality. However, changing this behaviour now could break some code so I don't know if the benefits are greater than the drawbacks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453012463
https://github.com/scverse/scanpy/issues/419#issuecomment-453587853:56,Testability,test,test,56,"Hi thinks for the answer and thanks for the link on the test data and visualization, I will try to use that going forward. I will cook up a non working example if needed, however just looking at the code https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302 there is missing return statements for a few of the plotting functions in the `_rank_genes_groups_plot` unless I missed something they will then not return an axes?. The [heatmap]( https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044) function itself return an axis but there is no return statement from the `_rank_genes_groups_plot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453587853
https://github.com/scverse/scanpy/issues/419#issuecomment-453606922:153,Testability,test,test,153,"I will take a look. On Fri, Jan 11, 2019 at 6:08 PM Andreas <notifications@github.com> wrote:. > Hi thinks for the answer and thanks for the link on the test data and; > visualization, I will try to use that going forward.; >; > I will cook up a non working example if needed, however just looking at; > the code; > https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/__init__.py#L302; > there is missing return statements for a few of the plotting functions in; > the _rank_genes_groups_plot unless I missed something they will then not; > return an axes?; >; > The heatmap; > <https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L1044>; > function itself return an axis but there is no return statement from the; > _rank_genes_groups_plot.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/419#issuecomment-453587853>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1aJAKobdjZYdCil5CcJ3vJz8h-2nks5vCMUmgaJpZM4Z4pAD>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453606922
https://github.com/scverse/scanpy/issues/419#issuecomment-453876840:437,Safety,avoid,avoid,437,"@falexwolf Thanks for the explanation.; I see now that it's an issue of how the package should be used, i.e. the philosophy behind your api, and I seem to have tried to use it in a different perhaps more low level way. I will look in to using more low level functions/modules if I need it and work with your original intended workflow which i think make sense. I have missed the whole settings functionality which seems really useful to avoid some of the issues I have had.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453876840
https://github.com/scverse/scanpy/issues/419#issuecomment-453980627:666,Safety,avoid,avoid,666,"Nevertheless, some of the plotting functions are returning ax by default. I; will need to change that. On Mon, Jan 14, 2019 at 12:44 AM Andreas <notifications@github.com> wrote:. > @falexwolf <https://github.com/falexwolf> Thanks for the explanation.; > I see now that it's an issue of how the package should be used, i.e. the; > philosophy behind your api, and I seem to have tried to use it in a; > different perhaps more low level way. I will look in to using more low; > level functions/modules if I need it and work with your original intended; > workflow which i think make sense. I have missed the whole settings; > functionality which seems really useful to avoid some of the issues I have; > had.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/419#issuecomment-453876840>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1YINwJpe8e_BJavkUulUdzp6IMItks5vC8TLgaJpZM4Z4pAD>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/419#issuecomment-453980627
https://github.com/scverse/scanpy/issues/420#issuecomment-453067108:62,Deployability,update,updated,62,"I think that the `all_data.uns['leiden_colors']` list is only updated if the new number of clusters is bigger than the previous cluster number as the goal is to avoid missing colors. . In you use the the `palette` argument, the color list will always be updated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108
https://github.com/scverse/scanpy/issues/420#issuecomment-453067108:254,Deployability,update,updated,254,"I think that the `all_data.uns['leiden_colors']` list is only updated if the new number of clusters is bigger than the previous cluster number as the goal is to avoid missing colors. . In you use the the `palette` argument, the color list will always be updated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108
https://github.com/scverse/scanpy/issues/420#issuecomment-453067108:161,Safety,avoid,avoid,161,"I think that the `all_data.uns['leiden_colors']` list is only updated if the new number of clusters is bigger than the previous cluster number as the goal is to avoid missing colors. . In you use the the `palette` argument, the color list will always be updated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453067108
https://github.com/scverse/scanpy/issues/420#issuecomment-453700295:161,Availability,avail,available,161,"Yes, the 'leiden_colors' field in `.uns` will only be updated if needed, i.e., if the number of categories in the `leiden` field in `.obs` exceeds the number of available colors. As Fidel mentions, passing `palette` will automatically trigger resetting the colors according to the chosen palette.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295
https://github.com/scverse/scanpy/issues/420#issuecomment-453700295:54,Deployability,update,updated,54,"Yes, the 'leiden_colors' field in `.uns` will only be updated if needed, i.e., if the number of categories in the `leiden` field in `.obs` exceeds the number of available colors. As Fidel mentions, passing `palette` will automatically trigger resetting the colors according to the chosen palette.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295
https://github.com/scverse/scanpy/issues/421#issuecomment-453896450:819,Modifiability,variab,variables,819,"Just load any data, e.g. pbmc3k, then do `sc.pp.calculate_qc_metrics(adata, percent_top=[])` which gives the following: (this is on v1.3.7, haven't tested on earlier versions). ```; In [5]: sc.pp.calculate_qc_metrics(adata, percent_top=[]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-385-66af52bcd3f3> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, percent_top=[]). ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, inplace); 70 obs_metrics[""log1p_total_{expr_type}""] = np.log1p(; 71 obs_metrics[""total_{expr_type}""]); ---> 72 proportions = top_segment_proportions(X, percent_top); 73 # Since there are local loop variables, formatting must occur in their scope; 74 # Probably worth looking into a python3.5 compatable way to make this better. ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in top_segment_proportions(mtx, ns); 182 if not isspmatrix_csr(mtx):; 183 mtx = csr_matrix(mtx); --> 184 return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, ns); 185 else:; 186 return top_segment_proportions_dense(mtx, ns). IndexError: index -1 is out of bounds for axis 0 with size 0; ```. Not sure if there are other impacts, but I think perhaps basically one just need to check `percent_top` before calling `top_segment_proportions()` at line 72.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450
https://github.com/scverse/scanpy/issues/421#issuecomment-453896450:5,Performance,load,load,5,"Just load any data, e.g. pbmc3k, then do `sc.pp.calculate_qc_metrics(adata, percent_top=[])` which gives the following: (this is on v1.3.7, haven't tested on earlier versions). ```; In [5]: sc.pp.calculate_qc_metrics(adata, percent_top=[]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-385-66af52bcd3f3> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, percent_top=[]). ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, inplace); 70 obs_metrics[""log1p_total_{expr_type}""] = np.log1p(; 71 obs_metrics[""total_{expr_type}""]); ---> 72 proportions = top_segment_proportions(X, percent_top); 73 # Since there are local loop variables, formatting must occur in their scope; 74 # Probably worth looking into a python3.5 compatable way to make this better. ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in top_segment_proportions(mtx, ns); 182 if not isspmatrix_csr(mtx):; 183 mtx = csr_matrix(mtx); --> 184 return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, ns); 185 else:; 186 return top_segment_proportions_dense(mtx, ns). IndexError: index -1 is out of bounds for axis 0 with size 0; ```. Not sure if there are other impacts, but I think perhaps basically one just need to check `percent_top` before calling `top_segment_proportions()` at line 72.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450
https://github.com/scverse/scanpy/issues/421#issuecomment-453896450:148,Testability,test,tested,148,"Just load any data, e.g. pbmc3k, then do `sc.pp.calculate_qc_metrics(adata, percent_top=[])` which gives the following: (this is on v1.3.7, haven't tested on earlier versions). ```; In [5]: sc.pp.calculate_qc_metrics(adata, percent_top=[]) ; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-385-66af52bcd3f3> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, percent_top=[]). ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, inplace); 70 obs_metrics[""log1p_total_{expr_type}""] = np.log1p(; 71 obs_metrics[""total_{expr_type}""]); ---> 72 proportions = top_segment_proportions(X, percent_top); 73 # Since there are local loop variables, formatting must occur in their scope; 74 # Probably worth looking into a python3.5 compatable way to make this better. ~/miniconda2/envs/py3/lib/python3.6/site-packages/scanpy/preprocessing/qc.py in top_segment_proportions(mtx, ns); 182 if not isspmatrix_csr(mtx):; 183 mtx = csr_matrix(mtx); --> 184 return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, ns); 185 else:; 186 return top_segment_proportions_dense(mtx, ns). IndexError: index -1 is out of bounds for axis 0 with size 0; ```. Not sure if there are other impacts, but I think perhaps basically one just need to check `percent_top` before calling `top_segment_proportions()` at line 72.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453896450
https://github.com/scverse/scanpy/issues/421#issuecomment-453899907:92,Availability,error,errors,92,"Just checking to make sure we're working with the same data, since there could be different errors coming from that. The PR should do the right thing on `pbmc3k`. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453899907
https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:629,Availability,error,error,629,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645
https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:166,Modifiability,variab,variable,166,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645
https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:144,Performance,load,loading,144,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645
https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:210,Performance,load,load,210,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645
https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:203,Usability,simpl,simply,203,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645
https://github.com/scverse/scanpy/issues/422#issuecomment-456034330:221,Performance,perform,performance,221,"OK, thank you for the explanation! Let us think about it. There are a couple of sanity checks running in the background, which are easy to call at the beginning of the plotting functions, for instance, if they don't cost performance. E.g., there was a standard `adata._sanitize()` call in all the plotting functions. Is it still there, @fidelram? If not, no problem... We should have a solution that essentially doesn't require writing new code. Also, what are your thoughts, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-456034330
https://github.com/scverse/scanpy/issues/422#issuecomment-456034330:80,Safety,sanity check,sanity checks,80,"OK, thank you for the explanation! Let us think about it. There are a couple of sanity checks running in the background, which are easy to call at the beginning of the plotting functions, for instance, if they don't cost performance. E.g., there was a standard `adata._sanitize()` call in all the plotting functions. Is it still there, @fidelram? If not, no problem... We should have a solution that essentially doesn't require writing new code. Also, what are your thoughts, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-456034330
https://github.com/scverse/scanpy/issues/422#issuecomment-766324476:425,Testability,test,test,425,"This seems to be working now. As these seem equivalent enough:. ```python; import scanpy as sc, pandas as pd. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). pbmc.obs[""louvain_int""] = pd.Categorical(pbmc.obs[""louvain""].cat.codes); sc.pl.heatmap(pbmc, genes, groupby=""louvain_int""); sc.pl.heatmap(pbmc, genes, groupby=""louvain""); ```. Not sure if this ever got a test case though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-766324476
https://github.com/scverse/scanpy/pull/423#issuecomment-453688357:131,Safety,redund,redundancy,131,"No, you're right. It's fine to continue having this. Initially, I wanted to get rid of it at some point... but also numpy has this redundancy between many array attributes which pop up as numpy level functions everywhere. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/423#issuecomment-453688357
https://github.com/scverse/scanpy/pull/424#issuecomment-453959469:50,Modifiability,extend,extended,50,"@ivirshup Do you mind adding as part of the PR an extended description of the function? I don't think that everyone is familiar with `calculateQCMetrics` and thus, the output of this function is unclear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-453959469
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:235,Deployability,Update,Updated,235,"It's the right function, but those docs are out of date (current version is `v1.10.1`). There's an up to date PDF on their bioconductor page, but I don't think I can link to the function from there. How about this: <details>; <summary>Updated docstring</summary>. ```python; def calculate_qc_metrics(adata, expr_type=""counts"", var_type=""genes"", qc_vars=(),; percent_top=(50, 100, 200, 500), inplace=False):; """"""; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:1485,Deployability,update,updates,1485,"ta object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variabes in ; `qc_vars`.; * `pct_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which ; are mitochondrial. Variable level metrics include:. * `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; * `mean_{expr_type}`; E.g. ""mean counts"". Mean expression over all cells.; * `n_cells_by_{expr_type}`; E.g. ""n_cells_by_counts"". Number of cells this expression is ; measu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:626,Energy Efficiency,efficient,efficient,626,"It's the right function, but those docs are out of date (current version is `v1.10.1`). There's an up to date PDF on their bioconductor page, but I don't think I can link to the function from there. How about this: <details>; <summary>Updated docstring</summary>. ```python; def calculate_qc_metrics(adata, expr_type=""counts"", var_type=""genes"", qc_vars=(),; percent_top=(50, 100, 200, 500), inplace=False):; """"""; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:1414,Integrability,Depend,Depending,1414,"rol metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variabes in ; `qc_vars`.; * `pct_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which ; are mitochondrial. Variable level metrics include:. * `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; * `mean_{expr_type}`; E.g. ""mean counts"". Mean expression over all cells.; * `n_cells_by_{expr_type}`; E.g. ""n_c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:904,Modifiability,variab,variables,904,"It's the right function, but those docs are out of date (current version is `v1.10.1`). There's an up to date PDF on their bioconductor page, but I don't think I can link to the function from there. How about this: <details>; <summary>Updated docstring</summary>. ```python; def calculate_qc_metrics(adata, expr_type=""counts"", var_type=""genes"", qc_vars=(),; percent_top=(50, 100, 200, 500), inplace=False):; """"""; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""to",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:1019,Modifiability,variab,variables,1019,"ose docs are out of date (current version is `v1.10.1`). There's an up to date PDF on their bioconductor page, but I don't think I can link to the function from there. How about this: <details>; <summary>Updated docstring</summary>. ```python; def calculate_qc_metrics(adata, expr_type=""counts"", var_type=""genes"", qc_vars=(),; percent_top=(50, 100, 200, 500), inplace=False):; """"""; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section ; Returns for specifics. Largely based on `calculateQCMetrics` from scater; [McCarthy17]_. Currently is most efficient on a sparse CSR or dense matrix. Parameters; ----------; adata : :class:`~anndata.AnnData`; Annotated data matrix.; expr_type : `str`, optional (default: `""counts""`); Name of kind of values in X.; var_type : `str`, optional (default: `""genes""`); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:2046,Modifiability,variab,variabes,2046,"); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variabes in ; `qc_vars`.; * `pct_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which ; are mitochondrial. Variable level metrics include:. * `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; * `mean_{expr_type}`; E.g. ""mean counts"". Mean expression over all cells.; * `n_cells_by_{expr_type}`; E.g. ""n_cells_by_counts"". Number of cells this expression is ; measured in.; * `pct_dropout_by_{expr_type}`; E.g. ""pct_dropout_by_counts"". Percentage of cells this feature does ; not appear in.; . Example; -------; Calculate qc metrics for visualization. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.calculate_qc_metrics(adata, inplace=True); >>> sns.jointplot(adata.obs, ""log1p_total_counts"", ""log1p_n_genes_by_counts"", kind=""hex""); """"""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454024688:2219,Modifiability,Variab,Variable,2219,"); The kind of thing the variables are.; qc_vars : `Container`, optional (default: `()`); Keys for boolean columns of `.var` which identify variables you could ; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top : `Container[int]`, optional (default: `(50, 100, 200, 500)`); Which proportions of top genes to cover. If empty or `None` don't; calculate.; inplace : bool, optional (default: `False`); Whether to place calculated metrics in `.obs` and `.var`. Returns; -------; Union[NoneType, Tuple[pd.DataFrame, pd.DataFrame]]; Depending on `inplace` returns calculated metrics (`pd.DataFrame`) or; updates `adata`'s `obs` and `var`. Observation level metrics include:. * `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts ; in a cell.; * `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; * `pct_{expr_type}_in_top_{n}_{var_type}` - for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts ; for 50 most expressed genes in a cell.; * `total_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variabes in ; `qc_vars`.; * `pct_{expr_type}_{qc_var}` - for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which ; are mitochondrial. Variable level metrics include:. * `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; * `mean_{expr_type}`; E.g. ""mean counts"". Mean expression over all cells.; * `n_cells_by_{expr_type}`; E.g. ""n_cells_by_counts"". Number of cells this expression is ; measured in.; * `pct_dropout_by_{expr_type}`; E.g. ""pct_dropout_by_counts"". Percentage of cells this feature does ; not appear in.; . Example; -------; Calculate qc metrics for visualization. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.calculate_qc_metrics(adata, inplace=True); >>> sns.jointplot(adata.obs, ""log1p_total_counts"", ""log1p_n_genes_by_counts"", kind=""hex""); """"""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454024688
https://github.com/scverse/scanpy/pull/424#issuecomment-454026591:17,Deployability,update,updated,17,I think that the updated docstring is much better.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/424#issuecomment-454026591
https://github.com/scverse/scanpy/pull/425#issuecomment-456024916:469,Modifiability,variab,variables,469,"Sorry for the late response! This seems to have come just after I went through the issues last weekend...; ; It looks great! :smile:. Some small notes:; * `sc.pl.correlation` should be `sc.pl.correlation_matrix` (there will be other ""correlation plots"", just think of the typical bivariate scatter plot...); * `sc.tl.dendrogram` suggests it is a function that can be generically applied to any hierarchical clustering of observations. We could even have dendrograms of variables, right? I'm fine with putting it into the API with just that generic name, but it would be good to have a `.. note::` in the docstring, which states that this does a very specific thing: computing hierarchical clustering on predefined groups using Pearson correlation as a distance metric; I know that this is super standard in the field, but we should nonetheless be very clear about it. In particular as Scanpy grows and we extend its functionality to other methods for grouping observations, structuring their relations (e.g. hierarchical clustering with another distance metric or so, or something that we don't think of at this stage), I fear that people might start to get confused. Even now, they don't know what, for instance, the relation of `tl.dendrogram` to PAGA is: instead of correlating cluster mediod vectors, PAGA computes the connectivity between clusters in the underlying graph. Also, it is not restricted to a tree. It would be great to have a note like that (I can also put it; also, I wanted to rewrite the PAGA docstring anyways and I'll make a link to `tl.dendrogram`...). Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456024916
https://github.com/scverse/scanpy/pull/425#issuecomment-456024916:905,Modifiability,extend,extend,905,"Sorry for the late response! This seems to have come just after I went through the issues last weekend...; ; It looks great! :smile:. Some small notes:; * `sc.pl.correlation` should be `sc.pl.correlation_matrix` (there will be other ""correlation plots"", just think of the typical bivariate scatter plot...); * `sc.tl.dendrogram` suggests it is a function that can be generically applied to any hierarchical clustering of observations. We could even have dendrograms of variables, right? I'm fine with putting it into the API with just that generic name, but it would be good to have a `.. note::` in the docstring, which states that this does a very specific thing: computing hierarchical clustering on predefined groups using Pearson correlation as a distance metric; I know that this is super standard in the field, but we should nonetheless be very clear about it. In particular as Scanpy grows and we extend its functionality to other methods for grouping observations, structuring their relations (e.g. hierarchical clustering with another distance metric or so, or something that we don't think of at this stage), I fear that people might start to get confused. Even now, they don't know what, for instance, the relation of `tl.dendrogram` to PAGA is: instead of correlating cluster mediod vectors, PAGA computes the connectivity between clusters in the underlying graph. Also, it is not restricted to a tree. It would be great to have a note like that (I can also put it; also, I wanted to rewrite the PAGA docstring anyways and I'll make a link to `tl.dendrogram`...). Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456024916
https://github.com/scverse/scanpy/pull/425#issuecomment-456024916:1497,Modifiability,rewrite,rewrite,1497,"Sorry for the late response! This seems to have come just after I went through the issues last weekend...; ; It looks great! :smile:. Some small notes:; * `sc.pl.correlation` should be `sc.pl.correlation_matrix` (there will be other ""correlation plots"", just think of the typical bivariate scatter plot...); * `sc.tl.dendrogram` suggests it is a function that can be generically applied to any hierarchical clustering of observations. We could even have dendrograms of variables, right? I'm fine with putting it into the API with just that generic name, but it would be good to have a `.. note::` in the docstring, which states that this does a very specific thing: computing hierarchical clustering on predefined groups using Pearson correlation as a distance metric; I know that this is super standard in the field, but we should nonetheless be very clear about it. In particular as Scanpy grows and we extend its functionality to other methods for grouping observations, structuring their relations (e.g. hierarchical clustering with another distance metric or so, or something that we don't think of at this stage), I fear that people might start to get confused. Even now, they don't know what, for instance, the relation of `tl.dendrogram` to PAGA is: instead of correlating cluster mediod vectors, PAGA computes the connectivity between clusters in the underlying graph. Also, it is not restricted to a tree. It would be great to have a note like that (I can also put it; also, I wanted to rewrite the PAGA docstring anyways and I'll make a link to `tl.dendrogram`...). Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456024916
https://github.com/scverse/scanpy/pull/425#issuecomment-456024916:852,Usability,clear,clear,852,"Sorry for the late response! This seems to have come just after I went through the issues last weekend...; ; It looks great! :smile:. Some small notes:; * `sc.pl.correlation` should be `sc.pl.correlation_matrix` (there will be other ""correlation plots"", just think of the typical bivariate scatter plot...); * `sc.tl.dendrogram` suggests it is a function that can be generically applied to any hierarchical clustering of observations. We could even have dendrograms of variables, right? I'm fine with putting it into the API with just that generic name, but it would be good to have a `.. note::` in the docstring, which states that this does a very specific thing: computing hierarchical clustering on predefined groups using Pearson correlation as a distance metric; I know that this is super standard in the field, but we should nonetheless be very clear about it. In particular as Scanpy grows and we extend its functionality to other methods for grouping observations, structuring their relations (e.g. hierarchical clustering with another distance metric or so, or something that we don't think of at this stage), I fear that people might start to get confused. Even now, they don't know what, for instance, the relation of `tl.dendrogram` to PAGA is: instead of correlating cluster mediod vectors, PAGA computes the connectivity between clusters in the underlying graph. Also, it is not restricted to a tree. It would be great to have a note like that (I can also put it; also, I wanted to rewrite the PAGA docstring anyways and I'll make a link to `tl.dendrogram`...). Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456024916
https://github.com/scverse/scanpy/pull/425#issuecomment-456065730:227,Modifiability,extend,extend,227,"@falexwolf thanks for the feedback. :). I agree with your comments on the `sc.tl.dendrogram`. Similar reasoning originally motivated me to separate and expose the implementation of the function. I expect that now, is easier to extend the creation of a correlation matrix to other methods and groupings as you suggest. Currently, by default `sc.tl.dendrogram` uses PCA by recycling the function used by `sc.tl.neighbors` (`tools._utils.choose_representation()`). Any other embedding in `.obsm` can be used (as is the case by `sc.tl.neighbors`. Also, any group of genes can be given as parameter . What tl.dendrogram does not do is to use the underlying network to compute a distance matrix as I think seurat does and apparently you also do in PAGA. . For me, what is important is that the plotting functions get the dendrogram data from `.uns` and thus the generation of the hierarchical clustering is separated and can be computed by any other method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456065730
https://github.com/scverse/scanpy/pull/425#issuecomment-456065730:152,Security,expose,expose,152,"@falexwolf thanks for the feedback. :). I agree with your comments on the `sc.tl.dendrogram`. Similar reasoning originally motivated me to separate and expose the implementation of the function. I expect that now, is easier to extend the creation of a correlation matrix to other methods and groupings as you suggest. Currently, by default `sc.tl.dendrogram` uses PCA by recycling the function used by `sc.tl.neighbors` (`tools._utils.choose_representation()`). Any other embedding in `.obsm` can be used (as is the case by `sc.tl.neighbors`. Also, any group of genes can be given as parameter . What tl.dendrogram does not do is to use the underlying network to compute a distance matrix as I think seurat does and apparently you also do in PAGA. . For me, what is important is that the plotting functions get the dendrogram data from `.uns` and thus the generation of the hierarchical clustering is separated and can be computed by any other method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456065730
https://github.com/scverse/scanpy/pull/425#issuecomment-456065730:26,Usability,feedback,feedback,26,"@falexwolf thanks for the feedback. :). I agree with your comments on the `sc.tl.dendrogram`. Similar reasoning originally motivated me to separate and expose the implementation of the function. I expect that now, is easier to extend the creation of a correlation matrix to other methods and groupings as you suggest. Currently, by default `sc.tl.dendrogram` uses PCA by recycling the function used by `sc.tl.neighbors` (`tools._utils.choose_representation()`). Any other embedding in `.obsm` can be used (as is the case by `sc.tl.neighbors`. Also, any group of genes can be given as parameter . What tl.dendrogram does not do is to use the underlying network to compute a distance matrix as I think seurat does and apparently you also do in PAGA. . For me, what is important is that the plotting functions get the dendrogram data from `.uns` and thus the generation of the hierarchical clustering is separated and can be computed by any other method.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-456065730
https://github.com/scverse/scanpy/pull/425#issuecomment-460068606:16,Availability,error,error,16,I am getting an error elsewhere that I want to revise before submitting a final version. Hopefully tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-460068606
https://github.com/scverse/scanpy/pull/425#issuecomment-460657479:40,Deployability,update,updated,40,I think it is ok to merge now. . I also updated some of the plotting functions to accept a `gene_symbol` column: . ![image](https://user-images.githubusercontent.com/4964309/52279718-85cb4f00-295a-11e9-99e9-f9b8648609a6.png). What is missing is `sc.pl.rank_genes_groups` and `sc.pl.violin` any volunteers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-460657479
https://github.com/scverse/scanpy/pull/425#issuecomment-462858876:55,Testability,log,logging,55,"Ah, sorry for being in the way here with the unrelated logging changes. Alex is currently a bit ill I learned, which is why he probably didn’t do it yet. I didn’t have time to review the whole thing, but if y’all want I can do that too",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876
https://github.com/scverse/scanpy/pull/425#issuecomment-462858876:102,Usability,learn,learned,102,"Ah, sorry for being in the way here with the unrelated logging changes. Alex is currently a bit ill I learned, which is why he probably didn’t do it yet. I didn’t have time to review the whole thing, but if y’all want I can do that too",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-462858876
https://github.com/scverse/scanpy/pull/425#issuecomment-463080680:153,Testability,log,logging,153,"Please go ahead!. On Tue, Feb 12, 2019 at 6:41 PM Philipp A. <notifications@github.com> wrote:. > Ah, sorry for being in the way here with the unrelated logging changes.; > Alex is currently a bit ill I learned, which is why he probably didn’t do; > it yet. I didn’t have time to review the whole thing, but if y’all want I; > can do that too; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-462858876>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RE9LYK4sL6sLFd586y_cpEBQKxwks5vMvzRgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680
https://github.com/scverse/scanpy/pull/425#issuecomment-463080680:203,Usability,learn,learned,203,"Please go ahead!. On Tue, Feb 12, 2019 at 6:41 PM Philipp A. <notifications@github.com> wrote:. > Ah, sorry for being in the way here with the unrelated logging changes.; > Alex is currently a bit ill I learned, which is why he probably didn’t do; > it yet. I didn’t have time to review the whole thing, but if y’all want I; > can do that too; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-462858876>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RE9LYK4sL6sLFd586y_cpEBQKxwks5vMvzRgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-463080680
https://github.com/scverse/scanpy/pull/425#issuecomment-473309434:99,Deployability,update,updated,99,Thanks a lot. All of these new features are what we need!. I notice that the tutorial has not been updated yet (such as sc.tl.filter_rank_genes_groups( ) and rna velocity function in https://github.com/theislab/scanpy/tree/master/scanpy/tools). I find these features occasionally. Could you add them in scanpy tutorial ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-473309434
https://github.com/scverse/scanpy/pull/425#issuecomment-474006729:28,Deployability,update,updated,28,"Recently, this tutorial was updated with what you need:; https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. You can find the link to that tutorial from; https://scanpy.readthedocs.io/en/latest/. On Fri, Mar 15, 2019 at 3:34 PM jiawen wang <notifications@github.com>; wrote:. > Thanks a lot. All of these new features are what we need!; >; > I notice that the tutorial has not been updated yet (such as; > sc.tl.filter_rank_genes_groups( ) and rna velocity function in; > https://github.com/theislab/scanpy/tree/master/scanpy/tools). I find; > these features occasionally. Could you add them in scanpy tutorial ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-473309434>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1S565VMCgOnXCQetV2R6_A1HONPZks5vW69qgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-474006729
https://github.com/scverse/scanpy/pull/425#issuecomment-474006729:411,Deployability,update,updated,411,"Recently, this tutorial was updated with what you need:; https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html. You can find the link to that tutorial from; https://scanpy.readthedocs.io/en/latest/. On Fri, Mar 15, 2019 at 3:34 PM jiawen wang <notifications@github.com>; wrote:. > Thanks a lot. All of these new features are what we need!; >; > I notice that the tutorial has not been updated yet (such as; > sc.tl.filter_rank_genes_groups( ) and rna velocity function in; > https://github.com/theislab/scanpy/tree/master/scanpy/tools). I find; > these features occasionally. Could you add them in scanpy tutorial ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/425#issuecomment-473309434>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1S565VMCgOnXCQetV2R6_A1HONPZks5vW69qgaJpZM4Z-M3d>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-474006729
https://github.com/scverse/scanpy/issues/426#issuecomment-454072095:143,Modifiability,layers,layers,143,"Yeah, AnnData doesn’t serialize arbitrary attributes to disk. I assume the output of `fit_transform` is cell×gene? Then you could do `all_data.layers['magic'] = ...`. If the output is `cell×y` with `y != n_genes` then you should do `all_data.obsm['magic'] = ...`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/426#issuecomment-454072095
https://github.com/scverse/scanpy/issues/428#issuecomment-456015073:355,Deployability,update,updated,355,Thank you very much for pointing me to this! What you assume is absolutely right! I just replaced the file. The previous file was created when there wasn't even a function `read_10x_mtx`... I added a section to the docstring describing how the file was produced: https://github.com/theislab/scanpy/commit/fcd125252c307b5ecc077ad0e69fa9d6a1106ebb. See the updated docs: https://scanpy.readthedocs.io/en/latest/api/scanpy.datasets.pbmc3k.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428#issuecomment-456015073
https://github.com/scverse/scanpy/issues/429#issuecomment-457869063:170,Usability,simpl,simpler,170,"@VolkerBergen, is this really important? I had the intend of allowing passing a precomputed `counts_per_cell` vector, but I think it wasn't really ever used... So, for a simpler function and cleaner code, it would be nice to get rid of it; as @Koncopd did for the new version. Any objections?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-457869063
https://github.com/scverse/scanpy/issues/429#issuecomment-460612249:724,Usability,simpl,simple,724,"I like @VolkerBergen's suggestion. On the other Hand, @LuckyMD uses the scran estimate of size factors for normalization. Processing something like that would need a `counts_per_cell` argument (which I'd call `normalization_factor` today, I guess). If one needs to manually compute the `counts_per_cell` before calling the function, then the whole convenience and purpose of the function is gone, though. So, I'd say the convenience of an argument `by_initial` absolutely outweighs the flexibility of an argument `normalization_factor` (`size_factor`). In case we have another size factor estimator in Scanpy, it will definitely not occur in `normalize_total` or `normalize_quantile` (the names already suggest that this is simple normalization) but in a new function `normalize_...`...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-460612249
https://github.com/scverse/scanpy/issues/429#issuecomment-460629186:343,Testability,log,logical,343,"I was wondering if using the initial `total_counts` versus the post-filtering `total_counts` really matter that much. In the end we typically only filter out genes that have very few counts, so that the difference between the initial and post-filtering `total_counts` should be minimal. Principally using pre-filtering values is probably more logical, although I'm not sure it really changes anything. I wonder how hard it would be to put scran's size factor calculation into python... that might be a good HiWi project.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-460629186
https://github.com/scverse/scanpy/issues/429#issuecomment-460689393:54,Usability,simpl,simply,54,"That's good to know! That means, `filter_genes` would simply annotate the genes kept just like `highly_variable_genes`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-460689393
https://github.com/scverse/scanpy/issues/429#issuecomment-469643226:90,Usability,simpl,simple,90,"@LuckyMD: Yes, scran's size factor calculation would be very nice-to-have and should be a simple task.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/429#issuecomment-469643226
https://github.com/scverse/scanpy/pull/430#issuecomment-456008629:136,Usability,simpl,simply,136,"Thank you! This is great and very helpful! :smile:. Yes, it would be nicer if the user were allowed to pass both. But isn't it possible simply by virtue of not passing `gene_symbols`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/430#issuecomment-456008629
https://github.com/scverse/scanpy/issues/432#issuecomment-498925141:20,Availability,error,error,20,I ran into the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-498925141
https://github.com/scverse/scanpy/issues/432#issuecomment-499145170:107,Availability,error,error,107,"I have larger number of cells than 50. but sc.tl.pca(adata, use_highly_variable_genes = False) resolved my error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-499145170
https://github.com/scverse/scanpy/issues/432#issuecomment-499561060:113,Modifiability,variab,variable,113,"Another option is to set fewer components to use in sc.tl.pca, option n_comps should be set to at most number of variable genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-499561060
https://github.com/scverse/scanpy/issues/434#issuecomment-456003799:273,Performance,load,loaded,273,"Well, but the amount of memory should be a lot smaller than if you used; ```; adata = sc.read('test.h5ad'); ```; There should not be any difference between `'r`' and `'r+'`, so that's intended behavior. If you open it in backed mode, everything except the data matrix gets loaded into memory (using the `h5py` package). It should use as little memory as your custom solution. If it doesn't, I'd be happy to go through more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456003799
https://github.com/scverse/scanpy/issues/434#issuecomment-456003799:95,Testability,test,test,95,"Well, but the amount of memory should be a lot smaller than if you used; ```; adata = sc.read('test.h5ad'); ```; There should not be any difference between `'r`' and `'r+'`, so that's intended behavior. If you open it in backed mode, everything except the data matrix gets loaded into memory (using the `h5py` package). It should use as little memory as your custom solution. If it doesn't, I'd be happy to go through more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456003799
https://github.com/scverse/scanpy/issues/434#issuecomment-456037752:96,Testability,test,test,96,"I've noticed this behavior too. Here's a couple examples:. ```python; # First, using a standard test dataset; In [1]: %load_ext memory_profiler . In [2]: import scanpy as sc . In [3]: adatas = [] . In [4]: adatas_backed = [] . In [5]: for i in range(10): ; ...: %memit adatas.append(sc.read(""data/pbmc3k_raw.h5ad"")) ; ...: ; peak memory: 223.52 MiB, increment: 48.47 MiB; peak memory: 275.66 MiB, increment: 52.14 MiB; peak memory: 319.36 MiB, increment: 43.71 MiB; peak memory: 361.41 MiB, increment: 42.04 MiB; peak memory: 403.64 MiB, increment: 42.24 MiB; peak memory: 446.02 MiB, increment: 42.37 MiB; peak memory: 488.57 MiB, increment: 42.56 MiB; peak memory: 530.31 MiB, increment: 41.74 MiB; peak memory: 573.53 MiB, increment: 43.21 MiB; peak memory: 615.81 MiB, increment: 42.29 MiB. In [6]: for i in range(10): ; ...: %memit adatas_backed.append(sc.read(""data/pbmc3k_raw.h5ad"", backed=""r"")) ; ...: ; peak memory: 658.04 MiB, increment: 42.07 MiB; peak memory: 700.22 MiB, increment: 42.19 MiB; peak memory: 742.49 MiB, increment: 42.27 MiB; peak memory: 784.62 MiB, increment: 42.14 MiB; peak memory: 827.00 MiB, increment: 42.38 MiB; peak memory: 869.21 MiB, increment: 42.21 MiB; peak memory: 911.36 MiB, increment: 42.14 MiB; peak memory: 953.34 MiB, increment: 41.98 MiB; peak memory: 996.37 MiB, increment: 43.03 MiB; peak memory: 1038.57 MiB, increment: 42.20 MiB. In [7]: %memit ; peak memory: 1038.62 MiB, increment: -0.09 MiB. In [8]: sc.__version__ ; Out[8]: '1.3.7+59.ge0d2ea6'; ```. Using a larger dataset:. ```python; # In a new session:; In [4]: %memit adata = sc.read(""tmp_bm.h5ad"") ; peak memory: 2975.57 MiB, increment: 2799.25 MiB. # In another session:; In [4]: %memit adata_backed = sc.read(""tmp_bm.h5ad"", backed=""r"") ; peak memory: 2969.57 MiB, increment: 2794.57 MiB; ```. While making those examples I got a range of results, though what I've posted are the ones I saw most often. It's enough to make me think there's something strange going on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456037752
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:272,Testability,log,log,272,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:358,Testability,test,test,358,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:486,Testability,test,test,486,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:588,Testability,test,test,588,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:706,Testability,test,test,706,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:1781,Testability,log,logging,1781,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-456056835:1886,Usability,learn,learn,1886,"To add on to what @ivirshup said, reading the file with a custom approach results in significantly less memory used:. I created the `h5ad` file with:. ```; adata = sc.read_10x_h5(""source.h5"", ""GRCh38""); adata.obs['n_counts'] = adata.X.sum(1); adata.obs['log_counts'] = np.log(adata.obs['n_counts']); adata.obs['n_genes'] = (adata.X > 0).sum(1); adata.write(""test.h5ad"", compression='gzip', compression_opts=1); ```. Then read it three different ways:. ```; In [7]: %memit a1 = sc.read(""test.h5ad""); peak memory: 2333.84 MiB, increment: 2170.77 MiB; ```. ```; In [8]: %memit a2 = sc.read(""test.h5ad"", backed=""r""); peak memory: 4400.07 MiB, increment: 2137.85 MiB; ```. ```; In [9]: %memit a3 = custom_read(""test.h5ad""); peak memory: 4390.11 MiB, increment: 66.90 MiB; ```. where `custom_read` is defined as:. ```; def custom_read(filename):; adata = AnnData(); hf = h5py.File(filename); adata.obs['n_counts'] = [x[1] for x in hf['obs'][()]]; adata.obs['log_counts'] = [x[2] for x in hf['obs'][()]]; adata.obs['n_genes'] = [x[3] for x in hf['obs'][()]]; adata.obs_names = [x[0] for x in hf['obs'][()]]; adata.var['gene_ids'] = [x[1] for x in hf['var'][()]]; adata.var_names = [x[0] for x in hf['var'][()]]; return adata; ```. and here's some verification the custom read is actually reading the data. ```; In [16]: a2.obs_keys(); Out[16]: ['n_counts', 'log_counts', 'n_genes']. In [17]: a3.obs_keys(); Out[17]: ['n_counts', 'log_counts', 'n_genes']. In [18]: len(a2.obs); Out[18]: 384000. In [19]: len(a3.obs); Out[19]: 384000. In [20]: a2.var_keys(); Out[20]: ['gene_ids']. In [21]: a3.var_keys(); Out[21]: ['gene_ids']. In [22]: len(a2.var); Out[22]: 33694. In [23]: len(a3.var); Out[23]: 33694; ```. Here's some version info I neglected in the original comment:. ```; In [28]: sc.logging.print_versions(); scanpy==1.3.3 anndata==0.6.17 numpy==1.16.0 scipy==1.2.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-456056835
https://github.com/scverse/scanpy/issues/434#issuecomment-457867258:135,Testability,test,test,135,"Thank you, both! It very likely wasn't there in the beginning and I probably messed it up at some point. It seems that I should make a test that checks that memory usage behaves properly...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/434#issuecomment-457867258
https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:200,Availability,error,error,200,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004
https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:284,Availability,error,error,284,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004
https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:312,Performance,Load,Load,312,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004
https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:31,Testability,log,log,31,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004
https://github.com/scverse/scanpy/issues/435#issuecomment-456634106:24,Availability,error,error,24,Could you post the full error traceback so that I see where the error is raised?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106
https://github.com/scverse/scanpy/issues/435#issuecomment-456634106:64,Availability,error,error,64,Could you post the full error traceback so that I see where the error is raised?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106
https://github.com/scverse/scanpy/issues/435#issuecomment-456954317:23,Availability,error,error,23,"Hi Alex,. Below is the error I get. Thank you for looking at this. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-12-4fad8adf5d00> in <module>; ----> 1 sc.pl.pca(adata, color='CD3D'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in pca(adata, **kwargs); 148 If `show==False` a `matplotlib.Axis` or a list of it.; 149 """"""; --> 150 return plot_scatter(adata, basis='pca', **kwargs); 151 ; 152 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 275 color_vector, categorical = _get_color_values(adata, value_to_plot,; 276 groups=groups, palette=palette,; --> 277 use_raw=use_raw); 278 ; 279 # check if higher value points should be plot on top. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 658 # check if value to plot is in var; 659 elif use_raw is False and value_to_plot in adata.var_names:; --> 660 color_vector = adata[:, value_to_plot].X; 661 ; 662 elif use_raw is True and value_to_plot in adata.raw.var_names:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1307 def __getitem__(self, index):; 1308 """"""Returns a sliced view of the object.""""""; -> 1309 return self._getitem_view(index); 1310 ; 1311 def _getitem_view(self, index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index); 1311 def _getitem_view(self, index):; 1312 oidx, vidx = self._normalize_indices(index); -> 1313 return AnnData(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317
https://github.com/scverse/scanpy/issues/435#issuecomment-456954317:2233,Modifiability,layers,layers,2233,"lots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 658 # check if value to plot is in var; 659 elif use_raw is False and value_to_plot in adata.var_names:; --> 660 color_vector = adata[:, value_to_plot].X; 661 ; 662 elif use_raw is True and value_to_plot in adata.raw.var_names:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1307 def __getitem__(self, index):; 1308 """"""Returns a sliced view of the object.""""""; -> 1309 return self._getitem_view(index); 1310 ; 1311 def _getitem_view(self, index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index); 1311 def _getitem_view(self, index):; 1312 oidx, vidx = self._normalize_indices(index); -> 1313 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1314 ; 1315 def _remove_unused_categories(self, df_full, df_sub, uns):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 662 if not isinstance(X, AnnData):; 663 raise ValueError('`X` has to be an AnnData object.'); --> 664 self._init_as_view(X, oidx, vidx); 665 else:; 666 self._init_as_actual(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_view(self, adata_ref, oidx, vidx); 723 self._X = None; 724 else:; --> 725 self._init_X_as_view(); 726 ; 727 self._layers = AnnDataLayers(self, adata_ref=adata_ref, oidx=oidx, vidx=vidx). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_X_as_view(self); 750 shape = (; 751 get_n_items_idx(self._oidx, self._adata_ref.n_obs),; --> 752 get_n_items_idx(self._vidx, self._adata_ref.n_vars); 753 ); 754 if np.isscalar(X):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\utils.py in get_n_items_idx(idx, l); 148 return 1; 149 else:; --> 150 return len(idx). TypeError: object of type 'numpy.int64' has no len(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317
https://github.com/scverse/scanpy/issues/435#issuecomment-457869163:44,Availability,down,download,44,Sorry for all the trouble. I just wanted to download from your dropbox link but the file wasn't there anymore...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-457869163
https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:26,Availability,error,error,26,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600
https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:387,Availability,down,downsampling,387,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600
https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:268,Testability,log,log,268,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600
https://github.com/scverse/scanpy/issues/435#issuecomment-475722334:17,Availability,error,error,17,"Exactly the same error message pops up when inputting `np.int64` data into `sc.pp.log1p()`. This is with the latest scanpy, and using data that has otherwise worked well when not using `sc.pp.downsample_counts()`. I thus wouldn't consider this resolved, although I can open another issue as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334
https://github.com/scverse/scanpy/issues/435#issuecomment-475722334:23,Integrability,message,message,23,"Exactly the same error message pops up when inputting `np.int64` data into `sc.pp.log1p()`. This is with the latest scanpy, and using data that has otherwise worked well when not using `sc.pp.downsample_counts()`. I thus wouldn't consider this resolved, although I can open another issue as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334
https://github.com/scverse/scanpy/issues/435#issuecomment-475779409:41,Deployability,update,updated,41,Aha okay. My problem was resolved when I updated the AnnData package for converting pandas dataframe into AnnData object using. '''adata = sc.AnnData(x)''',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475779409
https://github.com/scverse/scanpy/issues/435#issuecomment-475782293:124,Availability,down,downsampling,124,"We just merged an update on the `downsample_counts` function by @ivirshup; evidently, the data type shouldn't be changed by downsampling, should it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293
https://github.com/scverse/scanpy/issues/435#issuecomment-475782293:18,Deployability,update,update,18,"We just merged an update on the `downsample_counts` function by @ivirshup; evidently, the data type shouldn't be changed by downsampling, should it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:288,Availability,down,downsampling,288,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:2279,Availability,down,downstream,2279,"nse for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_counts` be? At the time I figured it didn't matter, since anything downstream should be able to deal with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:1209,Deployability,update,updates,1209," a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:1225,Integrability,depend,depending,1225," a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:1453,Performance,perform,perform,1453,"nse for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_counts` be? At the time I figured it didn't matter, since anything downstream should be able to deal with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:762,Testability,Log,Logarithmize,762,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:806,Testability,log,log,806,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:826,Testability,log,log,826,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:851,Testability,log,logarithm,851,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239
https://github.com/scverse/scanpy/issues/435#issuecomment-475999342:319,Testability,log,logarithmize,319,"Nothing should be hardcoded `np.float32`, but it might be that some functions still do that from an early time, where, for instance, scikit-learn's PCA was silently transforming to `float64` (and Scanpy silently transformed back etc.). Nothing should change the dtype that the user wants, except, for instance, when we logarithmize an integer matrix etc. Here, there should be a default `dtype='float32'` parameter. [PS: In algorithms that inherently are unstable and would profit more from higher precision, one could think about increasing precision.]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342
https://github.com/scverse/scanpy/issues/435#issuecomment-475999342:140,Usability,learn,learn,140,"Nothing should be hardcoded `np.float32`, but it might be that some functions still do that from an early time, where, for instance, scikit-learn's PCA was silently transforming to `float64` (and Scanpy silently transformed back etc.). Nothing should change the dtype that the user wants, except, for instance, when we logarithmize an integer matrix etc. Here, there should be a default `dtype='float32'` parameter. [PS: In algorithms that inherently are unstable and would profit more from higher precision, one could think about increasing precision.]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475999342
https://github.com/scverse/scanpy/issues/435#issuecomment-538776417:33,Availability,error,error,33,"Hi, . I've been getting the same error when trying to use `sc.pp.normalize_total` after `sc.pp.downsample_counts.` Normalize total returns a CSR sparse matrix of type `<class 'numpy.int64'>`, which then causes `sc.pp.normalize_total` to error. Not sure where the correct `dtype` should take place.; 	; ```python; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.pp.downsample_counts(pbmc, counts_per_cell=500); sc.pp.normalize_total(pbmc, target_sum=1e4); ```. Here's the traceback:. ```pytb; Normalizing counts per cell. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-136-3305b6c650f4> in <module>; 2 pbmc.X = pbmc.raw.X; 3 sc.pp.downsample_counts(pbmc, counts_per_cell=500); ----> 4 sc.pp.normalize_total(pbmc, target_sum=1e4). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layers, layer_norm, inplace); 166 adata.obs[key_added] = counts_per_cell; 167 if hasattr(adata.X, '__itruediv__'):; --> 168 _normalize_data(adata.X, counts_per_cell, target_sum); 169 else:; 170 adata.X = _normalize_data(adata.X, counts_per_cell, target_sum, copy=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in _normalize_data(X, counts, after, copy); 14 after = np.median(counts[counts>0]) if after is None else after; 15 counts += (counts == 0); ---> 16 counts /= after; 17 if issparse(X):; 18 sparsefuncs.inplace_row_scale(X, 1/counts). TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```. ```; >>> pbmc.X; <700x765 sparse matrix of type '<class 'numpy.int64'>'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417
https://github.com/scverse/scanpy/issues/435#issuecomment-538776417:237,Availability,error,error,237,"Hi, . I've been getting the same error when trying to use `sc.pp.normalize_total` after `sc.pp.downsample_counts.` Normalize total returns a CSR sparse matrix of type `<class 'numpy.int64'>`, which then causes `sc.pp.normalize_total` to error. Not sure where the correct `dtype` should take place.; 	; ```python; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.pp.downsample_counts(pbmc, counts_per_cell=500); sc.pp.normalize_total(pbmc, target_sum=1e4); ```. Here's the traceback:. ```pytb; Normalizing counts per cell. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-136-3305b6c650f4> in <module>; 2 pbmc.X = pbmc.raw.X; 3 sc.pp.downsample_counts(pbmc, counts_per_cell=500); ----> 4 sc.pp.normalize_total(pbmc, target_sum=1e4). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layers, layer_norm, inplace); 166 adata.obs[key_added] = counts_per_cell; 167 if hasattr(adata.X, '__itruediv__'):; --> 168 _normalize_data(adata.X, counts_per_cell, target_sum); 169 else:; 170 adata.X = _normalize_data(adata.X, counts_per_cell, target_sum, copy=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in _normalize_data(X, counts, after, copy); 14 after = np.median(counts[counts>0]) if after is None else after; 15 counts += (counts == 0); ---> 16 counts /= after; 17 if issparse(X):; 18 sparsefuncs.inplace_row_scale(X, 1/counts). TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```. ```; >>> pbmc.X; <700x765 sparse matrix of type '<class 'numpy.int64'>'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417
https://github.com/scverse/scanpy/issues/435#issuecomment-538776417:1013,Modifiability,layers,layers,1013,"Hi, . I've been getting the same error when trying to use `sc.pp.normalize_total` after `sc.pp.downsample_counts.` Normalize total returns a CSR sparse matrix of type `<class 'numpy.int64'>`, which then causes `sc.pp.normalize_total` to error. Not sure where the correct `dtype` should take place.; 	; ```python; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.pp.downsample_counts(pbmc, counts_per_cell=500); sc.pp.normalize_total(pbmc, target_sum=1e4); ```. Here's the traceback:. ```pytb; Normalizing counts per cell. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-136-3305b6c650f4> in <module>; 2 pbmc.X = pbmc.raw.X; 3 sc.pp.downsample_counts(pbmc, counts_per_cell=500); ----> 4 sc.pp.normalize_total(pbmc, target_sum=1e4). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layers, layer_norm, inplace); 166 adata.obs[key_added] = counts_per_cell; 167 if hasattr(adata.X, '__itruediv__'):; --> 168 _normalize_data(adata.X, counts_per_cell, target_sum); 169 else:; 170 adata.X = _normalize_data(adata.X, counts_per_cell, target_sum, copy=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in _normalize_data(X, counts, after, copy); 14 after = np.median(counts[counts>0]) if after is None else after; 15 counts += (counts == 0); ---> 16 counts /= after; 17 if issparse(X):; 18 sparsefuncs.inplace_row_scale(X, 1/counts). TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```. ```; >>> pbmc.X; <700x765 sparse matrix of type '<class 'numpy.int64'>'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417
https://github.com/scverse/scanpy/issues/435#issuecomment-680727659:699,Availability,error,error,699,"Hi there,; stumbled on this by chance when debugging a similar problem - though I'd share my gained insight:. As @LuckyMD already pointed out [here](https://github.com/theislab/scanpy/issues/435#issuecomment-475722334), the root of the problem is feeding `np.int64` into `sc.preprocessing.log1p`. More specifically, the problem occurs in `log1p_array` [here](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318). When specifying `out` in `np.log1p`, the input types need to be castable. However, `np.log1p` returns `np.floatX` (type code double precision `'d'`) which cannot be cast to `np.int64` (type code long integer `'l'`). The error is reproducible with this small snippet of code:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); np.log1p(x=a, out=a); ```. The error can be prevented like this:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); a = np.log1p(x=a); ```. In the case of `scanpy`, this would mean replacing [this](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318) line of code by `X = np.log1p(X)`. The drawback being that the operation is no longer `inplace`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659
https://github.com/scverse/scanpy/issues/435#issuecomment-680727659:854,Availability,error,error,854,"Hi there,; stumbled on this by chance when debugging a similar problem - though I'd share my gained insight:. As @LuckyMD already pointed out [here](https://github.com/theislab/scanpy/issues/435#issuecomment-475722334), the root of the problem is feeding `np.int64` into `sc.preprocessing.log1p`. More specifically, the problem occurs in `log1p_array` [here](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318). When specifying `out` in `np.log1p`, the input types need to be castable. However, `np.log1p` returns `np.floatX` (type code double precision `'d'`) which cannot be cast to `np.int64` (type code long integer `'l'`). The error is reproducible with this small snippet of code:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); np.log1p(x=a, out=a); ```. The error can be prevented like this:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); a = np.log1p(x=a); ```. In the case of `scanpy`, this would mean replacing [this](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318) line of code by `X = np.log1p(X)`. The drawback being that the operation is no longer `inplace`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659
https://github.com/scverse/scanpy/issues/435#issuecomment-683644812:497,Integrability,wrap,wrapper,497,"@ivirshup, yes, your example works. However, I would not consider the issue as resolved as it still exists IMO.; Your example only works as you are working with a sparse matrix. If `X` is a `np.ndarray`, the method still fails:. ```bash; >>> adata = sc.AnnData(; np.ceil(np.abs(np.random.randn(10, 10))).astype('int64'),; dtype=int,; ); >>> sc.pp.log1p(adata); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.7/functools.py"", line 840, in wrapper; return dispatch(args[0].__class__)(*args, **kw); File ""/opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 350, in log1p_anndata; X = log1p(X, copy=False, base=base); File ""/opt/anaconda3/lib/python3.7/functools.py"", line 840, in wrapper; return dispatch(args[0].__class__)(*args, **kw); File ""/opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 318, in log1p_array; np.log1p(X, out=X); TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-683644812
https://github.com/scverse/scanpy/issues/435#issuecomment-683644812:766,Integrability,wrap,wrapper,766,"@ivirshup, yes, your example works. However, I would not consider the issue as resolved as it still exists IMO.; Your example only works as you are working with a sparse matrix. If `X` is a `np.ndarray`, the method still fails:. ```bash; >>> adata = sc.AnnData(; np.ceil(np.abs(np.random.randn(10, 10))).astype('int64'),; dtype=int,; ); >>> sc.pp.log1p(adata); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.7/functools.py"", line 840, in wrapper; return dispatch(args[0].__class__)(*args, **kw); File ""/opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 350, in log1p_anndata; X = log1p(X, copy=False, base=base); File ""/opt/anaconda3/lib/python3.7/functools.py"", line 840, in wrapper; return dispatch(args[0].__class__)(*args, **kw); File ""/opt/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 318, in log1p_array; np.log1p(X, out=X); TypeError: ufunc 'log1p' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-683644812
https://github.com/scverse/scanpy/issues/437#issuecomment-456209252:23,Modifiability,config,configurable,23,"Well, `project_dir` is configurable:. https://github.com/theislab/scanpydoc/blob/02a0fcb5b5ddfd1f9427c27e736e83126f6cfc64/scanpydoc/rtd_github_links.py#L144. but why does it go to `__init__.py`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/437#issuecomment-456209252
https://github.com/scverse/scanpy/issues/438#issuecomment-456707222:1957,Modifiability,layers,layers,1957,"a import stacked_violin; 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); 308 ; 309 elif plot_type == 'tracksplot':. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 819 if isinstance(var_names, str):; 820 var_names = [var_names]; --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 822 ; 823 if 'color' in kwds:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); 510 ; 511 def __getitem__(self, index):; --> 512 oidx, vidx = self._normalize_indices(index); 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 514 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); 538 obs, var = super(Raw, self)._unpack_index(packed_index); 539 obs = _normalize_index(obs, self._adata.obs_names); --> 540 var = _normalize_index(var, self.var_names); 541 return obs, var; 542 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); 270 raise KeyError(; 271 'Indices ""{}"" contain invalid observation/variables names/indices.'; --> 272 .format(index)); 273 return positions.values; 274 else:; ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456707222
https://github.com/scverse/scanpy/issues/438#issuecomment-456707222:2892,Modifiability,variab,variables,2892,"olin; 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); 308 ; 309 elif plot_type == 'tracksplot':. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 819 if isinstance(var_names, str):; 820 var_names = [var_names]; --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 822 ; 823 if 'color' in kwds:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); 510 ; 511 def __getitem__(self, index):; --> 512 oidx, vidx = self._normalize_indices(index); 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 514 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); 538 obs, var = super(Raw, self)._unpack_index(packed_index); 539 obs = _normalize_index(obs, self._adata.obs_names); --> 540 var = _normalize_index(var, self.var_names); 541 return obs, var; 542 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); 270 raise KeyError(; 271 'Indices ""{}"" contain invalid observation/variables names/indices.'; --> 272 .format(index)); 273 return positions.values; 274 else:; ```. Cheers,; Samuele",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456707222
https://github.com/scverse/scanpy/issues/438#issuecomment-456707222:1339,Testability,log,log,1339,"es_groups_stacked_violin(adata, groups, n_genes, groupby, key, show, save, **kwds); 439 ; 440 _rank_genes_groups_plot(adata, plot_type='stacked_violin', groups=groups, n_genes=n_genes,; --> 441 groupby=groupby, key=key, show=show, save=save, **kwds); 442 ; 443 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 305 from ..anndata import stacked_violin; 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); 308 ; 309 elif plot_type == 'tracksplot':. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 819 if isinstance(var_names, str):; 820 var_names = [var_names]; --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 822 ; 823 if 'color' in kwds:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); 510 ; 511 def __getitem__(self, index):; --> 512 oidx, vidx = self._normalize_indices(index); 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 514 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456707222
https://github.com/scverse/scanpy/issues/438#issuecomment-456707222:1691,Testability,log,log,1691,"es_groups_stacked_violin(adata, groups, n_genes, groupby, key, show, save, **kwds); 439 ; 440 _rank_genes_groups_plot(adata, plot_type='stacked_violin', groups=groups, n_genes=n_genes,; --> 441 groupby=groupby, key=key, show=show, save=save, **kwds); 442 ; 443 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 305 from ..anndata import stacked_violin; 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); 308 ; 309 elif plot_type == 'tracksplot':. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 819 if isinstance(var_names, str):; 820 var_names = [var_names]; --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 822 ; 823 if 'color' in kwds:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); 510 ; 511 def __getitem__(self, index):; --> 512 oidx, vidx = self._normalize_indices(index); 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 514 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456707222
https://github.com/scverse/scanpy/issues/438#issuecomment-456707222:1894,Testability,log,log,1894,"lot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); 305 from ..anndata import stacked_violin; 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); 308 ; 309 elif plot_type == 'tracksplot':. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 819 if isinstance(var_names, str):; 820 var_names = [var_names]; --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 822 ; 823 if 'color' in kwds:. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); 510 ; 511 def __getitem__(self, index):; --> 512 oidx, vidx = self._normalize_indices(index); 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 514 else: X = self._adata.file['raw.X'][oidx, vidx]. ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); 538 obs, var = super(Raw, self)._unpack_index(packed_index); 539 obs = _normalize_index(obs, self._adata.obs_names); --> 540 var = _normalize_index(var, self.var_names); 541 return obs, var; 542 . ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); 270 raise KeyError(; 271 'Indices ""{}"" contain invalid observation/var",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456707222
https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:2259,Modifiability,layers,layers,2259," return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; > --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); > 308; > 309 elif plot_type == 'tracksplot':; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); > 538 obs, var = super(Raw, self)._unpack_index(packed_index); > 539 obs = _normalize_index(obs, self._adata.obs_names); > --> 540 var = _normalize_index(var, self.var_names); > 541 return obs, var; > 542; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); > 270 raise KeyError(; > 271 'Indices ""{}"" contain invalid observation/variables names/indices.'; > --> 272 .format(index)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910
https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:3239,Modifiability,variab,variables,3239,"group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); > 538 obs, var = super(Raw, self)._unpack_index(packed_index); > 539 obs = _normalize_index(obs, self._adata.obs_names); > --> 540 var = _normalize_index(var, self.var_names); > 541 return obs, var; > 542; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); > 270 raise KeyError(; > 271 'Indices ""{}"" contain invalid observation/variables names/indices.'; > --> 272 .format(index)); > 273 return positions.values; > 274 else:; >; > Cheers,; > Samuele; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/438#issuecomment-456707222>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1XEPWhKAyeK0sWLrAzmqJvm45H-vks5vGBhDgaJpZM4aMT_6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910
https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:1625,Testability,log,log,1625,"upby, key, show, save, **kwds); > 439; > 440 _rank_genes_groups_plot(adata, plot_type='stacked_violin', groups=groups, n_genes=n_genes,; > --> 441 groupby=groupby, key=key, show=show, save=save, **kwds); > 442; > 443; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); > 305 from ..anndata import stacked_violin; > 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; > --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); > 308; > 309 elif plot_type == 'tracksplot':; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910
https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:1983,Testability,log,log,1983,"upby, key, show, save, **kwds); > 439; > 440 _rank_genes_groups_plot(adata, plot_type='stacked_violin', groups=groups, n_genes=n_genes,; > --> 441 groupby=groupby, key=key, show=show, save=save, **kwds); > 442; > 443; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); > 305 from ..anndata import stacked_violin; > 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; > --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); > 308; > 309 elif plot_type == 'tracksplot':; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(se",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910
https://github.com/scverse/scanpy/issues/438#issuecomment-456735910:2194,Testability,log,log,2194," n_genes, groupby, key, show, save, **kwds); > 305 from ..anndata import stacked_violin; > 306 return stacked_violin(adata, gene_names, groupby, var_group_labels=group_names,; > --> 307 var_group_positions=group_positions, show=show, save=save, **kwds); > 308; > 309 elif plot_type == 'tracksplot':; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); > 819 if isinstance(var_names, str):; > 820 var_names = [var_names]; > --> 821 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); > 822; > 823 if 'color' in kwds:; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); > 1983 matrix = adata[:, var_names].layers[layer]; > 1984 elif use_raw:; > -> 1985 matrix = adata.raw[:, var_names].X; > 1986 else:; > 1987 matrix = adata[:, var_names].X; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in __getitem__(self, index); > 510; > 511 def __getitem__(self, index):; > --> 512 oidx, vidx = self._normalize_indices(index); > 513 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; > 514 else: X = self._adata.file['raw.X'][oidx, vidx]; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_indices(self, packed_index); > 538 obs, var = super(Raw, self)._unpack_index(packed_index); > 539 obs = _normalize_index(obs, self._adata.obs_names); > --> 540 var = _normalize_index(var, self.var_names); > 541 return obs, var; > 542; >; > ~/miniconda3/envs/scRNA/lib/python3.6/site-packages/anndata/base.py in _normalize_index(index, names); > 270 raise KeyError(; > 271",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456735910
https://github.com/scverse/scanpy/issues/438#issuecomment-456760052:86,Integrability,message,message,86,"Yeah, the UMAP plots work alright, and I can recognize many of the genes I get in the message are indeed genes that are expressed in the data, for I can visualize them on my UMAP plots. It is kind of weird, I am wondering if somewhere I messed up the format of those names, but then why would they work on UMAP?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456760052
https://github.com/scverse/scanpy/issues/438#issuecomment-456769781:49,Modifiability,variab,variable,49,"Have you subsetted your AnnData object to highly variable genes, while keeping the full dataset in `.raw`? In that case it could be that genes that are found as markers via `rank_genes_groups`, are not in `adata.var_names`, but only in `adata.raw.var_names` and therefore cannot be found by the plotting function. I've previously encountered issues with this, but I thought it had been solved now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456769781
https://github.com/scverse/scanpy/issues/438#issuecomment-456776304:78,Modifiability,variab,variable,78,"Yeah, the raw data has been indeed assigned before I subsetted through highly variable genes. It might be this sort of mismatching that is problematic.; However I encounter the same problem when trying to plot a layer. The layers should contain the same set of genes as the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456776304
https://github.com/scverse/scanpy/issues/438#issuecomment-456776304:223,Modifiability,layers,layers,223,"Yeah, the raw data has been indeed assigned before I subsetted through highly variable genes. It might be this sort of mismatching that is problematic.; However I encounter the same problem when trying to plot a layer. The layers should contain the same set of genes as the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-456776304
https://github.com/scverse/scanpy/issues/438#issuecomment-459668085:35,Modifiability,layers,layers,35,"@SamueleSoraggi you are right, the layers contain the same genes as the adata.X matrix. I assume that in your case, you did a highly variable gene selection which affects both adata.X and adata.layers but not adata.raw. The solution is to mark highly variable genes without removing the other less variable genes. This functionality was added some few months ago and may not be properly reflected on the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-459668085
https://github.com/scverse/scanpy/issues/438#issuecomment-459668085:133,Modifiability,variab,variable,133,"@SamueleSoraggi you are right, the layers contain the same genes as the adata.X matrix. I assume that in your case, you did a highly variable gene selection which affects both adata.X and adata.layers but not adata.raw. The solution is to mark highly variable genes without removing the other less variable genes. This functionality was added some few months ago and may not be properly reflected on the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-459668085
https://github.com/scverse/scanpy/issues/438#issuecomment-459668085:194,Modifiability,layers,layers,194,"@SamueleSoraggi you are right, the layers contain the same genes as the adata.X matrix. I assume that in your case, you did a highly variable gene selection which affects both adata.X and adata.layers but not adata.raw. The solution is to mark highly variable genes without removing the other less variable genes. This functionality was added some few months ago and may not be properly reflected on the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-459668085
https://github.com/scverse/scanpy/issues/438#issuecomment-459668085:251,Modifiability,variab,variable,251,"@SamueleSoraggi you are right, the layers contain the same genes as the adata.X matrix. I assume that in your case, you did a highly variable gene selection which affects both adata.X and adata.layers but not adata.raw. The solution is to mark highly variable genes without removing the other less variable genes. This functionality was added some few months ago and may not be properly reflected on the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-459668085
https://github.com/scverse/scanpy/issues/438#issuecomment-459668085:298,Modifiability,variab,variable,298,"@SamueleSoraggi you are right, the layers contain the same genes as the adata.X matrix. I assume that in your case, you did a highly variable gene selection which affects both adata.X and adata.layers but not adata.raw. The solution is to mark highly variable genes without removing the other less variable genes. This functionality was added some few months ago and may not be properly reflected on the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/438#issuecomment-459668085
https://github.com/scverse/scanpy/pull/439#issuecomment-456365133:44,Testability,test,tests,44,BTW I have successfully run the distributed tests with this change (`pytest scanpy/tests/test_preprocessing_distributed.py`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133
https://github.com/scverse/scanpy/pull/439#issuecomment-456365133:83,Testability,test,tests,83,BTW I have successfully run the distributed tests with this change (`pytest scanpy/tests/test_preprocessing_distributed.py`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456365133
https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:93,Integrability,depend,dependencies,93,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443
https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:6,Testability,Test,Tests,6,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443
https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:115,Testability,test,tests,115,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443
https://github.com/scverse/scanpy/pull/439#issuecomment-456635443:234,Testability,test,tests,234,"Nice! Tests should also be run by Travis, shouldn't they? Or have we missed out on demanding dependencies and your tests won't run through for that reason? If so, please point me to it and I'll make sure that Travis actually runs the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456635443
https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:75,Deployability,install,installed,75,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801
https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:88,Deployability,install,install,88,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801
https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:159,Deployability,install,install,159,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801
https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:195,Deployability,install,install,195,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801
https://github.com/scverse/scanpy/pull/439#issuecomment-456825801:23,Testability,test,tests,23,Thanks @falexwolf. The tests are not run by default since dask etc are not installed. I install them with the following to get them to be picked up:. ```; pip install dask[array] zappy zarr; pip install pytest; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-456825801
https://github.com/scverse/scanpy/pull/439#issuecomment-457869443:146,Usability,simpl,simply,146,"@flying-sheep: Do you agree that we should add this to the travis setup? I thought about creating a `requirements_tests.txt` as for `anndata` and simply adding the line to `.travis.yml`. Good solution? Maybe it's even your solution, I don't remember. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457869443
https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:48,Deployability,install,install,48,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041
https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:442,Deployability,install,installed,442,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041
https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:242,Testability,test,test,242,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041
https://github.com/scverse/scanpy/pull/439#issuecomment-457915041:218,Usability,simpl,simply,218,"I’m not a fan of duplicating things. We already install optional requirements via the list of extras here:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/.travis.yml#L8. so we should simply add them to the `test` extra:. https://github.com/theislab/scanpy/blob/f428848ece1d7a4794090eb70a34a3b8f1953dee/setup.py#L35. or add more extras (e.g. `dask=['dask[array]'],`) and add them to the list of extras to be installed in .travis.yml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-457915041
https://github.com/scverse/scanpy/pull/439#issuecomment-460071018:48,Testability,test,test,48,"I completely agree. It should simply go in the `test` extra. @tomwhite, would you do that? It might that the tests don't run through on Travis for some reason and then, I guess, it would be great if you could look into it (would for sure be a problem that would pop elsewhere, too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018
https://github.com/scverse/scanpy/pull/439#issuecomment-460071018:109,Testability,test,tests,109,"I completely agree. It should simply go in the `test` extra. @tomwhite, would you do that? It might that the tests don't run through on Travis for some reason and then, I guess, it would be great if you could look into it (would for sure be a problem that would pop elsewhere, too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018
https://github.com/scverse/scanpy/pull/439#issuecomment-460071018:30,Usability,simpl,simply,30,"I completely agree. It should simply go in the `test` extra. @tomwhite, would you do that? It might that the tests don't run through on Travis for some reason and then, I guess, it would be great if you could look into it (would for sure be a problem that would pop elsewhere, too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/439#issuecomment-460071018
https://github.com/scverse/scanpy/issues/440#issuecomment-456429967:79,Performance,cache,cache,79,"Hej again,. I found a solution to my problem. If I read my object enabling the cache, I do not need to have it backed, because the huge use of memory when I generate the plots does not happen anymore. However I like the idea of having backed data, and it would be nice to understand why it did not work. Maybe it will be useful with larger datasets. Cheers,; Samuele",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440#issuecomment-456429967
https://github.com/scverse/scanpy/issues/440#issuecomment-456702805:156,Deployability,update,update,156,"When I have again time I will try step by step my script and try to see what happens, Maybe it will be useful in future for someone else :); I will post an update here in a little while.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/440#issuecomment-456702805
https://github.com/scverse/scanpy/pull/441#issuecomment-456715454:203,Usability,intuit,intuitive,203,"Yeah, I think I invented that convention in the early days of destiny, and it sloshed over to here. It recently completely confused a destiny user, which made me realize that this is *not* canonical and intuitive use, but just something I came up with so long ago that I forgot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-456715454
https://github.com/scverse/scanpy/pull/441#issuecomment-457914722:142,Energy Efficiency,efficient,efficient,142,"> Also the code in Scanpy solely started off Laleh's Matlab version. In which I introduced that convention when helping Laleh to make it more efficient :wink: . I don’t know if others came up with it independently before I did in early 2015, but it wouldn’t surprise me :laughing:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-457914722
https://github.com/scverse/scanpy/pull/441#issuecomment-460070455:345,Deployability,integrat,integration,345,"> In which I introduced that convention when helping Laleh to make it more efficient. Cool, I didn't know that! Should have made it a lot more efficient! :smile:. > The convention I know is to return two n × k matrices. Right, this is the default in sklearn. But yes, in the end, we want some sort of adjacency matrix for convenience and direct integration with all the graph stuff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455
https://github.com/scverse/scanpy/pull/441#issuecomment-460070455:75,Energy Efficiency,efficient,efficient,75,"> In which I introduced that convention when helping Laleh to make it more efficient. Cool, I didn't know that! Should have made it a lot more efficient! :smile:. > The convention I know is to return two n × k matrices. Right, this is the default in sklearn. But yes, in the end, we want some sort of adjacency matrix for convenience and direct integration with all the graph stuff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455
https://github.com/scverse/scanpy/pull/441#issuecomment-460070455:143,Energy Efficiency,efficient,efficient,143,"> In which I introduced that convention when helping Laleh to make it more efficient. Cool, I didn't know that! Should have made it a lot more efficient! :smile:. > The convention I know is to return two n × k matrices. Right, this is the default in sklearn. But yes, in the end, we want some sort of adjacency matrix for convenience and direct integration with all the graph stuff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455
https://github.com/scverse/scanpy/pull/441#issuecomment-460070455:345,Integrability,integrat,integration,345,"> In which I introduced that convention when helping Laleh to make it more efficient. Cool, I didn't know that! Should have made it a lot more efficient! :smile:. > The convention I know is to return two n × k matrices. Right, this is the default in sklearn. But yes, in the end, we want some sort of adjacency matrix for convenience and direct integration with all the graph stuff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/441#issuecomment-460070455
https://github.com/scverse/scanpy/pull/442#issuecomment-456713441:182,Availability,error,error,182,"I don’t consider it breaking. If I understod you right, the only change in behavior are that not specifying a genome works now in cases where there’s only one. No longer throwing an error is a perfectly fine change!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441
https://github.com/scverse/scanpy/pull/442#issuecomment-456723024:306,Availability,error,error,306,"I thought it was breaking due to a couple behavior changes:. One case where the results would be different is the call `sc.read_10x_h5(h5pth)`, where the file at `h5pth` is a legacy formatted file which contains `mm10` and `hg38` genomes. Prior to this PR, only the `mm10` genome would be read in. Now, an error is thrown. . If the file had the `v3` format (also containing two genomes), now values for features from both genomes would be read in, instead of just `mm10`. Even better than removing an error, previously `v3` files would get all the vars filtered out and not throw an error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024
https://github.com/scverse/scanpy/pull/442#issuecomment-456723024:501,Availability,error,error,501,"I thought it was breaking due to a couple behavior changes:. One case where the results would be different is the call `sc.read_10x_h5(h5pth)`, where the file at `h5pth` is a legacy formatted file which contains `mm10` and `hg38` genomes. Prior to this PR, only the `mm10` genome would be read in. Now, an error is thrown. . If the file had the `v3` format (also containing two genomes), now values for features from both genomes would be read in, instead of just `mm10`. Even better than removing an error, previously `v3` files would get all the vars filtered out and not throw an error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024
https://github.com/scverse/scanpy/pull/442#issuecomment-456723024:583,Availability,error,error,583,"I thought it was breaking due to a couple behavior changes:. One case where the results would be different is the call `sc.read_10x_h5(h5pth)`, where the file at `h5pth` is a legacy formatted file which contains `mm10` and `hg38` genomes. Prior to this PR, only the `mm10` genome would be read in. Now, an error is thrown. . If the file had the `v3` format (also containing two genomes), now values for features from both genomes would be read in, instead of just `mm10`. Even better than removing an error, previously `v3` files would get all the vars filtered out and not throw an error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024
https://github.com/scverse/scanpy/pull/442#issuecomment-456793309:131,Availability,error,error,131,"Ha, that’s what I meant, that you said it doesn’t make sense. > If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. I very much agree!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456793309
https://github.com/scverse/scanpy/pull/442#issuecomment-457870095:172,Deployability,release,release,172,"Oh, I was too hasty in merging this. Thanks for clarifying more of this. I think it's perfectly fine to have this better and more stringent behavior. . Added a note in the release notes: https://github.com/theislab/scanpy/commit/f428848ece1d7a4794090eb70a34a3b8f1953dee. Btw: I think we should have much nicer release notes with batches both for subversions and author contributions. I'll try improving them very soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-457870095
https://github.com/scverse/scanpy/pull/442#issuecomment-457870095:310,Deployability,release,release,310,"Oh, I was too hasty in merging this. Thanks for clarifying more of this. I think it's perfectly fine to have this better and more stringent behavior. . Added a note in the release notes: https://github.com/theislab/scanpy/commit/f428848ece1d7a4794090eb70a34a3b8f1953dee. Btw: I think we should have much nicer release notes with batches both for subversions and author contributions. I'll try improving them very soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-457870095
https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:136,Availability,avail,available,136,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216
https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:36,Testability,test,tests,36,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216
https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:461,Testability,test,tests,461,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216
https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:278,Usability,learn,learn,278,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216
https://github.com/scverse/scanpy/issues/446#issuecomment-457339569:265,Testability,log,logfoldchange,265,"Thank you for the kind words!. Hm, it's in the [docs in the returns section](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.api.tl.rank_genes_groups.html). Should it be somewhere else?. But you're right, I'm also not completely happy with the name `logfoldchange`. We'll harmonize with what's out there at some point and I'm currently tending to `log2FC` because @davidsebfischer started to using that in `diffxpy` and I guess it's also used in some R tools.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446#issuecomment-457339569
https://github.com/scverse/scanpy/issues/446#issuecomment-457617601:72,Usability,intuit,intuitive,72,"@falexwolf, yes I think overall fold changes with 2 as a basis are more intuitive than with e as a basis for most people, similar to basis=10, but basis 2 gives a more sensible dynamic range than 10 does on gene expression data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446#issuecomment-457617601
https://github.com/scverse/scanpy/issues/446#issuecomment-457868274:128,Testability,log,logfoldchange,128,"Thanks David, I completely agree, but I was really just talking about the naming convention: `log2FC` vs. `log2foldchange` vs. `logfoldchange` vs. other possibilities... 🙂",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/446#issuecomment-457868274
https://github.com/scverse/scanpy/issues/447#issuecomment-457810196:180,Usability,simpl,simple,180,"I don't think that what you want is possible. sc.pl.tracksplot plots data in a way that resemble a genome browser track; but ist not because it does not understand coordinates. It simple groups; the cells by the given groupby condition and then plots the value of each; gene in a separate track. The y value is the gene expression (or in your; case the ATAC-seq value). The x coordinate, simple puts all cells one after; the other without any ordering. On Sat, Jan 26, 2019 at 12:55 AM manarai <notifications@github.com> wrote:. > Hi,; >; > Thanks for this amazing package.; >; > I have been playing with scanpy on scATACSeq data generated from 10x. And; > in comparison to the cellranger analysis, I think analysis scanpy does; > pretty descent job and adds more possibilities. I would like to displays; > some peaks that are highly present if some clusters using the genome; > browser which scanpy seem to be able to do ""I think"" ( as shown below). Is; > it possible to the same thing but with the peak averaged for all cells; > within the same cluster?; >; > import matplotlib.pyplot as plt; > genes =['chr15:101708546_101718131','chr11:117961932_117970696',; > 'chr19:5821847_5852441','chr15:101422873_101429606',; > 'chr17:39842811_39849028','chr13:6108971_6109684']; > sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]); >; > [image: atacseq]; > <https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png>; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/447>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1VUU1fUPbHKqadt-yXNKrA4amCXQks5vG5lngaJpZM4aT2VQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447#issuecomment-457810196
https://github.com/scverse/scanpy/issues/447#issuecomment-457810196:388,Usability,simpl,simple,388,"I don't think that what you want is possible. sc.pl.tracksplot plots data in a way that resemble a genome browser track; but ist not because it does not understand coordinates. It simple groups; the cells by the given groupby condition and then plots the value of each; gene in a separate track. The y value is the gene expression (or in your; case the ATAC-seq value). The x coordinate, simple puts all cells one after; the other without any ordering. On Sat, Jan 26, 2019 at 12:55 AM manarai <notifications@github.com> wrote:. > Hi,; >; > Thanks for this amazing package.; >; > I have been playing with scanpy on scATACSeq data generated from 10x. And; > in comparison to the cellranger analysis, I think analysis scanpy does; > pretty descent job and adds more possibilities. I would like to displays; > some peaks that are highly present if some clusters using the genome; > browser which scanpy seem to be able to do ""I think"" ( as shown below). Is; > it possible to the same thing but with the peak averaged for all cells; > within the same cluster?; >; > import matplotlib.pyplot as plt; > genes =['chr15:101708546_101718131','chr11:117961932_117970696',; > 'chr19:5821847_5852441','chr15:101422873_101429606',; > 'chr17:39842811_39849028','chr13:6108971_6109684']; > sc.pl.tracksplot(adata,genes,groupby='louvain', figsize=[40,50]); >; > [image: atacseq]; > <https://user-images.githubusercontent.com/39877296/51778958-d7e4c700-2147-11e9-88cd-78f3e100c75f.png>; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/447>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1VUU1fUPbHKqadt-yXNKrA4amCXQks5vG5lngaJpZM4aT2VQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/447#issuecomment-457810196
https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:1553,Availability,avail,available,1553,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946
https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:295,Integrability,protocol,protocol,295,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946
https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:120,Modifiability,variab,variable,120,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946
https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:626,Modifiability,variab,variable,626,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946
https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:669,Modifiability,variab,variable,669,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946
https://github.com/scverse/scanpy/issues/449#issuecomment-458246040:95,Modifiability,variab,variable,95,"Hi @LuckyMD, thanks for the recommendations we (@SharkieJones) will try lowering the number of variable genes (we ranked based on variance) and will look through the tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458246040
https://github.com/scverse/scanpy/issues/450#issuecomment-458954075:144,Availability,down,downgrading,144,"Same problem here. So glad that I found this ticket. From flying-sheep's commit, it looks like either upgrading scanpy to the newest version or downgrading pandas would work. There is also some anndata version requirement going up, no idea why.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-458954075
https://github.com/scverse/scanpy/issues/450#issuecomment-460184736:525,Modifiability,variab,variable,525,"Sure! @ivirshup figured out independently within 2 hours of me that `is_string_dtype` now works differently: theislab/anndata#107. The fix needed three parts:. 1. I fixed the tests to actually work (they were broken since forever because they used a hardcoded file name instead of `tmp_path`, and therefore reused the same file); 2. I pulled his changes, which covered the writing portion of the needed fixes; 3. I fixed the reading portion in theislab/anndata@4c8163129302391419c7ee4943e7fb766599e2a2; 4. I fixed the highly variable genes function that relied on a slightly different behavior of series in 0.23",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460184736
https://github.com/scverse/scanpy/issues/450#issuecomment-460184736:175,Testability,test,tests,175,"Sure! @ivirshup figured out independently within 2 hours of me that `is_string_dtype` now works differently: theislab/anndata#107. The fix needed three parts:. 1. I fixed the tests to actually work (they were broken since forever because they used a hardcoded file name instead of `tmp_path`, and therefore reused the same file); 2. I pulled his changes, which covered the writing portion of the needed fixes; 3. I fixed the reading portion in theislab/anndata@4c8163129302391419c7ee4943e7fb766599e2a2; 4. I fixed the highly variable genes function that relied on a slightly different behavior of series in 0.23",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460184736
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:64,Availability,error,error,64,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1847,Availability,toler,tolerance,1847,"ies.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1969,Availability,toler,tolerance,1969,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:2130,Availability,toler,tolerance,2130,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:2277,Availability,toler,tolerance,2277,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:2287,Availability,toler,tolerance,2287,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:2501,Availability,toler,tolerance,2501,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:2852,Deployability,install,installed,2852,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1763,Performance,perform,perform,1763,"ogg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:764,Testability,log,logg,764,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264
https://github.com/scverse/scanpy/issues/450#issuecomment-460306375:30,Deployability,install,install,30,"Hi @helios,. You will have to install scanpy from github to use the fix for this. The latest release (1.3.7) does not yet include the fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460306375
https://github.com/scverse/scanpy/issues/450#issuecomment-460306375:93,Deployability,release,release,93,"Hi @helios,. You will have to install scanpy from github to use the fix for this. The latest release (1.3.7) does not yet include the fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460306375
https://github.com/scverse/scanpy/issues/450#issuecomment-460560176:74,Deployability,release,releases,74,Yes. Do you think scanpy is quality-controlled enough that we can cut new releases whenever we please? Else I’m not comfortable to just create a new tag from master and release it by myself.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460560176
https://github.com/scverse/scanpy/issues/450#issuecomment-460560176:169,Deployability,release,release,169,Yes. Do you think scanpy is quality-controlled enough that we can cut new releases whenever we please? Else I’m not comfortable to just create a new tag from master and release it by myself.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460560176
https://github.com/scverse/scanpy/issues/450#issuecomment-460614412:228,Deployability,release,release,228,"Good, yes, in the meanwhile, test coverage should be high enough. I can't think of any major hole anymore. Still, it would be nice to briefly coordinate for Scanpy; at least, still these days. But yes, in this case, please make release 1.3.8!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412
https://github.com/scverse/scanpy/issues/450#issuecomment-460614412:29,Testability,test,test,29,"Good, yes, in the meanwhile, test coverage should be high enough. I can't think of any major hole anymore. Still, it would be nice to briefly coordinate for Scanpy; at least, still these days. But yes, in this case, please make release 1.3.8!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460614412
https://github.com/scverse/scanpy/issues/450#issuecomment-460625486:199,Deployability,release,releases,199,"I did, and then I realized that we have the `import scanpy as sc` change and more features, so I called it 1.4. Btw: could you please add me as owner to scanpy and anndata on PyPI? then I can manage releases and delete files on PyPI.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460625486
https://github.com/scverse/scanpy/issues/454#issuecomment-459034769:55,Integrability,depend,depending,55,"hmm, I’m not sure if it’s possible to require versions depending on the platform. where’s the h5py issue about this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-459034769
https://github.com/scverse/scanpy/issues/454#issuecomment-462042014:58,Deployability,install,install,58,"Same issue with OSX python 3.7, solved simply with `conda install pytables`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462042014
https://github.com/scverse/scanpy/issues/454#issuecomment-462042014:39,Usability,simpl,simply,39,"Same issue with OSX python 3.7, solved simply with `conda install pytables`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462042014
https://github.com/scverse/scanpy/issues/454#issuecomment-462133198:96,Deployability,install,installed,96,"Pytables is in requirements.txt (the PyPI package is called “tables”), how did y’all get Scanpy installed without all its dependencies?. https://github.com/theislab/scanpy/blob/f252d3a84200cc76060a786ef0589405fc5c9c12/requirements.txt#L7",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462133198
https://github.com/scverse/scanpy/issues/454#issuecomment-462133198:122,Integrability,depend,dependencies,122,"Pytables is in requirements.txt (the PyPI package is called “tables”), how did y’all get Scanpy installed without all its dependencies?. https://github.com/theislab/scanpy/blob/f252d3a84200cc76060a786ef0589405fc5c9c12/requirements.txt#L7",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462133198
https://github.com/scverse/scanpy/issues/454#issuecomment-462140438:7,Deployability,install,install,7,"`conda install` (not `pip`). Perhaps, that is due to pytables' conda dependencies (such as hdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140438
https://github.com/scverse/scanpy/issues/454#issuecomment-462140438:69,Integrability,depend,dependencies,69,"`conda install` (not `pip`). Perhaps, that is due to pytables' conda dependencies (such as hdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140438
https://github.com/scverse/scanpy/issues/454#issuecomment-462140641:61,Availability,error,error,61,Just checked.. same thing applies for windows. It returns an error until you `conda install pytables`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641
https://github.com/scverse/scanpy/issues/454#issuecomment-462140641:84,Deployability,install,install,84,Just checked.. same thing applies for windows. It returns an error until you `conda install pytables`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641
https://github.com/scverse/scanpy/issues/454#issuecomment-462259888:35,Availability,avail,availability,35,"Hm. the conda package doesn’t list availability for windows: https://anaconda.org/bioconda/scanpy, just “conda install linux-64 v1.3.7, osx-64 v1.3.7”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888
https://github.com/scverse/scanpy/issues/454#issuecomment-462259888:111,Deployability,install,install,111,"Hm. the conda package doesn’t list availability for windows: https://anaconda.org/bioconda/scanpy, just “conda install linux-64 v1.3.7, osx-64 v1.3.7”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888
https://github.com/scverse/scanpy/issues/454#issuecomment-462261457:7,Deployability,install,install,7,"`conda install` meant to be related to `pytables`, not `scanpy`. `scanpy` runs easily via `pip`, only the tables dependency complains..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462261457
https://github.com/scverse/scanpy/issues/454#issuecomment-462261457:113,Integrability,depend,dependency,113,"`conda install` meant to be related to `pytables`, not `scanpy`. `scanpy` runs easily via `pip`, only the tables dependency complains..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462261457
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:92,Deployability,install,installation,92,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:114,Deployability,install,install,114,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:257,Deployability,install,installed,257,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:314,Deployability,install,install,314,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:375,Deployability,install,install,375,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:398,Deployability,install,install,398,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:422,Deployability,install,install,422,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:442,Deployability,install,install,442,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:469,Deployability,install,install,469,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:492,Deployability,install,install,492,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:527,Deployability,install,install,527,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814856541:354,Testability,test,test,354,"I had a same issue. My environment is; ```; windows10; python3.8.8 (conda env); ```. scanpy installation ; `conda install -c conda-forge -c bioconda scanpy`. It looks work well on command prompt, but it wasn't work on jupyterlab(3.0). To solve this, I just installed all packages using pip, not conda.; here is my install procedure. ```; conda create -n test python=3.8; pip install ipykernel; pip install jupyterlab; pip install scanpy; pip install python-igraph; pip install leidenalg; pip install fa2; ```. I tired a lot of install and environment combination, but always there was a problem with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814856541
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:126,Deployability,install,installation,126,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:149,Deployability,install,install,149,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:304,Deployability,install,installed,304,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:363,Deployability,install,install,363,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:434,Deployability,install,install,434,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:459,Deployability,install,install,459,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:485,Deployability,install,install,485,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:507,Deployability,install,install,507,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:536,Deployability,install,install,536,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:561,Deployability,install,install,561,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:604,Deployability,install,install,604,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:411,Testability,test,test,411,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:24,Availability,error,error,24,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:122,Availability,down,download,122,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:439,Availability,down,downloaded,439,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:714,Availability,down,download,714,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:286,Deployability,install,install,286,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:331,Deployability,install,install,331,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:823,Deployability,install,installing,823,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:26,Availability,error,error,26,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:130,Availability,down,download,130,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:449,Availability,down,downloaded,449,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:739,Availability,down,download,739,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:1019,Availability,error,error,1019,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:296,Deployability,install,install,296,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:341,Deployability,install,install,341,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:848,Deployability,install,installing,848,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214
https://github.com/scverse/scanpy/issues/454#issuecomment-954032488:125,Availability,down,download,125,"Had this issue again recently using python 3.7, and the solution above wasn't enough to solve it. Turns out I also needed to download the tables .whl file: `pip install .\h5py-2.10.0-cp37-cp37m-win_amd64.whl .\tables-3.6.1-cp37-cp37m-win_amd64.whl numpy==1.20.0 --user --force-reinstall`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488
https://github.com/scverse/scanpy/issues/454#issuecomment-954032488:161,Deployability,install,install,161,"Had this issue again recently using python 3.7, and the solution above wasn't enough to solve it. Turns out I also needed to download the tables .whl file: `pip install .\h5py-2.10.0-cp37-cp37m-win_amd64.whl .\tables-3.6.1-cp37-cp37m-win_amd64.whl numpy==1.20.0 --user --force-reinstall`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:26,Availability,error,error,26,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:130,Availability,down,download,130,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:449,Availability,down,downloaded,449,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:739,Availability,down,download,739,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:296,Deployability,install,install,296,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:341,Deployability,install,install,341,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:848,Deployability,install,installing,848,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217
https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:19,Availability,error,error,19,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910
https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:173,Availability,error,error,173,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910
https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:69,Deployability,install,install,69,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910
https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:220,Deployability,install,install,220,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:33,Availability,error,error,33,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:251,Availability,error,error,251,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:359,Availability,down,download,359,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:680,Availability,down,downloaded,680,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:974,Availability,down,download,974,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:78,Deployability,install,install,78,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:147,Deployability,install,install,147,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:527,Deployability,install,install,527,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:572,Deployability,install,install,572,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:1083,Deployability,install,installing,1083,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040
https://github.com/scverse/scanpy/issues/455#issuecomment-459584385:59,Deployability,release,release,59,"Hey @sebpott. That feature was implemented after the 1.3.7 release, so it should work if you use the development version or wait until the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-459584385
https://github.com/scverse/scanpy/issues/455#issuecomment-459584385:144,Deployability,release,release,144,"Hey @sebpott. That feature was implemented after the 1.3.7 release, so it should work if you use the development version or wait until the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-459584385
https://github.com/scverse/scanpy/issues/455#issuecomment-472756442:528,Availability,error,error,528,"Hello, I'm having a bit of trouble with this. I know the issues is closed, but I thought it might be better to continue this discussion rather than start a new one, though I can do that if you prefer. I have an AnnData object `adata` with ensembl ids as `adata.var_name` and mouse gene symbols under the column `adata.var[“gene_name”]`. When I call:; `sc.pl.umap(adata, color=['ENSMUSG00000074637'])`; It plots no problem. However, when I call:; `sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name')`; I get the following error:; ```; Traceback (most recent call last):. File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; return plot_scatter(adata, basis='umap', **kwargs). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; use_raw=use_raw, gene_symbols=gene_symbols). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; .format(value_to_plot, adata.obs.columns)). ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; 'louvain'],; dtype='object'); ```; Inspecting adata.var[""gene_name""] give:; ```; index; ENSMUSG00000002459 Rgs20; ENSMUSG00000033740 St18; ENSMUSG00000067879 3110035E14Rik; ENSMUSG00000025912 Mybl1; ENSMUSG00000016918 Sulf1; ENSMUSG00000025938 Slco5a1; ENSMUSG00000025930 Msc; ENSMUSG00000025921 Rdh10; ENSMUSG00000025777 Gdap1; ENSMUSG00000025776 Crispld1; ENSMUSG00000025927 Tfap2b; ENSMUSG00000025931 Paqr8; ENSMUSG00000026158 Ogfrl1; ...; ```; I'm not sure what I'm doing wrong here. I can do just about anything using the ensembl ids, but I am having a lot of trouble using the gene symbols. I would like to be abl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442
https://github.com/scverse/scanpy/issues/455#issuecomment-472756442:1252,Modifiability,variab,variable,1252,"continue this discussion rather than start a new one, though I can do that if you prefer. I have an AnnData object `adata` with ensembl ids as `adata.var_name` and mouse gene symbols under the column `adata.var[“gene_name”]`. When I call:; `sc.pl.umap(adata, color=['ENSMUSG00000074637'])`; It plots no problem. However, when I call:; `sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name')`; I get the following error:; ```; Traceback (most recent call last):. File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; return plot_scatter(adata, basis='umap', **kwargs). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; use_raw=use_raw, gene_symbols=gene_symbols). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; .format(value_to_plot, adata.obs.columns)). ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; 'louvain'],; dtype='object'); ```; Inspecting adata.var[""gene_name""] give:; ```; index; ENSMUSG00000002459 Rgs20; ENSMUSG00000033740 St18; ENSMUSG00000067879 3110035E14Rik; ENSMUSG00000025912 Mybl1; ENSMUSG00000016918 Sulf1; ENSMUSG00000025938 Slco5a1; ENSMUSG00000025930 Msc; ENSMUSG00000025921 Rdh10; ENSMUSG00000025777 Gdap1; ENSMUSG00000025776 Crispld1; ENSMUSG00000025927 Tfap2b; ENSMUSG00000025931 Paqr8; ENSMUSG00000026158 Ogfrl1; ...; ```; I'm not sure what I'm doing wrong here. I can do just about anything using the ensembl ids, but I am having a lot of trouble using the gene symbols. I would like to be able to use the gene symbols in the plots for umap, violin, pca, etc. Any help would be much appreciated. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442
https://github.com/scverse/scanpy/issues/455#issuecomment-472840788:648,Availability,error,error,648,"should be gene_symbols in plural. On Thu, Mar 14, 2019 at 9:46 AM csijcs <notifications@github.com> wrote:. > Hello, I'm having a bit of trouble with this. I know the issues is closed,; > but I thought it might be better to continue this discussion rather than; > start a new one, though I can do that if you prefer. I have an AnnData; > object adata with ensembl ids as adata.var_name and mouse gene symbols; > under the column adata.var[“gene_name”]. When I call:; > sc.pl.umap(adata, color=['ENSMUSG00000074637']); > It plots no problem. However, when I call:; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); > I get the following error:; >; > Traceback (most recent call last):; >; >; >; > File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; >; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; >; > return plot_scatter(adata, basis='umap', **kwargs); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; >; > use_raw=use_raw, gene_symbols=gene_symbols); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; >; > .format(value_to_plot, adata.obs.columns)); >; >; >; > ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; >; > 'louvain'],; >; > dtype='object'); >; >; > Inspecting adata.var[""gene_name""] give:; >; > index; >; > ENSMUSG00000002459 Rgs20; >; > ENSMUSG00000033740 St18; >; > ENSMUSG00000067879 3110035E14Rik; >; > ENSMUSG00000025912 Mybl1; >; > ENSMUSG00000016918 Sulf1; >; > ENSMUSG00000025938 Slco5a1; >; > ENSMUSG00000025930 Msc; >; > ENSMUSG00000025921 Rdh10; >; > ENSMUSG00000025777 Gdap1; >; > ENSMUSG00000025776 Crispld1; >; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788
https://github.com/scverse/scanpy/issues/455#issuecomment-472840788:1447,Modifiability,variab,variable,1447,"bols; > under the column adata.var[“gene_name”]. When I call:; > sc.pl.umap(adata, color=['ENSMUSG00000074637']); > It plots no problem. However, when I call:; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); > I get the following error:; >; > Traceback (most recent call last):; >; >; >; > File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; >; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; >; > return plot_scatter(adata, basis='umap', **kwargs); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; >; > use_raw=use_raw, gene_symbols=gene_symbols); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; >; > .format(value_to_plot, adata.obs.columns)); >; >; >; > ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; >; > 'louvain'],; >; > dtype='object'); >; >; > Inspecting adata.var[""gene_name""] give:; >; > index; >; > ENSMUSG00000002459 Rgs20; >; > ENSMUSG00000033740 St18; >; > ENSMUSG00000067879 3110035E14Rik; >; > ENSMUSG00000025912 Mybl1; >; > ENSMUSG00000016918 Sulf1; >; > ENSMUSG00000025938 Slco5a1; >; > ENSMUSG00000025930 Msc; >; > ENSMUSG00000025921 Rdh10; >; > ENSMUSG00000025777 Gdap1; >; > ENSMUSG00000025776 Crispld1; >; > ENSMUSG00000025927 Tfap2b; >; > ENSMUSG00000025931 Paqr8; >; > ENSMUSG00000026158 Ogfrl1; >; > ...; >; >; > I'm not sure what I'm doing wrong here. I can do just about anything using; > the ensembl ids, but I am having a lot of trouble using the gene symbols. I; > would like to be able to use the gene symbols in the plots for umap,; > violin, pca, etc. Any help would be much appreciated. Thanks!; >;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788
https://github.com/scverse/scanpy/issues/455#issuecomment-473506355:102,Availability,down,downstream,102,"@fidelram knows more about the plotting code than me, but here's some recommendations:. * Many of the downstream plotting functions for `rank_genes_groups` take `gene_symbols` arguments. See the docs for functions like: `sc.pl.rank_genes_groups_*`; * The `gene_symbols` argument is recent, and is gradually being added to functions.; * You can always set `var_names` to be gene symbols. I prefer keeping `var_names` as unique, canonical identifiers, but sometimes do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473506355
https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:215,Availability,error,error,215,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184
https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:501,Availability,error,error,501,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184
https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:66,Integrability,message,message,66,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184
https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:77,Modifiability,Variab,Variable,77,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184
https://github.com/scverse/scanpy/issues/455#issuecomment-474290381:39,Usability,learn,learn,39,"The slight difference is due to scikit learn's implementation of PCA. If the top PCs are enough for you, you get perfect reproducibility, as in the tutorials [clustering](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) and [trajectory inference](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html). Higher PCs are subject to the instability of the underlying iterative methods for computing them. You'll always see slight inconsistencies. However, I've never seen this to affect any conclusion drawn from an analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-474290381
https://github.com/scverse/scanpy/issues/455#issuecomment-474334322:246,Testability,test,test,246,"I have gotten fairly different clustering results when using `svd_solver='arpack'` in all but 1 case actually. The biological interpretation is still roughly the same, but the depth of subclustering you can do does differ. Based on a preliminary test, using arpack for all `sc.pp.pca()` calls does improve the reproducibility, although clustering results still differ (tested on Fedora 25 and Fedora 28, e.g. cluster sizes change by 100-200 cells). I can show you the differences when you're around next if you like. This is definitely a discussion for a different thread though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322
https://github.com/scverse/scanpy/issues/455#issuecomment-474334322:369,Testability,test,tested,369,"I have gotten fairly different clustering results when using `svd_solver='arpack'` in all but 1 case actually. The biological interpretation is still roughly the same, but the depth of subclustering you can do does differ. Based on a preliminary test, using arpack for all `sc.pp.pca()` calls does improve the reproducibility, although clustering results still differ (tested on Fedora 25 and Fedora 28, e.g. cluster sizes change by 100-200 cells). I can show you the differences when you're around next if you like. This is definitely a discussion for a different thread though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-474334322
https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087:475,Security,hash,hashtable,475,"`adata.var[""gene_name""]`. Traceback (most recent call last):; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'gene_name'. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py"", line 3458, in __getitem__; indexer = self.columns.get_loc(key); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 'gene_name'. Did something change in scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087
https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087:588,Security,hash,hashtable,588,"`adata.var[""gene_name""]`. Traceback (most recent call last):; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item; KeyError: 'gene_name'. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py"", line 3458, in __getitem__; indexer = self.columns.get_loc(key); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 'gene_name'. Did something change in scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1117713087
https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546:19,Availability,error,error,19,I get an identical error as @hemantgujar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546
https://github.com/scverse/scanpy/issues/456#issuecomment-459623293:253,Availability,down,downstream,253,"Hi, I have fixed the issue.; It appears that adding, subtracting or dividing numpy.ndarrays with scipy.sparse matrices returns a numpy.matrix. numpy_array /= scipy_sparse_matrix, This command changed the type of numpy_array to numpy.matrix which caused downstream problems. So, you have to transfer the matrix to sparse format again for downstream analysis.; I used the command 'adata.X = scipy.sparse.csr_matrix(adata.X) ' after dividing the measured counts by the size factor.; So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293
https://github.com/scverse/scanpy/issues/456#issuecomment-459623293:337,Availability,down,downstream,337,"Hi, I have fixed the issue.; It appears that adding, subtracting or dividing numpy.ndarrays with scipy.sparse matrices returns a numpy.matrix. numpy_array /= scipy_sparse_matrix, This command changed the type of numpy_array to numpy.matrix which caused downstream problems. So, you have to transfer the matrix to sparse format again for downstream analysis.; I used the command 'adata.X = scipy.sparse.csr_matrix(adata.X) ' after dividing the measured counts by the size factor.; So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293
https://github.com/scverse/scanpy/issues/456#issuecomment-459623293:526,Performance,perform,performing,526,"Hi, I have fixed the issue.; It appears that adding, subtracting or dividing numpy.ndarrays with scipy.sparse matrices returns a numpy.matrix. numpy_array /= scipy_sparse_matrix, This command changed the type of numpy_array to numpy.matrix which caused downstream problems. So, you have to transfer the matrix to sparse format again for downstream analysis.; I used the command 'adata.X = scipy.sparse.csr_matrix(adata.X) ' after dividing the measured counts by the size factor.; So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293
https://github.com/scverse/scanpy/pull/457#issuecomment-460063532:15,Deployability,update,update,15,"@falexwolf any update on the plug-ins idea for scanpy?. On Sun, Feb 3, 2019 at 4:50 PM Alex Wolf <notifications@github.com> wrote:. > Merged #457 <https://github.com/theislab/scanpy/pull/457> into master.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/457#event-2114366554>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1auPPM2VVhh2E_5Gwd8djTqP9ltAks5vJwVLgaJpZM4agJQ1>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063532
https://github.com/scverse/scanpy/pull/457#issuecomment-460063532:29,Modifiability,plug-in,plug-ins,29,"@falexwolf any update on the plug-ins idea for scanpy?. On Sun, Feb 3, 2019 at 4:50 PM Alex Wolf <notifications@github.com> wrote:. > Merged #457 <https://github.com/theislab/scanpy/pull/457> into master.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/457#event-2114366554>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1auPPM2VVhh2E_5Gwd8djTqP9ltAks5vJwVLgaJpZM4agJQ1>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063532
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:290,Deployability,install,install,290,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:404,Energy Efficiency,sustainab,sustainable,404,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:56,Integrability,interface,interfaces,56,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:335,Integrability,interface,interfaces,335,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:133,Security,access,accessible,133,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/pull/457#issuecomment-460063977:370,Usability,clear,clearly,370,"The reorganization of using the ""external API"" (shallow interfaces) via an `import scanpy.external as sce` and the ""internal API"" as accessible via `import scanpy as sc`, sort of, provided a solution to what bothered people the most: expecting the ""internal API"" to run through at a single install, be properly maintained etc. and the interfaces to external packages be clearly marked. I think this is a sustainable, long-term solution, which scales and is convenient for contributors. @flying-sheep agreed as I understood it. Do you think we need more?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/457#issuecomment-460063977
https://github.com/scverse/scanpy/issues/458#issuecomment-460351011:42,Deployability,install,installation,42,"I think that there is no up to date Conda installation. Only Pip. The current version is 1.3.7. . > On 4 Feb 2019, at 10:26, Bérénice Batut <notifications@github.com> wrote:; > ; > right_margin and left_margin are still listed as parameters for pl.scatter:; > ; > https://github.com/theislab/scanpy/blob/c15a5e8763097082c82cd8ef6fee697954c487dc/scanpy/plotting/_anndata.py#L49; > ; > And ncols, wspace and hspace are not accepted (with the current version on conda) 😟; > ; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-460351011
https://github.com/scverse/scanpy/issues/458#issuecomment-460560962:45,Deployability,install,install,45,"We have the ![](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg) badge. I think we should remove that if we’re not actually recommending installation that way. If there’s a “[On ]bioconda” badge to put next to the PyPI badge, I’d prefer that. /edit: The badges are custom, we can control the text. I replaced it to match the PyPI badge, except that we can’t get a version, so I put a cute snake: ![](https://img.shields.io/pypi/v/scanpy.svg) ![](https://img.shields.io/badge/bioconda-🐍-blue.svg)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-460560962
https://github.com/scverse/scanpy/issues/458#issuecomment-460560962:158,Deployability,install,installation,158,"We have the ![](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg) badge. I think we should remove that if we’re not actually recommending installation that way. If there’s a “[On ]bioconda” badge to put next to the PyPI badge, I’d prefer that. /edit: The badges are custom, we can control the text. I replaced it to match the PyPI badge, except that we can’t get a version, so I put a cute snake: ![](https://img.shields.io/pypi/v/scanpy.svg) ![](https://img.shields.io/badge/bioconda-🐍-blue.svg)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-460560962
https://github.com/scverse/scanpy/issues/458#issuecomment-460613715:55,Deployability,update,update,55,Thanks! Makes sense! (Both the badge and the automatic update from PyPI).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-460613715
https://github.com/scverse/scanpy/issues/458#issuecomment-475639263:258,Modifiability,layers,layers,258,"I also just realised that `pl.scatter` does not take `ncols` as an argument. I am also using scanpy v1.4 from bioconda. The online documentation also does not mention ncols as an argument:; `scanpy.pl.scatter(adata, x=None, y=None, color=None, use_raw=None, layers='X', sort_order=True, alpha=None, basis=None, groups=None, components=None, projection='2d', legend_loc='right margin', legend_fontsize=None, legend_fontweight=None, color_map=None, palette=None, frameon=None, right_margin=None, left_margin=None, size=None, title=None, show=None, save=None, ax=None)` (copy-paste from https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.scatter.html), but it does mention `ncols` below in the description.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-475639263
https://github.com/scverse/scanpy/issues/458#issuecomment-476000764:210,Usability,simpl,simplified,210,"`pl.scatter` is, unfortunately, not in the best shape anymore. Since Fidel rewrote a large part of the plotting API, it's not used by any of the frequently used embeddings scatters anymore and would need to be simplified a lot, before actually adding new functionality (like `ncols`). Would you mind correcting the docs? What are you using `pl.scatter` for?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-476000764
https://github.com/scverse/scanpy/issues/458#issuecomment-476005968:72,Modifiability,layers,layers,72,"Sure, I can have a look at the docs. I've been using it because of the `layers` argument since `pl.umap` does not seem to have it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-476005968
https://github.com/scverse/scanpy/issues/458#issuecomment-476095057:19,Modifiability,layers,layers,19,"@fabianrost84 The 'layers' were not added to anndata until recently and had not been implemented in all functions. However, adding this functionality to the different scatter plot functions is straightforward. Let me prepare a quick PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-476095057
https://github.com/scverse/scanpy/issues/458#issuecomment-476513549:205,Modifiability,variab,variable,205,> copy paste. please never say those words when speaking about code again :stuck_out_tongue_winking_eye: . No but seriously: There’s at least 6 reasons not to do that and to introduce a second (temporary) variable instead: https://github.com/theislab/scanpy/pull/557#issuecomment-476512533,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/458#issuecomment-476513549
https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:80,Performance,tune,tune,80,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654
https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:291,Testability,log,logfc,291,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654
https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:474,Testability,log,logreg,474,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654
https://github.com/scverse/scanpy/issues/460#issuecomment-471241654:557,Testability,log,logreg,557,"@andrea-tango ; Really awesome!; I am also wondering to find some parameters to tune in scanpy's `rank_genes_groups` like in Seurat. . Because I found there is some difference in makers by scanpy's default(using `wilcoxon` ) and Seurat's default parameters` only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25`. (Seurat's default method is wilcoxon), in this case, I can find interesting markers calculated by Seurat but not in Scanpy's. However, when I tried scanpy's `logreg` method, I found many overlap DEGs between two calculations, aka, scanpy's `logreg` and Seurat's `wilcox`. Have you ever came into similar results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471241654
https://github.com/scverse/scanpy/issues/460#issuecomment-471321592:421,Testability,test,test,421,"@MichaelPeibo @falexwolf I started working on points 2 and 3, but it is better if you will work on these points.; I wrote the code for points 1 and 4.; In order to generate volcano plots, I calculated the log2FC relying on the `diffxpy` library.; I can push again the code for tSNE and also the code for volcano plots. Please, check the `rank_genes_groups` function.; Considering 2 groups of cells and using the Wilcoxon test (`de.test.wilcoxon`) provided by the `diffxpy` library, I obtained different marker genes with respect to those calculated by using `rank_genes_groups` function (Wilcoxon test). Many thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592
https://github.com/scverse/scanpy/issues/460#issuecomment-471321592:431,Testability,test,test,431,"@MichaelPeibo @falexwolf I started working on points 2 and 3, but it is better if you will work on these points.; I wrote the code for points 1 and 4.; In order to generate volcano plots, I calculated the log2FC relying on the `diffxpy` library.; I can push again the code for tSNE and also the code for volcano plots. Please, check the `rank_genes_groups` function.; Considering 2 groups of cells and using the Wilcoxon test (`de.test.wilcoxon`) provided by the `diffxpy` library, I obtained different marker genes with respect to those calculated by using `rank_genes_groups` function (Wilcoxon test). Many thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592
https://github.com/scverse/scanpy/issues/460#issuecomment-471321592:597,Testability,test,test,597,"@MichaelPeibo @falexwolf I started working on points 2 and 3, but it is better if you will work on these points.; I wrote the code for points 1 and 4.; In order to generate volcano plots, I calculated the log2FC relying on the `diffxpy` library.; I can push again the code for tSNE and also the code for volcano plots. Please, check the `rank_genes_groups` function.; Considering 2 groups of cells and using the Wilcoxon test (`de.test.wilcoxon`) provided by the `diffxpy` library, I obtained different marker genes with respect to those calculated by using `rank_genes_groups` function (Wilcoxon test). Many thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471321592
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:688,Availability,avail,available,688,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:178,Integrability,depend,dependency,178,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:203,Integrability,depend,depends,203,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:250,Integrability,depend,dependency,250,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:298,Integrability,wrap,wrapper,298,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:815,Testability,benchmark,benchmarked,815,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:849,Testability,test,test,849,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:1118,Testability,Test,Test,1118,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:1168,Testability,test,tests,1168,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:1229,Testability,test,tests,1229,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:1286,Testability,test,tests,1286,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:1347,Usability,simpl,simple,1347,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809
https://github.com/scverse/scanpy/issues/460#issuecomment-471324466:59,Integrability,depend,dependencies,59,"@falexwolf I agree with you about the `diffxpy` a `scanpy` dependencies, Tensorflow is a very important dependency!. > would you make a PR?. I did it, I pushed the code where I added the parameter `n_components` for `scanpy.tl.tsne` function. > Why not using `diffxpy` Volcano plots right away?. I wrote a function in which you can change the colour of the genes, you can add the names of the genes etc. > How did you write your tests?. I tried them on data coming from the lab in which I am working.; I can write a jupyter notebook using public dataset and push it on my copy of the `scanpy` repository.; Give me a couple of days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466
https://github.com/scverse/scanpy/issues/460#issuecomment-471324466:104,Integrability,depend,dependency,104,"@falexwolf I agree with you about the `diffxpy` a `scanpy` dependencies, Tensorflow is a very important dependency!. > would you make a PR?. I did it, I pushed the code where I added the parameter `n_components` for `scanpy.tl.tsne` function. > Why not using `diffxpy` Volcano plots right away?. I wrote a function in which you can change the colour of the genes, you can add the names of the genes etc. > How did you write your tests?. I tried them on data coming from the lab in which I am working.; I can write a jupyter notebook using public dataset and push it on my copy of the `scanpy` repository.; Give me a couple of days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466
https://github.com/scverse/scanpy/issues/460#issuecomment-471324466:429,Testability,test,tests,429,"@falexwolf I agree with you about the `diffxpy` a `scanpy` dependencies, Tensorflow is a very important dependency!. > would you make a PR?. I did it, I pushed the code where I added the parameter `n_components` for `scanpy.tl.tsne` function. > Why not using `diffxpy` Volcano plots right away?. I wrote a function in which you can change the colour of the genes, you can add the names of the genes etc. > How did you write your tests?. I tried them on data coming from the lab in which I am working.; I can write a jupyter notebook using public dataset and push it on my copy of the `scanpy` repository.; Give me a couple of days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471324466
https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:31,Availability,downtime,downtime,31,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039
https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:104,Testability,test,tests,104,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039
https://github.com/scverse/scanpy/issues/460#issuecomment-471373445:37,Usability,simpl,simpler,37,"Hi @falexwolf ; I am sending you the simpler code ,my anndata which can be reproduced in some way, and csv marker file calculated by Seurat to your email, you might to repeat my marker analysis if you would like. Sorry for doing it in this way, I not familiar about how to make public notebook...and our data is too preliminary to be public.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471373445
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1597,Integrability,wrap,wrapping,1597,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1237,Safety,avoid,avoid,1237,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:278,Testability,test,tests,278,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:311,Testability,test,tests,311,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:338,Testability,test,tests,338,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:385,Testability,test,tests,385,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:433,Testability,test,test,433,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:451,Testability,test,test,451,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:592,Testability,test,test,592,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:622,Testability,test,tests,622,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:673,Testability,test,test,673,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:741,Testability,test,test,741,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:915,Testability,test,test,915,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:964,Testability,test,test,964,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:972,Testability,test,test,972,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1045,Testability,test,test,1045,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1151,Testability,test,test,1151,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1220,Testability,test,test,1220,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1333,Testability,test,tests,1333,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1456,Testability,test,testing,1456,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471487617:1613,Testability,test,tests,1613,"Hi all, thanks for the mention @andrea-tango! If have been making multiple changes in diffxpy and batchglm recently, the following refers to the branch diffxpy dev, I haven' merged all of this into master yet as I am waiting for some last issues to be fixed. . 1. Are diffxpy's tests correct: We are using unit tests to check a) that all tests fullfill the null model. b) for standard tests that do not require model fits (Welch's t-test and rank sum test) we check that we produce the same results as scipy. We vectorise where possible but we do actually directly call scipy in the rank sum test right now. Both of these tests check out on the dev branch for the rank sum test, so this is working correctly. @falexwolf this might be a unit test that you could also introduce? I did not see this in the ones that you linked but I just glanced over. @andrea-tango please use dev right now. 2. Nature of the rank sum test. We previously called the Wilcoxon rank sum test de.test.wilcoxon, note that this is also alternatively named Mann-Whitney U test (MWU). Importantly, MWU is for independent samples, which we always have in scRNAseq, the ""wilcoxon"" test in scipy is for paired samples. We therefore renamed this to de.test.rank_sum to avoid confusion. Which one are you using @falexwolf? . 3. Comparison scanpy vs diffxpy (in unit tests). I would discourage this and compare against scipy because I would consider scipy the gold standard for statistical testing. I can run comparisons if the above comments do not resolve all issues discussed here, which would imply that we might differ in our wrapping in the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471487617
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:620,Availability,error,error,620,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:748,Availability,down,downloaded,748,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:531,Testability,test,test,531,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:541,Testability,test,test,541,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:723,Testability,test,test,723,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:36,Usability,simpl,simple,36,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124
https://github.com/scverse/scanpy/issues/460#issuecomment-471531524:388,Deployability,update,updated,388,"@andrea-tango @MichaelPeibo To address the filtering of rank_genes_groups (eg. `min.pct = 0.25, logfc.threshold = 0.25`) I recently added a function called `sc.tl.filter_rank_genes_groups`. See https://github.com/theislab/scanpy/pull/425. @falexwolf I don't know why`sc.tl.filter_rank_genes_groups` does not show up in the docs. I will take a look. Also, I just noticed that this PR with updated examples is still open. I think it would be useful to merge: https://github.com/theislab/scanpy_usage/pull/11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524
https://github.com/scverse/scanpy/issues/460#issuecomment-471531524:96,Testability,log,logfc,96,"@andrea-tango @MichaelPeibo To address the filtering of rank_genes_groups (eg. `min.pct = 0.25, logfc.threshold = 0.25`) I recently added a function called `sc.tl.filter_rank_genes_groups`. See https://github.com/theislab/scanpy/pull/425. @falexwolf I don't know why`sc.tl.filter_rank_genes_groups` does not show up in the docs. I will take a look. Also, I just noticed that this PR with updated examples is still open. I think it would be useful to merge: https://github.com/theislab/scanpy_usage/pull/11",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471531524
https://github.com/scverse/scanpy/issues/460#issuecomment-471569285:149,Testability,test,testing,149,does `sc.tl.filter_rank_genes_groups` filter the `sc.tl.rank_genes_groups` result? Or does it recompute? The former would not alleviate the multiple testing burden.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471569285
https://github.com/scverse/scanpy/issues/460#issuecomment-471643748:134,Testability,test,tested,134,"does not recompute, simply saves the filtered data under; adata.uns['rank_genes_groups_filtered']. Thus, different parameters can be; tested quickly. Off course, sc.tl.rank_genes_groups has to be call first. On Mon, Mar 11, 2019 at 3:47 PM MalteDLuecken <notifications@github.com>; wrote:. > does sc.tl.filter_rank_genes_groups filter the sc.tl.rank_genes_groups; > result? Or does it recompute? The former would not alleviate the multiple; > testing burden.; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/460#issuecomment-471569285>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1debC8DotLkQywhO8zJpEvfkBbSHks5vVmxpgaJpZM4ahuSs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471643748
https://github.com/scverse/scanpy/issues/460#issuecomment-471643748:443,Testability,test,testing,443,"does not recompute, simply saves the filtered data under; adata.uns['rank_genes_groups_filtered']. Thus, different parameters can be; tested quickly. Off course, sc.tl.rank_genes_groups has to be call first. On Mon, Mar 11, 2019 at 3:47 PM MalteDLuecken <notifications@github.com>; wrote:. > does sc.tl.filter_rank_genes_groups filter the sc.tl.rank_genes_groups; > result? Or does it recompute? The former would not alleviate the multiple; > testing burden.; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/460#issuecomment-471569285>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1debC8DotLkQywhO8zJpEvfkBbSHks5vVmxpgaJpZM4ahuSs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471643748
https://github.com/scverse/scanpy/issues/460#issuecomment-471643748:20,Usability,simpl,simply,20,"does not recompute, simply saves the filtered data under; adata.uns['rank_genes_groups_filtered']. Thus, different parameters can be; tested quickly. Off course, sc.tl.rank_genes_groups has to be call first. On Mon, Mar 11, 2019 at 3:47 PM MalteDLuecken <notifications@github.com>; wrote:. > does sc.tl.filter_rank_genes_groups filter the sc.tl.rank_genes_groups; > result? Or does it recompute? The former would not alleviate the multiple; > testing burden.; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/460#issuecomment-471569285>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1debC8DotLkQywhO8zJpEvfkBbSHks5vVmxpgaJpZM4ahuSs>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471643748
https://github.com/scverse/scanpy/issues/460#issuecomment-471664988:144,Testability,test,testing,144,"If p-values are regarded as a valuable output rather than just the ranks, it might be worth recomputing as thresholding would ease the multiple testing burden. I guess that's the idea behind the `min_pCells` parameter request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471664988
https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:121,Testability,log,logreg,121,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514
https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:152,Testability,log,logfoldchanges,152,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514
https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:172,Testability,log,logfoldchanges,172,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514
https://github.com/scverse/scanpy/issues/460#issuecomment-471938514:212,Testability,log,logreg,212,@falexwolf @andrea-tango ; I have a question regarding point 2 (log2FC values in `rank_genes_groups`). I see that only `'logreg'` method doesn't return logfoldchanges. But logfoldchanges don't seem natural for `'logreg'` as this method doesn't even use `reference` for calculation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471938514
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:312,Testability,log,logfoldchanges,312,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:361,Testability,log,logy,361,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:701,Testability,log,logfoldchanges,701,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:901,Testability,log,logfoldchanges,901,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:1138,Testability,log,logfoldchanges,1138,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-473498942:1187,Testability,log,logy,1187,"Sorry this is a little off topic, but it's something I've found useful:. @LuckyMD and anyone else looking for an interactive volcano plot, I've been using [`hvplot`](https://hvplot.pyviz.org) in my notebooks. A volcano plot can be made from DE data frame with something like:. ```python; de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. <details>; <summary> Complete example using scanpy </summary>. ```python; import pandas as pd; import numpy as np; import hvplot.pandas; import scanpy as sc. def rank_genes_groups_df(adata, group, pval_cutoff : float =None, logfc_cutoff=None): ; d = pd.DataFrame() ; for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']: ; d[k] = adata.uns[""rank_genes_groups""][k][group] ; if pval_cutoff is not None: ; d = d[d[""pvals_adj""] < pval_cutoff] ; if logfc_cutoff is not None: ; d = d[d[""logfoldchanges""].abs() > logfc_cutoff] ; return d. pbmcs = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(pbmcs, ""bulk_labels"", n_genes=pbmcs.var_names.size); de_df = rank_genes_groups_df(pbmcs, ""CD34+""). de_df.hvplot.scatter(; ""logfoldchanges"", ""pvals_adj"", ; flip_yaxis=True, logy=True, ; hover_cols=[""names""]; ); ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-473498942
https://github.com/scverse/scanpy/issues/460#issuecomment-474305372:20,Testability,log,logreg,20,"@Koncopd, updating `logreg` with a proper implementation accounting for `reference` is another story. We can talk about it sometime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-474305372
https://github.com/scverse/scanpy/pull/461#issuecomment-460703629:2,Testability,test,tested,2,"I tested the code, now it is possible to calculate more components for the tSNE embedding method",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/461#issuecomment-460703629
https://github.com/scverse/scanpy/pull/462#issuecomment-460938211:358,Energy Efficiency,reduce,reduce,358,"Thank you! I think we should only use `@njit` anyway. I don’t understand why `@jit` exists if it can silently fail. Could you please elaborate on the following?. > The ideal solution is it becoming possible to have numba functions which are both parallel and cached. So am I deducing correctly that numba can parallelize code and usually caches functions to reduce compilation times, but can’t do both for the same function yet?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460938211
https://github.com/scverse/scanpy/pull/462#issuecomment-460938211:259,Performance,cache,cached,259,"Thank you! I think we should only use `@njit` anyway. I don’t understand why `@jit` exists if it can silently fail. Could you please elaborate on the following?. > The ideal solution is it becoming possible to have numba functions which are both parallel and cached. So am I deducing correctly that numba can parallelize code and usually caches functions to reduce compilation times, but can’t do both for the same function yet?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460938211
https://github.com/scverse/scanpy/pull/462#issuecomment-460938211:338,Performance,cache,caches,338,"Thank you! I think we should only use `@njit` anyway. I don’t understand why `@jit` exists if it can silently fail. Could you please elaborate on the following?. > The ideal solution is it becoming possible to have numba functions which are both parallel and cached. So am I deducing correctly that numba can parallelize code and usually caches functions to reduce compilation times, but can’t do both for the same function yet?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460938211
https://github.com/scverse/scanpy/pull/462#issuecomment-460941854:242,Energy Efficiency,reduce,reduce,242,"`@jit` can be fine for supporting a greater range of `numba` versions or just compiling parts of the function through lifted loops (which this was using before). I don't think caching is on by default, but you can cache compiled functions to reduce compilation times ([docs](https://numba.pydata.org/numba-doc/dev/user/jit.html#cache)). However, I don't think you can use `@jit(parallel=True, cached=True)`. Here's an issue for it: https://github.com/numba/numba/issues/2712",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460941854
https://github.com/scverse/scanpy/pull/462#issuecomment-460941854:214,Performance,cache,cache,214,"`@jit` can be fine for supporting a greater range of `numba` versions or just compiling parts of the function through lifted loops (which this was using before). I don't think caching is on by default, but you can cache compiled functions to reduce compilation times ([docs](https://numba.pydata.org/numba-doc/dev/user/jit.html#cache)). However, I don't think you can use `@jit(parallel=True, cached=True)`. Here's an issue for it: https://github.com/numba/numba/issues/2712",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460941854
https://github.com/scverse/scanpy/pull/462#issuecomment-460941854:328,Performance,cache,cache,328,"`@jit` can be fine for supporting a greater range of `numba` versions or just compiling parts of the function through lifted loops (which this was using before). I don't think caching is on by default, but you can cache compiled functions to reduce compilation times ([docs](https://numba.pydata.org/numba-doc/dev/user/jit.html#cache)). However, I don't think you can use `@jit(parallel=True, cached=True)`. Here's an issue for it: https://github.com/numba/numba/issues/2712",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460941854
https://github.com/scverse/scanpy/pull/462#issuecomment-460941854:393,Performance,cache,cached,393,"`@jit` can be fine for supporting a greater range of `numba` versions or just compiling parts of the function through lifted loops (which this was using before). I don't think caching is on by default, but you can cache compiled functions to reduce compilation times ([docs](https://numba.pydata.org/numba-doc/dev/user/jit.html#cache)). However, I don't think you can use `@jit(parallel=True, cached=True)`. Here's an issue for it: https://github.com/numba/numba/issues/2712",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-460941854
https://github.com/scverse/scanpy/pull/462#issuecomment-461002334:204,Performance,perform,performance-critical,204,OK got it! I still think `@jit` is too opaque – how should you know that some innocent-looking change results in a loop no longer being compiled? I think we should use `@njit` to be sure we have compiled performance-critical parts going forward.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-461002334
https://github.com/scverse/scanpy/pull/462#issuecomment-461279367:107,Testability,test,tests,107,I believe numba will always throw a warning if some part of the requested compilation failed. We could add tests for compilation based on this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-461279367
https://github.com/scverse/scanpy/pull/462#issuecomment-464624309:22,Testability,test,test,22,"No, looks good and we test the QC metrics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/462#issuecomment-464624309
https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:17,Availability,error,error,17,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618
https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:172,Availability,error,error,172,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618
https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:710,Modifiability,variab,variable,710,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618
https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:459,Testability,log,log,459,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618
https://github.com/scverse/scanpy/issues/465#issuecomment-461456817:53,Modifiability,enhance,enhancements,53,This is solved in PR #425 (which also includes other enhancements),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461456817
https://github.com/scverse/scanpy/pull/466#issuecomment-471328945:34,Testability,test,test,34,@falexwolf ; This is just a small test for the existing pca. You asked me to write it some time ago.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/466#issuecomment-471328945
https://github.com/scverse/scanpy/pull/467#issuecomment-463965367:169,Availability,error,error,169,`gprofiler` functionality is being added to scanpy? I have a small wrapper for that as well... the main components being a try-catch wrapper around it as it can give an error when there are no results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367
https://github.com/scverse/scanpy/pull/467#issuecomment-463965367:67,Integrability,wrap,wrapper,67,`gprofiler` functionality is being added to scanpy? I have a small wrapper for that as well... the main components being a try-catch wrapper around it as it can give an error when there are no results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367
https://github.com/scverse/scanpy/pull/467#issuecomment-463965367:133,Integrability,wrap,wrapper,133,`gprofiler` functionality is being added to scanpy? I have a small wrapper for that as well... the main components being a try-catch wrapper around it as it can give an error when there are no results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367
https://github.com/scverse/scanpy/pull/467#issuecomment-464011097:92,Availability,error,error,92,Ah? The code seems like it just returns an empty list when there’s no results. Where is the error thrown?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464011097
https://github.com/scverse/scanpy/pull/467#issuecomment-464073234:233,Testability,test,test,233,"This is the traceback I get when I receive no results:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-91-65d9edda0106> in <module>(); 1 test = gprofiler(list(module_membership['MEpink']), ; 2 custom_bg=list(np.unique([v.split(""."")[0] for v in var.index.tolist()])),; ----> 3 organism='mmusculus', correction_method='fdr', src_filter=['GO:BP']). ~/anaconda3/lib/python3.6/site-packages/gprofiler/__init__.py in gprofiler(query, organism, ordered_query, significant, exclude_iea, region_query, max_p_value, max_set_size, correction_method, hier_filtering, domain_size, custom_bg, numeric_ns, no_isects, png_fn, include_graph, src_filter); 147 ""query.size"", ""overlap.size"", ""recall"", ""precision"",; 148 ""term.id"", ""domain"", ""subgraph.number"", ""term.name"",; --> 149 ""relative.depth"", ""intersection""]; 150 enrichment.index = enrichment['term.id']; 151 numeric_columns = [""query.number"", ""p.value"", ""term.size"",. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __setattr__(self, name, value); 4387 try:; 4388 object.__getattribute__(self, name); -> 4389 return object.__setattr__(self, name, value); 4390 except AttributeError:; 4391 pass. pandas/_libs/properties.pyx in pandas._libs.properties.AxisProperty.__set__(). ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in _set_axis(self, axis, labels); 644 ; 645 def _set_axis(self, axis, labels):; --> 646 self._data.set_axis(axis, labels); 647 self._clear_item_cache(); 648 . ~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py in set_axis(self, axis, new_labels); 3321 raise ValueError(; 3322 'Length mismatch: Expected axis has {old} elements, new '; -> 3323 'values have {new} elements'.format(old=old_len, new=new_len)); 3324 ; 3325 self.axes[axis] = new_labels. ValueError: Length mismatch: Expected axis has 0 elements, new values have 14 elements; ```. I guess it has to do with the output expecting 14 value",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464073234
https://github.com/scverse/scanpy/pull/467#issuecomment-464278846:227,Testability,test,tests,227,"How about an empty `DataFrame` instead of `None`? I think I prefer `len(results) == 0` to `results is None`. Also, I need to look into the arguments to `gprofiler` a bit more before this is ready to merge. I'd also like to add tests, but probably ones that are optional. Does `scanpy` have a preferred way of adding tests that don't run by default?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846
https://github.com/scverse/scanpy/pull/467#issuecomment-464278846:316,Testability,test,tests,316,"How about an empty `DataFrame` instead of `None`? I think I prefer `len(results) == 0` to `results is None`. Also, I need to look into the arguments to `gprofiler` a bit more before this is ready to merge. I'd also like to add tests, but probably ones that are optional. Does `scanpy` have a preferred way of adding tests that don't run by default?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464278846
https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:189,Deployability,update,update,189,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205
https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:235,Deployability,pipeline,pipelines,235,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205
https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:133,Integrability,depend,depend,133,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205
https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:249,Integrability,wrap,wrappers,249,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205
https://github.com/scverse/scanpy/pull/467#issuecomment-466359205:381,Security,access,access,381,"Hey!; I'm a member of g:Profiler (biit.cs.ut.ee/gprofiler) development team and was scanning through web to find services that might depend on us. . We recently went live with an extensive update which might break some of the previous pipelines and wrappers. . All the existing Python and R packages should work, however they are linking to an archived data version and they don't access the most up-to-date data from g:Profiler due to the new API etc. . We have already created a new R package that corresponds to the new API, Python package is still in the progress. . I just wanted to let you know and please feel free to contact me if I can be of any help. All the best,; Liis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-466359205
https://github.com/scverse/scanpy/pull/467#issuecomment-472269046:78,Deployability,release,released,78,"@liiskolb, any chance you have an estimate of when the python package will be released? I'd like to have this PR merge with up-to-date results, and am trying to figure out if I should write a little client. @fidelram Sure!. Just a heads up to everyone, I'm pretty swamped this week and probably won't get around to updating this PR until at least this weekend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-472269046
https://github.com/scverse/scanpy/pull/467#issuecomment-472857688:47,Deployability,release,released,47,"@ivirshup We estimate that the package will be released around 15th of April. So, in a month or so. ; If this is ok, then I'll let you know when it is out:)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-472857688
https://github.com/scverse/scanpy/pull/467#issuecomment-473615430:321,Deployability,release,released,321,"Writing the example for `sc.queries.enrich(adata, ...)` made me realize I probably don't want to encourage that. Potentially could be fixed by a default p-value cutoff. As for the `gprofiler` version, there are two paths forward I think would work:. 1. Put a hold on the `enrich` function for a bit for the new API to be released; 2. If it'd be useful enough to include now, the docs could note current implementation is provisional and results will change pretty soon. Maybe @fidelram and @LuckyMD have thoughts on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-473615430
https://github.com/scverse/scanpy/pull/467#issuecomment-481192068:18,Deployability,update,updated,18,@ivirshup We have updated gprofiler-official to version 1.0.0 that corresponds to the new API.; See the descriptions here: https://pypi.org/project/gprofiler-official/#description,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-481192068
https://github.com/scverse/scanpy/pull/467#issuecomment-483199474:17,Deployability,update,updates,17,"Just pushing the updates now @LuckyMD 😄. One issue with the enrichment as is, is that `gprofiler-official` import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?. Otherwise, I think this should be alright. I'd like to know if there'd be any interest in moving the utility function `rank_genes_groups_df` (added here) into a more central place. I personally use it anytime I use scanpys differential expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-483199474
https://github.com/scverse/scanpy/pull/467#issuecomment-483199474:158,Integrability,wrap,wrapper,158,"Just pushing the updates now @LuckyMD 😄. One issue with the enrichment as is, is that `gprofiler-official` import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?. Otherwise, I think this should be alright. I'd like to know if there'd be any interest in moving the utility function `rank_genes_groups_df` (added here) into a more central place. I personally use it anytime I use scanpys differential expression.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-483199474
https://github.com/scverse/scanpy/pull/467#issuecomment-484043323:527,Deployability,release,release,527,"@ivirshup ""One issue with the enrichment as is, is that gprofiler-official import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?"". I'm not really sure I got it right, but if new version of scanpy includes new version of gprofiler-official, then it should work well. If people have old version of scanpy that uses old version of gprofiler, then it should also work but with data from archived release of gprofiler. . With this kind of updates it is inevitable that some environments break (we have the experience as you can see;)), these just need to be solved case by case if people with problems start to contact. They could be advised to update their packages to solve these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323
https://github.com/scverse/scanpy/pull/467#issuecomment-484043323:569,Deployability,update,updates,569,"@ivirshup ""One issue with the enrichment as is, is that gprofiler-official import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?"". I'm not really sure I got it right, but if new version of scanpy includes new version of gprofiler-official, then it should work well. If people have old version of scanpy that uses old version of gprofiler, then it should also work but with data from archived release of gprofiler. . With this kind of updates it is inevitable that some environments break (we have the experience as you can see;)), these just need to be solved case by case if people with problems start to contact. They could be advised to update their packages to solve these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323
https://github.com/scverse/scanpy/pull/467#issuecomment-484043323:775,Deployability,update,update,775,"@ivirshup ""One issue with the enrichment as is, is that gprofiler-official import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?"". I'm not really sure I got it right, but if new version of scanpy includes new version of gprofiler-official, then it should work well. If people have old version of scanpy that uses old version of gprofiler, then it should also work but with data from archived release of gprofiler. . With this kind of updates it is inevitable that some environments break (we have the experience as you can see;)), these just need to be solved case by case if people with problems start to contact. They could be advised to update their packages to solve these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323
https://github.com/scverse/scanpy/pull/467#issuecomment-484043323:126,Integrability,wrap,wrapper,126,"@ivirshup ""One issue with the enrichment as is, is that gprofiler-official import name conflicts with the previous unofficial wrapper. I'm worried that this will break peoples environments if they're not aware of this. @liiskolb, do you have any thoughts on this?"". I'm not really sure I got it right, but if new version of scanpy includes new version of gprofiler-official, then it should work well. If people have old version of scanpy that uses old version of gprofiler, then it should also work but with data from archived release of gprofiler. . With this kind of updates it is inevitable that some environments break (we have the experience as you can see;)), these just need to be solved case by case if people with problems start to contact. They could be advised to update their packages to solve these issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-484043323
https://github.com/scverse/scanpy/pull/467#issuecomment-504960614:160,Deployability,install,installed,160,@liiskolb The problem is that the `python-gprofiler` and `gprofiler-official` packages are both imported as `import gprofiler`. That means that someone who has installed one of them and then gets the other with scanpy won't know what they are importing if they just run `import gprofiler`. This is not ideal. I just experienced the same thing and decided to remove `python-gprofiler`. But we can't really mandate that everyone does this. @ivirshup maybe the solution is to detect which version people have and then parse according to their version? The format is quite similar. I've used both now and could probably convert inputs and outputs easily. And then I'd throw a warning if `python-gprofiler` is installed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614
https://github.com/scverse/scanpy/pull/467#issuecomment-504960614:705,Deployability,install,installed,705,@liiskolb The problem is that the `python-gprofiler` and `gprofiler-official` packages are both imported as `import gprofiler`. That means that someone who has installed one of them and then gets the other with scanpy won't know what they are importing if they just run `import gprofiler`. This is not ideal. I just experienced the same thing and decided to remove `python-gprofiler`. But we can't really mandate that everyone does this. @ivirshup maybe the solution is to detect which version people have and then parse according to their version? The format is quite similar. I've used both now and could probably convert inputs and outputs easily. And then I'd throw a warning if `python-gprofiler` is installed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614
https://github.com/scverse/scanpy/pull/467#issuecomment-504960614:473,Safety,detect,detect,473,@liiskolb The problem is that the `python-gprofiler` and `gprofiler-official` packages are both imported as `import gprofiler`. That means that someone who has installed one of them and then gets the other with scanpy won't know what they are importing if they just run `import gprofiler`. This is not ideal. I just experienced the same thing and decided to remove `python-gprofiler`. But we can't really mandate that everyone does this. @ivirshup maybe the solution is to detect which version people have and then parse according to their version? The format is quite similar. I've used both now and could probably convert inputs and outputs easily. And then I'd throw a warning if `python-gprofiler` is installed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504960614
https://github.com/scverse/scanpy/pull/467#issuecomment-504998754:260,Deployability,install,installed,260,@LuckyMD Ok. For me it seems that the packages can be differentiated by using `from gprofiler import GProfiler` for official package (for `python-gprofiler` this is `from gprofiler import gprofiler`). Possibly this allows to control if `gprofiler-official` is installed and used.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-504998754
https://github.com/scverse/scanpy/issues/468#issuecomment-461985115:85,Deployability,update,updated,85,"This did fix the recursion issue, thanks. But imortlib.reload(sc) still didn't allow updated source to take effect. I don't know why. Maybe the import tree for this package too complex for importlib.reload???. But the following worked for me. ; ```; ipython; In [1]: %load_ext autoreload; In [2]: %autoreload 2; ln [3]: import scanpy as sc; ln [4]: sc.plotting._tools.scatterplots.tr_test(); [does nothing as expected, then change source to print something out]; ln [5]: sc.plotting._tools.scatterplots.tr_test(); hellya!!!. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468#issuecomment-461985115
https://github.com/scverse/scanpy/issues/468#issuecomment-462133529:210,Deployability,upgrade,upgraded,210,I think autoreload does indeed do more than importlib.reload:. https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#caveats. > Functions and classes imported via ‘from xxx import foo’ are upgraded to new versions when ‘xxx’ is reloaded.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468#issuecomment-462133529
https://github.com/scverse/scanpy/issues/468#issuecomment-462133529:104,Modifiability,config,config,104,I think autoreload does indeed do more than importlib.reload:. https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html#caveats. > Functions and classes imported via ‘from xxx import foo’ are upgraded to new versions when ‘xxx’ is reloaded.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/468#issuecomment-462133529
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:728,Integrability,wrap,wraps,728,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:849,Integrability,wrap,wraps,849,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2466,Integrability,wrap,wraps,2466,"eturn func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2869,Integrability,wrap,wraps,2869,"elta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper; return logged_decorator. # Usage. @logged(logged_args=[""x""]); def foo(adata, x, copy=True):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1, copy=True);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:420,Performance,perform,performance,420,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:114,Testability,log,logging,114,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:161,Testability,log,logging,161,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:479,Testability,log,logging,479,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:572,Testability,Log,Logs,572,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:806,Testability,log,logger,806,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:833,Testability,log,logged,833,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:1117,Testability,log,logger,1117,"benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:1386,Testability,log,logger,1386,"is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value loggin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:1498,Testability,log,logged,1498," what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; fro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2331,Testability,log,logging,2331,"ype(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2589,Testability,log,logger,2589,"; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish""",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2616,Testability,log,logged,2616,"call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:2739,Testability,log,log,2739,"call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo; # 2019-02-13 19:28.03 call_finish call_id=UUID('986f57e4-656a-41b1-9c7c-a7c5ad5b01fc') called_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:3243,Testability,log,logged,3243,"lled_func=foo elapsed=datetime.timedelta(microseconds=505970) returned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper; return logged_decorator. # Usage. @logged(logged_args=[""x""]); def foo(adata, x, copy=True):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1, copy=True); # 2019-02-13 19:35.48 call call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo logged_args={'adata': 4476410456, 'x': 1}; # 2019-02-13 19:35.48 call_finish call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo elapsed=datetime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:3251,Testability,log,logger,3251,"urned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper; return logged_decorator. # Usage. @logged(logged_args=[""x""]); def foo(adata, x, copy=True):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1, copy=True); # 2019-02-13 19:35.48 call call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo logged_args={'adata': 4476410456, 'x': 1}; # 2019-02-13 19:35.48 call_finish call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo elapsed=datetime.timedelta(microseconds=507880) returned_adata_id=5064494384; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:3576,Testability,log,logger,3576,"urned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper; return logged_decorator. # Usage. @logged(logged_args=[""x""]); def foo(adata, x, copy=True):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1, copy=True); # 2019-02-13 19:35.48 call call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo logged_args={'adata': 4476410456, 'x': 1}; # 2019-02-13 19:35.48 call_finish call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo elapsed=datetime.timedelta(microseconds=507880) returned_adata_id=5064494384; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:3713,Testability,log,logged,3713,"urned_adata_id=4940502352; ```. </details>. <details>; <summary>More complicated example with argument value logging</summary>. ```python; from anndata import AnnData; from copy import copy; from datetime import datetime; from functools import wraps; import inspect; from itertools import chain; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(logged_args=None):; """"""; Params; ------; logged_args : list[str], optional (default: `None`); Names of arguments to log.; """"""; if logged_args is None:; logged_args = []; def logged_decorator(func):; argnames = inspect.getfullargspec(func).args; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; logged_params = {}. for param, val in chain(zip(argnames, args), kwargs.items()):; if type(val) is AnnData:; logged_params[param] = id(val); elif param in logged_args:; logged_params[param] = copy(val) # Probably need to consider how these values get logged. logger.msg(""call"", called_func=func.__name__,; logged_args=logged_params, call_id=call_id). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(; called_func=func.__name__, elapsed=dt,; ); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper; return logged_decorator. # Usage. @logged(logged_args=[""x""]); def foo(adata, x, copy=True):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1, copy=True); # 2019-02-13 19:35.48 call call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo logged_args={'adata': 4476410456, 'x': 1}; # 2019-02-13 19:35.48 call_finish call_id=UUID('f7623504-31c5-4afa-ae26-4f58fc5341a8') called_func=foo elapsed=datetime.timedelta(microseconds=507880) returned_adata_id=5064494384; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-463117273:556,Usability,Simpl,Simple,556,"I like this idea, but think it could be expanded on a bit. I think there are benefits to approaching this through logging. Some advantages of doing this through logging:. * Global record. If a copy is made or an AnnData split, you could figure out which object came from where.; * Control over level of detail. What kind of information is recorded can be customized. Maybe the user wants provenance, but maybe they want performance information. What if tracking was done through logging? Here's a couple quick examples of what I mean:. <details>. <summary>Simple example. Logs `anndata` used, function called, time elapsed </summary>. ```python; from anndata import AnnData; from datetime import datetime; from functools import wraps; from structlog import get_logger; from time import sleep; import uuid. logger = get_logger(). def logged(func):; @wraps(func); def func_wrapper(*args, **kwargs):; call_id = uuid.uuid4() # So we can always match call start with call end; call_start_record = dict(call_id=call_id, called_func=func.__name__); if type(args[0]) is AnnData:; call_start_record[""adata_id""] = id(args[0]); logger.msg(""call"", **call_start_record). t0 = datetime.now(); output = func(*args, **kwargs); dt = datetime.now() - t0. call_finish_record = dict(called_func=func.__name__, elapsed=dt); if type(output) is AnnData:; call_finish_record[""returned_adata_id""] = id(output); logger.msg(""call_finish"", **call_finish_record, call_id=call_id); return output; return func_wrapper. # Usage. @logged; def foo(adata, x, copy=False):; sleep(0.5); if copy: return adata.copy(). import scanpy as sc; pbmcs = sc.datasets.pbmc68k_reduced(). foo(pbmcs, 1); # 2019-02-13 19:27.58 call adata_id=4937049368 call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo; # 2019-02-13 19:27.58 call_finish call_id=UUID('82f3944c-08c1-470a-9d39-03dcabc091a2') called_func=foo elapsed=datetime.timedelta(microseconds=500777); foo(pbmcs, 1, copy=True);; # 2019-02-13 19:28.02 call adata_id=4937049368 cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-463117273
https://github.com/scverse/scanpy/issues/472#issuecomment-464492356:58,Testability,log,logging,58,"Interesting ideas. I actually didn't notice scanpy has no logging implemented - this would indeed be useful and could already solve half the problem indeed. However, I doubt the best way to go about this would be post hoc with decorators etc, but rather intrinsically throughout the various API functions. Regardless of logging, I still think that having something which is intrinsically attached to the object would have the advantage of knowing the exact set of operations solely from the h5ad file/AnnData object itself. Don't know if people are actually out there are also sharing these or not but it could be useful from that perspective too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356
https://github.com/scverse/scanpy/issues/472#issuecomment-464492356:320,Testability,log,logging,320,"Interesting ideas. I actually didn't notice scanpy has no logging implemented - this would indeed be useful and could already solve half the problem indeed. However, I doubt the best way to go about this would be post hoc with decorators etc, but rather intrinsically throughout the various API functions. Regardless of logging, I still think that having something which is intrinsically attached to the object would have the advantage of knowing the exact set of operations solely from the h5ad file/AnnData object itself. Don't know if people are actually out there are also sharing these or not but it could be useful from that perspective too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464492356
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:736,Integrability,message,messages,736,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:933,Integrability,wrap,wrapped,933,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:184,Modifiability,variab,variable,184,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1171,Performance,cache,cache,1171,"y variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1642,Performance,cache,cache,1642,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1950,Performance,cache,cache,1950,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1798,Security,access,accessible,1798,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:17,Testability,log,logging,17,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:729,Testability,log,logged,729,"Scanpy does have logging implemented (examples: [neighbors](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/neighbors/__init__.py#L84), [highly variable genes](https://github.com/theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1739,Testability,log,logs,1739,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1862,Testability,log,logging,1862,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:1913,Testability,log,logging,1913,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464575063:2129,Testability,log,log,2129,"theislab/scanpy/blob/d4a7a2d98c1ea219c93d798170a2ca31d208cdbf/scanpy/preprocessing/_highly_variable_genes.py#L81)), but it's not that widely used. I think this is because it has to be implemented manually in the code (not sure if this is what you mean by ""intrinsic""?), which makes it take some effort to implement and not all contributors are aware of. I think using a decorator would be nice for abstracting out the process. This would have benefits of consistency of usage by making it easy, consistency of logged messages, and separation of concerns between computation and tracking. I also think you'd be able to know the exact set of operations from this approach. Assuming all top level functions have been wrapped with a decorator like the one I presented above, this code:. ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""); ```. Should result in a set of (psuedo-)records like:. ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""read_10x_h5"", ""args"": {""filename"": ""./10x_run/outs/filtered_gene_matrix.h5""}, ""returned_adata"": id(1)}; {""call"": ""normalize_per_cell"", ""args"": {""counts_per_cell_after"": 1000}, ""adata_id"": id(1)}; {""call"": ""log1p"", ""adata_id"": id(1)}; {""call"": ""pca"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```. It's pretty trivial to go through these logs and figure out what happened to the AnnData, and made accessible through helper functions. Maybe they'd look like `sc.logging.get_operations(adata_id=id(adata))` or `sc.logging.get_operations(written_to=""./cache/01_simple_process.h5ad"")`. There could also be a helper function to add the relevant records to some field in `.uns` of the relevant AnnData object or a setting which has a log handler do that automatically. Is there some set of information this wouldn't capture?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464575063
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:439,Performance,perform,performed,439,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:665,Performance,cache,cache,665,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:716,Performance,cache,cache,716,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:783,Performance,cache,cache,783,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:1068,Performance,cache,cache,1068,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:19,Testability,log,logging,19,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:63,Testability,log,logfile,63,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:240,Testability,log,logging,240,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:314,Testability,log,logging,314,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:824,Testability,log,logging,824,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464691691:1188,Testability,log,log,1188,"Sorry I missed the logging. I also didn't see the `sc.settings.logfile` option, which obviously makes absolute sense and is convenient to have persistent records when working interactively with anndata objects. I guess just more consistent logging across scanpy functions would be really great. Something like `sc.logging.get_operations(adata_id=id(adata))` would also be super cool, but would it be able to retrieve records of operations performed within rounds of object serialization?. e.g.:; ```python; adata = sc.read_10x_h5(""./10x_run/outs/filtered_gene_matrix.h5""); sc.pp.normalize_per_cell(adata, 1000); sc.pp.log1p(adata); sc.pp.pca(adata); adata.write(""./cache/01_simple_process.h5ad""). adata = sc.read(""./cache/01_simple_process.h5ad""); sc.pp.scale(adata); adata.write(""./cache/01_simple_process.h5ad""); print(sc.logging.get_operations(adata_id=id(adata))); ```; would probably forget the first set of operations?; ```; # Where id(1) is a stand in for value like `id(adata)`; {""call"": ""scale"", ""adata_id"": id(1)}; {""call"": ""write"", ""args"" : {""filename"": ""./cache/01_simple_process.h5ad""}, ""adata_id"": id(1)}; ```; I guess one solution would be to follow the path of ids up the log to retrieve all which seems doable, so this could be a good system. The one thing this wouldn't cover though is persistence within the h5ad object itself. This would be useful in the case of sharing the object with someone for example. As I mentioned before, I'm not sure this is a widespread use case yet, but could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464691691
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:252,Testability,log,logs,252,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:297,Testability,log,logs,297,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:486,Testability,log,logging,486,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:521,Testability,log,logger,521,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:624,Testability,log,logic,624,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:767,Testability,log,logged,767,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:914,Testability,log,logging,914,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-464964127:942,Testability,log,logs,942,"Yeah that's what I was thinking for tracking between serializations. I figure there could be a boolean argument like `exhaustive` which would signify whether you want this particular AnnData or all previous `AnnData`s this could be derived from in the logs. I think it'll be possible to write the logs to some field in an object. There is a question of how complicated this would be to implement, which I haven't quite figured out yet. Maybe you'd add a reference to the AnnData to the logging context, and make a custom logger which decides where to write based on that? Alternatively, maybe this just gets handled by some logic in the decorator. So after a method is called, there's a flag about whether to add records to the modified object. Of course, nothing is logged persistently by default, so it's already an extra step to enable. It's possible sharing could just need two extra steps, ""enable persistent logging"" and ""send them the logs"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-464964127
https://github.com/scverse/scanpy/issues/472#issuecomment-465522391:4,Testability,log,logging,4,"`sc.logging.get_operations` with `exhaustive` would be great, but if one could find a way to store the same persistently or in the object too upon the user's request that would cover all the ground.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/472#issuecomment-465522391
https://github.com/scverse/scanpy/issues/473#issuecomment-462346509:566,Usability,simpl,simple,566,"Thank you for your kind replies, and sorry for my poor descriptions. This is what happend on my env. ![image](https://user-images.githubusercontent.com/19543497/52568903-597c6a80-2e53-11e9-8d9a-3e530bd6f991.png). And now I solved by just adding this,. ```python; import matplotlib as mpl; mpl.rcParams['figure.facecolor'] = 'white'; ```. I verified the same thing on another environment, but it didn't happen.; So this might be critically relating to my personal environment.; I apologize that I didn't verify on another computer before the issue. Lastly, this is a simple example for the thing. ```python; %matplotlib inline. # 2 lines below solved the facecolor problem.; # import matplotlib as mpl; # mpl.rcParams['figure.facecolor'] = 'white'. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='paul15_clusters', legend_loc='on data'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/473#issuecomment-462346509
https://github.com/scverse/scanpy/issues/473#issuecomment-462694429:285,Integrability,message,message,285,"What do you mean? In which way is it incompatible?. In matplotlib/matplotlib#9698 it’s said that. > The goal is to ultimately replace setting `savefig.transparent` by; `figure.facecolor = (0, 0, 0, 0)`. So we should add a `facecolor` parameter and deprecate `transparent` (with a nice message to point people to `set_figure_params(facecolor=(0, 0, 0, 0))`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/473#issuecomment-462694429
https://github.com/scverse/scanpy/issues/473#issuecomment-463049965:683,Integrability,message,message,683,"I was wrong, it worked well... ```python; %matplotlib inline. import scanpy as sc; import matplotlib as mpl. # 2 lines below solved the facecolor problem.; mpl.rcParams['figure.facecolor'] = 'white'; sc.settings.set_figure_params(dpi=80, color_map='viridis', transparent=False). adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='paul15_clusters', legend_loc='on data'); ```; ![screenshot from 2019-02-13 12-42-06](https://user-images.githubusercontent.com/19543497/52685380-d9f2b680-2f8c-11e9-8ca2-692b083116ee.png). Anyway, . > So we should add a `facecolor` parameter and deprecate `transparent` (with a nice message to point people to `set_figure_params(facecolor=(0, 0, 0, 0))`). sounds a good solution. Expliciting that 'white', 'w' or (1,1,1) are also applicable may be kind.; Of course, you can add theme like Seurat's one though I'm not sure how many people are requiring it. - https://satijalab.org/seurat/mca.html; - https://matplotlib.org/gallery/style_sheets/style_sheets_reference.html#sphx-glr-gallery-style-sheets-style-sheets-reference-py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/473#issuecomment-463049965
https://github.com/scverse/scanpy/pull/474#issuecomment-470910941:72,Integrability,wrap,wrap,72,Hi! I’ve wanted to introduce https://github.com/flying-sheep/legacy-api-wrap for some time. do you think that would be sufficient or should we take the deprecation of kwargs into account?. There’s also tantale/deprecated#8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-470910941
https://github.com/scverse/scanpy/pull/474#issuecomment-471489422:66,Integrability,wrap,wrap,66,"OK, so now the question is: should this become part of legacy-api-wrap?. I’d rather have the API fixed once than using multiple decorators. I think It’s clearer to see what the new API is like if you don’t have to think about the order of multiple decorators being applied. Also, I think. ```py; @renamed_args(new=""old""); ```. feels more natural than. ```py; @deprecated_arg_names({""old"": ""new""}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-471489422
https://github.com/scverse/scanpy/pull/474#issuecomment-471489422:153,Usability,clear,clearer,153,"OK, so now the question is: should this become part of legacy-api-wrap?. I’d rather have the API fixed once than using multiple decorators. I think It’s clearer to see what the new API is like if you don’t have to think about the order of multiple decorators being applied. Also, I think. ```py; @renamed_args(new=""old""); ```. feels more natural than. ```py; @deprecated_arg_names({""old"": ""new""}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-471489422
https://github.com/scverse/scanpy/pull/474#issuecomment-473500100:393,Usability,guid,guide,393,"On `legacy_api_wrap`, I don't think I have enough experience maintaining stable APIs to make a call. I'm not too worried about the api for this decorator if it's just in scanpy. Since it'd be only meant for internal use there aren't any promises about the api that should be kept. It also means the issue of multiple decorators can be dealt with when it occurs, and an example case could help guide the decision. I think that I prefer passing a dict to using `kwargs` because it might make sense to give this decorator keyword arguments of its own. For example, if you can specify the version it'll be removed. If keyword arguments we used I agree `new=""old""` would make sense to me, but with a `dict` I see ""old"" maps to ""new"" as more intuitive.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-473500100
https://github.com/scverse/scanpy/pull/474#issuecomment-473500100:736,Usability,intuit,intuitive,736,"On `legacy_api_wrap`, I don't think I have enough experience maintaining stable APIs to make a call. I'm not too worried about the api for this decorator if it's just in scanpy. Since it'd be only meant for internal use there aren't any promises about the api that should be kept. It also means the issue of multiple decorators can be dealt with when it occurs, and an example case could help guide the decision. I think that I prefer passing a dict to using `kwargs` because it might make sense to give this decorator keyword arguments of its own. For example, if you can specify the version it'll be removed. If keyword arguments we used I agree `new=""old""` would make sense to me, but with a `dict` I see ""old"" maps to ""new"" as more intuitive.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-473500100
https://github.com/scverse/scanpy/pull/474#issuecomment-475422571:126,Deployability,release,release,126,"Thanks for clarifying this again, @ivirshup! We should have changed the default value already for 1.4. I'll add a note to the release notes and it's fine... ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474#issuecomment-475422571
https://github.com/scverse/scanpy/issues/476#issuecomment-462582018:0,Deployability,Continuous,Continuous,0,"Continuous color schemes are given with the `color_map` argument, categorical schemes are given with `palette`. All the scatter plots (`scatter`, `pca`, `tsne`, `umap`, etc...) share these arguments. Here's an example:. ```python; import scanpy as sc; import matplotlib as mpl; adata = sc.datasets.pbmc68k_reduced(); sc.pl.umap(adata, color=[""louvain"", ""HES4""]); sc.pl.umap(adata, color=[""louvain"", ""HES4""], palette=""Set2"", color_map=mpl.cm.Reds); ```. It's not that clearly documented for `umap`, and is pretty easy to miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/476#issuecomment-462582018
https://github.com/scverse/scanpy/issues/476#issuecomment-462582018:467,Usability,clear,clearly,467,"Continuous color schemes are given with the `color_map` argument, categorical schemes are given with `palette`. All the scatter plots (`scatter`, `pca`, `tsne`, `umap`, etc...) share these arguments. Here's an example:. ```python; import scanpy as sc; import matplotlib as mpl; adata = sc.datasets.pbmc68k_reduced(); sc.pl.umap(adata, color=[""louvain"", ""HES4""]); sc.pl.umap(adata, color=[""louvain"", ""HES4""], palette=""Set2"", color_map=mpl.cm.Reds); ```. It's not that clearly documented for `umap`, and is pretty easy to miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/476#issuecomment-462582018
https://github.com/scverse/scanpy/pull/477#issuecomment-462730256:206,Modifiability,variab,variables,206,"It sounds like you have a better idea than me. But I'll give it a shot. How does this look?. ```; color_map : `matplotlib.colors.Colormap` or `str`, optional (default: None); Color map to use for continous variables. Anything that works for `cmap`; argument of `pyplot.scatter` should work here (e.g. `""magma""`, `""viridis""`,; `mpl.cm.cividis`). If `None` value of `mpl.rcParams[""image.cmap""]` is used.; palette : `str`, list of `str`, or `Cycler` optional (default: `None`); Colors to use for plotting categorical annotation groups. The palette can be; a valid `matplotlib.pyplot.colormap` name like `'Set2'` or `'tab20'`, a list; of colors like `['red', '#ccdd11', (0.1, 0.2, 1)]` or a Cycler object.; If `None`, `mpl.rcParams[""axes.prop_cycle""]` is used unless categorical; variable already has colors stored in `adata.uns[""{var}_colors""]`.; ```. I could maybe also mention that passing an argument for palette overwrites the values in `adata.uns[""{var}_colors""]`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/477#issuecomment-462730256
https://github.com/scverse/scanpy/pull/477#issuecomment-462730256:776,Modifiability,variab,variable,776,"It sounds like you have a better idea than me. But I'll give it a shot. How does this look?. ```; color_map : `matplotlib.colors.Colormap` or `str`, optional (default: None); Color map to use for continous variables. Anything that works for `cmap`; argument of `pyplot.scatter` should work here (e.g. `""magma""`, `""viridis""`,; `mpl.cm.cividis`). If `None` value of `mpl.rcParams[""image.cmap""]` is used.; palette : `str`, list of `str`, or `Cycler` optional (default: `None`); Colors to use for plotting categorical annotation groups. The palette can be; a valid `matplotlib.pyplot.colormap` name like `'Set2'` or `'tab20'`, a list; of colors like `['red', '#ccdd11', (0.1, 0.2, 1)]` or a Cycler object.; If `None`, `mpl.rcParams[""axes.prop_cycle""]` is used unless categorical; variable already has colors stored in `adata.uns[""{var}_colors""]`.; ```. I could maybe also mention that passing an argument for palette overwrites the values in `adata.uns[""{var}_colors""]`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/477#issuecomment-462730256
https://github.com/scverse/scanpy/pull/477#issuecomment-462743341:36,Deployability,continuous,continuous,36,@flying-sheep @ivirshup The default continuous color map is usually set using `sc.set_figure_params` in the example tutorials. I am not totally sure but I think that internally the `rcParams` are modified. Maybe you can also mention this on the improved documentation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/477#issuecomment-462743341
https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:795,Modifiability,variab,variable,795,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152
https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:479,Testability,test,testdir,479,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152
https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:534,Testability,log,logging,534,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152
https://github.com/scverse/scanpy/issues/478#issuecomment-462722152:671,Usability,learn,learn,671,"I think the problem is the option `sort_order` which is True by default for; numerical data. This changes the ordering of the dots and thus it messes; up with your own sizes. Setting `sort_order=False` should fix the problem. On Tue, Feb 12, 2019 at 6:07 AM Andreas <notifications@github.com> wrote:. > I'm trying to use an array for the size argument to my umap/scatterplot; > with the following code; >; > import scanpy.api as sc; > import numpy as np; > sc.settings.figdir = ""testdir""; > sc.settings.file_format_figs = ""png""; > sc.logging.print_versions(); >; > With these libraries; > scanpy==1.3.7 anndata==0.6.16 numpy==1.16.1 scipy==1.2.0 pandas==0.23.4; > scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Running the following code bit. I use some dummy variable for size.; >; > somedata = sc.datasets.paul15(); > sc.pp.pca(somedata); > sc.pp.neighbors(somedata, n_neighbors=4, n_pcs=20); > sc.tl.umap(somedata, spread=1, min_dist=0.1, random_state=42); > sc.tl.leiden(somedata, resolution=0.5, random_state=42); > z = np.abs(somedata.obsm['X_pca'][:,0])**1; > sc.pl.umap(somedata, color=['1110007C09Rik'], size=z, cmap='viridis', save='continuous_expr.png'); > sc.pl.umap(somedata, color=['leiden'], size=z, cmap='viridis', save='group_value.png'); >; > I get the following two figure as output; > [image: umapcontinuous_expr]; > <https://user-images.githubusercontent.com/715716/52612879-951a3300-2e59-11e9-9dad-a8afc60a4b54.png>; > [image: umapgroup_value]; > <https://user-images.githubusercontent.com/715716/52612880-95b2c980-2e59-11e9-9a44-81dd84e3274d.png>; >; > I would expect to see a similar size allocation/distribution but they are; > very different. I Could not really find a cause for this looking at the; > scatter plot function so it might be somewhere deeper.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/478>, or ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/478#issuecomment-462722152
https://github.com/scverse/scanpy/issues/479#issuecomment-464417618:66,Availability,error,errors,66,"In theory I think we can do most of that. In practice, I got some errors. I think it would be worth formalizing what the supported interface for doing multimodal analysis is. I'd really like it to be uniform. I could see it being based on keys in `.var`:. ```python; adata.var[""gex""] = adata.var[""expression_type""] == ""Gene Expression""; sc.pl.pca(adata, var_key=""gex""); sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); # This also has the nice feature that it could abstract out the current `use_highly_variable` argument; ```. View based:. ```python; gex_view = adata[:, adata.var[""expression_type""] == ""Gene Expression""]; sc.pp.pca(gex_view) # Calculate pca on gene expression; sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); ```. Different expression types could be put under `.obsm` (probably the closest ""analogy"" to `SingleCellExperiment`'s `assays()`). But this raises questions of what counts as a variable, and I think would take more work to implement. Of course, there are many other ways this could be done as well. As it could impact APIs throughout `scanpy`, I think input from @falexwolf and @flying-sheep is important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618
https://github.com/scverse/scanpy/issues/479#issuecomment-464417618:131,Integrability,interface,interface,131,"In theory I think we can do most of that. In practice, I got some errors. I think it would be worth formalizing what the supported interface for doing multimodal analysis is. I'd really like it to be uniform. I could see it being based on keys in `.var`:. ```python; adata.var[""gex""] = adata.var[""expression_type""] == ""Gene Expression""; sc.pl.pca(adata, var_key=""gex""); sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); # This also has the nice feature that it could abstract out the current `use_highly_variable` argument; ```. View based:. ```python; gex_view = adata[:, adata.var[""expression_type""] == ""Gene Expression""]; sc.pp.pca(gex_view) # Calculate pca on gene expression; sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); ```. Different expression types could be put under `.obsm` (probably the closest ""analogy"" to `SingleCellExperiment`'s `assays()`). But this raises questions of what counts as a variable, and I think would take more work to implement. Of course, there are many other ways this could be done as well. As it could impact APIs throughout `scanpy`, I think input from @falexwolf and @flying-sheep is important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618
https://github.com/scverse/scanpy/issues/479#issuecomment-464417618:909,Modifiability,variab,variable,909,"In theory I think we can do most of that. In practice, I got some errors. I think it would be worth formalizing what the supported interface for doing multimodal analysis is. I'd really like it to be uniform. I could see it being based on keys in `.var`:. ```python; adata.var[""gex""] = adata.var[""expression_type""] == ""Gene Expression""; sc.pl.pca(adata, var_key=""gex""); sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); # This also has the nice feature that it could abstract out the current `use_highly_variable` argument; ```. View based:. ```python; gex_view = adata[:, adata.var[""expression_type""] == ""Gene Expression""]; sc.pp.pca(gex_view) # Calculate pca on gene expression; sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); ```. Different expression types could be put under `.obsm` (probably the closest ""analogy"" to `SingleCellExperiment`'s `assays()`). But this raises questions of what counts as a variable, and I think would take more work to implement. Of course, there are many other ways this could be done as well. As it could impact APIs throughout `scanpy`, I think input from @falexwolf and @flying-sheep is important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618
https://github.com/scverse/scanpy/issues/479#issuecomment-510453095:257,Deployability,integrat,integrated,257,>Could epiScanpy be used as a multi-modal analysis tool ? @falexwolf. I think this is a question that is best asked in the episcanpy forum:; https://github.com/colomemaria/epiScanpy/issues. They have used it for multiple epigenomics modalities. Not sure if integrated though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-510453095
https://github.com/scverse/scanpy/issues/479#issuecomment-510453095:257,Integrability,integrat,integrated,257,>Could epiScanpy be used as a multi-modal analysis tool ? @falexwolf. I think this is a question that is best asked in the episcanpy forum:; https://github.com/colomemaria/epiScanpy/issues. They have used it for multiple epigenomics modalities. Not sure if integrated though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-510453095
https://github.com/scverse/scanpy/issues/480#issuecomment-463308380:27,Deployability,Update,Update,27,I have matplotlib 2.2.2. . Update!; I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480#issuecomment-463308380
https://github.com/scverse/scanpy/issues/480#issuecomment-463308380:43,Deployability,update,updated,43,I have matplotlib 2.2.2. . Update!; I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480#issuecomment-463308380
https://github.com/scverse/scanpy/issues/480#issuecomment-463521833:127,Deployability,update,updated,127,"Glad that it worked, and thanks for reporting the issue. I realized that the requirement for scanpy was `matplotlib>=2.2.2`. I updated it to 3.0.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480#issuecomment-463521833
https://github.com/scverse/scanpy/issues/482#issuecomment-463285227:29,Deployability,install,install,29,"In any case, running: `$ pip install anndata -U --no-deps` solves the problem, as then the problematic part of utils.py is not run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482#issuecomment-463285227
https://github.com/scverse/scanpy/issues/483#issuecomment-463602100:167,Modifiability,variab,variable,167,Already fixed in 6c3e92924ea09ef288e422b283c6e03410d64a0b. > This may result in passing an empty `adj_tree` to the `_compute_pos()` function. empty? you mean an unset variable.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/483#issuecomment-463602100
https://github.com/scverse/scanpy/issues/488#issuecomment-464412167:172,Energy Efficiency,efficient,efficient,172,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python; adata.X.eliminate_zeros() # Removes explicit zeros; n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array; np.ravel((adata.X != 0).sum(axis=1)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488#issuecomment-464412167
https://github.com/scverse/scanpy/issues/488#issuecomment-464412167:369,Energy Efficiency,efficient,efficient,369,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python; adata.X.eliminate_zeros() # Removes explicit zeros; n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array; np.ravel((adata.X != 0).sum(axis=1)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488#issuecomment-464412167
https://github.com/scverse/scanpy/issues/488#issuecomment-464412167:394,Energy Efficiency,efficient,efficient,394,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python; adata.X.eliminate_zeros() # Removes explicit zeros; n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array; np.ravel((adata.X != 0).sum(axis=1)); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488#issuecomment-464412167
https://github.com/scverse/scanpy/issues/489#issuecomment-470934197:215,Usability,feedback,feedback,215,"Awesome idea! :). Sorry that I haven't merged all your other PRs, yet. I got back to work on Scanpy yesterday or so after being sick for 2 weeks and another 2 weeks of complete chaos (sick babies)... ;). You'll get feedback very soon, but at first sight, all of them looked fine, anyway. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/489#issuecomment-470934197
https://github.com/scverse/scanpy/issues/490#issuecomment-587473372:183,Security,access,access,183,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```; gene1 = 'XXX'; gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372
https://github.com/scverse/scanpy/issues/490#issuecomment-587473372:244,Testability,log,log,244,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```; gene1 = 'XXX'; gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587473372
https://github.com/scverse/scanpy/issues/490#issuecomment-587532154:32,Usability,simpl,simple,32,"Hi @GMaciag,. This looks like a simple function that people may like to use. Do you want to write a small helper function for this maybe? This might be nice to add to `sc.tl`. One way you could make it display nicely in `sc.pl.umap()` is by turning the values into `pd.Categorical`. In the end you want to show which cells are co-expressing your genes. . Also, this may be a good use for imputation methods. Otherwise you may struggle with the sparsity of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-587532154
https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:800,Availability,avail,available,800,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560
https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:392,Deployability,integrat,integrated,392,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560
https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:392,Integrability,integrat,integrated,392,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560
https://github.com/scverse/scanpy/issues/490#issuecomment-588981048:121,Deployability,continuous,continuous,121,"Regarding Q3 from my previous comment, I tried few things and I think it is the easiest to keep the coexpression data as continuous and remove the colorbar afterwards. . I have, however, correction to what what was written before. `ax.images.im[-1].colorbar.remove()` doesn't work (in the case of umap) since it is a scatter plot. `ax.collections[-1].colorbar.remove()` needs to be used instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588981048
https://github.com/scverse/scanpy/issues/490#issuecomment-589225328:290,Deployability,continuous,continuous,290,"Hey! Sorry for the late reply:; 1. Yes, a separate file, please.; 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`.; 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work.; 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-589225328
https://github.com/scverse/scanpy/issues/490#issuecomment-589225328:466,Usability,usab,usable,466,"Hey! Sorry for the late reply:; 1. Yes, a separate file, please.; 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`.; 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work.; 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-589225328
https://github.com/scverse/scanpy/issues/490#issuecomment-768282049:67,Deployability,continuous,continuous,67,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```; coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &; (adata.raw[:,'{}'.format(gene2)].X.todense() > 0); coex_list = [item for sublist in coex.tolist() for item in sublist]; adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]); ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:; ```; sc.pl.umap(adata, color='CoEx', groups=[True]); ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-768282049
https://github.com/scverse/scanpy/issues/491#issuecomment-464778874:61,Integrability,depend,depends,61,"Hi,; Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491#issuecomment-464778874
https://github.com/scverse/scanpy/issues/491#issuecomment-464778874:115,Integrability,depend,depending,115,"Hi,; Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491#issuecomment-464778874
https://github.com/scverse/scanpy/issues/491#issuecomment-464778874:961,Usability,clear,clearer,961,"Hi,; Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491#issuecomment-464778874
https://github.com/scverse/scanpy/issues/492#issuecomment-465046253:769,Testability,test,tested,769,"Hi,; I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`?. Something like this:; ```; adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```; If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:; ```; adata_tmp = adata.copy(); sc.pp.scale(adata_tmp); adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0); sc.pp.regress_out(adata, genes_of_interest); ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-465046253
https://github.com/scverse/scanpy/issues/492#issuecomment-766321134:143,Availability,error,errors,143,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-766321134
https://github.com/scverse/scanpy/pull/493#issuecomment-471330146:152,Integrability,wrap,wrapper,152,"Thank you for this, @awnimo! I added a few small comments. Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-471330146
https://github.com/scverse/scanpy/pull/493#issuecomment-471725401:161,Integrability,wrap,wrapper,161,"> Thank you for this, @awnimo! I added a few small comments.; > ; > Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you!. Hey @falexwolf ,; I have completed the changes you requestedI.; Please let me know if there are any other issues. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-471725401
https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:155,Availability,error,error,155,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448
https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:38,Deployability,update,updated,38,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448
https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:54,Deployability,install,install,54,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448
https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:301,Deployability,install,install,301,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448
https://github.com/scverse/scanpy/pull/493#issuecomment-477679626:25,Deployability,release,released,25,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477679626
https://github.com/scverse/scanpy/pull/493#issuecomment-477679626:156,Deployability,install,install,156,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477679626
https://github.com/scverse/scanpy/pull/493#issuecomment-477679626:196,Deployability,install,installation,196,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477679626
https://github.com/scverse/scanpy/pull/493#issuecomment-477692840:31,Deployability,install,installation,31,Should’ve checked the docs for installation. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477692840
https://github.com/scverse/scanpy/pull/494#issuecomment-465918085:15,Testability,test,test,15,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085
https://github.com/scverse/scanpy/pull/494#issuecomment-465918085:45,Testability,test,testing,45,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465918085
https://github.com/scverse/scanpy/pull/494#issuecomment-465924110:46,Testability,test,testing,46,"It would've succeeded anyways, it just wasn't testing the right thing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494#issuecomment-465924110
https://github.com/scverse/scanpy/issues/501#issuecomment-479507574:363,Availability,error,error,363,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501#issuecomment-479507574
https://github.com/scverse/scanpy/issues/502#issuecomment-467172649:138,Availability,error,error,138,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:; > ; > I get the following error when I tun dotplot:; > ; > `ValueError Traceback (most recent call last); > in (); > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'); > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds); > 409; > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,; > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds); > 412; > 413; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > ValueError: no field of name MYL2; > `; > ; > Do we need to store marker genes within the adata object?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502#issuecomment-467172649
https://github.com/scverse/scanpy/pull/503#issuecomment-467181263:44,Safety,avoid,avoid,44,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-467181263
https://github.com/scverse/scanpy/pull/503#issuecomment-520200213:195,Testability,test,test,195,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!. To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; * Any thoughts on solutions for the name collision?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-520200213
https://github.com/scverse/scanpy/pull/503#issuecomment-562279386:209,Testability,test,test,209,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!; > ; > To me, this looks pretty close to ready. Just a few things to address:; > ; > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; > * Any thoughts on solutions for the name collision?; > ; > Thanks!. Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1; Please let me know if there is anything else needed to merge.; Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386
https://github.com/scverse/scanpy/pull/503#issuecomment-562279386:564,Testability,test,test,564,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion!; > ; > To me, this looks pretty close to ready. Just a few things to address:; > ; > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this.; > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns?; > * Any thoughts on solutions for the name collision?; > ; > Thanks!. Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1; Please let me know if there is anything else needed to merge.; Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503#issuecomment-562279386
https://github.com/scverse/scanpy/issues/504#issuecomment-467361094:184,Deployability,update,updated,184,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version; > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:; ```; adata; print(adata); ```; > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object; ```; adata2 = adata[:, adata.var['highly_variable']]; print(adata2); print(adata); ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field; `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-25-05be375bfc24> in <module>; > 5 print(adata); > 6 print(adata2); > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'); > 8 print(adata2); > ; > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); > 504 ; > 505 if data_is_AnnData:; > --> 506 adata.obsm['X_pca'] = X_pca; > 507 if use_highly_variable:; > 508 adata.varm['PCs'] = np.zeros(shape=(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094
https://github.com/scverse/scanpy/issues/504#issuecomment-467361094:703,Modifiability,variab,variable,703,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version; > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:; ```; adata; print(adata); ```; > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object; ```; adata2 = adata[:, adata.var['highly_variable']]; print(adata2); print(adata); ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field; `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-25-05be375bfc24> in <module>; > 5 print(adata); > 6 print(adata2); > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'); > 8 print(adata2); > ; > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); > 504 ; > 505 if data_is_AnnData:; > --> 506 adata.obsm['X_pca'] = X_pca; > 507 if use_highly_variable:; > 508 adata.varm['PCs'] = np.zeros(shape=(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094
https://github.com/scverse/scanpy/issues/504#issuecomment-467361094:2555,Modifiability,variab,variable,2555," ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field; `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-25-05be375bfc24> in <module>; > 5 print(adata); > 6 print(adata2); > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'); > 8 print(adata2); > ; > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); > 504 ; > 505 if data_is_AnnData:; > --> 506 adata.obsm['X_pca'] = X_pca; > 507 if use_highly_variable:; > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)); > ; > ValueError: no field of name X_pca. ```; print(adata2); print(adata); ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I do the pca on the original AnnData object for the highly variable genes, it works:; ```; sc.tl.pca(adata, use_highly_variable=True, svd_solver='arpack'); print(adata); ```. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'; > uns: 'pca'; > obsm: 'X_pca'; > varm: 'PCs'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094
https://github.com/scverse/scanpy/issues/504#issuecomment-467361094:336,Usability,learn,learn,336,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version; > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:; ```; adata; print(adata); ```; > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object; ```; adata2 = adata[:, adata.var['highly_variable']]; print(adata2); print(adata); ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 ; > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'; > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field; `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-25-05be375bfc24> in <module>; > 5 print(adata); > 6 print(adata2); > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'); > 8 print(adata2); > ; > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); > 504 ; > 505 if data_is_AnnData:; > --> 506 adata.obsm['X_pca'] = X_pca; > 507 if use_highly_variable:; > 508 adata.varm['PCs'] = np.zeros(shape=(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504#issuecomment-467361094
https://github.com/scverse/scanpy/issues/506#issuecomment-468005012:78,Availability,error,error,78,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468005012
https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:258,Availability,down,downstream,258,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649
https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:643,Testability,test,test,643,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649
https://github.com/scverse/scanpy/issues/509#issuecomment-468852316:239,Availability,avail,available,239,"Hi!. It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316
https://github.com/scverse/scanpy/issues/509#issuecomment-468852316:125,Modifiability,variab,variable,125,"Hi!. It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316
https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544:24,Availability,error,error,24,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544
https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:22,Availability,error,error,22,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922
https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:323,Availability,error,error,323,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922
https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:950,Availability,error,error,950,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922
https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:33,Usability,clear,clear,33,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922
https://github.com/scverse/scanpy/issues/510#issuecomment-473506882:434,Modifiability,variab,variable,434,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python; # Joint distribution with marginal histograms:; sns.jointplot(; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; data=adata.obs,; kind=""hex""; ). # For a single variable; sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":; g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) ; g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids; # I do have a PR for a ridge plot based on this in the works; ```. If you'd like it to be interactive:. ```python; import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""); adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting; adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1); ```. Or, if you want to play with cool most-biggest-data toys:. ```python; adata.obs.hvplot.scatter(; ""log1p_total_counts"",; ""log1p_n_genes_by_counts"",; datashade=True,; dynspread=True; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-473506882
https://github.com/scverse/scanpy/issues/510#issuecomment-487964976:845,Availability,error,error,845,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm; adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: ; #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:; sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976
https://github.com/scverse/scanpy/issues/510#issuecomment-487964976:243,Modifiability,variab,variable,243,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm; adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: ; #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:; sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976
https://github.com/scverse/scanpy/issues/510#issuecomment-487964976:548,Modifiability,variab,variable,548,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm; adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: ; #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:; sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976
https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:436,Availability,error,error,436,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089
https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:1301,Integrability,rout,route,1301,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089
https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:815,Modifiability,extend,extended,815,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089
https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:1128,Performance,perform,performs,1128,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089
https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:51,Integrability,rout,route,51,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552
https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:992,Integrability,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552
https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:592,Modifiability,variab,variables,592,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552
https://github.com/scverse/scanpy/issues/510#issuecomment-488001552:883,Testability,log,log-normalization,883,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```; adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X; ```; It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ ; Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488001552
https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:851,Availability,avail,available,851,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785
https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:564,Deployability,pipeline,pipeline,564,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785
https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:246,Modifiability,variab,variable,246,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785
https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:456,Safety,avoid,avoiding,456,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785
https://github.com/scverse/scanpy/issues/510#issuecomment-488044083:120,Safety,avoid,avoiding,120,"> I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Yes, it's https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.normalize_total.html with param `fraction=0.95`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488044083
https://github.com/scverse/scanpy/issues/510#issuecomment-489055148:651,Testability,Log,Logistic,651,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). ; ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-489055148
https://github.com/scverse/scanpy/issues/510#issuecomment-489055148:1150,Usability,simpl,simply,1150,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). ; ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-489055148
https://github.com/scverse/scanpy/issues/511#issuecomment-469641352:192,Testability,test,test,192,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469641352
https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:566,Modifiability,Variab,Variable,566,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995
https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:804,Modifiability,Variab,Variable,804,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995
https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:888,Modifiability,Variab,Variable,888,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995
https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:772,Safety,detect,detected,772,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995
https://github.com/scverse/scanpy/issues/511#issuecomment-469664995:29,Testability,test,test,29,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM); The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ ; This is what i type into the terminal; $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78); running recipe zheng17; filtered out 3983 genes that are detected in less than 1 counts; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; Killed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469664995
https://github.com/scverse/scanpy/issues/511#issuecomment-469746553:214,Availability,error,error,214,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469746553
https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:208,Deployability,update,update,208,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466
https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:18,Testability,test,tested,18,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466
https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:201,Usability,simpl,simply,201,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466
https://github.com/scverse/scanpy/issues/511#issuecomment-470050466:388,Usability,simpl,simple,388,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050466
https://github.com/scverse/scanpy/issues/511#issuecomment-470050921:5,Deployability,update,updated,5,Just updated the readme https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470050921
https://github.com/scverse/scanpy/issues/511#issuecomment-470255319:42,Testability,test,tested,42,"Hi, @ShobiStassen.; As @falexwolf said, i tested the memory usage in the step where you have the problem.; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb; The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319
https://github.com/scverse/scanpy/issues/511#issuecomment-470255319:149,Testability,benchmark,benchmarks,149,"Hi, @ShobiStassen.; As @falexwolf said, i tested the memory usage in the step where you have the problem.; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb; The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470255319
https://github.com/scverse/scanpy/issues/511#issuecomment-470782494:174,Energy Efficiency,efficient,efficient,174,"Ok, so the first problem is normalization for some reason.; @falexwolf , it seems we should just use new normalize_total when the pull request is accepted, it is more memory efficient.; ![image](https://user-images.githubusercontent.com/3065736/54003760-9afeed80-4153-11e9-9187-8e474a2fa03e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470782494
https://github.com/scverse/scanpy/issues/511#issuecomment-470859467:21,Modifiability,rewrite,rewrite,21,"Cool, @Koncopd! I'll rewrite a recipe for this with the new functions, which should be a lot more memory effective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-470859467
https://github.com/scverse/scanpy/pull/512#issuecomment-469287586:59,Testability,test,test,59,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469287586
https://github.com/scverse/scanpy/pull/512#issuecomment-469287586:75,Testability,test,tests,75,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469287586
https://github.com/scverse/scanpy/pull/512#issuecomment-469314623:21,Testability,test,tests,21,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469314623
https://github.com/scverse/scanpy/pull/512#issuecomment-469320886:6,Testability,test,tests,6,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886
https://github.com/scverse/scanpy/pull/512#issuecomment-469320886:19,Testability,Test,Tests,19,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469320886
https://github.com/scverse/scanpy/pull/512#issuecomment-469609880:15,Testability,Test,Tests,15,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469609880
https://github.com/scverse/scanpy/pull/512#issuecomment-469760800:17,Testability,Test,Tests,17,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?. Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python; sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False); ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-469760800
https://github.com/scverse/scanpy/pull/512#issuecomment-470914298:78,Usability,simpl,simpler,78,I think we should remove the that uses the divergent colormap and keep things simpler.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512#issuecomment-470914298
https://github.com/scverse/scanpy/issues/513#issuecomment-469174695:49,Modifiability,variab,variable,49,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:; `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513#issuecomment-469174695
https://github.com/scverse/scanpy/issues/513#issuecomment-469174695:271,Modifiability,variab,variables,271,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:; `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513#issuecomment-469174695
https://github.com/scverse/scanpy/issues/515#issuecomment-469460276:20,Availability,error,error,20,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469460276
https://github.com/scverse/scanpy/issues/515#issuecomment-469487061:19,Deployability,install,install,19,@macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469487061
https://github.com/scverse/scanpy/issues/515#issuecomment-469502578:21,Deployability,install,install,21,"> @macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving. That indeed solved it! Thanks alot, @shayanhoss ! Although I still don't know what caused the issue in the first place exactly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469502578
https://github.com/scverse/scanpy/issues/515#issuecomment-469639489:13,Deployability,update,update,13,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469639489
https://github.com/scverse/scanpy/issues/515#issuecomment-469639489:104,Deployability,update,update,104,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469639489
https://github.com/scverse/scanpy/issues/515#issuecomment-469639489:240,Deployability,update,updated,240,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469639489
https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:30,Testability,log,logs,30,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225
https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:105,Testability,log,log-scale,105,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225
https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:123,Testability,log,log-fold,123,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225
https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:244,Testability,test,test,244,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225
https://github.com/scverse/scanpy/issues/517#issuecomment-470239225:302,Testability,log,log-normalized,302,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470239225
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:78,Testability,log,log-scale,78,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:378,Testability,test,testing,378,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:463,Testability,test,tests,463,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:527,Testability,test,test,527,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:669,Testability,log,log,669,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:752,Testability,log,loge,752,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:888,Testability,test,tests,888,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:920,Testability,log,loge,920,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:999,Testability,log,log-mean,999,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:1016,Testability,log,log,1016,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:1027,Testability,log,log,1027,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:1052,Testability,log,log,1052,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:1071,Testability,test,tests,1071,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:1112,Testability,log,log,1112,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:144,Usability,intuit,intuitive,144,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470250609:800,Usability,simpl,simplicity,800,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way!. For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts?. Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470250609
https://github.com/scverse/scanpy/issues/517#issuecomment-470311545:40,Testability,log,logs,40,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470311545
https://github.com/scverse/scanpy/issues/517#issuecomment-470319979:108,Testability,log,log-transformed,108,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470319979
https://github.com/scverse/scanpy/issues/517#issuecomment-470319979:267,Testability,test,test,267,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470319979
https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:314,Testability,test,test,314,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611
https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:468,Testability,log,log,468,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611
https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:485,Testability,log,log,485,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611
https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:498,Testability,log,log,498,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611
https://github.com/scverse/scanpy/issues/517#issuecomment-470456611:541,Testability,log,log,541,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-470456611
https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:148,Deployability,pipeline,pipelines,148,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:185,Testability,log,log,185,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:234,Testability,log,log,234,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:273,Testability,log,log,273,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
https://github.com/scverse/scanpy/issues/517#issuecomment-471054932:307,Testability,test,tests,307,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471054932
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:327,Availability,down,downstream,327,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:218,Energy Efficiency,reduce,reduces,218,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:708,Performance,perform,performing,708,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:101,Testability,log,log,101,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:150,Testability,Log,Log-transforming,150,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:433,Testability,log,log,433,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:589,Testability,test,tests,589,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:723,Testability,test,test,723,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:752,Testability,log,log-mean,752,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:769,Testability,log,log,769,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:800,Testability,test,test,800,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:826,Testability,log,log,826,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:867,Testability,test,test,867,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:921,Testability,test,test,921,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:1005,Testability,log,log-mean,1005,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:1022,Testability,log,log,1022,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:1464,Testability,log,log-transformation,1464,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:819,Availability,down,downstream,819,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1639,Availability,down,downstream,1639," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:613,Energy Efficiency,reduce,reduces,613,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:621,Energy Efficiency,power,power,621,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1661,Integrability,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:2152,Security,validat,validating,2152," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:426,Testability,test,testing,426,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:534,Testability,test,testing,534,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1084,Testability,test,tested,1084," And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1126,Testability,test,testing,1126," And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mea",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1542,Testability,log,log-mean,1542," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1559,Testability,log,log,1559," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1753,Testability,log,log-transformation,1753," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:2037,Testability,log,log,2037," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:2102,Testability,test,test,2102," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823
https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492:78,Availability,avail,available,78,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492
https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492:130,Performance,load,loading,130,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492
https://github.com/scverse/scanpy/issues/518#issuecomment-470310775:34,Deployability,install,install,34,"They should if you call; ```; pip install scanpy[louvain] -U; ```; anndata will also update if you call; ```; pip install scanpy -U; ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518#issuecomment-470310775
https://github.com/scverse/scanpy/issues/518#issuecomment-470310775:85,Deployability,update,update,85,"They should if you call; ```; pip install scanpy[louvain] -U; ```; anndata will also update if you call; ```; pip install scanpy -U; ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518#issuecomment-470310775
https://github.com/scverse/scanpy/issues/518#issuecomment-470310775:114,Deployability,install,install,114,"They should if you call; ```; pip install scanpy[louvain] -U; ```; anndata will also update if you call; ```; pip install scanpy -U; ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518#issuecomment-470310775
https://github.com/scverse/scanpy/issues/518#issuecomment-470310775:206,Deployability,install,install,206,"They should if you call; ```; pip install scanpy[louvain] -U; ```; anndata will also update if you call; ```; pip install scanpy -U; ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518#issuecomment-470310775
https://github.com/scverse/scanpy/issues/518#issuecomment-470310775:355,Deployability,install,installation,355,"They should if you call; ```; pip install scanpy[louvain] -U; ```; anndata will also update if you call; ```; pip install scanpy -U; ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518#issuecomment-470310775
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:713,Availability,down,down-weighted,713,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:1246,Availability,robust,robust,1246,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:192,Testability,log,log,192,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:211,Testability,log,log,211,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:353,Testability,log,log,353,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:369,Testability,log,log,369,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:386,Testability,log,log,386,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:468,Testability,test,tests,468,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720
https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:262,Availability,error,error,262,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111
https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:105,Testability,test,tests,105,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111
https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:203,Availability,robust,robust,203,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027
https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:446,Availability,down,downstream,446,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027
https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:514,Availability,error,error,514,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027
https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:358,Testability,test,testing,358,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:122,Availability,error,error,122,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:385,Availability,error,error,385,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:421,Availability,error,error,421,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:520,Availability,error,error,520,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:225,Testability,log,log,225,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:243,Testability,log,log-mean,243,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631
https://github.com/scverse/scanpy/pull/519#issuecomment-477907809:148,Integrability,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-477907809
https://github.com/scverse/scanpy/pull/519#issuecomment-477907809:250,Testability,test,test,250,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-477907809
https://github.com/scverse/scanpy/pull/519#issuecomment-477907809:264,Testability,log,logarithmized,264,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-477907809
https://github.com/scverse/scanpy/pull/519#issuecomment-477907809:364,Testability,log,logarithmized,364,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-477907809
https://github.com/scverse/scanpy/pull/519#issuecomment-477907809:117,Usability,simpl,simply,117,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-477907809
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:93,Integrability,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:214,Testability,test,test,214,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:228,Testability,log,logarithmized,228,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:347,Testability,log,logarithmized,347,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:395,Testability,log,log,395,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478377325:62,Usability,simpl,simply,62,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > ; > Also: If trying to call a t-test with non-logarithmized data, a warning should be written.; > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?. Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478377325
https://github.com/scverse/scanpy/pull/519#issuecomment-478391082:32,Testability,log,log-transformed,32,"Ok, good to read that it wasn't log-transformed!. @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082
https://github.com/scverse/scanpy/pull/519#issuecomment-478391082:94,Usability,simpl,simple,94,"Ok, good to read that it wasn't log-transformed!. @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082
https://github.com/scverse/scanpy/pull/519#issuecomment-478391082:155,Usability,simpl,simple,155,"Ok, good to read that it wasn't log-transformed!. @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-478391082
https://github.com/scverse/scanpy/issues/520#issuecomment-470977867:22,Deployability,integrat,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-470977867
https://github.com/scverse/scanpy/issues/520#issuecomment-470977867:22,Integrability,integrat,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-470977867
https://github.com/scverse/scanpy/issues/520#issuecomment-553385617:49,Deployability,integrat,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-553385617
https://github.com/scverse/scanpy/issues/520#issuecomment-553385617:49,Integrability,integrat,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-553385617
https://github.com/scverse/scanpy/issues/520#issuecomment-553385617:68,Testability,benchmark,benchmarking,68,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520#issuecomment-553385617
https://github.com/scverse/scanpy/issues/521#issuecomment-766287782:16,Deployability,continuous,continuous,16,"If the issue is continuous color maps, that can be specified with the `cmap` parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521#issuecomment-766287782
https://github.com/scverse/scanpy/issues/522#issuecomment-470900854:39,Availability,avail,available,39,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-470900854
https://github.com/scverse/scanpy/issues/522#issuecomment-472497425:166,Integrability,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-472497425
https://github.com/scverse/scanpy/issues/522#issuecomment-476592722:106,Deployability,update,updates,106,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476592722
https://github.com/scverse/scanpy/issues/522#issuecomment-476592722:139,Deployability,integrat,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476592722
https://github.com/scverse/scanpy/issues/522#issuecomment-476592722:139,Integrability,integrat,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476592722
https://github.com/scverse/scanpy/issues/522#issuecomment-476643493:1182,Testability,log,logic,1182,"@falexwolf ; Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105; This can be replaced by importing this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258; This is basicly this; https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329; But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`?. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107; This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-476643493
https://github.com/scverse/scanpy/issues/522#issuecomment-477199838:263,Integrability,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-477199838
https://github.com/scverse/scanpy/issues/522#issuecomment-477325247:269,Integrability,depend,depended,269,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments!. @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions?. @Koncopd ; > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set?. I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-477325247
https://github.com/scverse/scanpy/issues/522#issuecomment-477325247:904,Integrability,depend,depending,904,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments!. @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions?. @Koncopd ; > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set?. I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-477325247
https://github.com/scverse/scanpy/pull/524#issuecomment-471454944:57,Deployability,integrat,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524#issuecomment-471454944
https://github.com/scverse/scanpy/pull/524#issuecomment-471454944:57,Integrability,integrat,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524#issuecomment-471454944
https://github.com/scverse/scanpy/pull/525#issuecomment-471318618:49,Testability,test,tests,49,"Thank you for this! Unfortunately, it breaks the tests. It's such a small change, but I guess @fidelram had something in mind when setting it the way he did...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471318618
https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:52,Deployability,integrat,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638
https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:52,Integrability,integrat,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638
https://github.com/scverse/scanpy/pull/525#issuecomment-471455638:43,Testability,test,test,43,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471455638
https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:42,Availability,error,error,42,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072
https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:394,Availability,error,error,394,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072
https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:186,Deployability,integrat,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072
https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:186,Integrability,integrat,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072
https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:83,Testability,test,tests,83,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072
https://github.com/scverse/scanpy/issues/526#issuecomment-471317931:386,Integrability,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931
https://github.com/scverse/scanpy/issues/526#issuecomment-471317931:548,Testability,Benchmark,Benchmark,548,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471317931
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:599,Availability,down,downstream,599,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:1670,Availability,down,downstream,1670,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:152,Deployability,integrat,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:152,Integrability,integrat,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:560,Integrability,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:582,Integrability,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594
https://github.com/scverse/scanpy/pull/528#issuecomment-471660400:13,Deployability,update,updated,13,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528#issuecomment-471660400
https://github.com/scverse/scanpy/issues/530#issuecomment-474171747:110,Usability,guid,guide,110,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-474171747
https://github.com/scverse/scanpy/issues/530#issuecomment-474301716:238,Testability,log,logarithmization,238,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-474301716
https://github.com/scverse/scanpy/issues/530#issuecomment-474301716:280,Usability,simpl,simple,280,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-474301716
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:69,Availability,error,error,69,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:777,Availability,error,error,777,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:1156,Availability,error,error,1156,". . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:2064,Availability,error,error,2064,"ith #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:120,Deployability,release,release,120,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:587,Deployability,release,release,587,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:219,Testability,test,test,219,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:227,Testability,log,logreg,227,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611
https://github.com/scverse/scanpy/issues/532#issuecomment-572642526:21,Usability,simpl,simple,21,"Hi,; We don't have a simple function for this atm. But you could check out the dotplot, maybe that already does what you'd like. I'm not sure about Seurat, as I predominantly use scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-572642526
https://github.com/scverse/scanpy/issues/532#issuecomment-882140601:400,Deployability,continuous,continuous,400,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```; #make red colormap; colors2 = plt.cm.Reds(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap = mymap(np.arange(mymap.N)); my_cmap[:,-1] = np.linspace(0, 1, mymap.N); my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```; #make blue colormap; colors2 = plt.cm.Blues(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap2 = mymap(np.arange(mymap.N)); my_cmap2[:,-1] = np.linspace(0, 1, mymap.N); my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3); ```; ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```; #make green colormap; colors2 = plt.cm.Greens(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap3 = mymap(np.arange(mymap.N)); my_cmap3[:,-1] = np.linspace(0, 1, mymap.N); my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601
https://github.com/scverse/scanpy/issues/532#issuecomment-882140601:1602,Energy Efficiency,green,green,1602,"orsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap = mymap(np.arange(mymap.N)); my_cmap[:,-1] = np.linspace(0, 1, mymap.N); my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```; #make blue colormap; colors2 = plt.cm.Blues(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap2 = mymap(np.arange(mymap.N)); my_cmap2[:,-1] = np.linspace(0, 1, mymap.N); my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3); ```; ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```; #make green colormap; colors2 = plt.cm.Greens(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap3 = mymap(np.arange(mymap.N)); my_cmap3[:,-1] = np.linspace(0, 1, mymap.N); my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```; #make purple colormap; colors2 = plt.cm.Purples(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap4 = mymap(np.arange(mymap.N)); my_cmap4[:,-1] = np.linspace(0, 1, mymap.N); my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5); ```; ![image](https://user-images.githubusercontent.com/56206488/12608",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601
https://github.com/scverse/scanpy/issues/532#issuecomment-882140601:1635,Energy Efficiency,Green,Greens,1635,"); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap = mymap(np.arange(mymap.N)); my_cmap[:,-1] = np.linspace(0, 1, mymap.N); my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```; #make blue colormap; colors2 = plt.cm.Blues(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap2 = mymap(np.arange(mymap.N)); my_cmap2[:,-1] = np.linspace(0, 1, mymap.N); my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3); ```; ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```; #make green colormap; colors2 = plt.cm.Greens(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap3 = mymap(np.arange(mymap.N)); my_cmap3[:,-1] = np.linspace(0, 1, mymap.N); my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```; #make purple colormap; colors2 = plt.cm.Purples(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap4 = mymap(np.arange(mymap.N)); my_cmap4[:,-1] = np.linspace(0, 1, mymap.N); my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5); ```; ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-8573-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601
https://github.com/scverse/scanpy/issues/532#issuecomment-882140601:411,Modifiability,variab,variables,411,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```; #make red colormap; colors2 = plt.cm.Reds(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap = mymap(np.arange(mymap.N)); my_cmap[:,-1] = np.linspace(0, 1, mymap.N); my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False); ```; ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```; #make blue colormap; colors2 = plt.cm.Blues(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap2 = mymap(np.arange(mymap.N)); my_cmap2[:,-1] = np.linspace(0, 1, mymap.N); my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3); ```; ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```; #make green colormap; colors2 = plt.cm.Greens(np.linspace(0, 1, 128)); colorsComb = np.vstack([colors2]); mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb); my_cmap3 = mymap(np.arange(mymap.N)); my_cmap3[:,-1] = np.linspace(0, 1, mymap.N); my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532#issuecomment-882140601
https://github.com/scverse/scanpy/issues/535#issuecomment-473907861:113,Integrability,wrap,wraps,113,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py; def wraps_plot_scatter(wrapper):; wrapper.__annotations__ = {; k: v for k, v in plot_scatter.__annotations__.items(); if k != 'basis'; }; wrapper.__wrapped__ = plot_scatter; return wrapper. @wraps_plot_scatter; def umap(adata, **kwargs):; """"""...""""""; return plot_scatter(adata, basis='umap', **kwargs); ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-473907861
https://github.com/scverse/scanpy/issues/535#issuecomment-473907861:158,Integrability,wrap,wrapper,158,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py; def wraps_plot_scatter(wrapper):; wrapper.__annotations__ = {; k: v for k, v in plot_scatter.__annotations__.items(); if k != 'basis'; }; wrapper.__wrapped__ = plot_scatter; return wrapper. @wraps_plot_scatter; def umap(adata, **kwargs):; """"""...""""""; return plot_scatter(adata, basis='umap', **kwargs); ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-473907861
https://github.com/scverse/scanpy/issues/535#issuecomment-473907861:169,Integrability,wrap,wrapper,169,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py; def wraps_plot_scatter(wrapper):; wrapper.__annotations__ = {; k: v for k, v in plot_scatter.__annotations__.items(); if k != 'basis'; }; wrapper.__wrapped__ = plot_scatter; return wrapper. @wraps_plot_scatter; def umap(adata, **kwargs):; """"""...""""""; return plot_scatter(adata, basis='umap', **kwargs); ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-473907861
https://github.com/scverse/scanpy/issues/535#issuecomment-473907861:273,Integrability,wrap,wrapper,273,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py; def wraps_plot_scatter(wrapper):; wrapper.__annotations__ = {; k: v for k, v in plot_scatter.__annotations__.items(); if k != 'basis'; }; wrapper.__wrapped__ = plot_scatter; return wrapper. @wraps_plot_scatter; def umap(adata, **kwargs):; """"""...""""""; return plot_scatter(adata, basis='umap', **kwargs); ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-473907861
https://github.com/scverse/scanpy/issues/535#issuecomment-473907861:316,Integrability,wrap,wrapper,316,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py; def wraps_plot_scatter(wrapper):; wrapper.__annotations__ = {; k: v for k, v in plot_scatter.__annotations__.items(); if k != 'basis'; }; wrapper.__wrapped__ = plot_scatter; return wrapper. @wraps_plot_scatter; def umap(adata, **kwargs):; """"""...""""""; return plot_scatter(adata, basis='umap', **kwargs); ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-473907861
https://github.com/scverse/scanpy/issues/535#issuecomment-474168347:91,Integrability,wrap,wraps,91,"Here's pretty much what I've tried:. ```python; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")); pca( #tried tab completion here; ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474168347
https://github.com/scverse/scanpy/issues/535#issuecomment-474168347:113,Integrability,wrap,wraps,113,"Here's pretty much what I've tried:. ```python; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")); pca( #tried tab completion here; ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474168347
https://github.com/scverse/scanpy/issues/535#issuecomment-474255934:156,Integrability,wrap,wraps,156,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)); ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474255934
https://github.com/scverse/scanpy/issues/535#issuecomment-474255934:178,Integrability,wrap,wraps,178,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)); ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474255934
https://github.com/scverse/scanpy/issues/535#issuecomment-474255934:323,Integrability,wrap,wraps,323,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)); ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474255934
https://github.com/scverse/scanpy/issues/535#issuecomment-474255934:367,Integrability,wrap,wrapped,367,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)); ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474255934
https://github.com/scverse/scanpy/issues/535#issuecomment-474255934:407,Modifiability,inherit,inherit,407,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py; import scanpy as sc; from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)); ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474255934
https://github.com/scverse/scanpy/issues/535#issuecomment-474279197:142,Energy Efficiency,reduce,reduce,142,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535#issuecomment-474279197
https://github.com/scverse/scanpy/issues/536#issuecomment-474007740:185,Availability,avail,available,185,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>; wrote:. > I have a dataset for which I have an observation that is only available; > for some cells. When I make a scatter plot that I color code for this; > observation not all cells are plotted:; >; > import randomimport scanpy as sc; >; > adata = sc.datasets.blobs(); > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]; >; > sc.tl.pca(adata); > sc.pl.pca(adata, color='property', size=50); >; > While this should plot 10 cells it only shows one cell:; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>; > I can get the plot I want by filtering cells first:; >; > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50); >; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>; > Would you agree that scanpy should plot all cells that have a valid; > observation?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/536>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474007740
https://github.com/scverse/scanpy/issues/536#issuecomment-474301705:47,Testability,log,logging,47,I just add the versions I used:; ```python; sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705
https://github.com/scverse/scanpy/issues/536#issuecomment-474301705:150,Usability,learn,learn,150,I just add the versions I used:; ```python; sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474301705
https://github.com/scverse/scanpy/issues/536#issuecomment-474344606:371,Testability,log,logging,371,"the problem is that at some point the code calls np.argsort on a; pandas.Series and this returns -1 for NaN values. I will submit a PR to fix; this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',; size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>; wrote:. > I just add the versions I used:; >; > sc.logging.print_versions(); >; > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474344606
https://github.com/scverse/scanpy/issues/536#issuecomment-474344606:479,Usability,learn,learn,479,"the problem is that at some point the code calls np.argsort on a; pandas.Series and this returns -1 for NaN values. I will submit a PR to fix; this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',; size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>; wrote:. > I just add the versions I used:; >; > sc.logging.print_versions(); >; > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > —; > You are receiving this because you commented.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474344606
https://github.com/scverse/scanpy/issues/537#issuecomment-474286898:16,Deployability,release,release,16,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537#issuecomment-474286898
https://github.com/scverse/scanpy/issues/537#issuecomment-474286898:63,Deployability,install,install,63,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537#issuecomment-474286898
https://github.com/scverse/scanpy/issues/537#issuecomment-474286898:116,Deployability,update,updates,116,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537#issuecomment-474286898
https://github.com/scverse/scanpy/issues/537#issuecomment-474286898:219,Deployability,release,release,219,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537#issuecomment-474286898
https://github.com/scverse/scanpy/pull/538#issuecomment-474281330:28,Security,access,access,28,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-474281330
https://github.com/scverse/scanpy/pull/538#issuecomment-474721527:329,Security,access,access,329,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes?. @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-474721527
https://github.com/scverse/scanpy/pull/538#issuecomment-474786478:105,Modifiability,config,configurable,105,"@fidelram Thanks, no further changes. I agree about the arbitrariness but I think it's good to provide a configurable implementation with reasonable defaults. This, I believe, is also what we do in other functions like pp.neighbors and pp.highly_variable_genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-474786478
https://github.com/scverse/scanpy/pull/538#issuecomment-475421495:35,Security,access,access,35,"Cool! Great to have you with write access, @fidelram! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538#issuecomment-475421495
https://github.com/scverse/scanpy/pull/539#issuecomment-474326729:32,Testability,test,tests,32,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474326729
https://github.com/scverse/scanpy/pull/539#issuecomment-474329957:259,Availability,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957
https://github.com/scverse/scanpy/pull/539#issuecomment-474329957:283,Availability,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957
https://github.com/scverse/scanpy/pull/540#issuecomment-474352903:12,Testability,test,test,12,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540#issuecomment-474352903
https://github.com/scverse/scanpy/issues/542#issuecomment-476053717:254,Energy Efficiency,reduce,reduce,254,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-476053717
https://github.com/scverse/scanpy/issues/542#issuecomment-476057005:442,Integrability,message,messages,442,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-476057005
https://github.com/scverse/scanpy/issues/542#issuecomment-476058909:34,Integrability,message,message,34,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-476058909
https://github.com/scverse/scanpy/issues/542#issuecomment-479554225:25,Integrability,message,message,25,"not yet, but we sent the message to them only recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-479554225
https://github.com/scverse/scanpy/issues/542#issuecomment-509026804:316,Usability,simpl,simply,316,"I have to admit that I'm still not an expert in these forums. I'm happy if we go with https://gitter.im/scanpyhelp as a solution. I also know discourse is super popular among many people and I'm happy if we go with it if all three of you, @outlace, @ivirshup and @flying-sheep, think this could be a better place. I simply can't judge myself as I haven't used either of them. Most importantly, let's put what you guys choose on the top of the webpage and properly announce it; it would be terrible to have several of these chat rooms; one on gitter, one discourse, etc. with potentially even different names `scanpyhelp`, `scanpy` etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-509026804
https://github.com/scverse/scanpy/issues/542#issuecomment-509111551:426,Safety,avoid,avoid,426,"Great! @ivirshup set up this https://scanpy.discourse.group. We'll properly announce it and, I hope this becomes the persistent place for discussing issues around using Scanpy. Thank you for the initiative, Brandon! I'll close this for now; if we're unhappy with this solution, we can get back at some point. I'll also follow up on this with an email to you guys. PS: Brandon, could you delete scanpyhelp at gitter so that we avoid potentially confusing people? Thank you. ; PPS: For reference: https://github.com/theislab/scanpy/commit/df80290a2c24403d4af4c8eb4091acaa49e39496",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542#issuecomment-509111551
https://github.com/scverse/scanpy/pull/543#issuecomment-474914457:182,Testability,test,test,182,This looks good so far! Thank you!. Can we call it `embedding_density` or something similar? `density` is a little generic; we might have other methods in the future... Some form of test would also be great! ;). Let me know when this should be merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-474914457
https://github.com/scverse/scanpy/pull/543#issuecomment-474979855:404,Integrability,wrap,wrapping,404,"@fidelram I guess you are the right person to ask for help with this... I'm struggling to work nicely with `plot_scatter()`. I am trying to generate a plot where density values for non-selected conditions are grey, while density values for the selected condition are on 'YlOrRd' or another color map. It seems this is not ideal with a single `plot_scatter()` call (which I was hoping to use as the facet wrapping is already done there). For the grey values I am using a color value of -1, while the others are between 0 and 1. However, when I define a color map that is symmetric around 0, positive values near 0 are mapped to grey instead of colours... any idea why?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-474979855
https://github.com/scverse/scanpy/pull/543#issuecomment-475287691:165,Modifiability,variab,variable,165,"@fidelram Thanks a lot! I was getting confused why my dot sizes weren't working (only sometimes, strangely...). If the dot sizes are sorted according to the `color` variable it should hopefully work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475287691
https://github.com/scverse/scanpy/pull/543#issuecomment-475592847:158,Testability,test,test,158,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475592847
https://github.com/scverse/scanpy/pull/543#issuecomment-475595551:84,Deployability,integrat,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475595551
https://github.com/scverse/scanpy/pull/543#issuecomment-475595551:84,Integrability,integrat,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475595551
https://github.com/scverse/scanpy/pull/543#issuecomment-475598355:149,Deployability,release,release,149,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475598355
https://github.com/scverse/scanpy/pull/543#issuecomment-475598355:66,Usability,simpl,simply,66,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-475598355
https://github.com/scverse/scanpy/pull/543#issuecomment-476209255:29,Testability,test,test,29,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255
https://github.com/scverse/scanpy/pull/543#issuecomment-476209255:45,Testability,test,tests,45,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476209255
https://github.com/scverse/scanpy/pull/543#issuecomment-476406754:12,Testability,test,tests,12,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754
https://github.com/scverse/scanpy/pull/543#issuecomment-476406754:29,Testability,test,tests,29,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754
https://github.com/scverse/scanpy/pull/543#issuecomment-476406754:85,Testability,test,test,85,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543#issuecomment-476406754
https://github.com/scverse/scanpy/issues/544#issuecomment-475183206:78,Deployability,install,install,78,"I think that correlation matrix is only in the latest master version. You can install it using:; ```; pip install git+https://github.com/theislab/scanpy.git; ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475183206
https://github.com/scverse/scanpy/issues/544#issuecomment-475183206:106,Deployability,install,install,106,"I think that correlation matrix is only in the latest master version. You can install it using:; ```; pip install git+https://github.com/theislab/scanpy.git; ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475183206
https://github.com/scverse/scanpy/issues/544#issuecomment-475183206:180,Performance,load,load,180,"I think that correlation matrix is only in the latest master version. You can install it using:; ```; pip install git+https://github.com/theislab/scanpy.git; ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475183206
https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:96,Availability,error,error,96,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377
https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:382,Availability,error,error,382,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377
https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:681,Availability,error,error,681,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377
https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:137,Deployability,install,install,137,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377
https://github.com/scverse/scanpy/issues/544#issuecomment-475911257:2,Availability,down,downloaded,2,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257
https://github.com/scverse/scanpy/issues/544#issuecomment-475911257:45,Deployability,install,installed,45,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257
https://github.com/scverse/scanpy/issues/545#issuecomment-475158480:111,Availability,avail,available,111,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480
https://github.com/scverse/scanpy/issues/545#issuecomment-475158480:38,Usability,undo,undocumented,38,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480
https://github.com/scverse/scanpy/issues/547#issuecomment-475415786:164,Testability,test,test,164,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:; https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547#issuecomment-475415786
https://github.com/scverse/scanpy/issues/547#issuecomment-1164419928:14,Deployability,update,updated,14,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547#issuecomment-1164419928
https://github.com/scverse/scanpy/issues/548#issuecomment-477997099:205,Modifiability,enhance,enhancements,205,"@gokceneraslan If I follow you correctly, the idea would be to add a palette argument to heatmap. That indeed may solve the issue and should not be difficult to achieve. I will put it on my list of future enhancements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548#issuecomment-477997099
https://github.com/scverse/scanpy/issues/548#issuecomment-490092784:240,Deployability,update,update,240,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ?; It feels weird to run umap just to create the slot for colormap althought it worked for me.; Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548#issuecomment-490092784
https://github.com/scverse/scanpy/issues/548#issuecomment-490100552:50,Deployability,update,update,50,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548#issuecomment-490100552
https://github.com/scverse/scanpy/pull/549#issuecomment-476111286:310,Availability,redundant,redundant,310,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations?. @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286
https://github.com/scverse/scanpy/pull/549#issuecomment-476111286:310,Safety,redund,redundant,310,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations?. @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286
https://github.com/scverse/scanpy/pull/549#issuecomment-478145349:79,Modifiability,extend,extending,79,"From my side it's ready to be merged. I have left a note in the comments about extending this to enrichment scores, and that this would be difficult. I though it might be good to leave that in there in case anyone wants to extend it later. Thoughts on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478145349
https://github.com/scverse/scanpy/pull/549#issuecomment-478145349:223,Modifiability,extend,extend,223,"From my side it's ready to be merged. I have left a note in the comments about extending this to enrichment scores, and that this would be difficult. I though it might be good to leave that in there in case anyone wants to extend it later. Thoughts on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478145349
https://github.com/scverse/scanpy/pull/549#issuecomment-478158473:146,Security,expose,exposed,146,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478158473
https://github.com/scverse/scanpy/pull/549#issuecomment-478161476:38,Testability,test,tests,38,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478161476
https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:137,Availability,down,down,137,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193
https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:120,Testability,test,tests,120,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193
https://github.com/scverse/scanpy/pull/549#issuecomment-478667021:130,Availability,down,down,130,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021
https://github.com/scverse/scanpy/pull/549#issuecomment-478667021:152,Availability,error,error,152,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021
https://github.com/scverse/scanpy/pull/549#issuecomment-478933342:257,Testability,assert,assert,257,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342
https://github.com/scverse/scanpy/pull/549#issuecomment-478933342:319,Testability,assert,assert,319,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342
https://github.com/scverse/scanpy/pull/549#issuecomment-478933342:393,Testability,test,testing,393,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478933342
https://github.com/scverse/scanpy/pull/551#issuecomment-476000016:477,Energy Efficiency,reduce,reduce,477,"Ah sorry, I should have told you that. All of the preprocessing functions can be migrated to only work with AnnData; there is no important setting in which you want to pass an array or a sparse matrix. That's also remniscient from the early days when I thought people might not like to use AnnData. But that's of course stupid, they wouldn't use Scanpy in that case, anyway. I'm merging this for now so that we have something working for 1.4.1, but if you want to simplify and reduce this to AnnData-only, happy to merge a PR on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/551#issuecomment-476000016
https://github.com/scverse/scanpy/pull/551#issuecomment-476000016:464,Usability,simpl,simplify,464,"Ah sorry, I should have told you that. All of the preprocessing functions can be migrated to only work with AnnData; there is no important setting in which you want to pass an array or a sparse matrix. That's also remniscient from the early days when I thought people might not like to use AnnData. But that's of course stupid, they wouldn't use Scanpy in that case, anyway. I'm merging this for now so that we have something working for 1.4.1, but if you want to simplify and reduce this to AnnData-only, happy to merge a PR on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/551#issuecomment-476000016
https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:573,Testability,test,test,573,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652
https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:630,Testability,test,test,630,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652
https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:816,Testability,test,test,816,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652
https://github.com/scverse/scanpy/pull/555#issuecomment-483342652:881,Testability,test,test,881,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback.; ```; TypeErrorTraceback (most recent call last); <ipython-input-963-f4f784156b06> in <module>; ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 285 If `show==False` a `matplotlib.Axis` or a list of it.; 286 """"""; --> 287 return plot_scatter(adata, 'umap', **kwargs); 288 ; 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 202 _data_points[:, 0], _data_points[:, 1],; 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 204 **kwargs,; 205 ); 206 . ~/.virtualenvs/intel_default/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555#issuecomment-483342652
https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:13,Availability,redundant,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242
https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:94,Modifiability,variab,variable,94,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242
https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:13,Safety,redund,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242
https://github.com/scverse/scanpy/pull/557#issuecomment-476509763:93,Modifiability,variab,variable,93,"In #458 @fidelram suggested that this would be the way to go. If I put the text into another variable, this variable will only be used once. Does this still make sense? Anyways, I think this is just temporary until `pl.scatter` is in a better shape if I follow @falexwolf correctly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476509763
https://github.com/scverse/scanpy/pull/557#issuecomment-476509763:108,Modifiability,variab,variable,108,"In #458 @fidelram suggested that this would be the way to go. If I put the text into another variable, this variable will only be used once. Does this still make sense? Anyways, I think this is just temporary until `pl.scatter` is in a better shape if I follow @falexwolf correctly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476509763
https://github.com/scverse/scanpy/pull/557#issuecomment-476512533:55,Modifiability,variab,variable,55,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476512533
https://github.com/scverse/scanpy/pull/557#issuecomment-476512533:305,Modifiability,variab,variables,305,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476512533
https://github.com/scverse/scanpy/issues/558#issuecomment-476509564:11,Deployability,install,install,11,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476509564
https://github.com/scverse/scanpy/issues/558#issuecomment-476509564:149,Performance,cache,cache,149,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476509564
https://github.com/scverse/scanpy/issues/558#issuecomment-476509564:411,Performance,cache,cache,411,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476509564
https://github.com/scverse/scanpy/issues/558#issuecomment-476540482:65,Availability,down,downloader,65,"Hi Isaac, I have a related question: does your expression atlas; downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476540482
https://github.com/scverse/scanpy/issues/558#issuecomment-476555082:287,Modifiability,config,configurable,287,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476555082
https://github.com/scverse/scanpy/issues/558#issuecomment-476555082:333,Modifiability,variab,variable,333,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476555082
https://github.com/scverse/scanpy/issues/558#issuecomment-476556129:200,Availability,down,downloadable,200,"Well, I know nothing, maybe you already have everything, but I could; look at an example? The advantage of the expression atlas is that they; have really good meta data. That's provided through their downloadable; files, as far as I remember. So if you got everything that is in their; downloadable meta data files, then you certainly have everything of; interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129
https://github.com/scverse/scanpy/issues/558#issuecomment-476556129:286,Availability,down,downloadable,286,"Well, I know nothing, maybe you already have everything, but I could; look at an example? The advantage of the expression atlas is that they; have really good meta data. That's provided through their downloadable; files, as far as I remember. So if you got everything that is in their; downloadable meta data files, then you certainly have everything of; interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129
https://github.com/scverse/scanpy/issues/558#issuecomment-476558610:455,Performance,Cache,Caches,455,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476558610
https://github.com/scverse/scanpy/issues/558#issuecomment-476558610:573,Performance,cache,cache,573,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476558610
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:159,Deployability,install,installation,159,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:72,Performance,cache,cachedir,72,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:90,Performance,cache,cache,90,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:328,Performance,cache,cache-scanpy,328,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:735,Performance,cache,cachedir,735,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476588843:673,Security,access,accessible,673,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476588843
https://github.com/scverse/scanpy/issues/558#issuecomment-476589204:205,Availability,down,download,205,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204
https://github.com/scverse/scanpy/issues/558#issuecomment-476589204:27,Deployability,toggle,toggleswitch,27,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:114,Availability,down,download,114,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:411,Availability,down,download,411,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:501,Availability,down,download,501,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:576,Availability,down,downloads,576,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:676,Availability,redundant,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:196,Deployability,install,installed,196,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:676,Safety,redund,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:299,Security,access,accession,299,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:324,Security,access,accession,324,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271
https://github.com/scverse/scanpy/issues/558#issuecomment-476615093:189,Modifiability,variab,variables,189,I think @falexwolf voiced my thoughts much more eloquently. A non-hidden directory in the root folder makes a sensible default to me. Would anyone be against also having some environmental variables/ a scanpy config (I’m thinking `.cfg` or `.json`) so this (and things like verbosity) don’t have to be set manually each session?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476615093
https://github.com/scverse/scanpy/issues/558#issuecomment-476615093:209,Modifiability,config,config,209,I think @falexwolf voiced my thoughts much more eloquently. A non-hidden directory in the root folder makes a sensible default to me. Would anyone be against also having some environmental variables/ a scanpy config (I’m thinking `.cfg` or `.json`) so this (and things like verbosity) don’t have to be set manually each session?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476615093
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:214,Availability,Error,Error,214,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:198,Integrability,message,message,198,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:409,Modifiability,variab,variables,409,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:242,Performance,cache,cache,242,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:323,Performance,cache,cache,323,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:504,Performance,cache,cache,504,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808
https://github.com/scverse/scanpy/issues/558#issuecomment-476677167:364,Integrability,message,message,364,"@flyingsheep I can assure you, that's the normal case in academic HPC; systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files; >; > That's a misconfigured server, not a normal case. We should use appdirs as; > default, catch a IOError on write, and send a nice message like; >; > Your cache directory is full. Please make sure there's space in; > {cache_dir} or override the cache directory by setting the; > $SCANPY_CACHE_DIR environment variable.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476677167
https://github.com/scverse/scanpy/issues/558#issuecomment-476677167:542,Modifiability,variab,variable,542,"@flyingsheep I can assure you, that's the normal case in academic HPC; systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files; >; > That's a misconfigured server, not a normal case. We should use appdirs as; > default, catch a IOError on write, and send a nice message like; >; > Your cache directory is full. Please make sure there's space in; > {cache_dir} or override the cache directory by setting the; > $SCANPY_CACHE_DIR environment variable.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476677167
https://github.com/scverse/scanpy/issues/558#issuecomment-476677167:388,Performance,cache,cache,388,"@flyingsheep I can assure you, that's the normal case in academic HPC; systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files; >; > That's a misconfigured server, not a normal case. We should use appdirs as; > default, catch a IOError on write, and send a nice message like; >; > Your cache directory is full. Please make sure there's space in; > {cache_dir} or override the cache directory by setting the; > $SCANPY_CACHE_DIR environment variable.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476677167
https://github.com/scverse/scanpy/issues/558#issuecomment-476677167:478,Performance,cache,cache,478,"@flyingsheep I can assure you, that's the normal case in academic HPC; systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files; >; > That's a misconfigured server, not a normal case. We should use appdirs as; > default, catch a IOError on write, and send a nice message like; >; > Your cache directory is full. Please make sure there's space in; > {cache_dir} or override the cache directory by setting the; > $SCANPY_CACHE_DIR environment variable.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476677167
https://github.com/scverse/scanpy/issues/558#issuecomment-476680606:248,Modifiability,variab,variable,248,"Sure, and I'm not against supporting special cases! Could you please explain the setup?. Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606
https://github.com/scverse/scanpy/issues/558#issuecomment-476680606:135,Performance,cache,cache,135,"Sure, and I'm not against supporting special cases! Could you please explain the setup?. Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606
https://github.com/scverse/scanpy/issues/558#issuecomment-476680606:283,Performance,cache,cache,283,"Sure, and I'm not against supporting special cases! Could you please explain the setup?. Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606
https://github.com/scverse/scanpy/issues/558#issuecomment-476680606:195,Safety,detect,detect,195,"Sure, and I'm not against supporting special cases! Could you please explain the setup?. Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476680606
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:159,Deployability,install,install,159,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:297,Deployability,install,installing,297,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:526,Modifiability,variab,variable,526,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:413,Performance,cache,cache,413,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:561,Performance,cache,cache,561,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:608,Performance,cache,cache,608,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:621,Performance,cache,cache,621,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:873,Performance,cache,cache,873,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:233,Safety,avoid,avoid,233,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:473,Safety,detect,detect,473,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:218,Availability,down,download,218,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:273,Availability,error,error,273,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:1038,Availability,avail,available,1038,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:493,Deployability,install,installing,493,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:832,Modifiability,variab,variable,832,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:934,Performance,Cache,Caches,934,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:1302,Performance,cache,cache,1302,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:852,Testability,log,log,852,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:535,Usability,clear,clear,535,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:625,Usability,intuit,intuitive,625,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:731,Usability,Guid,Guide,731,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:1109,Usability,learn,learn,1109,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:325,Availability,down,download,325,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:389,Availability,down,download,389,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1165,Availability,down,downloaded,1165,"that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them ha",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1375,Availability,avail,available,1375,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:943,Deployability,install,installing,943,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1735,Deployability,install,installs,1735,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1781,Deployability,install,installs,1781,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:629,Modifiability,config,configured,629,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:2167,Modifiability,config,configure,2167,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:431,Performance,cache,cached,431,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:451,Performance,cache,cache,451,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:512,Performance,cache,cache,512,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1291,Performance,cache,cache,1291,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1320,Performance,cache,cache,1320,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1821,Performance,cache,cache,1821,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:839,Usability,clear,clear,839,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:985,Usability,clear,clear,985,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1075,Usability,intuit,intuitive,1075,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:39,Integrability,interface,interfaces,39,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:125,Modifiability,config,config,125,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:299,Modifiability,Config,Config,299,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:315,Modifiability,config,config,315,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:457,Modifiability,config,config,457,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:342,Performance,cache,cachedir,342,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:355,Performance,cache,cache,355,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:403,Performance,cache,cachedir,403,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:428,Performance,cache,cachedir,428,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477113150:502,Performance,cache,cachedir,502,"I'm thinking. My favorite command line interfaces have the ability to query options and set options globally by writing to a config file (jupyter, npm, git, …). Maybe we should give scanpy that ability. People could use that if they use scanpy mainly through scripts. ```console; $ scanpy settings; Config file: ~/.config/scanpy/scanpy.toml; cachedir='~/.cache/scanpy' (default); ...; $ scanpy settings cachedir '/my/path'; Set cachedir to '/my/path' in ~/.config/scanpy/scanpy.toml; $ scanpy settings cachedir; /my/path; ```. And of course we also have a python API for this. People who use scanpy mainly interactively can use that one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477113150
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:104,Availability,down,download,104,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:201,Availability,down,download,201,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:781,Availability,down,downloading,781,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:861,Availability,error,error,861,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:159,Modifiability,config,configure,159,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:427,Modifiability,config,configured,427,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:924,Modifiability,config,configured,924,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:173,Performance,cache,cache,173,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:332,Performance,load,loaded,332,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:372,Performance,cache,cache,372,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:1030,Performance,cache,cachedir,1030,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:1065,Performance,cache,cachedir,1065,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:7,Usability,user experience,user experience,7,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:91,Usability,learn,learn,91,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:134,Availability,down,download,134,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:626,Availability,down,downloaded,626,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:958,Availability,down,downloaded,958,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:1033,Availability,down,downloaded,1033,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:1141,Integrability,interface,interfaces,1141,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:1288,Integrability,interface,interface,1288,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:1227,Modifiability,config,config,1227,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:1307,Modifiability,config,configs,1307,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:68,Performance,cache,cache,68,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:176,Performance,cache,cached,176,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:196,Performance,cache,cache,196,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:984,Performance,cache,cached,984,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:266,Testability,log,logging,266,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:834,Testability,test,test,834,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:889,Usability,clear,cleared,889,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:59,Availability,down,downloader,59,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:168,Deployability,configurat,configuration,168,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:277,Deployability,configurat,configuration,277,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:692,Deployability,configurat,configuration,692,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:168,Modifiability,config,configuration,168,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:277,Modifiability,config,configuration,277,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:692,Modifiability,config,configuration,692,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:1023,Modifiability,config,config,1023,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:1079,Modifiability,variab,variable,1079,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:1090,Modifiability,config,config,1090,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:565,Testability,test,testing,565,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:921,Testability,log,logging,921,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932
https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:93,Availability,down,down,93,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437
https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:361,Availability,error,errors,361,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437
https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:200,Security,access,access,200,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437
https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:19,Usability,user experience,user experience,19,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1070,Availability,down,downloaded,1070,"t I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1145,Availability,down,downloaded,1145,"e of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1402,Availability,down,download,1402,"changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a lon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2510,Availability,down,down,2510,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2207,Deployability,configurat,configuration,2207,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2418,Deployability,configurat,configuration,2418,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1753,Integrability,interface,interface,1753,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:779,Modifiability,config,configs,779,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:793,Modifiability,config,config,793,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:930,Modifiability,config,config,930,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1457,Modifiability,config,configured,1457,"py log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1772,Modifiability,config,configs,1772,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2207,Modifiability,config,configuration,2207,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2418,Modifiability,config,configuration,2418,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:29,Performance,cache,cache,29,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:116,Performance,cache,cached,116,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:160,Performance,cache,cache,160,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:751,Performance,cache,cache,751,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:768,Performance,cache,cache,768,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:924,Performance,cache,cache,924,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1096,Performance,cache,cached,1096,"t I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1423,Performance,cache,cache,1423,"changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a lon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2617,Security,access,access,2617,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:336,Testability,log,logging,336,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:523,Testability,log,log,523,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:600,Testability,log,log,600,"> Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1001,Usability,clear,cleared,1001," Scipy is actually under ~/.cache on my mac, ¯\\_(ツ)_/¯. Sorry, I was too terse here: What I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:109,Deployability,release,released,109,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:142,Deployability,install,install,142,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:197,Deployability,install,install,197,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:326,Deployability,install,installation,326,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:489,Deployability,release,released,489,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476770853:555,Deployability,install,installed,555,"These are the features that are added recently in the development version of scanpy and therefore not in any released version. You can either install the development version from github using `pip install git+https://github.com/theislab/scanpy -U` or by following the instructions here https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Note that the development version is more likely to be unstable. Alternatively, you can browse the documentation of stable (released) version of scanpy (which is what you get when scanpy is installed via pip or conda) by selecting the `stable version` on the documentation page from the menu at the bottom left:. ![image](https://user-images.githubusercontent.com/1140359/55020552-7026ed00-4fcd-11e9-8302-02a4f8f973ed.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476770853
https://github.com/scverse/scanpy/issues/560#issuecomment-476837808:92,Deployability,release,releases,92,"Thank you and sorry about the confusion, I remembered this was an option present in earlier releases, but I was wrong!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-476837808
https://github.com/scverse/scanpy/issues/560#issuecomment-477453468:219,Availability,avail,available,219,"@gokceneraslan We had it switched to stable by default for some time already. I'm fine doing this again; I switched it back because I found some typos, etc., some missing explanation that I wanted to become immediately available...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-477453468
https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:573,Availability,error,error,573,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168
https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:325,Deployability,install,install,325,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168
https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:275,Testability,test,testenv,275,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168
https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:312,Testability,test,testenv,312,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168
https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:115,Deployability,release,releases,115,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825
https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:179,Deployability,update,update,179,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825
https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:213,Security,secur,security,213,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825
https://github.com/scverse/scanpy/issues/561#issuecomment-477128825:25,Usability,simpl,simple,25,"If someone figures out a simple workaround and submits a PR, we'll merge it, but we only support the newest bugfix releases ourselves. You should definitely tell your sysadmin to update to Python 3.5.4, there are security holes in your version as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477128825
https://github.com/scverse/scanpy/issues/561#issuecomment-477340341:422,Availability,error,error,422,"Thank you so much for the feedback!; I'll definitely talk to the admin, but I am not sure he would update. Considering conda, I've tried using ; conda create -n scanpy python=3.6 scanpy; conda activate scanpy. It creates the environment, but then apparently I need to run a jupyter notebook from the terminal for the environment to be activated. When trying to do it, I am getting a ""Jupyter Notebook requires JavaScript"" error, and I can't figure out how to solve it while connecting through ssh, because running ""jupyter notebook --no-browser"" generates a token I can use only on the local machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341
https://github.com/scverse/scanpy/issues/561#issuecomment-477340341:99,Deployability,update,update,99,"Thank you so much for the feedback!; I'll definitely talk to the admin, but I am not sure he would update. Considering conda, I've tried using ; conda create -n scanpy python=3.6 scanpy; conda activate scanpy. It creates the environment, but then apparently I need to run a jupyter notebook from the terminal for the environment to be activated. When trying to do it, I am getting a ""Jupyter Notebook requires JavaScript"" error, and I can't figure out how to solve it while connecting through ssh, because running ""jupyter notebook --no-browser"" generates a token I can use only on the local machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341
https://github.com/scverse/scanpy/issues/561#issuecomment-477340341:26,Usability,feedback,feedback,26,"Thank you so much for the feedback!; I'll definitely talk to the admin, but I am not sure he would update. Considering conda, I've tried using ; conda create -n scanpy python=3.6 scanpy; conda activate scanpy. It creates the environment, but then apparently I need to run a jupyter notebook from the terminal for the environment to be activated. When trying to do it, I am getting a ""Jupyter Notebook requires JavaScript"" error, and I can't figure out how to solve it while connecting through ssh, because running ""jupyter notebook --no-browser"" generates a token I can use only on the local machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341
https://github.com/scverse/scanpy/issues/561#issuecomment-477403279:367,Security,secur,security,367,"Hmm, that's strange. I use the generated token to connect to remote notebook servers pretty frequently. Any ideas why it isn't working for you?. Here's the workflow I follow. First, on the machine you'd like to work on, in the conda environment you want to use:. ```; jupyter notebook --no-browser --port=8889; ```. This will start the notebook server and report the security token. On my machine I create an ssh tunnel to the server with the following command (replacing `<remote_user>` and `<remote_host>` with your info):. ```; ssh -N -L 8889:localhost:8889 <remote_user>@<remote_host>; ```. Now I point my browser to `localhost:8889` and will be connected to the remote server, where it'll ask for the token. After pasting that in I'm connected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477403279
https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:64,Deployability,update,update,64,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477
https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:108,Safety,risk,risks,108,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477
https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:99,Security,secur,security,99,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477
https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:492,Security,password,password-setup,492,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477
https://github.com/scverse/scanpy/issues/561#issuecomment-477595971:46,Deployability,install,installed,46,"Just an extra idea... In case you have docker installed, you could use a dockerized scanpy. The guys running SCENIC have a dockerized version of it in their workflow. Maybe you could ask them nicely for their docker image?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477595971
https://github.com/scverse/scanpy/issues/561#issuecomment-477937882:90,Deployability,update,updated,90,"There’s also https://github.com/FASTGenomics/base_image_alpine_scanpy, but it hasn’t been updated in a while. Should be no big problem to update it though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477937882
https://github.com/scverse/scanpy/issues/561#issuecomment-477937882:138,Deployability,update,update,138,"There’s also https://github.com/FASTGenomics/base_image_alpine_scanpy, but it hasn’t been updated in a while. Should be no big problem to update it though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477937882
https://github.com/scverse/scanpy/issues/562#issuecomment-477015393:326,Usability,simpl,simple,326,"I thing that is not so difficult to achieve this. I submit a PR soon. Fidel Ramírez . > On 26 Mar 2019, at 22:02, Alex Wolf <notifications@github.com> wrote:; > ; > @fidelram, as discussed today, could we adopt pl.rank_genes_groups_dotplot so that it reads this information from .uns['rank_genes_groups']?; > ; > Maybe just a simple switch? Or having arguments color and size be a choice from a selection {pvals, pvals_adj, log2FC, expression, frac-genes-expressed}.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-477015393
https://github.com/scverse/scanpy/issues/562#issuecomment-480385619:167,Usability,simpl,simple,167,"> @fidelram, as discussed today, could we adopt `pl.rank_genes_groups_dotplot` so that it reads this information from `.uns['rank_genes_groups']`?; > ; > Maybe just a simple switch? Or having arguments `color` and `size` be a choice from a selection {`pvals`, `pvals_adj`, `log2FC`, `expression`, `frac-genes-expressed`}. I would also love that actually 😄 . `rank_genes_groups` results (LFC, p-val etc) and things like `mean-expression`, `frac-genes-expressed` are all cluster-specific features, which reminds me of an `obs`-like structure with clusters in rows. Right now, mean expression and fractions are calculated in a private function (`_prepare_dataframe`) in `plotting/_anndata.py` but we can move this to `utils.py` or so, call it in sc.tl.rank_genes_groups() and store the resulting data frame in ad.uns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-480385619
https://github.com/scverse/scanpy/issues/562#issuecomment-483204895:471,Security,access,accessible,471,"Why is it that .obs, .var, and .uns don't have data frames in them? `np.recarray` don't seem like a very popular data structure elsewhere. Also, I'd like to suggest that storing all differential expression within the anndata object might get complicated, and deserve it's own class. It'd be nice if it could be easy to tell what cells and genes were compared, what exactly was being tested, and which direction is ""up"". That said, the results should definitely be easily accessible as a data frame.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-483204895
https://github.com/scverse/scanpy/issues/562#issuecomment-483204895:383,Testability,test,tested,383,"Why is it that .obs, .var, and .uns don't have data frames in them? `np.recarray` don't seem like a very popular data structure elsewhere. Also, I'd like to suggest that storing all differential expression within the anndata object might get complicated, and deserve it's own class. It'd be nice if it could be easy to tell what cells and genes were compared, what exactly was being tested, and which direction is ""up"". That said, the results should definitely be easily accessible as a data frame.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-483204895
https://github.com/scverse/scanpy/issues/562#issuecomment-483216799:228,Usability,simpl,simpler,228,"Huh? `obs` and `var` have been `DataFrame`s for a long time now. and `uns` is a dict. The reason why they haven’t originally been that is that `DataFrame`s are super complicated and have a giant API. We thought having something simpler would be easier to work with, but in the end convenience won.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-483216799
https://github.com/scverse/scanpy/issues/562#issuecomment-485384100:50,Modifiability,flexible,flexible,50,"Back on the topic of getting dot plots a bit more flexible, I've been working on an approach that could work. You can check it out in [this binder environment](https://mybinder.org/v2/gh/ivirshup/scanpy-interactive/master?filepath=notebooks%2Fflexible_de.ipynb), but it's based on two main ideas:. 1. It'd be nice if there were an easy way to get aggregated values for groups, so I've added a crude `groupby` to `AnnData`; 2. Our differential expression results are like a 3d array, with axes `[""genes"", ""group"", ""values""]` where values are things like p-values and mean expression. Here's a quick example of the output:. ![image](https://user-images.githubusercontent.com/8238804/56495993-0dc4fc00-653b-11e9-8831-a830b2ead841.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-485384100
https://github.com/scverse/scanpy/issues/562#issuecomment-485712812:310,Testability,log,log,310,"This looks really cool... but then I haven't used dot plots much before, so not sure what this is replacing... I just wonder if you can put different thresholds on the `pvals_adj` colour bar, such that every p-value `> 0.05` is grey or something like that... Or even better would be to put the colour bar on a log scale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-485712812
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:305,Energy Efficiency,power,powerful,305,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:525,Security,access,accessible,525,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:1028,Security,access,accessing,1028,"like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means of aggr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:273,Testability,test,test,273,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:677,Testability,log,logic,677,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:158,Usability,simpl,simply,158,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487279241:440,Usability,intuit,intuitive,440,"> obs-like structure with clusters in rows. Completely agreed!; 1. agreed with @ivirshup that there should be a more comprehensive object (which can possibly simply be stored as a dataframe and params in `.uns['rank_genes_groups']`, that clarify what the reference for the test was, but that might be not powerful enough)... your latest suggestion, @ivirshup, representing things as in 3d array sounds very promising, too... how to make an intuitive object? represent the 3d array in a long-form dataframe where two axes are accessible from one multi-index? or store an actual 3d array in AnnData, which can be cast into a convenient object, through a casting namespace... the logic being `sc.tl....` computes some complicated annotation, `sc.pl...` visualizes this annotation and `sc.ex....` extracts and casts annotation into more easily manageable objects. One example is `sc.Neigbors` (which should go into `sc.ex...`) which takes the weird annotation that `sc.pp.neighbors` writes and casts them into an object that allows accessing things... ; 2. Related, but really independent of `rank_genes_groups`: I had implemented a [draft of a `.collapse()` function](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/zebrafish/zebrafish.ipynb#Collapsing-the-AnnData-object), which is very similar to the [`.groupby()` function](https://github.com/ivirshup/mantis#group-by) that @ivirshup suggests, but much less elegant (I would also never have put it into the main repo...). You take a summary metric like `.mean()` or `.std()` and collapse the object by that (in pandas, would be `df.groupby('louvain').mean()`. > Why is it that .obs, .var, and .uns don't have data frames in them? np.recarray don't seem like a very popular data structure elsewhere. We just did only allow rec arrays in `.uns` as they are natively supported by hdf5 and dataframes aren't. It was really just that reason, nothing else. As mentioned in anndata, I'd love to completely move away from rec arrays as a means o",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487279241
https://github.com/scverse/scanpy/issues/562#issuecomment-487343093:205,Security,access,access,205,"1. I've been playing around with `xarray` and finding the `Dataset` objects fairly intuitive for storing multidimensional arrays. I think it makes sense to store calculated values like this, but give easy access to a long (/tidy) dataframe (similar to that binder notebook). I think representing it internally as a tidy dataframe could be inefficient, since that's pretty close to 100% dense COO matrix. My impression is this is broadly similar to how diffxpy is representing it's results. I think there are also two separate problems here, which are ""what's a better way to store differential expression results"" and ""what's a good api for differential expression"". I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. 2. I'd really like to get a generalized version of this implemented. Right now, I think the biggest thing holding it back is being smart about how sparse matrices are handled, but otherwise xarray has a good model for the semantics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487343093
https://github.com/scverse/scanpy/issues/562#issuecomment-487343093:83,Usability,intuit,intuitive,83,"1. I've been playing around with `xarray` and finding the `Dataset` objects fairly intuitive for storing multidimensional arrays. I think it makes sense to store calculated values like this, but give easy access to a long (/tidy) dataframe (similar to that binder notebook). I think representing it internally as a tidy dataframe could be inefficient, since that's pretty close to 100% dense COO matrix. My impression is this is broadly similar to how diffxpy is representing it's results. I think there are also two separate problems here, which are ""what's a better way to store differential expression results"" and ""what's a good api for differential expression"". I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. 2. I'd really like to get a generalized version of this implemented. Right now, I think the biggest thing holding it back is being smart about how sparse matrices are handled, but otherwise xarray has a good model for the semantics.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487343093
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:2948,Deployability,pipeline,pipeline,2948,"sk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `sc.ex.neighbors`, which should return an instance of `sc.Neighbors` (which can then disappear from the root API). Similarly, when `sc.pp.neighbors` is called with `inplace=False`, one should directly get a `Neighbors` object returned. Now, we can apply this logic to every single function that doesn't have a simple return value. Upon calling the function with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cas",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:1180,Energy Efficiency,efficient,efficient,1180," :smile:. Re diffxpy: If you say that diffxpy has a good solution, why should we build a new one? Can't we just use their solution?. > I think there are also two separate problems here, which are ""what's a better way to store differential expression results"" and ""what's a good API for differential expression"". Completely agreed. > I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. **Re sc.extract**. One of the core ideas of Scanpy (as opposed to, say, scikit learn) was to have this model of taking the burden of bookkeeping from the user as much as possible. This design messed up, in particular, the return values of `rank_genes_groups`. I would have loved to return a collection of dataframes, but I didn't want to mess this up. Also, the return values of `pp.neighbors` or `pl.paga` aren't great. There is a trade-off between having nice APIs and return values (such as dataframes) and a transparent and efficient on-disk representation in terms of HDF5, zarr or another format. These days, I'd even consider simply pickling things, which would have saved us a lot of work; but I thought that we'd need established compression facilities, concatenation possibilities, some way to manually ""look into"" an on-disk object (both from R and from the command line) so that it's maximally transparent and then the widely established, cross-language, but old-school and not entirely scalable HDF5 seemed the best. The Human Cell Atlas decided in favor of zarr meanwhile. But that's not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:3639,Energy Efficiency,efficient,efficient,3639," get a `Neighbors` object returned. Now, we can apply this logic to every single function that doesn't have a simple return value. Upon calling the function with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4969,Integrability,depend,dependency,4969,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:3864,Modifiability,rewrite,rewrite,3864,"tion with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:1651,Performance,scalab,scalable,1651,"ssion"". Completely agreed. > I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. **Re sc.extract**. One of the core ideas of Scanpy (as opposed to, say, scikit learn) was to have this model of taking the burden of bookkeeping from the user as much as possible. This design messed up, in particular, the return values of `rank_genes_groups`. I would have loved to return a collection of dataframes, but I didn't want to mess this up. Also, the return values of `pp.neighbors` or `pl.paga` aren't great. There is a trade-off between having nice APIs and return values (such as dataframes) and a transparent and efficient on-disk representation in terms of HDF5, zarr or another format. These days, I'd even consider simply pickling things, which would have saved us a lot of work; but I thought that we'd need established compression facilities, concatenation possibilities, some way to manually ""look into"" an on-disk object (both from R and from the command line) so that it's maximally transparent and then the widely established, cross-language, but old-school and not entirely scalable HDF5 seemed the best. The Human Cell Atlas decided in favor of zarr meanwhile. But that's not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4818,Performance,scalab,scalable,4818,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4852,Performance,scalab,scalable,4852,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:2726,Testability,log,logic,2726," not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `sc.ex.neighbors`, which should return an instance of `sc.Neighbors` (which can then disappear from the root API). Similarly, when `sc.pp.neighbors` is called with `inplace=False`, one should directly get a `Neighbors` object returned. Now, we can apply this logic to every single function that doesn't have a simple return value. Upon calling the function with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might co",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4533,Testability,test,tests,4533,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4895,Testability,test,test,4895,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4921,Testability,log,logreg,4921,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:731,Usability,learn,learn,731,"Sounds great!. Re tidy: Storing things internally in tidy format also seems inefficient to me... I remember a long discussion with Philipp more than 2 years ago... :smile:. Re diffxpy: If you say that diffxpy has a good solution, why should we build a new one? Can't we just use their solution?. > I think there are also two separate problems here, which are ""what's a better way to store differential expression results"" and ""what's a good API for differential expression"". Completely agreed. > I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. **Re sc.extract**. One of the core ideas of Scanpy (as opposed to, say, scikit learn) was to have this model of taking the burden of bookkeeping from the user as much as possible. This design messed up, in particular, the return values of `rank_genes_groups`. I would have loved to return a collection of dataframes, but I didn't want to mess this up. Also, the return values of `pp.neighbors` or `pl.paga` aren't great. There is a trade-off between having nice APIs and return values (such as dataframes) and a transparent and efficient on-disk representation in terms of HDF5, zarr or another format. These days, I'd even consider simply pickling things, which would have saved us a lot of work; but I thought that we'd need established compression facilities, concatenation possibilities, some way to manually ""look into"" an on-disk object (both from R and from the command line) so that it's maximally transparent and then the widely established, cross-language, but old-school and not entirely scalable HDF5 seemed the best. The Human Cell Atlas decided in favor of zarr meanwhile. But that's not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being sa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:1285,Usability,simpl,simply,1285,"ssion"". Completely agreed. > I'm interested in the `sc.ex` module you're suggesting. Would you mind elaborating a bit more on that, particularly on some functions that would be there?. **Re sc.extract**. One of the core ideas of Scanpy (as opposed to, say, scikit learn) was to have this model of taking the burden of bookkeeping from the user as much as possible. This design messed up, in particular, the return values of `rank_genes_groups`. I would have loved to return a collection of dataframes, but I didn't want to mess this up. Also, the return values of `pp.neighbors` or `pl.paga` aren't great. There is a trade-off between having nice APIs and return values (such as dataframes) and a transparent and efficient on-disk representation in terms of HDF5, zarr or another format. These days, I'd even consider simply pickling things, which would have saved us a lot of work; but I thought that we'd need established compression facilities, concatenation possibilities, some way to manually ""look into"" an on-disk object (both from R and from the command line) so that it's maximally transparent and then the widely established, cross-language, but old-school and not entirely scalable HDF5 seemed the best. The Human Cell Atlas decided in favor of zarr meanwhile. But that's not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:2777,Usability,simpl,simple,2777," not a drama, because Scanpy only writes ""storage-friendly"" values to AnnData, that is, arrays and dicts. HDF5 knows how to handle them and zarr also. If one uses xarray or dataframes, one has to think about how this gets written to disk. That being said: it's likely that we'll continue to choose representations for on-disk (and in-memory) storage that aren't convenient (rec arrays, for instance), a three-dimensional xarray and dicts. A general solution for this problem would be the mentioned `sc.extract` API, similar to `sc.plotting` (which also completely hides the complexity of the object from the user), but not for returning visualizations, but nice objects. The first function in that namespace should be `sc.ex.neighbors`, which should return an instance of `sc.Neighbors` (which can then disappear from the root API). Similarly, when `sc.pp.neighbors` is called with `inplace=False`, one should directly get a `Neighbors` object returned. Now, we can apply this logic to every single function that doesn't have a simple return value. Upon calling the function with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might co",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:3857,Usability,simpl,simply,3857,"tion with `inplace=False`, you'll get a ""nice"" object that is convenient to handle. If you call a function `sc.tl.function` in a pipeline with `inplace=True` but later on, you'll want this nice object, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4098,Usability,clear,clear,4098,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4418,Usability,simpl,simply,4418,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487409358:4915,Usability,learn,learn,4915,"ct, you'd call `sc.ex.function`. I think DataFrames (a case like `tl.marker_gene_overlap`) should definitely be handled within AnnData and no `extract` function is necessary. But the differential expression result is a prime example for such a case. I think a function `rank_genes_groups` that returns a `RankGenesGroups` object, which then has `.to_df()` function (e.g. the function `rank_genes_groups` from (https://github.com/theislab/scanpy/pull/619) could immediately go into that namespace. Maybe we can even borrow a `diffxpy` object for that. The good thing is, we can keep the current rec arrays as they are very efficient and basic data types, which will work with hdf5 and zarr and xarray and everything else that might come in the future. And: Fidel wrote a ton of plotting functions around them already, which we don't want to simply rewrite... We don't have to as users won't see the recarrays anymore... Other possible names for the API would be `sc.cast` or `sc.object` (`sc.ob`), less conflicting with `sc.external`. I think `sc.ob` makes sense as it really makes clear that Scanpy's main API is for writing convenient scripts for compute-heavy stuff in a functional way. If one wants to transition to more light-weight ""post-analysis"", one can transition to objects that are designed for specific tasks. PS: I'd love to move away from the name `rank_genes_groups` at some point, and simply have something like `difftest` or `DiffTest`... I always thought that we might have differential expression tests for longitudinal data at some point (like Monocle), otherwise the function would be `rank_genes` but I don't think this is gonna happen soon, and if, it will be in the `external` API... A minimal difftest API should though continue be in the core of Scanpy, with at its heart, a scalable Wilcoxon rank (much more scalable than scipy's or diffxpy's), the t test and the scikit learn logreg approach. `diffxpy` with it's tensorflow dependency can then handle very complex cases...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487409358
https://github.com/scverse/scanpy/issues/562#issuecomment-487563174:390,Modifiability,extend,extend,390,"I really like the `sc.extract` idea (or `sc.cast`/`sc.object`). It would be pretty cool if that went both ways though. For example, if I want to generate differential expression results with `diffxpy`, store everything in my `AnnData` object, and visualize later with `sc.pl.rank_genes_groups_violin()`, this could be done by some kind of `sc.read.diffxpy()` function. Maybe you could just extend `sc.read` and `sc.write` and make them into larger modules? Or rename both to `sc.io`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487563174
https://github.com/scverse/scanpy/issues/562#issuecomment-487830709:35,Security,access,accessors,35,"I like the idea for the ""nice data accessors module""! Maybe `sc.get`? `sc.get.obs_values(adata, ...)`, `sc.get.neighbors(adata, ...)`. We'd definitely have to be sure we're returning a nice object. | If you say that diffxpy has a good solution, why should we build a new one? Can't we just use their solution?. I think this would involve throwing away recarrays, unless someone wants to write a converter (not me). I'm also not so sure how mature/ stable `diffxpy` is, but Theis lab people might have a better sense of that?. | That being said: it's likely that we'll continue to choose representations for on-disk. I like that the current representations are pretty easy to read in other languages as they're mostly standard hdf5 types. I think there are definitely cases where it make sense to break cross-compat, like complicated datastructures for a specific package (an index, for example). | If one uses xarray or dataframes, one has to think about how this gets written to disk. My impression is `xarray` were designed to be similar to `netCDF` files, which [are a subset of hdf5](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#How-can-I-convert-netCDF-4-files-into-HDF5-files). `pandas`, on the other hand, has a pretty opaque `hdf5` representation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487830709
https://github.com/scverse/scanpy/issues/562#issuecomment-487930836:295,Energy Efficiency,power,powerful,295,"`sc.get` is a good suggestion, too! I'd be fine with it. > diffxpy. @davidsebfischer: do you feel you have a mature solution for storing simple difftest results that could be reused for `rank_genes_groups`? If yes, can you point us to it? It might be that you don't as you have these relatively powerful objects that do a lot more than what we want in the context of a simple Wilcoxon Rank group-vs-reference comparison. > My impression is xarray were designed to be similar to netCDF files, which are a subset of hdf5. pandas, on the other hand, has a pretty opaque hdf5 representation. If xarray does everything we want (sparse and categorical data), that would be great, of course. I was investigating pandas hdf5 early on and decided against it as it was very opaque (e.g., I couldn't see how to easily implement on-disk concatenation on it) and it didn't seem to offer performance gains.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487930836
https://github.com/scverse/scanpy/issues/562#issuecomment-487930836:874,Performance,perform,performance,874,"`sc.get` is a good suggestion, too! I'd be fine with it. > diffxpy. @davidsebfischer: do you feel you have a mature solution for storing simple difftest results that could be reused for `rank_genes_groups`? If yes, can you point us to it? It might be that you don't as you have these relatively powerful objects that do a lot more than what we want in the context of a simple Wilcoxon Rank group-vs-reference comparison. > My impression is xarray were designed to be similar to netCDF files, which are a subset of hdf5. pandas, on the other hand, has a pretty opaque hdf5 representation. If xarray does everything we want (sparse and categorical data), that would be great, of course. I was investigating pandas hdf5 early on and decided against it as it was very opaque (e.g., I couldn't see how to easily implement on-disk concatenation on it) and it didn't seem to offer performance gains.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487930836
https://github.com/scverse/scanpy/issues/562#issuecomment-487930836:137,Usability,simpl,simple,137,"`sc.get` is a good suggestion, too! I'd be fine with it. > diffxpy. @davidsebfischer: do you feel you have a mature solution for storing simple difftest results that could be reused for `rank_genes_groups`? If yes, can you point us to it? It might be that you don't as you have these relatively powerful objects that do a lot more than what we want in the context of a simple Wilcoxon Rank group-vs-reference comparison. > My impression is xarray were designed to be similar to netCDF files, which are a subset of hdf5. pandas, on the other hand, has a pretty opaque hdf5 representation. If xarray does everything we want (sparse and categorical data), that would be great, of course. I was investigating pandas hdf5 early on and decided against it as it was very opaque (e.g., I couldn't see how to easily implement on-disk concatenation on it) and it didn't seem to offer performance gains.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487930836
https://github.com/scverse/scanpy/issues/562#issuecomment-487930836:369,Usability,simpl,simple,369,"`sc.get` is a good suggestion, too! I'd be fine with it. > diffxpy. @davidsebfischer: do you feel you have a mature solution for storing simple difftest results that could be reused for `rank_genes_groups`? If yes, can you point us to it? It might be that you don't as you have these relatively powerful objects that do a lot more than what we want in the context of a simple Wilcoxon Rank group-vs-reference comparison. > My impression is xarray were designed to be similar to netCDF files, which are a subset of hdf5. pandas, on the other hand, has a pretty opaque hdf5 representation. If xarray does everything we want (sparse and categorical data), that would be great, of course. I was investigating pandas hdf5 early on and decided against it as it was very opaque (e.g., I couldn't see how to easily implement on-disk concatenation on it) and it didn't seem to offer performance gains.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-487930836
https://github.com/scverse/scanpy/issues/562#issuecomment-503949436:234,Security,access,accessor,234,"OK, we have those alternatives:. Alternative | Pro | Con; ---|---|---; Keep everything as it is | People will have the best unterstanding of its structure and not treat it as a black box | Unwieldy; Subclass AnnData in scanpy and add accessor methods/attrs | Nice API | <ul><li>Everyone would start using Scanpy’s AnnData subclass instead of the generic container that I think is a great design choice for extensibility<li>Hides AnnData structure</ul>; `sc.get` | <ul><li>Nice API<li>Separates Scanpy-specific API from AnnData API</ul> | Hides AnnData structure. I think `sc.get` is the best option here!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/562#issuecomment-503949436
https://github.com/scverse/scanpy/issues/563#issuecomment-477527532:227,Availability,error,error-prone,227,"> it is trying to use linux formatting on a Windows machine. that’s not the issue, forward slashes and relative paths work perfectly on windows. The issue is that this code uses string manipulation to work with paths, which is error-prone. https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/readwrite.py#L440-L441. @falexwolf using `pathlib` for path manipulation as much as possible protects us from mistakes like this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532
https://github.com/scverse/scanpy/issues/565#issuecomment-477833445:74,Availability,avail,available,74,"This feature is still in the development version of scanpy, therefore not available in the released scanpy version yet. See https://github.com/theislab/scanpy/issues/560 for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445
https://github.com/scverse/scanpy/issues/565#issuecomment-477833445:91,Deployability,release,released,91,"This feature is still in the development version of scanpy, therefore not available in the released scanpy version yet. See https://github.com/theislab/scanpy/issues/560 for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445
https://github.com/scverse/scanpy/issues/566#issuecomment-477933420:73,Availability,error,error,73,"```py; >>> from math import sqrt ; >>> sqrt(-1); ValueError: math domain error; ```. I assume it’s the square root throwing this. Assuming that it only happens when you pass a negative argument, the term inside can only become negative if `ns[imask] < 0` or `ns[imask] > n_cells`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-477933420
https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:160,Availability,error,error,160,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998
https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:78,Testability,test,test,78,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998
https://github.com/scverse/scanpy/issues/566#issuecomment-611280022:35,Availability,error,error,35,"Hi, I am also still receiving this error!. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-141-e471c5e20fbd> in <module>; > ----> 1 sc.tl.rank_genes_groups(adata, 'louvain_05',n_genes=100,method=""wilcoxon"",use_raw=False); > ; > e:\programs\python\python38\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, layer, **kwds); > 398 mean_rest, var_rest = _get_mean_var(X[mask_rest]); > 399 ; > --> 400 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; > 401 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); > 402 scores[np.isnan(scores)] = 0; > ; > ValueError: math domain error. How can I deal with it? I though it was a bug that is fixed now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022
https://github.com/scverse/scanpy/issues/566#issuecomment-611280022:832,Availability,error,error,832,"Hi, I am also still receiving this error!. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-141-e471c5e20fbd> in <module>; > ----> 1 sc.tl.rank_genes_groups(adata, 'louvain_05',n_genes=100,method=""wilcoxon"",use_raw=False); > ; > e:\programs\python\python38\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, layer, **kwds); > 398 mean_rest, var_rest = _get_mean_var(X[mask_rest]); > 399 ; > --> 400 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; > 401 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); > 402 scores[np.isnan(scores)] = 0; > ; > ValueError: math domain error. How can I deal with it? I though it was a bug that is fixed now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022
https://github.com/scverse/scanpy/issues/567#issuecomment-477832283:171,Availability,error,error,171,"Not sure we can do a lot with just a traceback. Could you create a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to reproduce this error, and describe what you were trying to do?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-477832283
https://github.com/scverse/scanpy/issues/567#issuecomment-478651835:294,Availability,error,errors,294,"Hi. Please see below for the minimal script used. Thanks!. ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; import matplotlib.pyplot as plt; from pathlib import Path. scv.settings.set_figure_params('scvelo'). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.autosave = True; sc.settings.autoshow = False; sc.set_figure_params(scanpy=True, dpi=80, dpi_save=160, frameon=False, vector_friendly=False, format='pdf'). adata = sc.read_loom(""./Velocyto_comb.loom""). sc.pp.filter_cells(adata, min_genes=1000); sc.pp.filter_genes(adata, min_cells=10). print('\nDoing initial filtering...\nKeeping', len(adata.obs_names), 'cells and', len(adata.var_names), 'genes.\n'). mito_genes = adata.var_names.str.startswith('MT-'); # Calculate the percent of genes derived from mito vs genome; # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing); adata.obs['percent_mito'] = np.sum(; 	adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; # add the total counts per cell as observations-annotation to adata; adata.obs['n_counts'] = adata.X.sum(axis=1).A1. sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],; 			 jitter=0.4, multi_panel=True, save = '_preFiltering_plot.pdf', show = False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478651835
https://github.com/scverse/scanpy/issues/567#issuecomment-478795943:195,Availability,error,error,195,"Would you mind reading through the link I sent and cutting this back?. This doesn't fit the ""reproducible"" criteria (I don't have that data file), and I'm not sure which line actually causes the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478795943
https://github.com/scverse/scanpy/issues/567#issuecomment-479346876:218,Availability,error,error,218,"Actually, no need to post more. A labmate managed to find this too. It looks like it has something to do with Matplotlib and the `TkAgg` backend (see: https://github.com/matplotlib/matplotlib/issues/13414). While this error doesn't occur in my normal environment, I can reproduce this error in a conda environment:. ```sh; conda create -yn conda_scanpy scanpy; conda activate conda_scanpy; python -c ""import matplotlib.pyplot as plt; plt.figure()""; ```. We were able to get plotting to work by switching to the `Agg` backend. You can do this by adding the following lines to the top of your script:. ```python; import matplotlib as mpl; mpl.use(""Agg""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876
https://github.com/scverse/scanpy/issues/567#issuecomment-479346876:285,Availability,error,error,285,"Actually, no need to post more. A labmate managed to find this too. It looks like it has something to do with Matplotlib and the `TkAgg` backend (see: https://github.com/matplotlib/matplotlib/issues/13414). While this error doesn't occur in my normal environment, I can reproduce this error in a conda environment:. ```sh; conda create -yn conda_scanpy scanpy; conda activate conda_scanpy; python -c ""import matplotlib.pyplot as plt; plt.figure()""; ```. We were able to get plotting to work by switching to the `Agg` backend. You can do this by adding the following lines to the top of your script:. ```python; import matplotlib as mpl; mpl.use(""Agg""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876
https://github.com/scverse/scanpy/issues/567#issuecomment-479352073:59,Availability,error,error,59,@kt6k were you using a conda environment when you hit this error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479352073
https://github.com/scverse/scanpy/issues/567#issuecomment-489908092:299,Integrability,depend,depending,299,"@kt6k, I think that's worth opening a separate issue for. I'm not too experienced with the velocyto tools, but I suspect the issue might be more appropriate for either [velocyto-team/velocyto.py](https://github.com/velocyto-team/velocyto.py) or [theislab/scvelo](https://github.com/theislab/scvelo) depending on when this filtering is occurring.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-489908092
https://github.com/scverse/scanpy/pull/568#issuecomment-478230333:26,Usability,simpl,simple,26,"Those are good! Short and simple. On Sat, Mar 30, 2019 at 9:02 PM Philipp A. <notifications@github.com> wrote:. > The ones from vscode are pretty good:; > https://github.com/Microsoft/vscode/issues/new/choose; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/568#issuecomment-478229664>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AH221DYPmPqIrPkmsxrzuc2eWtN_QRLzks5vbzY9gaJpZM4cRcJj>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/568#issuecomment-478230333
https://github.com/scverse/scanpy/issues/569#issuecomment-477995981:39,Testability,test,test,39,"Can you provide an example that we can test for this?. On Fri, Mar 29, 2019 at 8:37 AM jiawen wang <notifications@github.com>; wrote:. > Dear,; > I used sc.pl.rank_genes_groups_heatmap(adata) to create a heatmap of; > top100 marker genes of 8,000 cells, 4 clusters, but it ran slowly, about 30; > times slowers than seurat's Doheatmap(). Could you modify it to accelerate; > the process ?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/569>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1VPvaV-CHAOc88jcDpj8iSlwQgqUks5vbcK7gaJpZM4cRzgZ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/569#issuecomment-477995981
https://github.com/scverse/scanpy/issues/570#issuecomment-477971741:381,Availability,avail,available,381,"Sounds like a great idea. generally the order should be the same as in the signature, but I don’t see a problem in reshuffling the lovain args to match the leiden ones. We have to be careful with details though: e.g. `partition_type` needs to be slightly different for both:. ```rst; Type of partition to use. Defaults to :class:`~louvain.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~louvain.find_partition`.; ```; ```rst; Type of partition to use. Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~leidenalg.find_partition`.; ```. @falexwolf do you think we should go ahead with https://pypi.org/project/legacy-api-wrap (and introduce `*` in `louvain`’s signature` or do you think we can slightly reshuffle the last few arguments of `louvain` without considering it a backwards compat break?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741
https://github.com/scverse/scanpy/issues/570#issuecomment-477971741:576,Availability,avail,available,576,"Sounds like a great idea. generally the order should be the same as in the signature, but I don’t see a problem in reshuffling the lovain args to match the leiden ones. We have to be careful with details though: e.g. `partition_type` needs to be slightly different for both:. ```rst; Type of partition to use. Defaults to :class:`~louvain.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~louvain.find_partition`.; ```; ```rst; Type of partition to use. Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~leidenalg.find_partition`.; ```. @falexwolf do you think we should go ahead with https://pypi.org/project/legacy-api-wrap (and introduce `*` in `louvain`’s signature` or do you think we can slightly reshuffle the last few arguments of `louvain` without considering it a backwards compat break?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741
https://github.com/scverse/scanpy/issues/570#issuecomment-477971741:750,Integrability,wrap,wrap,750,"Sounds like a great idea. generally the order should be the same as in the signature, but I don’t see a problem in reshuffling the lovain args to match the leiden ones. We have to be careful with details though: e.g. `partition_type` needs to be slightly different for both:. ```rst; Type of partition to use. Defaults to :class:`~louvain.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~louvain.find_partition`.; ```; ```rst; Type of partition to use. Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~leidenalg.find_partition`.; ```. @falexwolf do you think we should go ahead with https://pypi.org/project/legacy-api-wrap (and introduce `*` in `louvain`’s signature` or do you think we can slightly reshuffle the last few arguments of `louvain` without considering it a backwards compat break?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741
https://github.com/scverse/scanpy/issues/570#issuecomment-478211254:71,Performance,optimiz,optimization,71,"@gokceneraslan since they are largely the same thing (just a different optimization strategy), do we even need to keep both?. Otherwise, I think I'd prefer them to be separate functions, so you don't get argument interactions. For example, the `partition_type` argument has to be a type from the same package as the method, otherwise there are segfaults.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-478211254
https://github.com/scverse/scanpy/pull/573#issuecomment-478207900:42,Availability,failure,failure,42,Changing to WIP since I'd like to improve failure handling before this gets merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478207900
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:967,Modifiability,config,config,967,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:1083,Modifiability,config,config,1083,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:1415,Modifiability,config,config,1415,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:1648,Modifiability,config,config,1648,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:624,Performance,cache,cache,624,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:722,Performance,cache,cache,722,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:779,Performance,cache,cache,779,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478388822:822,Performance,cache,cache,822,"Isaac,. this is great, thank you so much!. Regarding the default for the dataset directory. I like this solution!. Very small edits in addition to what I commented in the code:; * Can we call this `epi_sc_expression_atlas` instead of `expression_atlas`?; * For the time being, can we make this `settings.datasetsdir` instead of `settings.dataset_dir` and add it here: https://github.com/theislab/scanpy/blob/97c8b54ec884ac8e8396a80b6782a0d59a17a874/scanpy/api/__init__.py#L272; * Can we point it to the home directory by default, I'd say `~/scanpy-datasets/`?. Notes:; * By having a datasets dir, which is separate from the cache dir (which make sense), I guess, we can also use `user_cache_dir(…)` as the default for the cache dir (which would hopefully choose something in `~/.cache` on a Linux system, probably via `~/.cache/scanpy/`, I think this what you, also Phil (!) and Gökcen favored if I'm correctly summarizing the long thread?; * We already had a Scanpy config in the beginning (was an `.ini`) and we can reintroduce it in the future, and it should probably go into `~/.config/scanpy.ini` (or `.json` or `.yaml`). No reason not to have it. No need to have a CLI for this purpose.; * We can replace `.settings` with an instance of a class `._settings.Settings`. By that, attributes get auto-documented, we can do nice checks on setting attributes via properties, and we can also directly write to a `~/.config/scanpy.ini` file...; * `pyplot.rc_context` sounds awesome.; * Precedence for settings is correct as stated in https://github.com/theislab/scanpy/issues/558#issuecomment-478214932, this is also how I had it before removing the config file...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478388822
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:829,Deployability,configurat,configuration,829,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:681,Modifiability,config,config,681,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:829,Modifiability,config,configuration,829,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:904,Modifiability,config,config,904,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:989,Modifiability,config,config,989,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:1073,Modifiability,variab,variable,1073,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:43,Performance,load,loading,43,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:171,Security,access,access,171,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:17,Testability,test,tests,17,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:225,Testability,test,tests,225,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:356,Testability,test,tests,356,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478414881:402,Testability,assert,assertion,402,"Oh, I also added tests for example dataset loading since checking they worked manually was a pain. These won't run by default (they take a while, and can fail for network access reasons), but will run with `pytest --internet-tests`. Note that `test_burczynski06` will fail until this get's rebased on master. Thoughts?. Also travis failed this for `scanpy/tests/test_marker_gene_overlap.py` failing an assertion on the first time around, but passed when I triggered a new build. Not sure what's up with that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414881
https://github.com/scverse/scanpy/pull/573#issuecomment-478843888:233,Performance,cache,cachedir,233,"@falexwolf, @flying-sheep . Just to recap what's left to be resolved here. * I'll reset the default value of `datasetdir` to the current value ""./data""; * Related, how about `datasetdir` instead of `datasetsdir`? It matches more to `cachedir` and `figdir`. Also, by analogy, it's ""potato sack"" not ""potatoes sack"" so ""dataset directory"" sounds more natural that ""datasets directory"" to me.; * `ebi_expression_atlas` vs `ebi_sc_expression_atlas`; * Potentially adding a class for settings right now?; * I think this becomes more important if `datasetdir` is documented. I bet people will set it with a `str` instead of a `Path` and that'll break things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478843888
https://github.com/scverse/scanpy/pull/573#issuecomment-479385067:597,Usability,simpl,simple,597,"OK guys, I'm happy with all that!. I suggested `datasetsdir` over `datasetdir` because the module is called `datasets` and it's a place where many datasets end up. But, Isaac, you're the native speaker, so you're choice. Regarding making a settings a class: happy to if you feel you want to do that already in this PR. Really just change `scanpy/settings.py` to `scanpy/_settings.py`, put a `Settings` class in that file and generate an instance upon importing Scanpy. You could also just make `datasetdir` the only property and add all other attributes of the current `scanpy/settings` module as simple attributes. Then, all of this should be 10 min of work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479385067
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:416,Availability,error,error,416,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:51,Modifiability,variab,variables,51,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:558,Modifiability,variab,variable,558,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:143,Testability,test,tests,143,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:221,Testability,test,tested,221,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:479,Testability,log,logging,479,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756
https://github.com/scverse/scanpy/pull/573#issuecomment-479736498:53,Modifiability,variab,variables,53,"> Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Yes, now that you made everything a property, I would have expected it to take much longer than 10 minutes. It's great that you did!. I'll make some tiny additions and merge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479736498
https://github.com/scverse/scanpy/pull/573#issuecomment-479741041:144,Usability,simpl,simply,144,"Ah, I cannot push to your fork it seems. I think you would have had to set ""allow maintainers to edit"" or something on the right-hand side. I'm simply merging this and editing after that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479741041
https://github.com/scverse/scanpy/pull/573#issuecomment-479744957:310,Availability,avail,available,310,"Oh, huh, I thought allowing modifications was on by default. My bad. . > Yes, now that you made everything a property, I would have expected it to take much longer than 10 minutes. It's great that you did!. I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through `?sc.settings.{setting}`!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479744957
https://github.com/scverse/scanpy/pull/573#issuecomment-479745339:58,Modifiability,config,config,58,Oh! I keep forgetting to ask: Why did the original scanpy config file get removed?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479745339
https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:105,Availability,avail,available,105,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272
https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:338,Availability,avail,available,338,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272
https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:514,Modifiability,config,config,514,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272
https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:773,Modifiability,config,config,773,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272
https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:863,Modifiability,config,config,863,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272
https://github.com/scverse/scanpy/pull/573#issuecomment-479758866:395,Availability,error,error,395,">Only strange thing is the getdoc function. It looks like instance methods can't have new attributes assigned (probably have slots). It's possible the `.getdoc` attribute could be added to the classes method (not sure if that's the right way to say that, here's an example):. ```python; class Foo(object):; def bar(self):; return 1. # Setting an attribute on the method of an instance raises an error; Foo().bar.x = 1; # AttributeError: 'method' object has no attribute 'x'. # Setting an attribute on the method of a class seems fine:; Foo.bar.x = 1 ; Foo().bar.x; # 1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479758866
https://github.com/scverse/scanpy/issues/575#issuecomment-478268425:779,Testability,test,test,779,"Thanks for the heads up for the typo. That is fixed now. About the feature request... this is not entirely straightforward. The challenges to do this are:; 1. As densities are calculated relative to the sample (or the category subset from `.obs`), the values are not directly comparable. For example, you would get a value of 0.5 if you subtract the maximum density in one condition from a density of half the maximum in the other condition... but maybe the overall density is higher in the second condition. You could just interpret this as the relative differences within the samples I guess...; 2. Densities are currently calculated over cells... to subtract one from the other, you'd have to interpolate this to a grid layout.; 3. Ideally you'd want some kind of statistical test on differential densities... that's a whole other question... What do you think about the above points? If this were implemented, it probably wouldn't be a matter of a day or so... as I'm a bit low on time at the moment, I wouldn't be able to implement this in the next month even if we did find a good way forward unfortunately. You are welcome to submit a pull request though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478268425
https://github.com/scverse/scanpy/issues/575#issuecomment-478274180:394,Availability,down,down,394,"Thanks- that doesn't seem to be as easy as I was thinking.. ; 1. I think for most applications that I have in mind I would be interested in the relative differences. Are cells distributed differently in two conditions, regardless of whether there are more cells overall in one of the conditions?; 2. My bad, I thought the were already calculated over a grid layout.. would that also require to down sample the larger cell population to match the smaller one?; 3. That would be very cool, but having this for qualitative assessment would be already useful. Ok, thanks - will do if I come up with a satisfying solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478274180
https://github.com/scverse/scanpy/issues/575#issuecomment-478296037:977,Usability,simpl,simple,977,"I'm enjoying this brainstorming session... let's continue. I think the most difficult part would be the grid plotting in the end, but let's continue with the points in order. 1. We may need to rethink the scaling. At the moment it's scaled such that 1 is the highest density in one sample. Maybe it's more informative to make all sample densities to sum to 1 for this comparison? I didn't implement that currently as it's currently calculated over cells... if it were over grid points, then each condition would have the same number of grid points and this would be feasible again. 2. I'm not even sure if sampling is necessary... you could just as well take average densities in a grid square. That would make the calculation fairly easy. The issue, as I alluded to above, is plotting that grid I think. At the moment I can easily use scanpy's inherent `plot_scatter()` function... I'm not aware of any grid plotting function. That would probably need to be custom made. 3. A simple statistic would just be to use the outliers of the differences... but there are definitely better ideas...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478296037
https://github.com/scverse/scanpy/issues/575#issuecomment-478830365:131,Integrability,depend,depending,131,Thanks for your thoughts on this!. 1. That seems like a good approach - the size of the grid cells would be adjusted for each plot depending on cell number? ; 3. This probably depends a lot on the kind of dataset and comparison one wants to make: Does one want to know if there are *any* differences at all or also *where* on the grid these difference are? Up to now my approach was to use clusters as 'grid' and calculate the differences in proportion of cells per cluster across two or more conditions. The reason that I like your approach is that it is a very good (qualitative) visualization and much more subtle then just binning the data based on clusters. It seems hard to capture this visual aspect with a statistic.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478830365
https://github.com/scverse/scanpy/issues/575#issuecomment-478830365:176,Integrability,depend,depends,176,Thanks for your thoughts on this!. 1. That seems like a good approach - the size of the grid cells would be adjusted for each plot depending on cell number? ; 3. This probably depends a lot on the kind of dataset and comparison one wants to make: Does one want to know if there are *any* differences at all or also *where* on the grid these difference are? Up to now my approach was to use clusters as 'grid' and calculate the differences in proportion of cells per cluster across two or more conditions. The reason that I like your approach is that it is a very good (qualitative) visualization and much more subtle then just binning the data based on clusters. It seems hard to capture this visual aspect with a statistic.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478830365
https://github.com/scverse/scanpy/issues/575#issuecomment-478914589:42,Integrability,depend,depending,42,"1. You could create a heuristic grid size depending on cell numbers, or it's probably easier to just put grid dimensions as a user parameter with some (low) default value.; 2. I've been approaching this from the perspective that you care about where the densities occur on the visualization. That's why you can change the `basis` for the calculations and plotting. From my perspective, calculating densities over clusters and comparing these is actually just a sub-optimal replacement for testing for differential compositions. This is a separate problem, where the data should be modeled statistically, accounting for the compositional nature of the data. So sticking to the visualization is probably the right way forward for this function. On that note... we could use a seaborn heatmap function to plot the differential grid points. Overall I reckon we are moving toward a new plotting function here which does some calculations on the backend. Something like `sc.pl.embedding_density_diff()` where you take the output from `sc.tl.embedding_density()` and interpolate to a grid layout, rescale to sum to 1 across each grid separately, take the diff of two conditions, and then plot everything in a heatmap. Doesn't seem as difficult as I thought. I will get onto this when (read: if) I (ever) have some spare time 😉.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478914589
https://github.com/scverse/scanpy/issues/575#issuecomment-478914589:489,Testability,test,testing,489,"1. You could create a heuristic grid size depending on cell numbers, or it's probably easier to just put grid dimensions as a user parameter with some (low) default value.; 2. I've been approaching this from the perspective that you care about where the densities occur on the visualization. That's why you can change the `basis` for the calculations and plotting. From my perspective, calculating densities over clusters and comparing these is actually just a sub-optimal replacement for testing for differential compositions. This is a separate problem, where the data should be modeled statistically, accounting for the compositional nature of the data. So sticking to the visualization is probably the right way forward for this function. On that note... we could use a seaborn heatmap function to plot the differential grid points. Overall I reckon we are moving toward a new plotting function here which does some calculations on the backend. Something like `sc.pl.embedding_density_diff()` where you take the output from `sc.tl.embedding_density()` and interpolate to a grid layout, rescale to sum to 1 across each grid separately, take the diff of two conditions, and then plot everything in a heatmap. Doesn't seem as difficult as I thought. I will get onto this when (read: if) I (ever) have some spare time 😉.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478914589
https://github.com/scverse/scanpy/issues/575#issuecomment-479455800:42,Integrability,depend,dependency,42,Looks super cool... but also like a heavy dependency. Do you think it would be worth using datashader when we are just looking for a simple additional function?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479455800
https://github.com/scverse/scanpy/issues/575#issuecomment-479455800:133,Usability,simpl,simple,133,Looks super cool... but also like a heavy dependency. Do you think it would be worth using datashader when we are just looking for a simple additional function?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479455800
https://github.com/scverse/scanpy/issues/575#issuecomment-479510188:19,Integrability,depend,dependency,19,"Definitely a heavy dependency, you should see the size of the conda environment you need to test it. I think it'd be useful for playing around with ideas on how you'd like to aggregate and scale the values, since they've already got a bunch of methods implemented. Plus the plots often look pretty good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188
https://github.com/scverse/scanpy/issues/575#issuecomment-479510188:92,Testability,test,test,92,"Definitely a heavy dependency, you should see the size of the conda environment you need to test it. I think it'd be useful for playing around with ideas on how you'd like to aggregate and scale the values, since they've already got a bunch of methods implemented. Plus the plots often look pretty good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-479510188
https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:2035,Availability,Down,Downsample,2035,"ace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m); ); dblX = pos * adata.X; # TODO: Downsample total counts; srcs = np.sort(combos.reshape(n_doublets, 2), axis=1); obs = pd.DataFrame(srcs, columns=[""src1"", ""src2""]); var = pd.DataFrame(index=adata.var_names); return sc.AnnData(dblX, obs=obs, var=var). # Load data. # http: // cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5; pbmc = sc.read_10x_h5(""./data/10x/pbmc_10k_v3_filtered_feature_bc_matrix.h5""); pbmc.var[""gene_symbols""] = pbmc.var.index; pbmc.var.set_index(""gene_ids"", inplace=True). dblt = simulate_doublets(pbmc); dblt.var[""gene_symbols""] = pbmc.var[""gene_symbols""]. pbmc.raw = pbmc; dblt.raw = dblt. pbmc = preprocess(pbmc); dblt = preprocess(dblt). sc.pp.pca(pbmc); pca_update(dblt, pbmc). umap = UMAP(); pbmc.obsm[""X_umap""] = umap.fit_transform(pbmc.obsm[""X_pca""]); dblt.obsm[""X_umap""] = umap.transform(dblt.obsm[""X_pca""]). sc.tl.embedding_density(pbmc, ""umap""); sc.tl.embedding_density(dblt, ""umap""); ```; </details>. <details> ; <summary> Getting setup for datashader plots (much sh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384
https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:670,Performance,load,loading,670,"I think I've got an example for you, which should be pretty easy for you to play around with in datashader. The example is doublet detection. I'm following the basic outline of the methods which simulate doublets, then project those onto the real data to find which barcode (/cell) the simulated doublets sit next to. Those barcodes are presumed to be doublets. So we'd expect that areas of mostly singlets in the real data would have a lower relative (to the real data) density of points in the simulated. I'm still exploring what the best way to summarize that difference in density is through. Here's an example with some pbmcs from 10x:. <details>; <summary> Setup (loading, simulating, and projecting) </summary>. ```python; import scanpy as sc; import numpy as np; import pandas as pd; from scipy import sparse; from umap import UMAP. from itertools import repeat, chain. # Define functions. def preprocess(adata):; adata.var[""mito""] = adata.var[""gene_symbols""].str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mito""], inplace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384
https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:2255,Performance,Load,Load,2255,":; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m); ); dblX = pos * adata.X; # TODO: Downsample total counts; srcs = np.sort(combos.reshape(n_doublets, 2), axis=1); obs = pd.DataFrame(srcs, columns=[""src1"", ""src2""]); var = pd.DataFrame(index=adata.var_names); return sc.AnnData(dblX, obs=obs, var=var). # Load data. # http: // cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5; pbmc = sc.read_10x_h5(""./data/10x/pbmc_10k_v3_filtered_feature_bc_matrix.h5""); pbmc.var[""gene_symbols""] = pbmc.var.index; pbmc.var.set_index(""gene_ids"", inplace=True). dblt = simulate_doublets(pbmc); dblt.var[""gene_symbols""] = pbmc.var[""gene_symbols""]. pbmc.raw = pbmc; dblt.raw = dblt. pbmc = preprocess(pbmc); dblt = preprocess(dblt). sc.pp.pca(pbmc); pca_update(dblt, pbmc). umap = UMAP(); pbmc.obsm[""X_umap""] = umap.fit_transform(pbmc.obsm[""X_pca""]); dblt.obsm[""X_umap""] = umap.transform(dblt.obsm[""X_pca""]). sc.tl.embedding_density(pbmc, ""umap""); sc.tl.embedding_density(dblt, ""umap""); ```; </details>. <details> ; <summary> Getting setup for datashader plots (much shorter) : </summary>. Make dataframe:. ```python; pbmcdf = pd.DataFrame(pbmc.obsm[""X_umap""], columns=[""x"", ""y""]) # Real data; dbltdf = pd.DataFrame(dblt.obsm[""X_umap""], columns=[""x"", ""y""]) # Simulated doublets. pb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384
https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:131,Safety,detect,detection,131,"I think I've got an example for you, which should be pretty easy for you to play around with in datashader. The example is doublet detection. I'm following the basic outline of the methods which simulate doublets, then project those onto the real data to find which barcode (/cell) the simulated doublets sit next to. Those barcodes are presumed to be doublets. So we'd expect that areas of mostly singlets in the real data would have a lower relative (to the real data) density of points in the simulated. I'm still exploring what the best way to summarize that difference in density is through. Here's an example with some pbmcs from 10x:. <details>; <summary> Setup (loading, simulating, and projecting) </summary>. ```python; import scanpy as sc; import numpy as np; import pandas as pd; from scipy import sparse; from umap import UMAP. from itertools import repeat, chain. # Define functions. def preprocess(adata):; adata.var[""mito""] = adata.var[""gene_symbols""].str.startswith(""MT-""); sc.pp.calculate_qc_metrics(adata, qc_vars=[""mito""], inplace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m);",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384
https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:3766,Usability,simpl,simple,3766,"MAP(); pbmc.obsm[""X_umap""] = umap.fit_transform(pbmc.obsm[""X_pca""]); dblt.obsm[""X_umap""] = umap.transform(dblt.obsm[""X_pca""]). sc.tl.embedding_density(pbmc, ""umap""); sc.tl.embedding_density(dblt, ""umap""); ```; </details>. <details> ; <summary> Getting setup for datashader plots (much shorter) : </summary>. Make dataframe:. ```python; pbmcdf = pd.DataFrame(pbmc.obsm[""X_umap""], columns=[""x"", ""y""]) # Real data; dbltdf = pd.DataFrame(dblt.obsm[""X_umap""], columns=[""x"", ""y""]) # Simulated doublets. pbmcdf[""density""] = pbmc.obs[""umap_density""].values; dbltdf[""density""] = dblt.obs[""umap_density""].values; ```. Get plotting imports and canvas:. ```python; import datashader as ds; from datashader import transfer_functions as tf; from bokeh import palettes. canvas = ds.Canvas(plot_width=300, plot_height=300,; x_range=(pbmcdf[""x""].min() - .5, pbmcdf[""x""].max() + .5), ; y_range=(pbmcdf[""y""].min() - .5, pbmcdf[""y""].max() + .5),; x_axis_type='linear', y_axis_type='linear'); ```. </details>. First, something simple. Basically just a 2d histogram with 300 x 300 bins:. ```python; real = canvas.points(pbmcdf, 'x', 'y', ds.count()); sim = canvas.points(dbltdf, 'x', 'y', ds.count()). tf.Images(; tf.shade(real, name=""pbmcs""),; tf.shade(sim, name=""doublet""),; tf.shade(sim / (real + sim)),; ); ```. <img width=""857"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/55789263-532a0800-5afd-11e9-8c58-4ecde66a2717.png"">. Using the weights from your method, while making the plots look more similar (though there's something weird going on with non-overlapping areas here):. ```python; real_density = canvas.points(pbmcdf, 'x', 'y', ds.mean(""density"")); sim_density = canvas.points(dbltdf, 'x', 'y', ds.mean(""density"")). tf.Images(; tf.spread(tf.shade(real_density, name=""pbmc""), px=2),; tf.spread(tf.shade(sim_density, name=""doublet""), px=2),; tf.spread(; tf.shade(; sim_density / (sim_density + real_density), ; cmap=palettes.Viridis256; ), ; px=2,; name=""sim / (real + sim)""; ),; tf.spread",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384
https://github.com/scverse/scanpy/issues/575#issuecomment-483712379:381,Safety,detect,detection,381,"Sorry for the late reply, I was afk for a week. . This is really cool... What I had in mind is most similar to the 2D histogram you show. For the second part you fit the umap to one dataset and use that transformation to project the doublets in, right? What I do is join the two datasets and make a combined umap embedding. I can see how your approach makes more sense for doublet detection, but in a general case it's probably not as valid (i.e., when one dataset isn't ""fake"" data). . I will use this to play around a bit with the package when time permits though... thanks a lot for the extensive code!. And we discussed similar things for the normalization of the data for the subtraction above...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-483712379
https://github.com/scverse/scanpy/pull/576#issuecomment-478373219:13,Testability,test,tests,13,"Great!. Some tests should fail as there are probably differences in the neighbor algorithm. This is also why this is a backwards-compat breaking change. Can you just visually inspect https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html and see what's going on?. This is another notebook that should still do something meaningful after the change: https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb. And finally, of course, https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html should give somewhat consistent results. But I expect slight variations and no perfect consistence... Actually, I'd expect the associated tests (https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py) to fail. Can you check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219
https://github.com/scverse/scanpy/pull/576#issuecomment-478373219:683,Testability,test,tests,683,"Great!. Some tests should fail as there are probably differences in the neighbor algorithm. This is also why this is a backwards-compat breaking change. Can you just visually inspect https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html and see what's going on?. This is another notebook that should still do something meaningful after the change: https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb. And finally, of course, https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html should give somewhat consistent results. But I expect slight variations and no perfect consistence... Actually, I'd expect the associated tests (https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py) to fail. Can you check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219
https://github.com/scverse/scanpy/pull/576#issuecomment-478373219:744,Testability,test,tests,744,"Great!. Some tests should fail as there are probably differences in the neighbor algorithm. This is also why this is a backwards-compat breaking change. Can you just visually inspect https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html and see what's going on?. This is another notebook that should still do something meaningful after the change: https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170502_paul15/paul15.ipynb. And finally, of course, https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html should give somewhat consistent results. But I expect slight variations and no perfect consistence... Actually, I'd expect the associated tests (https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py) to fail. Can you check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478373219
https://github.com/scverse/scanpy/pull/576#issuecomment-478741723:145,Testability,test,tests,145,"@falexwolf . Hi, Alex.; Yes, i'm checking these. Actually, it somehow passes [test_pbmc3k](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py). Only [test_paga_paul15_subsampled](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py) fails. It seems that adjacency matrix is a bit different after the change and this affects paga connectivities. But it is preliminary, i'm checking still.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723
https://github.com/scverse/scanpy/pull/576#issuecomment-478741723:267,Testability,test,tests,267,"@falexwolf . Hi, Alex.; Yes, i'm checking these. Actually, it somehow passes [test_pbmc3k](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_pbmc3k.py). Only [test_paga_paul15_subsampled](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py) fails. It seems that adjacency matrix is a bit different after the change and this affects paga connectivities. But it is preliminary, i'm checking still.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-478741723
https://github.com/scverse/scanpy/pull/576#issuecomment-479420690:260,Deployability,update,update,260,"Great!. Yes, I would have expected that the adjacency matrix will differ slightly and hence, `test_paga_paul15` fails. We'll need to rerun and upload https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html with the new version in that case and also update the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690
https://github.com/scverse/scanpy/pull/576#issuecomment-479420690:271,Testability,test,tests,271,"Great!. Yes, I would have expected that the adjacency matrix will differ slightly and hence, `test_paga_paul15` fails. We'll need to rerun and upload https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html with the new version in that case and also update the tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479420690
https://github.com/scverse/scanpy/pull/576#issuecomment-479424924:381,Integrability,wrap,wrapping,381,"One other thing. We'd like to have two new convenience functions:. ```; def neighbors_update(adata, adata_new); def umap_update(adata, adata_new); ```. The first maps the new data into the existing neighbor graph based on the chosen latent representation. The second maps the new data into the existing UMAP embedding. For the second function, one just needs to find a good way of wrapping; ```; model = umap.UMAP(seed=1234); model.fit(X); model.transform(new_X); ```; For the first, I'm not quite sure how easy it is easy. I'm using `pynndescent` for it, which will become UMAP's dependency at some point, but isn't yet. Maybe what UMAP does internally is already sufficient, but I don't know. Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479424924
https://github.com/scverse/scanpy/pull/576#issuecomment-479424924:581,Integrability,depend,dependency,581,"One other thing. We'd like to have two new convenience functions:. ```; def neighbors_update(adata, adata_new); def umap_update(adata, adata_new); ```. The first maps the new data into the existing neighbor graph based on the chosen latent representation. The second maps the new data into the existing UMAP embedding. For the second function, one just needs to find a good way of wrapping; ```; model = umap.UMAP(seed=1234); model.fit(X); model.transform(new_X); ```; For the first, I'm not quite sure how easy it is easy. I'm using `pynndescent` for it, which will become UMAP's dependency at some point, but isn't yet. Maybe what UMAP does internally is already sufficient, but I don't know. Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-479424924
https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:1538,Availability,mask,masking,1538,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842
https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:161,Safety,predict,prediction,161,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842
https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:68,Testability,test,test,68,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842
https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:1087,Usability,learn,learning,1087,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842
https://github.com/scverse/scanpy/pull/576#issuecomment-487035737:107,Deployability,update,updates,107,"This looks good! :smile:. Storing the forest in the AnnData is good! It should also be compatible with the updates the @tomwhite plans on UMAP and pynndescent (UMAP will depend on pynndescent) as that should be the most basic object to store when to enable queries later on... But I would not store the ""forest"" in a default neighbors call. Or do you have any estimate on how large it is?. Great work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487035737
https://github.com/scverse/scanpy/pull/576#issuecomment-487035737:170,Integrability,depend,depend,170,"This looks good! :smile:. Storing the forest in the AnnData is good! It should also be compatible with the updates the @tomwhite plans on UMAP and pynndescent (UMAP will depend on pynndescent) as that should be the most basic object to store when to enable queries later on... But I would not store the ""forest"" in a default neighbors call. Or do you have any estimate on how large it is?. Great work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487035737
https://github.com/scverse/scanpy/pull/576#issuecomment-487410333:542,Testability,test,tests,542,"@Koncopd, can we merge this without the `neighbors_update` function and without writing the `rp_forest` to the AnnData object? Your code is good, but we should put it into another PR. > Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR. Is what I wrote in the beginning. I think it turned out tricky and is a case for https://github.com/theislab/scanpy/issues/562#issuecomment-487409358. So, let's keep this PR really simple and just be about removing the legacy code. Your statement about ""all tests pass except for the PAGA tests"" is still true? Did you manually inspect the PAGA notebook and does it look consistent? Just a few cosmetic things should have changed, I guess. If yes, we'll merge this, now that `1.4.1` is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333
https://github.com/scverse/scanpy/pull/576#issuecomment-487410333:573,Testability,test,tests,573,"@Koncopd, can we merge this without the `neighbors_update` function and without writing the `rp_forest` to the AnnData object? Your code is good, but we should put it into another PR. > Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR. Is what I wrote in the beginning. I think it turned out tricky and is a case for https://github.com/theislab/scanpy/issues/562#issuecomment-487409358. So, let's keep this PR really simple and just be about removing the legacy code. Your statement about ""all tests pass except for the PAGA tests"" is still true? Did you manually inspect the PAGA notebook and does it look consistent? Just a few cosmetic things should have changed, I guess. If yes, we'll merge this, now that `1.4.1` is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333
https://github.com/scverse/scanpy/pull/576#issuecomment-487410333:465,Usability,simpl,simple,465,"@Koncopd, can we merge this without the `neighbors_update` function and without writing the `rp_forest` to the AnnData object? Your code is good, but we should put it into another PR. > Can you investigate and if it's easy cover in this PR? If it's tricky, let's wait for another PR. Is what I wrote in the beginning. I think it turned out tricky and is a case for https://github.com/theislab/scanpy/issues/562#issuecomment-487409358. So, let's keep this PR really simple and just be about removing the legacy code. Your statement about ""all tests pass except for the PAGA tests"" is still true? Did you manually inspect the PAGA notebook and does it look consistent? Just a few cosmetic things should have changed, I guess. If yes, we'll merge this, now that `1.4.1` is out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487410333
https://github.com/scverse/scanpy/pull/576#issuecomment-487414554:95,Testability,test,tests,95,"@falexwolf ; Yes, i inspected the notebook, everything looks the same. Also this PR passes all tests now. So, yes, i think it can be merged",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487414554
https://github.com/scverse/scanpy/pull/576#issuecomment-487797746:99,Deployability,install,installed,99,"I tested myself and obtained exactly the same results. :). You probably don't have the FA2 package installed, that's why your graph look different... :). I'm merging this! Awesome work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746
https://github.com/scverse/scanpy/pull/576#issuecomment-487797746:2,Testability,test,tested,2,"I tested myself and obtained exactly the same results. :). You probably don't have the FA2 package installed, that's why your graph look different... :). I'm merging this! Awesome work!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487797746
https://github.com/scverse/scanpy/pull/576#issuecomment-487798308:27,Integrability,depend,depending,27,"@tomwhite, we're now fully depending on UMAP. :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-487798308
https://github.com/scverse/scanpy/issues/580#issuecomment-478620980:171,Testability,test,test,171,I'm as puzzled as you are... We've been discussing this a bit here: #549 . I didn't really change anything of note when Travis started failing. And I have no idea why the test would result in a `1.0`. Do you know if there are any instructions on how to rebuild the test environment in conda? Is it just python 3.5 and scanpy from github?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980
https://github.com/scverse/scanpy/issues/580#issuecomment-478620980:265,Testability,test,test,265,I'm as puzzled as you are... We've been discussing this a bit here: #549 . I didn't really change anything of note when Travis started failing. And I have no idea why the test would result in a `1.0`. Do you know if there are any instructions on how to rebuild the test environment in conda? Is it just python 3.5 and scanpy from github?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478620980
https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:250,Deployability,continuous,continuous-integration,250,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933
https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:261,Integrability,integrat,integration,261,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933
https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:447,Performance,cache,caches,447,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933
https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:245,Testability,test,test-continuous-integration,245,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933
https://github.com/scverse/scanpy/issues/580#issuecomment-478823933:154,Usability,Guid,Guide,154,"@LuckyMD, I think you can get the docker environment travis uses. * [Docker image for travis python env](https://hub.docker.com/r/travisci/ci-python); * [Guide on running it](https://andy-carter.com/blog/setting-up-travis-locally-with-docker-to-test-continuous-integration). I did this a couple years ago, but I know travis has changed a bunch since then. Another good first step would be to figure out if it only fails on the first build, and if caches are being used in any way. Also, do the builds ever fail for forks? I don't think they've been failing [for me](https://travis-ci.org/ivirshup/scanpy/builds).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478823933
https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:97,Availability,error,error,97,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906
https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:205,Availability,error,error,205,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906
https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:338,Performance,cache,cache,338,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906
https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:131,Testability,test,tests,131,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906
https://github.com/scverse/scanpy/issues/581#issuecomment-478798294:141,Availability,error,errors,141,"Probably is, I think the `nan`s are for all zero genes. But I think there's a better solution than a procedural warning and data that causes errors downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294
https://github.com/scverse/scanpy/issues/581#issuecomment-478798294:148,Availability,down,downstream,148,"Probably is, I think the `nan`s are for all zero genes. But I think there's a better solution than a procedural warning and data that causes errors downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294
https://github.com/scverse/scanpy/issues/581#issuecomment-479412666:84,Availability,down,downstream,84,"The nans (with a proper warning) would be the right way but having data that causes downstream is not an option. As an intermediate solution, I added a note to the docs and made them zeros:; https://github.com/theislab/scanpy/commit/dce2be194a6ff865ecaeb939f3c990f6c3b0e244",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479412666
https://github.com/scverse/scanpy/issues/581#issuecomment-479418054:214,Testability,test,tests,214,"Quick question to you @ivirshup, can't we simply replace all the `adata_neighbors` stuff with `scanpy.datasets.pbmc68k_reduced`? It already has the neighbor graph etc. in it and is smaller, that is, would speed up tests considerably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054
https://github.com/scverse/scanpy/issues/581#issuecomment-479418054:42,Usability,simpl,simply,42,"Quick question to you @ivirshup, can't we simply replace all the `adata_neighbors` stuff with `scanpy.datasets.pbmc68k_reduced`? It already has the neighbor graph etc. in it and is smaller, that is, would speed up tests considerably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479418054
https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:29,Availability,error,error,29,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348
https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:346,Availability,failure,failure,346,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348
https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:514,Testability,test,tests,514,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348
https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:676,Testability,test,tests,676,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:241,Integrability,wrap,wrapper,241,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:524,Integrability,interface,interface,524,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:40,Testability,test,tests,40,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:87,Testability,test,tests,87,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:278,Testability,test,tested,278,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:465,Testability,test,test,465,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:512,Testability,test,testing,512,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/581#issuecomment-479472437:584,Testability,test,tests,584,"Great!. I'll replace the dataset in the tests in that case. > It would be good to have tests that actually hit the parts of neighbors where non-pairwise distances are found (>4096 cells I think). We're just completely migrating to a shallow wrapper of umap there, where this is tested. I talked to Leland and he said it should be stable. At some point, we might move to `pynndescent` (when it get's introduced into umap). Long story short, I don't think we need to test the neighbors module within scanpy beyond testing the interface. > I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?. No, happy to have you put some dev docs in a location that you find sensible. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479472437
https://github.com/scverse/scanpy/issues/582#issuecomment-479187750:84,Testability,test,tested,84,"Hi! I just wrote a quick solution in https://github.com/theislab/scanpy/pull/586; I tested it manually and it seems to work (I used louvain code as template).; I assumed it could be interesting to work on a separate leiden function, due to possible argument clashes with louvain, instead of merging the two functions together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/582#issuecomment-479187750
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:79,Testability,test,tests,79,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:219,Testability,test,tests,219,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:275,Testability,test,test,275,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:297,Testability,test,testing,297,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:341,Testability,test,tests,341,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:751,Testability,test,tests,751,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-478954628:789,Testability,test,tests,789,"Okay... I have no idea what else I can do... . I put print statements into the tests and saw that the assignment of names of the `adata.uns['rank_genes_groups']['names']` recarrays is not in the expected order when the tests fail. That's why I put in explicit names into the test data and started testing by these names. For some reason the tests fail when I take the print statements out, but they pass when the print statements are in there... so I can't even look at why they are failing anymore... I may continue to play with this when I have some more time tonight, but I need to focus on some other things atm. If you have any ideas @flying-sheep @ivirshup @falexwolf, I'd be super keen to hear them. Should I just leave print statements in the tests so that it's super verbose when tests fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-478954628
https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:31,Deployability,install,installed,31,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950
https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:306,Deployability,install,installed,306,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950
https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:385,Testability,test,tests,385,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950
https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:317,Usability,Simpl,Simply,317,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950
https://github.com/scverse/scanpy/pull/583#issuecomment-479387950:457,Usability,simpl,simply,457,"Malte, don't you have `pytest` installed locally? Debugging using all these `added prints` etc. commits doesn't help maintain a clean git history. :wink:. Is it possible that there is any ambiguity regarding floating point precision? It's a bit hard for me to debug this. In case you don't have python 3.5 installed. Simply do `conda create -n py35 python=3.5`. Calling `pytest scanpy/tests/marker_gene_overlap.py` should rapidly reveal what's going on. Or simply debugging this in a notebook. Thank you and sorry that this causes trouble!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479387950
https://github.com/scverse/scanpy/pull/583#issuecomment-479462140:22,Deployability,install,installed,22,"I don't have `pytest` installed locally (will change that), and the plan was to emulate the Travis python 3.5 environment, but I'm not sure what versions of all the dependencies are in there. I've been debugging in a notebook, but it always works there... at least with python 3.6. I'll try just creating a conda python 3.5 env to see what happens when I do that. Chances are it will always work locally as well though... hence my remote debugging. Sorry for that... Previous print statements have shown that the order of covariates is just different sometimes in the recarrays. So I thought it would all be fixed with 5b602f5.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479462140
https://github.com/scverse/scanpy/pull/583#issuecomment-479462140:165,Integrability,depend,dependencies,165,"I don't have `pytest` installed locally (will change that), and the plan was to emulate the Travis python 3.5 environment, but I'm not sure what versions of all the dependencies are in there. I've been debugging in a notebook, but it always works there... at least with python 3.6. I'll try just creating a conda python 3.5 env to see what happens when I do that. Chances are it will always work locally as well though... hence my remote debugging. Sorry for that... Previous print statements have shown that the order of covariates is just different sometimes in the recarrays. So I thought it would all be fixed with 5b602f5.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479462140
https://github.com/scverse/scanpy/pull/583#issuecomment-479508416:88,Testability,test,tests,88,"@gokceneraslan that might have been an issue before... however I have now specified the tests via column and row names, and generated named recarrays, so I'm still looking now...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/583#issuecomment-479508416
https://github.com/scverse/scanpy/issues/584#issuecomment-482815578:74,Availability,error,error,74,"@LuckyMD is this the correct way of using pd.crosstab() ? I am getting an error as seen below:. adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-95-d09a5110597d> in <module>(); ----> 1 adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). AttributeError: 'AnnData' object has no attribute 'crosstab'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/584#issuecomment-482815578
https://github.com/scverse/scanpy/issues/584#issuecomment-482929037:441,Usability,guid,guide,441,"`pd.crosstab` is a function from `pandas`, and would only work on a pandas dataframe. You can find some documentation on that [here](http://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#cross-tabulations). I'm not sure why you would be losing any info. I'd also note this seems less related to scanpy, and more related to pandas, since `adata.obs` is just a pandas dataframe. Have you tried looking through the [pandas user guide](https://pandas.pydata.org/pandas-docs/stable/) to figure out how to do what you want?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/584#issuecomment-482929037
https://github.com/scverse/scanpy/pull/585#issuecomment-479508185:136,Availability,error,error,136,"This can’t be it, `__init__.py` is [optional since Python 3.3](https://www.python.org/dev/peps/pep-0420/). I also don’t see that import error, `import scanpy` works perfectly. Can you specify how you got that?. ```py; >>> import scanpy, anndata; >>> scanpy.external.tl.palantir(anndata.AnnData()); ImportError: ; please install palantir: . git clone git://github.com/dpeerlab/Palantir.git; cd Palantir; sudo -H pip3 install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185
https://github.com/scverse/scanpy/pull/585#issuecomment-479508185:320,Deployability,install,install,320,"This can’t be it, `__init__.py` is [optional since Python 3.3](https://www.python.org/dev/peps/pep-0420/). I also don’t see that import error, `import scanpy` works perfectly. Can you specify how you got that?. ```py; >>> import scanpy, anndata; >>> scanpy.external.tl.palantir(anndata.AnnData()); ImportError: ; please install palantir: . git clone git://github.com/dpeerlab/Palantir.git; cd Palantir; sudo -H pip3 install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185
https://github.com/scverse/scanpy/pull/585#issuecomment-479508185:416,Deployability,install,install,416,"This can’t be it, `__init__.py` is [optional since Python 3.3](https://www.python.org/dev/peps/pep-0420/). I also don’t see that import error, `import scanpy` works perfectly. Can you specify how you got that?. ```py; >>> import scanpy, anndata; >>> scanpy.external.tl.palantir(anndata.AnnData()); ImportError: ; please install palantir: . git clone git://github.com/dpeerlab/Palantir.git; cd Palantir; sudo -H pip3 install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185
https://github.com/scverse/scanpy/pull/585#issuecomment-479515587:58,Deployability,update,update,58,I had this problem importing `import scanpy as sc`.; I'll update you if this problem persists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479515587
https://github.com/scverse/scanpy/pull/585#issuecomment-480647524:35,Availability,error,error,35,"@fbrundu I just had the exact same error after installing from cloned master, so just wondering if it's working for you now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524
https://github.com/scverse/scanpy/pull/585#issuecomment-480647524:47,Deployability,install,installing,47,"@fbrundu I just had the exact same error after installing from cloned master, so just wondering if it's working for you now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524
https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:23,Availability,error,error,23,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534
https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:45,Testability,test,testing,45,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534
https://github.com/scverse/scanpy/pull/586#issuecomment-479282534:24,Testability,test,test,24,Would you mind adding a test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479282534
https://github.com/scverse/scanpy/pull/586#issuecomment-479539907:46,Testability,test,tests,46,"I added helper functions. I am working on the tests.; Apparently there's a test https://github.com/theislab/scanpy/blob/fc24dfc62c049a0d0c9cc491d4647d03b52bfb10/scanpy/tests/test_rank_genes_groups_logreg.py#L22; that fails locally in my machine.; It is because after `rank_genes_groups` categories are naturally sorted. I don't think this is due to my changes, but let me know how can I help. I am unsure why it is failing on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907
https://github.com/scverse/scanpy/pull/586#issuecomment-479539907:75,Testability,test,test,75,"I added helper functions. I am working on the tests.; Apparently there's a test https://github.com/theislab/scanpy/blob/fc24dfc62c049a0d0c9cc491d4647d03b52bfb10/scanpy/tests/test_rank_genes_groups_logreg.py#L22; that fails locally in my machine.; It is because after `rank_genes_groups` categories are naturally sorted. I don't think this is due to my changes, but let me know how can I help. I am unsure why it is failing on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907
https://github.com/scverse/scanpy/pull/586#issuecomment-479539907:168,Testability,test,tests,168,"I added helper functions. I am working on the tests.; Apparently there's a test https://github.com/theislab/scanpy/blob/fc24dfc62c049a0d0c9cc491d4647d03b52bfb10/scanpy/tests/test_rank_genes_groups_logreg.py#L22; that fails locally in my machine.; It is because after `rank_genes_groups` categories are naturally sorted. I don't think this is due to my changes, but let me know how can I help. I am unsure why it is failing on Travis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479539907
https://github.com/scverse/scanpy/pull/586#issuecomment-479587681:8,Testability,test,tests,8,I added tests for both louvain and leiden with restrict parameter. Please review the test code to be sure it is clear and working.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681
https://github.com/scverse/scanpy/pull/586#issuecomment-479587681:85,Testability,test,test,85,I added tests for both louvain and leiden with restrict parameter. Please review the test code to be sure it is clear and working.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681
https://github.com/scverse/scanpy/pull/586#issuecomment-479587681:112,Usability,clear,clear,112,I added tests for both louvain and leiden with restrict parameter. Please review the test code to be sure it is clear and working.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-479587681
https://github.com/scverse/scanpy/pull/586#issuecomment-480280193:70,Modifiability,maintainab,maintainable,70,"@falexwolf I added `_utils_clustering.py` since I think it's the more maintainable way to do it (e.g. if in the future, new clustering methods are added).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480280193
https://github.com/scverse/scanpy/pull/586#issuecomment-480637170:42,Availability,redundant,redundant,42,"I've got one minor comment left (one last redundant print statement), but otherwise I'm good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170
https://github.com/scverse/scanpy/pull/586#issuecomment-480637170:42,Safety,redund,redundant,42,"I've got one minor comment left (one last redundant print statement), but otherwise I'm good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170
https://github.com/scverse/scanpy/pull/586#issuecomment-482127774:10,Deployability,update,update,10,we should update the tutorials and notebooks to use ` leiden` instead of `louvain`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-482127774
https://github.com/scverse/scanpy/pull/586#issuecomment-482500682:54,Deployability,install,installation,54,"Yes, we should as soon as many people report seemless installation of the leiden package. I'm still using louvain as I never had any problems with it, but I agree that we should migrate when leiden is stable, mature and easily-installable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-482500682
https://github.com/scverse/scanpy/pull/586#issuecomment-482500682:227,Deployability,install,installable,227,"Yes, we should as soon as many people report seemless installation of the leiden package. I'm still using louvain as I never had any problems with it, but I agree that we should migrate when leiden is stable, mature and easily-installable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-482500682
https://github.com/scverse/scanpy/pull/586#issuecomment-483207692:221,Integrability,depend,depending,221,"I looked at it a while ago (for one test dataset, probably), and got the impression that `louvain` was faster. That said, they're both very fast. I would note that solutions from either can be pretty unstable, frequently depending on size of the community. @LuckyMD When you say heavy tailed, are you thinking of the unweighted KNN graph case or both?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692
https://github.com/scverse/scanpy/pull/586#issuecomment-483207692:36,Testability,test,test,36,"I looked at it a while ago (for one test dataset, probably), and got the impression that `louvain` was faster. That said, they're both very fast. I would note that solutions from either can be pretty unstable, frequently depending on size of the community. @LuckyMD When you say heavy tailed, are you thinking of the unweighted KNN graph case or both?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483207692
https://github.com/scverse/scanpy/pull/586#issuecomment-483313915:189,Deployability,configurat,configuration,189,"They'll both be affected by the [resolution limit](https://www.pnas.org/content/104/1/36), which might be what you're referring to. This is a well-described problem for Modularity with the configuration null model that it only optimally detects communities within a certain size range relative to the size of the network. For me heavy-tailed networks are PPIs.. KNNs are a lot more regular than that. I'm not sure what a weighted KNN graph would be... are you talking about the PhenoGraph approach?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483313915
https://github.com/scverse/scanpy/pull/586#issuecomment-483313915:189,Modifiability,config,configuration,189,"They'll both be affected by the [resolution limit](https://www.pnas.org/content/104/1/36), which might be what you're referring to. This is a well-described problem for Modularity with the configuration null model that it only optimally detects communities within a certain size range relative to the size of the network. For me heavy-tailed networks are PPIs.. KNNs are a lot more regular than that. I'm not sure what a weighted KNN graph would be... are you talking about the PhenoGraph approach?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483313915
https://github.com/scverse/scanpy/pull/586#issuecomment-483313915:237,Safety,detect,detects,237,"They'll both be affected by the [resolution limit](https://www.pnas.org/content/104/1/36), which might be what you're referring to. This is a well-described problem for Modularity with the configuration null model that it only optimally detects communities within a certain size range relative to the size of the network. For me heavy-tailed networks are PPIs.. KNNs are a lot more regular than that. I'm not sure what a weighted KNN graph would be... are you talking about the PhenoGraph approach?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-483313915
https://github.com/scverse/scanpy/pull/586#issuecomment-484016177:415,Energy Efficiency,adapt,adapting-to-real-world-data,415,"Sort of. I believe weights are between 0 and 1, where the edge to the nearest neighbor has weight=1, and the k-th+ neighbor has weight=0. I'm not quite sure how the weights are scaled within that, but I'm pretty sure it's not rank based. Leland Mcinnes has explained it much better than I can in his explanations of UMAP. It's discussed [in the docs](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html#adapting-to-real-world-data) starting with the part on Riemannian geometry, but is also covered in his talks or the UMAP paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484016177
https://github.com/scverse/scanpy/pull/586#issuecomment-484016177:415,Modifiability,adapt,adapting-to-real-world-data,415,"Sort of. I believe weights are between 0 and 1, where the edge to the nearest neighbor has weight=1, and the k-th+ neighbor has weight=0. I'm not quite sure how the weights are scaled within that, but I'm pretty sure it's not rank based. Leland Mcinnes has explained it much better than I can in his explanations of UMAP. It's discussed [in the docs](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html#adapting-to-real-world-data) starting with the part on Riemannian geometry, but is also covered in his talks or the UMAP paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484016177
https://github.com/scverse/scanpy/pull/586#issuecomment-484016177:364,Usability,learn,learn,364,"Sort of. I believe weights are between 0 and 1, where the edge to the nearest neighbor has weight=1, and the k-th+ neighbor has weight=0. I'm not quite sure how the weights are scaled within that, but I'm pretty sure it's not rank based. Leland Mcinnes has explained it much better than I can in his explanations of UMAP. It's discussed [in the docs](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html#adapting-to-real-world-data) starting with the part on Riemannian geometry, but is also covered in his talks or the UMAP paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484016177
https://github.com/scverse/scanpy/pull/586#issuecomment-484424732:740,Availability,error,errors,740,"We didn't use the weights in Louvain (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_louvain.py#L31)?. Why did you decide to change the default in Leiden; (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_leiden.py#L31)? I'm fine with it, but a brief discussion would have been appropriate. :wink:. @LuckyMD; > how different is that to clustering on the UMAP embedding directly?; It's very different. The choice of weights will likely not have a dramatic effect, you're always clustering a graph that proxies neighborhoods in high-dimensional space. If you embed this structure in 2 or 3 d, even if you use the fantastic UMAP for it, you'll make errors (https://twitter.com/falexwolf/status/1108284982001315840). Also, the most computationally intense part is the embedding optimization, not the graph construction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732
https://github.com/scverse/scanpy/pull/586#issuecomment-484424732:868,Performance,optimiz,optimization,868,"We didn't use the weights in Louvain (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_louvain.py#L31)?. Why did you decide to change the default in Leiden; (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_leiden.py#L31)? I'm fine with it, but a brief discussion would have been appropriate. :wink:. @LuckyMD; > how different is that to clustering on the UMAP embedding directly?; It's very different. The choice of weights will likely not have a dramatic effect, you're always clustering a graph that proxies neighborhoods in high-dimensional space. If you embed this structure in 2 or 3 d, even if you use the fantastic UMAP for it, you'll make errors (https://twitter.com/falexwolf/status/1108284982001315840). Also, the most computationally intense part is the embedding optimization, not the graph construction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1344,Availability,robust,robust,1344,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1417,Integrability,depend,dependent,1417,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1498,Integrability,depend,dependence,1498,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:817,Testability,test,tested,817,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:884,Testability,log,log-ish,884,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1014,Testability,log,log,1014,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:691,Usability,clear,clear,691,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638
https://github.com/scverse/scanpy/pull/586#issuecomment-485700014:894,Availability,robust,robust,894,"I'm not sure I agree with your interpretation of your total degree plot. To me, increasing `k` is meant to have the effect of densifying the network, and thus obtaining a lower resolution view of the manifold. It is somewhat analogous to choosing a lower resolution value for `leiden` or `louvain` clustering. What you see is that in the weighted case, the overall degree does not really increase (thus possibly neither does the overall density), so that increasing `k` may have little effect on clustering at all. This is the most I can get from this plot... as density is really about local changes and not the global degree increase. But I would still ask whether it is a good thing that increasing `k` has little effect? Does increasing `k` then change the clustering results (in the weighed case?). I wonder if the observation that you find smaller clusters better in the weighted case is robust. That would suggest that weights can counteract resolution limit issues, which would be very interesting...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485700014
https://github.com/scverse/scanpy/pull/586#issuecomment-487432411:1664,Safety,detect,detected,1664,"Sorry about the delay, I've been working on some writing about this stuff (though from a different perspective). I'm not sure `k` is ""meant"" to have any particular effect, since these methods weren't designed for KNN graphs. I'd also argue if the parameters are analogous, there's an advantage of simplicity to just choosing one of them. I've got some plots for the effect of resolution and number of neighbors on the size of clusters which are found. This is for the 10x example dataset with 10k pbmcs using the v3 chemistry. What I've done is build the networks at 5 different values of k, four times each (different random seeds). For each of those networks, I ran clustering at 50 different resolutions (`np.geomspace(0.05, 20, 50)`). Here are the maximum cluster sizes found for each combination of k and resolution for the unweighted and weighted graph (color bar is logscale, from 1 to 6000, but I couldn't get useful ticks to work):. ![image](https://user-images.githubusercontent.com/8238804/56872793-2c158500-6a70-11e9-91fd-ee7aac91b811.png); ![image](https://user-images.githubusercontent.com/8238804/56872794-2d46b200-6a70-11e9-9607-67147d7493f9.png). Overall, pretty similar. Now, the minimum cluster sizes (color scales are different, but you'll see why):. ![image](https://user-images.githubusercontent.com/8238804/56872836-a34b1900-6a70-11e9-9a60-7b2a51b53da2.png); ![image](https://user-images.githubusercontent.com/8238804/56872837-a6460980-6a70-11e9-8722-be6576f605e7.png). This looks to me like using the weighted graph allows identifying small clusters even at low resolutions. The cluster of 25 cells looks like megakaryocytes, and are being detected at pretty much every clustering (996 out of 1000) using the weighted graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411
https://github.com/scverse/scanpy/pull/586#issuecomment-487432411:873,Testability,log,logscale,873,"Sorry about the delay, I've been working on some writing about this stuff (though from a different perspective). I'm not sure `k` is ""meant"" to have any particular effect, since these methods weren't designed for KNN graphs. I'd also argue if the parameters are analogous, there's an advantage of simplicity to just choosing one of them. I've got some plots for the effect of resolution and number of neighbors on the size of clusters which are found. This is for the 10x example dataset with 10k pbmcs using the v3 chemistry. What I've done is build the networks at 5 different values of k, four times each (different random seeds). For each of those networks, I ran clustering at 50 different resolutions (`np.geomspace(0.05, 20, 50)`). Here are the maximum cluster sizes found for each combination of k and resolution for the unweighted and weighted graph (color bar is logscale, from 1 to 6000, but I couldn't get useful ticks to work):. ![image](https://user-images.githubusercontent.com/8238804/56872793-2c158500-6a70-11e9-91fd-ee7aac91b811.png); ![image](https://user-images.githubusercontent.com/8238804/56872794-2d46b200-6a70-11e9-9607-67147d7493f9.png). Overall, pretty similar. Now, the minimum cluster sizes (color scales are different, but you'll see why):. ![image](https://user-images.githubusercontent.com/8238804/56872836-a34b1900-6a70-11e9-9a60-7b2a51b53da2.png); ![image](https://user-images.githubusercontent.com/8238804/56872837-a6460980-6a70-11e9-8722-be6576f605e7.png). This looks to me like using the weighted graph allows identifying small clusters even at low resolutions. The cluster of 25 cells looks like megakaryocytes, and are being detected at pretty much every clustering (996 out of 1000) using the weighted graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411
https://github.com/scverse/scanpy/pull/586#issuecomment-487432411:297,Usability,simpl,simplicity,297,"Sorry about the delay, I've been working on some writing about this stuff (though from a different perspective). I'm not sure `k` is ""meant"" to have any particular effect, since these methods weren't designed for KNN graphs. I'd also argue if the parameters are analogous, there's an advantage of simplicity to just choosing one of them. I've got some plots for the effect of resolution and number of neighbors on the size of clusters which are found. This is for the 10x example dataset with 10k pbmcs using the v3 chemistry. What I've done is build the networks at 5 different values of k, four times each (different random seeds). For each of those networks, I ran clustering at 50 different resolutions (`np.geomspace(0.05, 20, 50)`). Here are the maximum cluster sizes found for each combination of k and resolution for the unweighted and weighted graph (color bar is logscale, from 1 to 6000, but I couldn't get useful ticks to work):. ![image](https://user-images.githubusercontent.com/8238804/56872793-2c158500-6a70-11e9-91fd-ee7aac91b811.png); ![image](https://user-images.githubusercontent.com/8238804/56872794-2d46b200-6a70-11e9-9607-67147d7493f9.png). Overall, pretty similar. Now, the minimum cluster sizes (color scales are different, but you'll see why):. ![image](https://user-images.githubusercontent.com/8238804/56872836-a34b1900-6a70-11e9-9a60-7b2a51b53da2.png); ![image](https://user-images.githubusercontent.com/8238804/56872837-a6460980-6a70-11e9-8722-be6576f605e7.png). This looks to me like using the weighted graph allows identifying small clusters even at low resolutions. The cluster of 25 cells looks like megakaryocytes, and are being detected at pretty much every clustering (996 out of 1000) using the weighted graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487432411
https://github.com/scverse/scanpy/pull/586#issuecomment-487559376:275,Safety,detect,detected,275,"This looks a lot more convincing... It's a bit hard to read the second last plot though... The black parts are also clusters around size 2-10, no? Or am I misreading the scale? Do you have a version with a few more annotations on the colour bar? How often are megakaryocytes detected as a separate cluster in the unweighted case? It looks like unweighted case is definitely worse for higher resolutions with >10 neighbours though. And coming back to the `k` discussion.. From my perspective, If you treat the clustering and knn graph generation as two separate steps, you may want `k` to have an effect. If you treat it as the same process, then I follow your argumentation that having a single parameter to affects the scale of the clustering suffices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-487559376
https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:568,Availability,robust,robust,568,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694
https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:353,Safety,detect,detected,353,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694
https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:135,Testability,log,log,135,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694
https://github.com/scverse/scanpy/pull/586#issuecomment-488610378:127,Safety,detect,detect,127,"I follow your argumentation on ""good clusters"". However, I also like the concept that putting k=35 means you make it harder to detect clusters of size < 35, as you 'over-connect' those clusters in a way. The weighted case is less interpretable in that way. However, here it clearly outperforms the unweighted case. I am still a little on the fence (due to interpretability), but I'd be okay with weighting I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488610378
https://github.com/scverse/scanpy/pull/586#issuecomment-488610378:274,Usability,clear,clearly,274,"I follow your argumentation on ""good clusters"". However, I also like the concept that putting k=35 means you make it harder to detect clusters of size < 35, as you 'over-connect' those clusters in a way. The weighted case is less interpretable in that way. However, here it clearly outperforms the unweighted case. I am still a little on the fence (due to interpretability), but I'd be okay with weighting I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488610378
https://github.com/scverse/scanpy/issues/587#issuecomment-479721635:62,Availability,error,error,62,"But also, that looks like an h5py issue. Do you still get the error if you try `import h5py` in that environment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479721635
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:258,Availability,error,error,258,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:27,Deployability,Install,Installing,27,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:480,Modifiability,variab,variable,480,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:496,Modifiability,variab,variables-axis,496,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:951,Modifiability,variab,variable,951,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:967,Modifiability,variab,variables-axis,967,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:519,Performance,cache,cache,519,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:541,Performance,cache,cache,541,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:998,Performance,cache,cache,998,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1020,Performance,cache,cache,1020,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1190,Performance,cache,cache,1190,"equent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1309,Performance,cache,cache,1309,"equent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1315,Performance,cache,cache,1315,"equent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1487,Performance,cache,cache,1487,"dex); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1626,Performance,cache,cache,1626,"-------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1632,Performance,cache,cache,1632,"-------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:1942,Performance,cache,cache,1942,"or faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:2119,Performance,cache,cache,2119,"or faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:2125,Performance,cache,cache,2125,"or faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:2363,Performance,cache,cache,2363,"che, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the future. Any solutions to these different formats???. Also, if you could provide the ling to a manual or a documentation written for scanpy that would be great.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:2566,Performance,cache,cache,2566,"che, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the future. Any solutions to these different formats???. Also, if you could provide the ling to a manual or a documentation written for scanpy that would be great.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:2519,Testability,log,logg,2519,"che, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, sheet=sheet, ext=ext,; 77 delimiter=delimiter, first_column_names=first_column_names,; ---> 78 backup_url=backup_url, cache=cache, **kwargs); 79 # generate filename and read to dict; 80 filekey = filename. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 447 else:; 448 if not is_present:; --> 449 raise FileNotFoundError('Did not find file {}.'.format(filename)); 450 logg.msg('reading', filename, v=4); 451 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file C:\Users\correap\Documents\03152019_scRNAseq\filtered_feature_bc_matrix_1\matrix.mtx.gz.; ```. ​My filtered_feature_bc_matrix_1 contains the folders barcodes.tsv, gene_symbols.tsv (manually changed to this from default 10X output of genes) and the matrix.mtx file. I could manually change the matrix.mtx to matrix.mtx.gz. but this might corrupt the file and not be very good practice in the future. Any solutions to these different formats???. Also, if you could provide the ling to a manual or a documentation written for scanpy that would be great.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733
https://github.com/scverse/scanpy/issues/587#issuecomment-480108879:72,Availability,avail,available,72,"Here's a link to the docs [https://scanpy.readthedocs.io/](), it's also available at the top of the github repo. EDIT: Whoops, posted some wrong info about how 10x pre v3 datasets are read before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-480108879
https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470:38,Availability,error,error,38,I am still getting the file not found error because when downloading it's lacking the `gz` extension. Will manually change but sharing so you are aware! @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470
https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470:57,Availability,down,downloading,57,I am still getting the file not found error because when downloading it's lacking the `gz` extension. Will manually change but sharing so you are aware! @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470
https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:109,Availability,avail,available,109,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101
https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:200,Availability,avail,available,200,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101
https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:249,Availability,avail,available,249,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101
https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:419,Deployability,integrat,integrate,419,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101
https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:419,Integrability,integrat,integrate,419,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101
https://github.com/scverse/scanpy/pull/591#issuecomment-480219397:31,Usability,simpl,simply,31,Of course that's fine. You can simply push such things to master. ;),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/591#issuecomment-480219397
https://github.com/scverse/scanpy/pull/594#issuecomment-480618565:102,Testability,test,test,102,"You're right `fraction` is better! Can you change it directly on this branch?. Also, I did not find a test for this. Can you add one? You can essentially copy your example and the test that's there for `normalize_per_cell`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-480618565
https://github.com/scverse/scanpy/pull/594#issuecomment-480618565:180,Testability,test,test,180,"You're right `fraction` is better! Can you change it directly on this branch?. Also, I did not find a test for this. Can you add one? You can essentially copy your example and the test that's there for `normalize_per_cell`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-480618565
https://github.com/scverse/scanpy/pull/594#issuecomment-481276242:45,Testability,test,tests,45,@falexwolf ; It is strange that there are no tests for this. I thought i added them...; I will try to do all these thing in two days. Sorry for the delays.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481276242
https://github.com/scverse/scanpy/pull/594#issuecomment-481653813:125,Testability,test,tests,125,"Ok, thank you! Maybe I just didn't find them. If so, please point me to them. Merging this in the meanwhile, you can add the tests in a new PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/594#issuecomment-481653813
https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:239,Availability,error,error,239,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396
https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:77,Deployability,install,installation,77,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396
https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:176,Deployability,install,installation,176,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396
https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:189,Integrability,depend,dependency,189,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396
https://github.com/scverse/scanpy/issues/596#issuecomment-480730857:771,Energy Efficiency,green,green,771,"I think we should do that in a way that doesn’t tempt the user to use literal colors like you just did. The color names people think of have a lot of bad properties for colorblind people and contrast. Maybe if we redefine common color names? When users specify “red” there, they only want some kind of red, not `#ff0000`. In one of my analyses, there’s predefined clusters which I recolor like this:. ![grafik](https://user-images.githubusercontent.com/291575/55707300-9001dc00-59e3-11e9-93b5-2dfac3814edf.png). It’s in R and what I do is that I give names to a lot of colorbrewer colors:. ```r; prettier_colors <- c(; setNames(brewer.pal(8, 'Dark2')[c(1,4,6,8)], c('turquoise', 'magenta', 'yellow', 'black')),; setNames(brewer.pal(9, 'Set1')[-c(4,6)], c('red', 'blue', 'green', 'darkorange', 'brown', 'pink', 'grey')); ); ```. In python that would be:. ```py; import numpy as np; from matplotlib import cm. prettier_colors = dict(zip(; [; 'turquoise', 'magenta', 'yellow', 'black',; 'red', 'blue', 'green', 'darkorange', 'brown', 'pink', 'grey',; ], np.concatenate([; np.array(cm.Dark2.colors)[[0,3,5,7]],; np.array(cm.Set1.colors)[np.setdiff1d(np.arange(9), [3, 5])],; ]); )); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480730857
https://github.com/scverse/scanpy/issues/596#issuecomment-480730857:1000,Energy Efficiency,green,green,1000,"I think we should do that in a way that doesn’t tempt the user to use literal colors like you just did. The color names people think of have a lot of bad properties for colorblind people and contrast. Maybe if we redefine common color names? When users specify “red” there, they only want some kind of red, not `#ff0000`. In one of my analyses, there’s predefined clusters which I recolor like this:. ![grafik](https://user-images.githubusercontent.com/291575/55707300-9001dc00-59e3-11e9-93b5-2dfac3814edf.png). It’s in R and what I do is that I give names to a lot of colorbrewer colors:. ```r; prettier_colors <- c(; setNames(brewer.pal(8, 'Dark2')[c(1,4,6,8)], c('turquoise', 'magenta', 'yellow', 'black')),; setNames(brewer.pal(9, 'Set1')[-c(4,6)], c('red', 'blue', 'green', 'darkorange', 'brown', 'pink', 'grey')); ); ```. In python that would be:. ```py; import numpy as np; from matplotlib import cm. prettier_colors = dict(zip(; [; 'turquoise', 'magenta', 'yellow', 'black',; 'red', 'blue', 'green', 'darkorange', 'brown', 'pink', 'grey',; ], np.concatenate([; np.array(cm.Dark2.colors)[[0,3,5,7]],; np.array(cm.Set1.colors)[np.setdiff1d(np.arange(9), [3, 5])],; ]); )); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480730857
https://github.com/scverse/scanpy/issues/596#issuecomment-480739679:258,Availability,down,down,258,"My main point is that having an implicit mapping between colors and the categories is not that user or developer friendly. It seems to me like it'd be simpler to just have the mapping be explicit. This wouldn't change much from right now, except for cutting down on some boiler plate in a bunch of plotting functions. That example was just to demonstrate that it could even be simpler to have an explicit mapping, since we don't have to do:. ```python; dict(zip(adata.obs[key].cat.categories, adata.uns[key + ""_colors""])); # and instead could just do:; adata.uns[key + ""_colors""]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679
https://github.com/scverse/scanpy/issues/596#issuecomment-480739679:151,Usability,simpl,simpler,151,"My main point is that having an implicit mapping between colors and the categories is not that user or developer friendly. It seems to me like it'd be simpler to just have the mapping be explicit. This wouldn't change much from right now, except for cutting down on some boiler plate in a bunch of plotting functions. That example was just to demonstrate that it could even be simpler to have an explicit mapping, since we don't have to do:. ```python; dict(zip(adata.obs[key].cat.categories, adata.uns[key + ""_colors""])); # and instead could just do:; adata.uns[key + ""_colors""]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679
https://github.com/scverse/scanpy/issues/596#issuecomment-480739679:377,Usability,simpl,simpler,377,"My main point is that having an implicit mapping between colors and the categories is not that user or developer friendly. It seems to me like it'd be simpler to just have the mapping be explicit. This wouldn't change much from right now, except for cutting down on some boiler plate in a bunch of plotting functions. That example was just to demonstrate that it could even be simpler to have an explicit mapping, since we don't have to do:. ```python; dict(zip(adata.obs[key].cat.categories, adata.uns[key + ""_colors""])); # and instead could just do:; adata.uns[key + ""_colors""]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679
https://github.com/scverse/scanpy/issues/596#issuecomment-480746287:166,Integrability,interface,interface,166,"Sure, I agree with you generally. I’m just saying that an easy, userfriendly way should make it easy to get beautiful colors, not ugly ones. So in the PR tuning that interface to be nicer, we should do something about that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480746287
https://github.com/scverse/scanpy/issues/596#issuecomment-487178978:981,Energy Efficiency,power,powerful,981,"Sorry about the late response here... I can imagine that we'd have more than the color attributes for each category. Just think of a `.groupby` followed by a summary statistics. This gives rise to dataframes that are ordered as `.cat.categories`. The array-way of storing color attributes is inspired by the way that `pd.Categorical` manages the string attributes of categories. Also, seaborn accepts this array-way of passing palettes. You can just do `palette=adata.uns['..._colors']` in any of the seaborn functions. At least I think I've done that many times already. I think that the current way of storing colors is ugly and bad. One improvement would be to have one dict for colors only; `adata.uns['colors'] = {'cat_var1': [...], 'cat_var2': ...}`; or one dict for all attributes of each categorical; `adata.uns['louvain'] = {'colors': [...], 'annotations': [...], 'mean_expr': [...], 'markers': [...]}`. Evidently, in the latter case, one would rather like to have a more powerful `pd.Categorical` class that can do more than just attach a string label to an integer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-487178978
https://github.com/scverse/scanpy/issues/598#issuecomment-487517773:104,Availability,error,error,104,"Hi, thanks for your answer. How do you remove a graph slot from a Seurat object? When I try, I get this error:; ```; > dataset@graphs <- NULL; Error in (function (cl, name, valueClass) : ; assignment of an object of class “NULL” is not valid for @‘graphs’ in an object of class “Seurat”; is(value, ""list"") is not TRUE; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773
https://github.com/scverse/scanpy/issues/598#issuecomment-487517773:143,Availability,Error,Error,143,"Hi, thanks for your answer. How do you remove a graph slot from a Seurat object? When I try, I get this error:; ```; > dataset@graphs <- NULL; Error in (function (cl, name, valueClass) : ; assignment of an object of class “NULL” is not valid for @‘graphs’ in an object of class “Seurat”; is(value, ""list"") is not TRUE; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:60,Availability,error,error,60,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:96,Availability,error,error,96,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:1783,Availability,Mask,MaskedArray,1783,"ame, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in sanitize_ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:493,Modifiability,layers,layers,493,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:500,Modifiability,layers,layers,500,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:658,Modifiability,layers,layers,658,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:730,Modifiability,layers,layers,730,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:737,Modifiability,layers,layers,737,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:1023,Modifiability,layers,layers,1023,"d remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885
https://github.com/scverse/scanpy/issues/598#issuecomment-487647761:89,Availability,error,error,89,It seems that something wrong happened for the Seurat meta slot. The code told that this error happened when AnnData tried to construct obs attribute. ; I am afraid this beyond my scope since I cannot access your data for further debugging,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761
https://github.com/scverse/scanpy/issues/598#issuecomment-487647761:201,Security,access,access,201,It seems that something wrong happened for the Seurat meta slot. The code told that this error happened when AnnData tried to construct obs attribute. ; I am afraid this beyond my scope since I cannot access your data for further debugging,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761
https://github.com/scverse/scanpy/issues/598#issuecomment-487687285:22,Availability,error,error,22,I am getting the same error. > Exception: Data must be 1-dimensional,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487687285
https://github.com/scverse/scanpy/issues/598#issuecomment-493118269:187,Testability,test,test,187,"Hi @PedroRaposo, unfortunately not. My colleague told me that this issue could be related to the versions of scanpy, anndata or loompy. I have the same scanpy version with the successful test above. Maybe, it is related to loompy and anndata version but I'm not sure...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493118269
https://github.com/scverse/scanpy/issues/598#issuecomment-493666985:18,Deployability,install,installing,18,"Hi, @cakirb ; Try installing `loompy` using `pip install -U loompy`, and make sure you are not using version 2.0.2.; see ; https://github.com/theislab/scvelo/issues/20#issuecomment-442186279. **EDITED**: I am encountering the same problem as yours. > Exception: Data must be 1-dimensional",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493666985
https://github.com/scverse/scanpy/issues/598#issuecomment-493666985:49,Deployability,install,install,49,"Hi, @cakirb ; Try installing `loompy` using `pip install -U loompy`, and make sure you are not using version 2.0.2.; see ; https://github.com/theislab/scvelo/issues/20#issuecomment-442186279. **EDITED**: I am encountering the same problem as yours. > Exception: Data must be 1-dimensional",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493666985
https://github.com/scverse/scanpy/issues/598#issuecomment-493672904:73,Availability,error,error,73,"I have tried using latest version of anndata(0.16.9), still got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493672904
https://github.com/scverse/scanpy/issues/598#issuecomment-493887143:46,Deployability,install,installed,46,My too. I had loompy version 2.0.17 and now I installed the version 2.0.16 and still I'm getting the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493887143
https://github.com/scverse/scanpy/issues/598#issuecomment-497943914:244,Performance,load,loading,244,"I'd love to help close this issue, but it's difficult for us to debug without a complete reproducible example. Could someone who's been experiencing this please provide a complete script which reproduces this issue?. This script should include loading data into Seurat, whatever minimal set of intermediate steps are necessary, then writing out the file which scanpy fails to read. Ideally, the data is computationally generated, something as simple as `x = matrix(1, nrow=10, ncol=10)` or `x = matrix(rpois(100, range(5)), ncol=10)`. If someone who is having this issue can please provide an example like this, we'll be able to help much faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-497943914
https://github.com/scverse/scanpy/issues/598#issuecomment-497943914:443,Usability,simpl,simple,443,"I'd love to help close this issue, but it's difficult for us to debug without a complete reproducible example. Could someone who's been experiencing this please provide a complete script which reproduces this issue?. This script should include loading data into Seurat, whatever minimal set of intermediate steps are necessary, then writing out the file which scanpy fails to read. Ideally, the data is computationally generated, something as simple as `x = matrix(1, nrow=10, ncol=10)` or `x = matrix(rpois(100, range(5)), ncol=10)`. If someone who is having this issue can please provide an example like this, we'll be able to help much faster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-497943914
https://github.com/scverse/scanpy/issues/598#issuecomment-653220911:30,Performance,load,loading,30,"After removing the graphs and loading the loom file into scanpy with the now empty graphs slot, is there a way to manually add it back in? For example, before removing the graphs attribute, I call as.matrix() and saved it as a CSV (probably a better way to do this to maintain the sparse property). I can now read this CSV back into Python (e.g. with pandas), but what is the correct way to reload it into the resulting AnnData object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-653220911
https://github.com/scverse/scanpy/issues/599#issuecomment-609054998:79,Availability,error,error,79,"For me,; adata[(adata[:,'elav'].X>0).flatten(), : ] works. otherwise, it gives error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-609054998
https://github.com/scverse/scanpy/issues/599#issuecomment-873451217:194,Availability,error,error,194,"Is there a way to filter for a set of genes, where if any one of the genes in a list are expressed, those cells will be plotted? I've tried switching Xparx's solution to a list, but receive the error ""ValueError: Buffer has wrong number of dimensions (expected 1, got 0)"". I've also tired chansigit's method, but find that flatten returns as not found?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-873451217
https://github.com/scverse/scanpy/issues/601#issuecomment-482069731:20,Availability,error,error,20,"Looks like the same error hit in #585, as well as https://github.com/theislab/scanpy/pull/493#issuecomment-477674448. @flying-sheep I haven't been able to reproduce, but maybe we should just throw an `__init__.py` in there, since it fixes this for @fbrundu, before the `v1.4.1` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731
https://github.com/scverse/scanpy/issues/601#issuecomment-482069731:278,Deployability,release,release,278,"Looks like the same error hit in #585, as well as https://github.com/theislab/scanpy/pull/493#issuecomment-477674448. @flying-sheep I haven't been able to reproduce, but maybe we should just throw an `__init__.py` in there, since it fixes this for @fbrundu, before the `v1.4.1` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731
https://github.com/scverse/scanpy/issues/601#issuecomment-482107875:244,Availability,fault,fault,244,"@vladie0, would you mind pulling again and checking if it works now?. @flying-sheep if at least four people can't install the package (including in a clean conda environment on a lab mate's machine), what do you call it? I don't think it's our fault, but I think there's a bug somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875
https://github.com/scverse/scanpy/issues/601#issuecomment-482107875:114,Deployability,install,install,114,"@vladie0, would you mind pulling again and checking if it works now?. @flying-sheep if at least four people can't install the package (including in a clean conda environment on a lab mate's machine), what do you call it? I don't think it's our fault, but I think there's a bug somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875
https://github.com/scverse/scanpy/pull/603#issuecomment-482103939:44,Deployability,install,installed,44,"Hmm, Maybe they have another scanpy version installed or some other weird broken setup. why not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/603#issuecomment-482103939
https://github.com/scverse/scanpy/issues/607#issuecomment-483195095:207,Energy Efficiency,adapt,adapted,207,"Why would a separate package be necessary? If you use it for transcriptome analysis, the only difference should be that the counts are (in theory) more accurate and there’s e.g. no need for methods that are adapted for zero-inflation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/607#issuecomment-483195095
https://github.com/scverse/scanpy/issues/607#issuecomment-483195095:207,Modifiability,adapt,adapted,207,"Why would a separate package be necessary? If you use it for transcriptome analysis, the only difference should be that the counts are (in theory) more accurate and there’s e.g. no need for methods that are adapted for zero-inflation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/607#issuecomment-483195095
https://github.com/scverse/scanpy/pull/610#issuecomment-484026464:327,Usability,simpl,simple,327,"> Ah, the problem was that the string actually contained that return type!. This is the standard way of writing a numpydoc returns section. Also see https://scanpy.readthedocs.io/en/return-formatting/api/scanpy.pp.filter_cells.html, for instance. This solution is dropping support for them. Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what `numpydoc` did 🙂)? Bold font and spacings around colons?. ![image](https://user-images.githubusercontent.com/16916678/56280862-67789100-610b-11e9-8c43-405072ce6fbd.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484026464
https://github.com/scverse/scanpy/pull/610#issuecomment-484027492:250,Usability,learn,learn,250,"Unfortunately, changing; ```; .rst-content dl:not(.docutils) dl dt {; font-weight: normal;; ```; to `bold` changes a whole lot of other stuff. https://scanpy.readthedocs.io/en/return-formatting/api/scanpy.tl.dpt.html. I just see that this how scikit-learn styles it, though; ![image](https://user-images.githubusercontent.com/16916678/56281210-567c4f80-610c-11e9-9e51-89af17c67664.png). Hence, only the spacing after the colon is the remaining inconsistency.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484027492
https://github.com/scverse/scanpy/pull/610#issuecomment-484029598:164,Availability,redundant,redundant,164,"@ivirshup @flying-sheep I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc.; ![image](https://user-images.githubusercontent.com/16916678/56281364-b3780580-610c-11e9-8e40-2f44d3007a19.png). In the auto-generated type annotations, the default values miss completely, and I don't think we'll ever restore the `, optional` descriptor, there. ![image](https://user-images.githubusercontent.com/16916678/56281431-e15d4a00-610c-11e9-990c-6a2477540535.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598
https://github.com/scverse/scanpy/pull/610#issuecomment-484029598:164,Safety,redund,redundant,164,"@ivirshup @flying-sheep I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc.; ![image](https://user-images.githubusercontent.com/16916678/56281364-b3780580-610c-11e9-8e40-2f44d3007a19.png). In the auto-generated type annotations, the default values miss completely, and I don't think we'll ever restore the `, optional` descriptor, there. ![image](https://user-images.githubusercontent.com/16916678/56281431-e15d4a00-610c-11e9-990c-6a2477540535.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598
https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:829,Availability,redundant,redundant,829,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417
https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:999,Availability,redundant,redundant,999,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417
https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:829,Safety,redund,redundant,829,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417
https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:999,Safety,redund,redundant,999,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417
https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:487,Usability,simpl,simple,487,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417
https://github.com/scverse/scanpy/pull/610#issuecomment-484050694:266,Deployability,update,updates,266,"I figured the one-item-thing out: The emitted code is:. ```rst; :param copy: If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; :type copy: `bool`, optional (default: `False`). :returns: AnnData, None; Depending on `copy` returns or updates `adata` with the corrected data matrix.; ```. And since `:returns:` is part of a field list, and field lists are defined by the indentation of the *block starting in the second line*, the additional indentation of the second line is ignored. So yes, only numpydoc-style sections with one item are affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484050694
https://github.com/scverse/scanpy/pull/610#issuecomment-484050694:235,Integrability,Depend,Depending,235,"I figured the one-item-thing out: The emitted code is:. ```rst; :param copy: If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; :type copy: `bool`, optional (default: `False`). :returns: AnnData, None; Depending on `copy` returns or updates `adata` with the corrected data matrix.; ```. And since `:returns:` is part of a field list, and field lists are defined by the indentation of the *block starting in the second line*, the additional indentation of the second line is ignored. So yes, only numpydoc-style sections with one item are affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484050694
https://github.com/scverse/scanpy/pull/610#issuecomment-484124854:100,Security,access,access,100,"This should work for now. The problem is that this really needs to live in scanpydoc, where we have access to the fancy parsing. My plan is to merge this now, which has a solution for the simple case of. ```rst; parameter : some.type; Description; ```. Later I’ll introduce the same behavior as what scanpydoc does with the parameters:. If the return type is `...) -> Tuple[foo.bar, baz.zab]:`, then I’ll check if there’s a section like. ```rst; one_identifier; Desc; second_identifier; Desc; ```. and replace them with the same code as parameters. ----. This leaves 3 styles:. 1. Prose for a single return value; 2. The above for returning a tuple; 3. “this function adds some AnnData.obs/var fields”. For 3., we have like 3 styles floating around and need to fix one:. 1. ``**dpt_pseudotime** : :class:`pandas.Series` (`adata.obs`, dtype `float`)``; 2. ``` ``adata.obs['louvain']`` (:class:`pandas.Series`, dtype ``category``) ```; 3. `` `adata.uns['leiden']['params']` : `dict` ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484124854
https://github.com/scverse/scanpy/pull/610#issuecomment-484124854:188,Usability,simpl,simple,188,"This should work for now. The problem is that this really needs to live in scanpydoc, where we have access to the fancy parsing. My plan is to merge this now, which has a solution for the simple case of. ```rst; parameter : some.type; Description; ```. Later I’ll introduce the same behavior as what scanpydoc does with the parameters:. If the return type is `...) -> Tuple[foo.bar, baz.zab]:`, then I’ll check if there’s a section like. ```rst; one_identifier; Desc; second_identifier; Desc; ```. and replace them with the same code as parameters. ----. This leaves 3 styles:. 1. Prose for a single return value; 2. The above for returning a tuple; 3. “this function adds some AnnData.obs/var fields”. For 3., we have like 3 styles floating around and need to fix one:. 1. ``**dpt_pseudotime** : :class:`pandas.Series` (`adata.obs`, dtype `float`)``; 2. ``` ``adata.obs['louvain']`` (:class:`pandas.Series`, dtype ``category``) ```; 3. `` `adata.uns['leiden']['params']` : `dict` ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484124854
https://github.com/scverse/scanpy/pull/610#issuecomment-484418235:483,Usability,simpl,simple,483,"As mentioned in the commit, fantastic! :smile:. Which style mentioned in https://github.com/theislab/scanpy/pull/610#issuecomment-484124854 did you decide for?. Most manual corrections I saw in your PR pointed to solution (1) [`**dpt_pseudotime** : :class:`pandas.Series` (`adata.obs`, dtype `float`)`]. That's fine, but we should mention it in `CONTRIBUTING.md`. 🙂What do you think, @flying-sheep?. ----. Why did you decide against the sklearn-style solution, which would have been simple to get without manual fixes (adding `**name**`)? https://github.com/theislab/scanpy/pull/610#issuecomment-484027492",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484418235
https://github.com/scverse/scanpy/pull/610#issuecomment-484427693:233,Usability,simpl,simple,233,"I think you misunderstood a bit. 1. There’s three *types* of return sections – prose, tuple, added anndata.obs/var fields.; 2. There’s *one style* for tuple return sections (like parameters). I implemented an automatic way to handle simple `name : type` cases of those and manually formatted the rest. I’ll automate the other cases in scanpydoc, then we can remove the manually formatted ones.; 3. There’s *3 styles* for anndata.obs/var field return sections. I left them as they are for now, since we have to decide one. I only reformatted tuple return sections, I neither formatted nor decided on anything about anndata.obs/var field return sections. I hope I was more clear this time :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484427693
https://github.com/scverse/scanpy/pull/610#issuecomment-484427693:671,Usability,clear,clear,671,"I think you misunderstood a bit. 1. There’s three *types* of return sections – prose, tuple, added anndata.obs/var fields.; 2. There’s *one style* for tuple return sections (like parameters). I implemented an automatic way to handle simple `name : type` cases of those and manually formatted the rest. I’ll automate the other cases in scanpydoc, then we can remove the manually formatted ones.; 3. There’s *3 styles* for anndata.obs/var field return sections. I left them as they are for now, since we have to decide one. I only reformatted tuple return sections, I neither formatted nor decided on anything about anndata.obs/var field return sections. I hope I was more clear this time :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484427693
https://github.com/scverse/scanpy/pull/610#issuecomment-484428516:188,Usability,simpl,simply,188,"This is unrelated to your post just now. :smile:. Also, `Parameters` etc. don't render as a heading (`rubric`) like the other sections (`Notes`, `Examples`, `See also` etc.) anymore. They simply render as ; ```; <dl class=""field-list simple"">; <dt class=""field-odd"">Parameters</dt>; ```; whereas; ```; <p class=""rubric"">Notes</p>; ```. This is the new styling decision around numpydoc, also visible here: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html. In order to have it look consistent (as in sklearn), I think we do need; ```; .rst-content dl:not(.docutils) dl dt {; font-weight: bold;; font-size: 16px;; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484428516
https://github.com/scverse/scanpy/pull/610#issuecomment-484428516:234,Usability,simpl,simple,234,"This is unrelated to your post just now. :smile:. Also, `Parameters` etc. don't render as a heading (`rubric`) like the other sections (`Notes`, `Examples`, `See also` etc.) anymore. They simply render as ; ```; <dl class=""field-list simple"">; <dt class=""field-odd"">Parameters</dt>; ```; whereas; ```; <p class=""rubric"">Notes</p>; ```. This is the new styling decision around numpydoc, also visible here: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html. In order to have it look consistent (as in sklearn), I think we do need; ```; .rst-content dl:not(.docutils) dl dt {; font-weight: bold;; font-size: 16px;; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484428516
https://github.com/scverse/scanpy/pull/610#issuecomment-484428516:420,Usability,learn,learn,420,"This is unrelated to your post just now. :smile:. Also, `Parameters` etc. don't render as a heading (`rubric`) like the other sections (`Notes`, `Examples`, `See also` etc.) anymore. They simply render as ; ```; <dl class=""field-list simple"">; <dt class=""field-odd"">Parameters</dt>; ```; whereas; ```; <p class=""rubric"">Notes</p>; ```. This is the new styling decision around numpydoc, also visible here: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html. In order to have it look consistent (as in sklearn), I think we do need; ```; .rst-content dl:not(.docutils) dl dt {; font-weight: bold;; font-size: 16px;; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484428516
https://github.com/scverse/scanpy/pull/610#issuecomment-484432495:0,Energy Efficiency,Adapt,Adapted,0,Adapted the css to enforce the consistent styling of headings on each page: https://github.com/theislab/scanpy/commit/1f579f6f745d01c599a39f38abadb8a32f95c12b,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484432495
https://github.com/scverse/scanpy/pull/610#issuecomment-484432495:0,Modifiability,Adapt,Adapted,0,Adapted the css to enforce the consistent styling of headings on each page: https://github.com/theislab/scanpy/commit/1f579f6f745d01c599a39f38abadb8a32f95c12b,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484432495
https://github.com/scverse/scanpy/issues/612#issuecomment-484037086:317,Safety,safe,safety,317,"Hey! Thank you for using Scanpy!. ```; # First solution: assign subset to cluster 1 -- does not work; adata[gene1_obs,:].obs[""my_cluster""] = 1; ```; If you print `adata[gene1_obs,:]`, you'll see that it generates a view on `adata`. If you try the annotations of the view, however, this view becomes a copy. This is a safety measure as most people treat subsets of the data matrix as if it was a copy. Views are necessary, however, to be able to index in a data matrix (also for efficiency reasons). But I realize that we should print warnings when someone tries to do this, similar to pandas, which also prints a warning if you do `df['col'].loc['a':'b'] = value`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/612#issuecomment-484037086
https://github.com/scverse/scanpy/issues/613#issuecomment-485800110:112,Modifiability,flexible,flexible,112,"@gokceneraslan, how about a tuple like `({obsm_key}, {obsm_value_column})`? It's more verbose, but I think more flexible, particularly if `obsm` starts to allow more kinds of values. Here's an example (using some stuff on personal branches):. <img width=""703"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/56583661-6c62a680-661d-11e9-8314-ca0b0bf8a309.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/613#issuecomment-485800110
https://github.com/scverse/scanpy/pull/614#issuecomment-485188655:38,Testability,log,log,38,"I just found out that raw was already log transformed. Now I fixed it and nanmin seems a bit too conservative, any ideas?. ![image](https://user-images.githubusercontent.com/1140359/56463105-ea177f80-639b-11e9-80d3-f96463734634.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485188655
https://github.com/scverse/scanpy/pull/614#issuecomment-485751500:335,Safety,detect,detected,335,"Hey! I think it's a great idea to put HVG calculation within batches as a pull request. This is also an important pre-processing step for `sce.mnn_correct`, which I usually run on the intersection of HVGs from each batch. Do you think you could output the intersection as well? Or would it just be a matter of subsetting HVGs that are detected in all batches from the resulting dataframe?. I'm a bit more skeptical for advertising this as a batch-correction approach though. Maybe for time-series data where you can't use other batch correction methods?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485751500
https://github.com/scverse/scanpy/pull/614#issuecomment-485822437:707,Availability,avail,available,707,"Hey. I also thought about the intersection but didn't implement it as the default output for two reasons. . 1) it can be too harsh, especially if there is some biological variation between batches. When we sort the genes based on in how many batches they're detected as HVG and on mean normalized dispersion, there is still a chance for the user to catch such ""biological"" genes with a high n_top_genes value. . 2) Output of highly_variable_genes should be consistent regardless of batch_key option. So n_top_genes and mean/dispersion cutoff flavors should still work the same way. I feel like using the intersection directly as the output violates that. However, making `'highly_variable': np.nansum` part available in adata.var is a good idea. Then users can manually make the selection more stringent by selecting genes where this value == nbatches.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437
https://github.com/scverse/scanpy/pull/614#issuecomment-485822437:258,Safety,detect,detected,258,"Hey. I also thought about the intersection but didn't implement it as the default output for two reasons. . 1) it can be too harsh, especially if there is some biological variation between batches. When we sort the genes based on in how many batches they're detected as HVG and on mean normalized dispersion, there is still a chance for the user to catch such ""biological"" genes with a high n_top_genes value. . 2) Output of highly_variable_genes should be consistent regardless of batch_key option. So n_top_genes and mean/dispersion cutoff flavors should still work the same way. I feel like using the intersection directly as the output violates that. However, making `'highly_variable': np.nansum` part available in adata.var is a good idea. Then users can manually make the selection more stringent by selecting genes where this value == nbatches.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437
https://github.com/scverse/scanpy/pull/614#issuecomment-485875031:66,Deployability,integrat,integration,66,"I agree that using the intersection is too harsh if the only data integration/batch correction you do is this HVG filtering, but for `mnn_correct` for example you only use these HVGs to calculate the technical batch vector. In that case you ideally don't want to capture the biological variation between batch samples. For that I reckon having an option of getting the intersection would be good. And for point 2... definitely agreed... but again, a different use case for me. The same approach (intersection of HVGs) is suggested for the new CCA in Seurat v3 btw.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485875031
https://github.com/scverse/scanpy/pull/614#issuecomment-485875031:66,Integrability,integrat,integration,66,"I agree that using the intersection is too harsh if the only data integration/batch correction you do is this HVG filtering, but for `mnn_correct` for example you only use these HVGs to calculate the technical batch vector. In that case you ideally don't want to capture the biological variation between batch samples. For that I reckon having an option of getting the intersection would be good. And for point 2... definitely agreed... but again, a different use case for me. The same approach (intersection of HVGs) is suggested for the new CCA in Seurat v3 btw.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485875031
https://github.com/scverse/scanpy/pull/614#issuecomment-486188826:67,Modifiability,variab,variable,67,@LuckyMD Can you maybe check if the new `highly_variable_nbatches` variable in `adata.var` is useful for finding the intersections? . `adata.var['highly_variable'] = adata.var['highly_variable_nbatches'] == len(adata.obs.batch.cat.categories)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-486188826
https://github.com/scverse/scanpy/pull/614#issuecomment-486205965:114,Testability,test,test,114,"I'm sure it will be... Just having network issues atm, so server storage is too slow to do anything. Can't really test this atm I'm afraid :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-486205965
https://github.com/scverse/scanpy/pull/615#issuecomment-487026013:93,Safety,avoid,avoid,93,"Cool! :smile:. But is it possible to stay within the naming scheme? Or maybe even better, to avoid cluttering the namespace with many similar functions, add a parameter to `calculate_qc_metrics` that allows to restrict to `obs` and `var` if wanted?. Updating `docs/release_notes.rst` would also be great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-487026013
https://github.com/scverse/scanpy/pull/615#issuecomment-487265939:817,Testability,test,tests,817,"I'd have to think about the naming scheme, since its something I've been going back and forth on recently. I'm playing around with these semantic a bit over in my [mantis](https://github.com/ivirshup/mantis) repo, but I don't think I'm ready to make a call on which one I like best. Right now I'm split between following [plyexperiment](https://github.com/sa-lee/plyexperiment) and `xarray`. I think I'd like to keep them as separate functions, since the `calculate_qc_metrics` function already has about as complicated a relationship as I'd want with parameter values and return type. How about these keep their current name for now, but we don't export these functions beyond `_qc.py`? This will let me play around with their naming scheme and the usefulness a bit more, while scanpy gets the faster, more thorough tests and improved `calculate_qc_metrics`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-487265939
https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:49,Availability,error,error,49,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287
https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:79,Testability,test,tests,79,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287
https://github.com/scverse/scanpy/pull/615#issuecomment-489554643:62,Deployability,release,release,62,"Yes, it's good to go! Sorry about the trivial conflict in the release notes: I just made 1.4.2 based on the changes of the last two weeks on master, which I had the chance to test in the past week...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-489554643
https://github.com/scverse/scanpy/pull/615#issuecomment-489554643:175,Testability,test,test,175,"Yes, it's good to go! Sorry about the trivial conflict in the release notes: I just made 1.4.2 based on the changes of the last two weeks on master, which I had the chance to test in the past week...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-489554643
https://github.com/scverse/scanpy/pull/615#issuecomment-489859578:42,Deployability,release,release,42,"No problem, thanks!. I think conflicts in release note are going to be common. Maybe those commits could be separate from the PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-489859578
https://github.com/scverse/scanpy/issues/617#issuecomment-487917974:72,Usability,simpl,simpler,72,"The question is whether we want two scatter functions. Two will lead to simpler code. The current `pl.scatter` function is a relict from earlier times and could be simplified by dropping support for `basis`. On the other hand, it might not be so much work to add support for `x` and `y` in `plot_scatter`, in which case both functions should do the same thing. If we decide we want two functions, the second one should be `pl.scatter_embedding`, I'd say, as it's a method to visualize results of the embedding algorithms. I'm also ok with `pl.scatter_obsm` (`dimred` is something that is basically not used in the language of the docs, and I think it's a pretty misguided name of a class of functions anyway). The first one can remain `pl.scatter` and is similar to `plt.scatter` or `sns.scatter`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-487917974
https://github.com/scverse/scanpy/issues/617#issuecomment-487917974:164,Usability,simpl,simplified,164,"The question is whether we want two scatter functions. Two will lead to simpler code. The current `pl.scatter` function is a relict from earlier times and could be simplified by dropping support for `basis`. On the other hand, it might not be so much work to add support for `x` and `y` in `plot_scatter`, in which case both functions should do the same thing. If we decide we want two functions, the second one should be `pl.scatter_embedding`, I'd say, as it's a method to visualize results of the embedding algorithms. I'm also ok with `pl.scatter_obsm` (`dimred` is something that is basically not used in the language of the docs, and I think it's a pretty misguided name of a class of functions anyway). The first one can remain `pl.scatter` and is similar to `plt.scatter` or `sns.scatter`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-487917974
https://github.com/scverse/scanpy/issues/617#issuecomment-490000909:138,Usability,simpl,simple,138,Sorry to be unresponsive for a while. I think exporting `plot_scatter` as `pl.scatter_embedding` and keeping `pl.scatter` sounds a like a simple and good solution!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-490000909
https://github.com/scverse/scanpy/issues/617#issuecomment-553490520:221,Usability,simpl,simple,221,"In scvelo I have decided to handle everything within one single `pl.scatter` module, where you can pass anything to `basis`, `x`, `y` and `color` from obs/var keys to arrays to lists of such. The implementation is rather simple and condensed, and @flying-sheep I'm happy to support you if (partly) merging into scanpy sounds reasonable to you. You find some exemplary use cases in this notebook: https://scvelo-notebooks.readthedocs.io/Pancreas.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553490520
https://github.com/scverse/scanpy/issues/617#issuecomment-553945910:154,Usability,simpl,simple,154,"Yes, but I’m not happy about the spaghetti code in pl.scatter. We should make pl.embedding and pl.scatter share most of their code, and make that code as simple as @VolkerBergen’s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553945910
https://github.com/scverse/scanpy/issues/617#issuecomment-553948802:29,Deployability,integrat,integrated,29,"Happy to discuss what can be integrated from scvelo's `pl.scatter` into scanpy or how scvelo's codebase can be used.. just to mention some of the features that may also be interesting for scanpy:; - (`x`, `y`) is `str` key of (var_names, var_names), (var, var), (obs, obs), (array, array), (obs, var_names), where I find particularly passing arrays to be very convenient.; - `basis` from obsm (what is the reason for having an additional `pl.embedding`?) or var_names (on layer1 vs layer2, e.g. spliced vs. unspliced).; - `color` is `str` key of obs, var, layers or directly pass an array (which I find very convenient); while each of these can also be a list/tuple of `str` or arrays. . Further, we 'beautified' the colorbar, ticks etc. and added some functionality such as plotting a lin.reg line or polynomial fit of any degree directly on top of the scatterplot, show histogram/density along x and y axes, added `dpi` and `figsize` attributes and **kwargs for all other matplotlib-specific attributes such as `vmin`/`vmax`. ; Apart from these it entails all functionality of scanpy's `pl.scatter`. It turned out to be very convenient to have pretty much everything within one single `pl.scatter` module, not matter whether you want to visualize an embedding, any user-specified arrays colored by clusters, or visualize a gene trend along a pseudotime. I'd start of with the general question of whether incorporating some of these functionalities into scanpy's `pl.scatter` that may be useful, or whether re-implementing it based on scvelo's `pl.scatter` codebase makes more sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553948802
https://github.com/scverse/scanpy/issues/617#issuecomment-553948802:29,Integrability,integrat,integrated,29,"Happy to discuss what can be integrated from scvelo's `pl.scatter` into scanpy or how scvelo's codebase can be used.. just to mention some of the features that may also be interesting for scanpy:; - (`x`, `y`) is `str` key of (var_names, var_names), (var, var), (obs, obs), (array, array), (obs, var_names), where I find particularly passing arrays to be very convenient.; - `basis` from obsm (what is the reason for having an additional `pl.embedding`?) or var_names (on layer1 vs layer2, e.g. spliced vs. unspliced).; - `color` is `str` key of obs, var, layers or directly pass an array (which I find very convenient); while each of these can also be a list/tuple of `str` or arrays. . Further, we 'beautified' the colorbar, ticks etc. and added some functionality such as plotting a lin.reg line or polynomial fit of any degree directly on top of the scatterplot, show histogram/density along x and y axes, added `dpi` and `figsize` attributes and **kwargs for all other matplotlib-specific attributes such as `vmin`/`vmax`. ; Apart from these it entails all functionality of scanpy's `pl.scatter`. It turned out to be very convenient to have pretty much everything within one single `pl.scatter` module, not matter whether you want to visualize an embedding, any user-specified arrays colored by clusters, or visualize a gene trend along a pseudotime. I'd start of with the general question of whether incorporating some of these functionalities into scanpy's `pl.scatter` that may be useful, or whether re-implementing it based on scvelo's `pl.scatter` codebase makes more sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553948802
https://github.com/scverse/scanpy/issues/617#issuecomment-553948802:556,Modifiability,layers,layers,556,"Happy to discuss what can be integrated from scvelo's `pl.scatter` into scanpy or how scvelo's codebase can be used.. just to mention some of the features that may also be interesting for scanpy:; - (`x`, `y`) is `str` key of (var_names, var_names), (var, var), (obs, obs), (array, array), (obs, var_names), where I find particularly passing arrays to be very convenient.; - `basis` from obsm (what is the reason for having an additional `pl.embedding`?) or var_names (on layer1 vs layer2, e.g. spliced vs. unspliced).; - `color` is `str` key of obs, var, layers or directly pass an array (which I find very convenient); while each of these can also be a list/tuple of `str` or arrays. . Further, we 'beautified' the colorbar, ticks etc. and added some functionality such as plotting a lin.reg line or polynomial fit of any degree directly on top of the scatterplot, show histogram/density along x and y axes, added `dpi` and `figsize` attributes and **kwargs for all other matplotlib-specific attributes such as `vmin`/`vmax`. ; Apart from these it entails all functionality of scanpy's `pl.scatter`. It turned out to be very convenient to have pretty much everything within one single `pl.scatter` module, not matter whether you want to visualize an embedding, any user-specified arrays colored by clusters, or visualize a gene trend along a pseudotime. I'd start of with the general question of whether incorporating some of these functionalities into scanpy's `pl.scatter` that may be useful, or whether re-implementing it based on scvelo's `pl.scatter` codebase makes more sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-553948802
https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:146,Deployability,integrat,integrate,146,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192
https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:146,Integrability,integrat,integrate,146,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192
https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:631,Integrability,depend,depending,631,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192
https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:499,Modifiability,variab,variables,499,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192
https://github.com/scverse/scanpy/issues/617#issuecomment-554257192:194,Testability,test,tests,194,"I welcome @VolkerBergen ideas about plot scatter. I have used the scvelo version of scatter and works quite well and always thought that we could integrate this. Our comprehensive collection of tests related to embeddings should facilitate the recreation of the current functionality using a scatter module. As @flying-sheep points out we have a mess with respect to `pl.scatter` and `pl.embeddings` and would be great to unify the code. Currently, `pl.scatter` is used to plot two genes or any two variables like in `sc.pl.highly_variable_genes`. `pl.embedding` takes x,y (and z if 3D) from `.obsm` while adjusting color and size depending on given parameters. When I started working on the plotting functions I didn't touch `pl.scatter` which remains quite convoluted and hard to follow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554257192
https://github.com/scverse/scanpy/issues/617#issuecomment-554375694:27,Testability,test,testing,27,@stefanpeidli is currently testing whether scVelo `pl.scatter` entails all scanpy functionality. @fidelram Can you give me a very brief outline of what functionality you added in `pl.embedding` so that I can account for these as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554375694
https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:637,Availability,avail,available,637,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886
https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:734,Availability,avail,available,734,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886
https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:0,Testability,Test,Tested,0,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886
https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:53,Testability,test,test,53,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886
https://github.com/scverse/scanpy/issues/617#issuecomment-555927399:429,Modifiability,layers,layers,429,"@VolkerBergen on the top of my head here are some features that were added recently:; * adjustment of multiple plots distance using `wspace` and `hspace` (indeed I have never used `left_margin` and `right_margin` which I think are not necessary); * multiple plots by a combination of `color` and `components`. E.g. This will produce four plots: `sc.pl.pca(adata, color=['CD14', 'CD8'], components=['1,2', '2,3']` ; * support for layers; * when the marker size given by the user is a vector, this is also subjected to any sorting of the cells (eg. `sort_order=True`, `groups=['<group name']` ); * added the option to outline the plot using the parameter `add_outline` #794 ; * added vmin and vmax as percentiles #794 ; * when using the `groups` parameter, plot those groups on top #891",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-555927399
https://github.com/scverse/scanpy/pull/618#issuecomment-487026924:32,Deployability,update,update,32,This is great! 👍 . Can you also update `docs/release_notes.rst` and then simply merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/618#issuecomment-487026924
https://github.com/scverse/scanpy/pull/618#issuecomment-487026924:73,Usability,simpl,simply,73,This is great! 👍 . Can you also update `docs/release_notes.rst` and then simply merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/618#issuecomment-487026924
https://github.com/scverse/scanpy/pull/619#issuecomment-487264046:14,Deployability,update,updated,14,"Thanks!. I've updated the docs, but it turned out not much was actually shared. Where should I put these in the api docs? A new `utils` section, or something under `Further modules`? I'm thinking I'd just include `rank_genes_groups_df` and `obs_values_df` on the site.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487264046
https://github.com/scverse/scanpy/pull/619#issuecomment-487811865:49,Deployability,update,updated,49,"Since the `obs_values_df ` will now depend on an updated version of AnnData, I'm thinking I'll move this version of `rank_genes_groups_df` over to #467 so that can get merged. Edit: Actually, this isn't the case since we'll need backwards compatibility anyways, nvm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487811865
https://github.com/scverse/scanpy/pull/619#issuecomment-487811865:36,Integrability,depend,depend,36,"Since the `obs_values_df ` will now depend on an updated version of AnnData, I'm thinking I'll move this version of `rank_genes_groups_df` over to #467 so that can get merged. Edit: Actually, this isn't the case since we'll need backwards compatibility anyways, nvm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487811865
https://github.com/scverse/scanpy/pull/619#issuecomment-487916208:237,Deployability,release,release,237,"I think `obs_values` is fine. But maybe, `aggregate_obs` is even better, as this describes what it does (aggregating annotations of observations with partial (projections of) observations). It's no problem at all to make the next Scanpy release depend on the current AnnData release, both in the requirements and the minimal version check upon importing Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487916208
https://github.com/scverse/scanpy/pull/619#issuecomment-487916208:275,Deployability,release,release,275,"I think `obs_values` is fine. But maybe, `aggregate_obs` is even better, as this describes what it does (aggregating annotations of observations with partial (projections of) observations). It's no problem at all to make the next Scanpy release depend on the current AnnData release, both in the requirements and the minimal version check upon importing Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487916208
https://github.com/scverse/scanpy/pull/619#issuecomment-487916208:245,Integrability,depend,depend,245,"I think `obs_values` is fine. But maybe, `aggregate_obs` is even better, as this describes what it does (aggregating annotations of observations with partial (projections of) observations). It's no problem at all to make the next Scanpy release depend on the current AnnData release, both in the requirements and the minimal version check upon importing Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-487916208
https://github.com/scverse/scanpy/pull/619#issuecomment-493013715:101,Deployability,release,release,101,Kinda? This is waiting on https://github.com/theislab/anndata/pull/144 and a following AnnData point release. But I think that PR is ready to go.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-493013715
https://github.com/scverse/scanpy/pull/619#issuecomment-504889159:59,Deployability,release,release,59,"The docs look great! I just wonder about the above: In the release notes, we refer to everything as `scanpy.*`, not `sc.*`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/619#issuecomment-504889159
https://github.com/scverse/scanpy/issues/620#issuecomment-486582258:376,Availability,error,error,376,"This seems to have something to do with not being able to estimate the variance within a group. If you add thes lines:; ```; adata.X[0,:] = np.array([1.,1.,1.]); adata.X[11,:] = np.array([1.,1.,1.]); ```; to your data, then it works as expected. I assume this is due to `NaN` being set to 1 in the p-value calculation. The t-test isn't defined in this case. Not sure what the error for `""logreg""` is though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258
https://github.com/scverse/scanpy/issues/620#issuecomment-486582258:325,Testability,test,test,325,"This seems to have something to do with not being able to estimate the variance within a group. If you add thes lines:; ```; adata.X[0,:] = np.array([1.,1.,1.]); adata.X[11,:] = np.array([1.,1.,1.]); ```; to your data, then it works as expected. I assume this is due to `NaN` being set to 1 in the p-value calculation. The t-test isn't defined in this case. Not sure what the error for `""logreg""` is though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258
https://github.com/scverse/scanpy/issues/620#issuecomment-486582258:388,Testability,log,logreg,388,"This seems to have something to do with not being able to estimate the variance within a group. If you add thes lines:; ```; adata.X[0,:] = np.array([1.,1.,1.]); adata.X[11,:] = np.array([1.,1.,1.]); ```; to your data, then it works as expected. I assume this is due to `NaN` being set to 1 in the p-value calculation. The t-test isn't defined in this case. Not sure what the error for `""logreg""` is though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258
https://github.com/scverse/scanpy/issues/620#issuecomment-486585476:35,Testability,test,test,35,Btw. I think scanpy uses Welch's t-test and not the standard t-test. So the comparison with `stats.ttest_ind` is not entirely correct. I guess `stats.ttest_ind` calculates the asymptote of the statistic (`-inf`) and uses that to give a p-value of 0.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476
https://github.com/scverse/scanpy/issues/620#issuecomment-486585476:63,Testability,test,test,63,Btw. I think scanpy uses Welch's t-test and not the standard t-test. So the comparison with `stats.ttest_ind` is not entirely correct. I guess `stats.ttest_ind` calculates the asymptote of the statistic (`-inf`) and uses that to give a p-value of 0.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486585476
https://github.com/scverse/scanpy/issues/620#issuecomment-486600972:158,Testability,test,test,158,"It doesn't matter for the topic of this discussion indeed. I reckon line 201 is the cause. If you want to solve this as scipy does, you will probably have to test for 0 variance and then assign a `-Inf` score, which defaults to a p-value of 0. I wonder if you get spurious marker gene results then though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486600972
https://github.com/scverse/scanpy/pull/621#issuecomment-486991947:73,Integrability,depend,dependency,73,I wonder why this wasn't done in the first place. Is scipy not already a dependency of scanpy? Or is this slower than the initial implementation?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-486991947
https://github.com/scverse/scanpy/pull/621#issuecomment-487019494:104,Energy Efficiency,efficient,efficient,104,"Looks great! I wasn't aware of this high-dimensional version of a t-test in Scipy, which seems to be as efficient as the current implementation. I only investigated thoroughly for Wilcoxon rank and found that Scipy doesn't have a scalable version to offer. But yes, this will get merged after 1.4.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494
https://github.com/scverse/scanpy/pull/621#issuecomment-487019494:230,Performance,scalab,scalable,230,"Looks great! I wasn't aware of this high-dimensional version of a t-test in Scipy, which seems to be as efficient as the current implementation. I only investigated thoroughly for Wilcoxon rank and found that Scipy doesn't have a scalable version to offer. But yes, this will get merged after 1.4.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494
https://github.com/scverse/scanpy/pull/621#issuecomment-487019494:68,Testability,test,test,68,"Looks great! I wasn't aware of this high-dimensional version of a t-test in Scipy, which seems to be as efficient as the current implementation. I only investigated thoroughly for Wilcoxon rank and found that Scipy doesn't have a scalable version to offer. But yes, this will get merged after 1.4.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487019494
https://github.com/scverse/scanpy/pull/621#issuecomment-487026612:37,Performance,scalab,scalable,37,"1.4.1 is out, are we sure this is as scalable as it was before and not a backwards breaking change. If yes, we can merge immediately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487026612
https://github.com/scverse/scanpy/pull/621#issuecomment-487260802:435,Performance,optimiz,optimize,435,"I'm not completely sure this doesn't break anything, but the regression tests pass. The internal code is very similar, so I'm not too worried about these changes. It does look like it's (very) slightly slower. Running this a thousand times for pbmc68k dataset took ~2.3% longer (about 1.4 ms per run) than the previous version. That said, we're very inefficient about mean and variance calculation, so I think that's a better place to optimize. Edit: I've force pushed to fix some minor formatting issues (trailing white space, blank line, typo) that I didn't think deserved it's own commit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802
https://github.com/scverse/scanpy/pull/621#issuecomment-487260802:72,Testability,test,tests,72,"I'm not completely sure this doesn't break anything, but the regression tests pass. The internal code is very similar, so I'm not too worried about these changes. It does look like it's (very) slightly slower. Running this a thousand times for pbmc68k dataset took ~2.3% longer (about 1.4 ms per run) than the previous version. That said, we're very inefficient about mean and variance calculation, so I think that's a better place to optimize. Edit: I've force pushed to fix some minor formatting issues (trailing white space, blank line, typo) that I didn't think deserved it's own commit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/621#issuecomment-487260802
https://github.com/scverse/scanpy/pull/622#issuecomment-487028811:463,Deployability,update,update,463,"This is very helpful! Great! :smile:. But, can have a non-recursive formulation of this? Others and I worked to get rid of many of the initial recursive formulations as they were hard to read. And here, it's the same thing. It's already a very long function and should not get longer. Can you just rename the old `highly_variable_genes` to `_highly_variable_genes_single_batch` and remove the recursion? It's a very simple change, I'd be grateful... Can you also update `docs/release_notes.rst` with a link to this PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/622#issuecomment-487028811
https://github.com/scverse/scanpy/pull/622#issuecomment-487028811:416,Usability,simpl,simple,416,"This is very helpful! Great! :smile:. But, can have a non-recursive formulation of this? Others and I worked to get rid of many of the initial recursive formulations as they were hard to read. And here, it's the same thing. It's already a very long function and should not get longer. Can you just rename the old `highly_variable_genes` to `_highly_variable_genes_single_batch` and remove the recursion? It's a very simple change, I'd be grateful... Can you also update `docs/release_notes.rst` with a link to this PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/622#issuecomment-487028811
https://github.com/scverse/scanpy/pull/622#issuecomment-488295556:72,Deployability,release,release,72,"Actually, I added two commits to my master branch and one was about the release notes. But then instead of pushing to my fork, I pushed these to the master branch of scanpy repo by mistake. Fortunately, there were just these two commits that I wanted to add to this PR, so everything should be all right. Sorry for the confusion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/622#issuecomment-488295556
https://github.com/scverse/scanpy/pull/623#issuecomment-487026385:63,Testability,log,logging,63,OK. I initially thought that PCA is such a fast step that much logging is not needed. But you're right. :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/623#issuecomment-487026385
https://github.com/scverse/scanpy/pull/624#issuecomment-1900349804:233,Testability,test,tests,233,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > Comparison is base [(`86b85ee`)](https://app.codecov.io/gh/scverse/scanpy/commit/86b85ee2f4e8acfc9db3ce4cfff6e905d96a59eb?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72% compared to head [(`f233d75`)](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) 72.72%. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #624 +/- ##; =======================================; Coverage 72.72% 72.72% ; =======================================; Files 111 111 ; Lines 12384 12384 ; =======================================; Hits 9006 9006 ; Misses 3378 3378 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/624?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `96.17% <ø> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/624#issuecomment-1900349804
https://github.com/scverse/scanpy/issues/625#issuecomment-487175852:150,Availability,down,down-regulated,150,"You can interchange the cluster order (reference with the cluster your intersted in) and get only-upregulated ones for the inverted comparison (hence down-regulated genes) or set `rankby_abs` to `True`, which will then give you down-regulated genes in addition to up-regulated ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852
https://github.com/scverse/scanpy/issues/625#issuecomment-487175852:228,Availability,down,down-regulated,228,"You can interchange the cluster order (reference with the cluster your intersted in) and get only-upregulated ones for the inverted comparison (hence down-regulated genes) or set `rankby_abs` to `True`, which will then give you down-regulated genes in addition to up-regulated ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852
https://github.com/scverse/scanpy/issues/625#issuecomment-487553407:44,Deployability,integrat,integrate,44,In case you're still looking to use MAST or integrate other `R` tools into a scanpy pipeline. That works quite well via [anndata2ri](www.github.com/flying-sheep/anndata2ri). An example of how you can do this can be found in the case study notebook [here](https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1904.ipynb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487553407
https://github.com/scverse/scanpy/issues/625#issuecomment-487553407:84,Deployability,pipeline,pipeline,84,In case you're still looking to use MAST or integrate other `R` tools into a scanpy pipeline. That works quite well via [anndata2ri](www.github.com/flying-sheep/anndata2ri). An example of how you can do this can be found in the case study notebook [here](https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1904.ipynb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487553407
https://github.com/scverse/scanpy/issues/625#issuecomment-487553407:44,Integrability,integrat,integrate,44,In case you're still looking to use MAST or integrate other `R` tools into a scanpy pipeline. That works quite well via [anndata2ri](www.github.com/flying-sheep/anndata2ri). An example of how you can do this can be found in the case study notebook [here](https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1904.ipynb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487553407
https://github.com/scverse/scanpy/issues/626#issuecomment-488057644:131,Availability,error,error,131,> That doesn't seem to be a Scanpy or AnnData issue but an issue with a corrupted HDF5 file as such. Thanks! I struggled with this error for a long time yet it turns out the file is corrupted.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/626#issuecomment-488057644
https://github.com/scverse/scanpy/issues/627#issuecomment-489157164:87,Testability,test,test,87,"Thanks for your reply. I have modified code and sent a pull request, but it seems that test is; failed, but i don't know why test is failed. I have double check my code,; its fine. Thanks ,; Waiting for your reply. Regards,; Khalid. On Fri, May 3, 2019 at 5:17 PM Philipp A. <notifications@github.com> wrote:. > Hi! Thank you for your contribution!; >; > Maintaining scanpy is a lot of work, so we like to rely on GitHub to help; > us here. Please read up on how to use github so you can create a pull; > request <https://help.github.com/en/articles/creating-a-pull-request>; > with your changes.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/627#issuecomment-489024928>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHDRLVEO2QTVBGAQ2TPTP7J7ANCNFSM4HJSV4RQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/627#issuecomment-489157164
https://github.com/scverse/scanpy/issues/627#issuecomment-489157164:125,Testability,test,test,125,"Thanks for your reply. I have modified code and sent a pull request, but it seems that test is; failed, but i don't know why test is failed. I have double check my code,; its fine. Thanks ,; Waiting for your reply. Regards,; Khalid. On Fri, May 3, 2019 at 5:17 PM Philipp A. <notifications@github.com> wrote:. > Hi! Thank you for your contribution!; >; > Maintaining scanpy is a lot of work, so we like to rely on GitHub to help; > us here. Please read up on how to use github so you can create a pull; > request <https://help.github.com/en/articles/creating-a-pull-request>; > with your changes.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/627#issuecomment-489024928>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHDRLVEO2QTVBGAQ2TPTP7J7ANCNFSM4HJSV4RQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/627#issuecomment-489157164
https://github.com/scverse/scanpy/pull/628#issuecomment-488684629:12,Testability,test,test,12,The failing test is un-related to the PR. @LuckyMD can you take a look at the changes?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/628#issuecomment-488684629
https://github.com/scverse/scanpy/pull/628#issuecomment-488715711:257,Usability,user-friendly,user-friendly,257,"I really like this! I was trying to figure out how to easily do this within the current `plot_scatter` framework, but I couldn't figure out how. One thing though... You could add an option `group='all'`, which should be the default. That would be much more user-friendly than the current setup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/628#issuecomment-488715711
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:824,Availability,Mask,Mask,824,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:1037,Integrability,Wrap,Wrap,1037,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:117,Testability,test,tests,117,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:171,Testability,test,tests,171,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:389,Testability,test,test,389,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:1048,Testability,test,test,1048,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:12,Availability,Mask,Mask,12,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:161,Availability,mask,masking,161,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:490,Integrability,Wrap,Wrap,490,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:397,Modifiability,maintainab,maintainability,397,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:501,Testability,test,test,501,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:418,Usability,simpl,simplicity,418,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754
https://github.com/scverse/scanpy/issues/629#issuecomment-489134176:52,Availability,mask,masked,52,You could just output `NaN` for all genes that were masked? That would be accurate as the test would fail in that case anyway. That should solve `n_genes == adata.n_vars`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176
https://github.com/scverse/scanpy/issues/629#issuecomment-489134176:90,Testability,test,test,90,You could just output `NaN` for all genes that were masked? That would be accurate as the test would fail in that case anyway. That should solve `n_genes == adata.n_vars`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176
https://github.com/scverse/scanpy/pull/630#issuecomment-489194292:337,Availability,down,downloaded,337,"seems like you did something wrong. the commit you added (74540cc133ca9cfe0744ca9d3b250454a76a9c4d) reverts a lot of changes we made since. i assume you just copied all your code over the current master branch, and not the version of the master branch as it was when you made the changes. you need to find the version of scanpy that you downloaded before you made your changes and modify that one to have just the changes you want to commit. otherwise we have no idea what your actual changes are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-489194292
https://github.com/scverse/scanpy/pull/630#issuecomment-492076397:676,Availability,down,downloaded,676,"Hi,. I have modified version 1.4, but i think git only allow latest version to; fork. Is there any other simple way, so that i can share my code for Scanpy; version 1.4. Thanks,; Khalid. On Sat, May 4, 2019 at 2:26 AM Philipp A. <notifications@github.com> wrote:. > seems like you did something wrong. the commit you added (74540cc; > <https://github.com/theislab/scanpy/commit/74540cc133ca9cfe0744ca9d3b250454a76a9c4d>); > reverts a lot of changes we made since.; >; > i assume you just copied all your code over the current master branch, and; > not the version of the master branch as it was when you made the changes.; >; > you need to find the version of scanpy that you downloaded before you made; > your changes and modify that one to have just the changes you want to; > commit. otherwise we have no idea what your actual changes are.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630#issuecomment-489194292>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOBLBVFOZLO23ZCULELPTR7U3ANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397
https://github.com/scverse/scanpy/pull/630#issuecomment-492076397:105,Usability,simpl,simple,105,"Hi,. I have modified version 1.4, but i think git only allow latest version to; fork. Is there any other simple way, so that i can share my code for Scanpy; version 1.4. Thanks,; Khalid. On Sat, May 4, 2019 at 2:26 AM Philipp A. <notifications@github.com> wrote:. > seems like you did something wrong. the commit you added (74540cc; > <https://github.com/theislab/scanpy/commit/74540cc133ca9cfe0744ca9d3b250454a76a9c4d>); > reverts a lot of changes we made since.; >; > i assume you just copied all your code over the current master branch, and; > not the version of the master branch as it was when you made the changes.; >; > you need to find the version of scanpy that you downloaded before you made; > your changes and modify that one to have just the changes you want to; > commit. otherwise we have no idea what your actual changes are.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630#issuecomment-489194292>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOBLBVFOZLO23ZCULELPTR7U3ANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397
https://github.com/scverse/scanpy/pull/630#issuecomment-492124539:777,Integrability,message,message,777,"yes!. 1. make sure you have all of your modified copy somewhere outside of the cloned directory! we’re going to destroy all changes inside of that directory!; 2. Destroy all changes and go back to 1.4: `git reset --hard 1.4` (if it’s really 1.4 and not e.g. 1.4.1); 3. Make a new branch based on 1.4: `git checkout -b weighted-clustering`; 4. Copy your changes over again.; 5. Check if all is right: `git diff` should only tell you about your modified files, not other junk.; 6. Add all files you changed individually (not `git add .` or `git add -A`, but `git add scanpy/file1.py scanpy/file2.py ...`); 7. `git diff` should now say that there’s a few staged files (your modifications), and no other added or modified files.; 8. Commit your changes `git commit -m 'your commit message'` and push them `git push`. Now you can make a new PR with just your changes in it: https://github.com/theislab/scanpy/compare/master...Khalid-Usman:weighted-clustering. Make sure that you only see your changes on the lower part of that page before hitting the “Create Pull Request” button",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492124539
https://github.com/scverse/scanpy/pull/630#issuecomment-492175356:703,Integrability,message,message,703,"Is it fine or need to do anything else before make a pull request ?. Thanks. On Tue, May 14, 2019 at 4:05 PM Philipp A. <notifications@github.com> wrote:. > yes!; >; > 1. make sure you have all your modified copy somewhere outside of the; > cloned directory! we’re going to destroy all changes inside of that; > directory!; > 2. Destroy all changes and go back to 1.4: git reset --hard 1.4 (if; > it’s really 1.4 and not e.g. 1.4.1); > 3. Make a new branch based on 1.4: git checkout -b weighted-clustering; > 4. Copy your changes over again.; > 5. Add all files you changed individually (not git add . or git add -A,; > but git add scanpy/file1.py scanpy/file2.py ...); > 6. git commit -m 'your commit message'; >; > Now you can make a new PR with just your changes in it:; > master...Khalid-Usman:weighted-clustering; > <https://github.com/theislab/scanpy/compare/master...Khalid-Usman:weighted-clustering>; >; > Make sure that you only see your changes on the lower part of that page; > before hitting the “Create Pull Request” button; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOA2G7HECFLNHTNNZ33PVJXFZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVKTS6Y#issuecomment-492124539>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHOOABYXSQL6HLZUN3PVJXFZANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492175356
https://github.com/scverse/scanpy/pull/630#issuecomment-492237208:212,Deployability,update,update,212,"Ok , thanks for letting me know. Please check the pull request. I have; verified my code by keeping weights 1 and it has same values when; observations has no weights or all weights equal to 1. I also suggest to update PCA for weighted sampled data. Thanks,; Khalid Usman. On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com> wrote:. > You can just open a new one, I’ll close this one then 🙂; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492237208
https://github.com/scverse/scanpy/pull/630#issuecomment-493836074:577,Deployability,update,update,577,"Hi Phillip,. I have removed issue from the pull request by the testing tool, now the; tools showed me duplications, which are mostly from other code and 1-2 from; my code. Please have a look into it. It's my first pull request and its; taking too much time :(. Thanks; Khalid. On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:. > Ok , thanks for letting me know. Please check the pull request. I have; > verified my code by keeping weights 1 and it has same values when; > observations has no weights or all weights equal to 1.; >; > I also suggest to update PCA for weighted sampled data.; >; > Thanks,; > Khalid Usman; >; > On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; > wrote:; >; >> You can just open a new one, I’ll close this one then 🙂; >>; >> —; >> You are receiving this because you authored the thread.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >> .; >>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074
https://github.com/scverse/scanpy/pull/630#issuecomment-493836074:63,Testability,test,testing,63,"Hi Phillip,. I have removed issue from the pull request by the testing tool, now the; tools showed me duplications, which are mostly from other code and 1-2 from; my code. Please have a look into it. It's my first pull request and its; taking too much time :(. Thanks; Khalid. On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:. > Ok , thanks for letting me know. Please check the pull request. I have; > verified my code by keeping weights 1 and it has same values when; > observations has no weights or all weights equal to 1.; >; > I also suggest to update PCA for weighted sampled data.; >; > Thanks,; > Khalid Usman; >; > On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; > wrote:; >; >> You can just open a new one, I’ll close this one then 🙂; >>; >> —; >> You are receiving this because you authored the thread.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >> .; >>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-493836074
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:883,Deployability,update,update,883,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:49,Testability,test,testing,49,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:107,Testability,test,tested,107,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:156,Testability,test,tests,156,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:343,Testability,test,testing,343,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/pull/630#issuecomment-494076520:41,Usability,learn,learned,41,"Thanks alot Philip for your help, I just learned testing :). Hopefully this version will be accepted, as I tested now on my laptop and; push when it passed tests for all 5 plots. Thanks,; Khalid. On Mon, May 20, 2019 at 12:37 PM khalid usman <khalid0491@gmail.com> wrote:. > Hi Phillip,; >; > I have removed issue from the pull request by the testing tool, now the; > tools showed me duplications, which are mostly from other code and 1-2 from; > my code. Please have a look into it. It's my first pull request and its; > taking too much time :(; >; > Thanks; > Khalid; >; > On Tue, May 14, 2019 at 9:28 PM khalid usman <khalid0491@gmail.com> wrote:; >; >> Ok , thanks for letting me know. Please check the pull request. I have; >> verified my code by keeping weights 1 and it has same values when; >> observations has no weights or all weights equal to 1.; >>; >> I also suggest to update PCA for weighted sampled data.; >>; >> Thanks,; >> Khalid Usman; >>; >> On Tue, May 14, 2019 at 7:53 PM Philipp A. <notifications@github.com>; >> wrote:; >>; >>> You can just open a new one, I’ll close this one then 🙂; >>>; >>> —; >>> You are receiving this because you authored the thread.; >>> Reply to this email directly, view it on GitHub; >>> <https://github.com/theislab/scanpy/pull/630?email_source=notifications&email_token=ABREGOFHXLS2NZRCDSLJHE3PVKR2ZA5CNFSM4HKUCBXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVLHMMQ#issuecomment-492205618>,; >>> or mute the thread; >>> <https://github.com/notifications/unsubscribe-auth/ABREGOBMZBMFMNA6FCEMFULPVKR2ZANCNFSM4HKUCBXA>; >>> .; >>>; >>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-494076520
https://github.com/scverse/scanpy/issues/631#issuecomment-489690557:22,Deployability,install,install,22,It should work if you install from github.; https://github.com/theislab/scanpy/commit/fe2580cb58e2ad6312ea989b0c9a40351510051a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/631#issuecomment-489690557
https://github.com/scverse/scanpy/issues/631#issuecomment-489750461:104,Deployability,install,install,104,"Thanks. On Mon, 6 May 2019 at 18:49, Koncopd <notifications@github.com> wrote:. > It should work if you install from github.; > fe2580c; > <https://github.com/theislab/scanpy/commit/fe2580cb58e2ad6312ea989b0c9a40351510051a>; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/631#issuecomment-489690557>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACPDY4SWBVPGTIQHOG365L3PUBOS3ANCNFSM4HLAPBTA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/631#issuecomment-489750461
https://github.com/scverse/scanpy/issues/632#issuecomment-490045550:83,Deployability,release,release,83,"As per the referencing issue, it looks like this should be fixed by the next bbknn release in a day or two. Thanks for the bug report @jipeifeng!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632#issuecomment-490045550
https://github.com/scverse/scanpy/issues/633#issuecomment-490792870:101,Energy Efficiency,reduce,reduce,101,"Thanks for your information. I am surprised that this step is taking too; long as is was supposed to reduce the plotting time. I would not wait for; more than 5 minutes to see a plot. How many genes were you planning to plot?. The background is that when plotting a heatmap, the matplotlib; visualization will randomly drop genes because the resolution of the; screens is not high enough. Thus, when the number of genes is large, I was; trying to find a compromise by fitting a line before the plotting and then; only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you; find an example that can reproduce the problem?. On Tue, May 7, 2019 at 10:19 AM brianpenghe <notifications@github.com>; wrote:. > I was trying to plot a heatmap using this command:; > ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident',; > use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0,; > dendrogram=True, save='ClusterMap.png'); >; > And it didn't finish running after an overnight, with the following; > warning message:; > WARNING: Gene labels are not shown when more than 50 genes are visualized.; > To show gene labels set show_gene_labels=True; > /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227:; > UserWarning:; > The maximal number of iterations maxit (set to 20 by the program); > allowed for finding a smoothing spline with fp=s has been reached: s; > too small.; > There is an approximation returned but the corresponding weighted sum; > of squared residuals does not satisfy the condition abs(fp-s)/s < tol.; > warnings.warn(message); >; > I don't understand why this is taking this long because seaborn was able; > to finish plotting within 30 minutes. Do you know why?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/633>, or mute the thread; > <https://github.com/notifications",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-490792870
https://github.com/scverse/scanpy/issues/633#issuecomment-490792870:1072,Integrability,message,message,1072,"too; long as is was supposed to reduce the plotting time. I would not wait for; more than 5 minutes to see a plot. How many genes were you planning to plot?. The background is that when plotting a heatmap, the matplotlib; visualization will randomly drop genes because the resolution of the; screens is not high enough. Thus, when the number of genes is large, I was; trying to find a compromise by fitting a line before the plotting and then; only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you; find an example that can reproduce the problem?. On Tue, May 7, 2019 at 10:19 AM brianpenghe <notifications@github.com>; wrote:. > I was trying to plot a heatmap using this command:; > ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident',; > use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0,; > dendrogram=True, save='ClusterMap.png'); >; > And it didn't finish running after an overnight, with the following; > warning message:; > WARNING: Gene labels are not shown when more than 50 genes are visualized.; > To show gene labels set show_gene_labels=True; > /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227:; > UserWarning:; > The maximal number of iterations maxit (set to 20 by the program); > allowed for finding a smoothing spline with fp=s has been reached: s; > too small.; > There is an approximation returned but the corresponding weighted sum; > of squared residuals does not satisfy the condition abs(fp-s)/s < tol.; > warnings.warn(message); >; > I don't understand why this is taking this long because seaborn was able; > to finish plotting within 30 minutes. Do you know why?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/633>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA>; > .;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-490792870
https://github.com/scverse/scanpy/issues/633#issuecomment-490792870:1620,Integrability,message,message,1620,"posed to reduce the plotting time. I would not wait for; more than 5 minutes to see a plot. How many genes were you planning to plot?. The background is that when plotting a heatmap, the matplotlib; visualization will randomly drop genes because the resolution of the; screens is not high enough. Thus, when the number of genes is large, I was; trying to find a compromise by fitting a line before the plotting and then; only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you; find an example that can reproduce the problem?. On Tue, May 7, 2019 at 10:19 AM brianpenghe <notifications@github.com>; wrote:. > I was trying to plot a heatmap using this command:; > ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident',; > use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0,; > dendrogram=True, save='ClusterMap.png'); >; > And it didn't finish running after an overnight, with the following; > warning message:; > WARNING: Gene labels are not shown when more than 50 genes are visualized.; > To show gene labels set show_gene_labels=True; > /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227:; > UserWarning:; > The maximal number of iterations maxit (set to 20 by the program); > allowed for finding a smoothing spline with fp=s has been reached: s; > too small.; > There is an approximation returned but the corresponding weighted sum; > of squared residuals does not satisfy the condition abs(fp-s)/s < tol.; > warnings.warn(message); >; > I don't understand why this is taking this long because seaborn was able; > to finish plotting within 30 minutes. Do you know why?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/633>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-490792870
https://github.com/scverse/scanpy/issues/633#issuecomment-491103142:102,Energy Efficiency,reduce,reduce,102,"> Thanks for your information. I am surprised that this step is taking too long as is was supposed to reduce the plotting time. I would not wait for more than 5 minutes to see a plot. How many genes were you planning to plot? The background is that when plotting a heatmap, the matplotlib visualization will randomly drop genes because the resolution of the screens is not high enough. Thus, when the number of genes is large, I was trying to find a compromise by fitting a line before the plotting and then only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you find an example that can reproduce the problem?; > […](#); > On Tue, May 7, 2019 at 10:19 AM brianpenghe ***@***.***> wrote: I was trying to plot a heatmap using this command: ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True, save='ClusterMap.png') And it didn't finish running after an overnight, with the following warning message: WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set show_gene_labels=True /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227: UserWarning: The maximal number of iterations maxit (set to 20 by the program) allowed for finding a smoothing spline with fp=s has been reached: s too small. There is an approximation returned but the corresponding weighted sum of squared residuals does not satisfy the condition abs(fp-s)/s < tol. warnings.warn(message) I don't understand why this is taking this long because seaborn was able to finish plotting within 30 minutes. Do you know why? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#633>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA> .; > -- Fidel Ramirez. I was planning to plot a heatmap of 300 g",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-491103142
https://github.com/scverse/scanpy/issues/633#issuecomment-491103142:1042,Integrability,message,message,1042,"sed that this step is taking too long as is was supposed to reduce the plotting time. I would not wait for more than 5 minutes to see a plot. How many genes were you planning to plot? The background is that when plotting a heatmap, the matplotlib visualization will randomly drop genes because the resolution of the screens is not high enough. Thus, when the number of genes is large, I was trying to find a compromise by fitting a line before the plotting and then only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you find an example that can reproduce the problem?; > […](#); > On Tue, May 7, 2019 at 10:19 AM brianpenghe ***@***.***> wrote: I was trying to plot a heatmap using this command: ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True, save='ClusterMap.png') And it didn't finish running after an overnight, with the following warning message: WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set show_gene_labels=True /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227: UserWarning: The maximal number of iterations maxit (set to 20 by the program) allowed for finding a smoothing spline with fp=s has been reached: s too small. There is an approximation returned but the corresponding weighted sum of squared residuals does not satisfy the condition abs(fp-s)/s < tol. warnings.warn(message) I don't understand why this is taking this long because seaborn was able to finish plotting within 30 minutes. Do you know why? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#633>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA> .; > -- Fidel Ramirez. I was planning to plot a heatmap of 300 genes. However, I have 90k cells. I guess t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-491103142
https://github.com/scverse/scanpy/issues/633#issuecomment-491103142:1560,Integrability,message,message,1560,"ng and then only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you find an example that can reproduce the problem?; > […](#); > On Tue, May 7, 2019 at 10:19 AM brianpenghe ***@***.***> wrote: I was trying to plot a heatmap using this command: ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True, save='ClusterMap.png') And it didn't finish running after an overnight, with the following warning message: WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set show_gene_labels=True /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227: UserWarning: The maximal number of iterations maxit (set to 20 by the program) allowed for finding a smoothing spline with fp=s has been reached: s too small. There is an approximation returned but the corresponding weighted sum of squared residuals does not satisfy the condition abs(fp-s)/s < tol. warnings.warn(message) I don't understand why this is taking this long because seaborn was able to finish plotting within 30 minutes. Do you know why? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#633>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA> .; > -- Fidel Ramirez. I was planning to plot a heatmap of 300 genes. However, I have 90k cells. I guess the time-consuming part is the PCA because that's what's required to do the clustering by groups. I thought a naive way to do the clustering is just to construct the ""pseudobulks"" for each group by calculating the average and then simply clustering the ""pseudobulks"", instead of trying to look at individual cells. Another advantage of checking the pseudobulk is that the size of each group won't affect the landscape of principle components in that way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-491103142
https://github.com/scverse/scanpy/issues/633#issuecomment-491103142:2273,Usability,simpl,simply,2273,"ng and then only plotting the fit. Can you help me solve the issue by sharing the data with me? Or, can you find an example that can reproduce the problem?; > […](#); > On Tue, May 7, 2019 at 10:19 AM brianpenghe ***@***.***> wrote: I was trying to plot a heatmap using this command: ax=sc2.pl.heatmap(adata, sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True, save='ClusterMap.png') And it didn't finish running after an overnight, with the following warning message: WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set show_gene_labels=True /usr/local/lib/python3.6/dist-packages/scipy/interpolate/fitpack2.py:227: UserWarning: The maximal number of iterations maxit (set to 20 by the program) allowed for finding a smoothing spline with fp=s has been reached: s too small. There is an approximation returned but the corresponding weighted sum of squared residuals does not satisfy the condition abs(fp-s)/s < tol. warnings.warn(message) I don't understand why this is taking this long because seaborn was able to finish plotting within 30 minutes. Do you know why? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <#633>, or mute the thread <https://github.com/notifications/unsubscribe-auth/ABF37VNDX37RZL256MWKDM3PUE3RFANCNFSM4HLGOYGA> .; > -- Fidel Ramirez. I was planning to plot a heatmap of 300 genes. However, I have 90k cells. I guess the time-consuming part is the PCA because that's what's required to do the clustering by groups. I thought a naive way to do the clustering is just to construct the ""pseudobulks"" for each group by calculating the average and then simply clustering the ""pseudobulks"", instead of trying to look at individual cells. Another advantage of checking the pseudobulk is that the size of each group won't affect the landscape of principle components in that way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-491103142
https://github.com/scverse/scanpy/issues/633#issuecomment-607391574:302,Integrability,message,message,302,"I have the same issue than @brianpenghe .; I am trying to plot a heatmap using:; `sc.pl.heatmap(adata_10x_day13_MPCs_early, output_great_1090, groupby='condition', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True)`. n_cells = 1071; n_genes = 1121. I got this message as well:. WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set `show_gene_labels=True`. /home/grupos_srs_ap/Programs/anaconda3/lib/python3.7/site-packages/scipy/interpolate/fitpack2.py:227: UserWarning: ; The maximal number of iterations maxit (set to 20 by the program); allowed for finding a smoothing spline with fp=s has been reached: s; too small.; There is an approximation returned but the corresponding weighted sum; of squared residuals does not satisfy the condition abs(fp-s)/s < tol.; warnings.warn(message). The heatmap was plotted after few minutes, though:; ![image](https://user-images.githubusercontent.com/63011975/78168487-675dc800-7426-11ea-9374-a6a4aab24506.png). I think the plot is not correct. I tried modifying the scanpy/plotting/_anndata.py, removing the smoothing function as described above, but got the same results. . Can you help me?; Thanks a lot in advance",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-607391574
https://github.com/scverse/scanpy/issues/633#issuecomment-607391574:867,Integrability,message,message,867,"I have the same issue than @brianpenghe .; I am trying to plot a heatmap using:; `sc.pl.heatmap(adata_10x_day13_MPCs_early, output_great_1090, groupby='condition', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True, var_group_rotation=0, dendrogram=True)`. n_cells = 1071; n_genes = 1121. I got this message as well:. WARNING: Gene labels are not shown when more than 50 genes are visualized. To show gene labels set `show_gene_labels=True`. /home/grupos_srs_ap/Programs/anaconda3/lib/python3.7/site-packages/scipy/interpolate/fitpack2.py:227: UserWarning: ; The maximal number of iterations maxit (set to 20 by the program); allowed for finding a smoothing spline with fp=s has been reached: s; too small.; There is an approximation returned but the corresponding weighted sum; of squared residuals does not satisfy the condition abs(fp-s)/s < tol.; warnings.warn(message). The heatmap was plotted after few minutes, though:; ![image](https://user-images.githubusercontent.com/63011975/78168487-675dc800-7426-11ea-9374-a6a4aab24506.png). I think the plot is not correct. I tried modifying the scanpy/plotting/_anndata.py, removing the smoothing function as described above, but got the same results. . Can you help me?; Thanks a lot in advance",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/633#issuecomment-607391574
https://github.com/scverse/scanpy/issues/637#issuecomment-492510374:169,Deployability,update,update,169,"There was a similar report not so long ago but I have not been able to reproduce the issue. . Seems to be related with the matplotlib version used. Maybe you can try to update to the latest version. . . > On 10 May 2019, at 01:38, brianpenghe <notifications@github.com> wrote:; > ; > I ran this:; > ax=sc.pl.heatmap(Mouse10Xdata[NewIndex3,:], sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True,swap_axes=True,figsize=(10,7), var_group_rotation=0, dendrogram=True, save='ClusterMap.png'); > ; > But the image has something weird. Here are the snapshot:; > ; > The lines don't align well with the heatmap.; > ; > Additionally, the lines don't align well with the group ID colors, either; > ; > ; > And the ID colors seem to be not aligned well with the heatmap either.; > ; > Any thoughts?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-492510374
https://github.com/scverse/scanpy/issues/637#issuecomment-492577684:169,Deployability,update,update,169,"> There was a similar report not so long ago but I have not been able to reproduce the issue. Seems to be related with the matplotlib version used. Maybe you can try to update to the latest version.; > […](#); > On 10 May 2019, at 01:38, brianpenghe ***@***.***> wrote: I ran this: ax=sc.pl.heatmap(Mouse10Xdata[NewIndex3,:], sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True,swap_axes=True,figsize=(10,7), var_group_rotation=0, dendrogram=True, save='ClusterMap.png') But the image has something weird. Here are the snapshot: The lines don't align well with the heatmap. Additionally, the lines don't align well with the group ID colors, either And the ID colors seem to be not aligned well with the heatmap either. Any thoughts? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread. I have been using matplotlib 3.0.3 and I believe it's the latest version already. My Scanpy version was 1.4.1. ; Can it be an issue about duplicated gene names/make unique?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-492577684
https://github.com/scverse/scanpy/issues/637#issuecomment-492700214:640,Deployability,update,update,640,"In your heat map the lines are separating categorical groups right? In other words genes are rows. . In your command you are doing a selection over a larger dataset. Have you tried to make a copy of the adata object?. adata = Mouse10Xdata[NewIndex3,:].copy(). I ask in case the categories reported in the selection that you are doing create a mismatch, which may be solved by doing a copy. . > On 15 May 2019, at 11:24, brianpenghe <notifications@github.com> wrote:; > ; > There was a similar report not so long ago but I have not been able to reproduce the issue. Seems to be related with the matplotlib version used. Maybe you can try to update to the latest version.; > …; > On 10 May 2019, at 01:38, brianpenghe @.***> wrote: I ran this: ax=sc.pl.heatmap(Mouse10Xdata[NewIndex3,:], sorted_unique_marker_genes, groupby='ident', use_raw=False, vmin=-3, vmax=3, cmap='bwr',show=True,swap_axes=True,figsize=(10,7), var_group_rotation=0, dendrogram=True, save='ClusterMap.png') But the image has something weird. Here are the snapshot: The lines don't align well with the heatmap. Additionally, the lines don't align well with the group ID colors, either And the ID colors seem to be not aligned well with the heatmap either. Any thoughts? — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.; > ; > I have been using matplotlib 3.0.3 and I believe it's the latest version already. My Scanpy version was 1.4.1.; > Can it be an issue about duplicated gene names/make unique?; > ; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-492700214
https://github.com/scverse/scanpy/issues/637#issuecomment-495211738:4,Deployability,update,update,4,Any update?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-495211738
https://github.com/scverse/scanpy/issues/637#issuecomment-496025833:6,Deployability,update,update,6,> Any update?. I tried that but it's still giving me exactly the same tree : (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-496025833
https://github.com/scverse/scanpy/issues/637#issuecomment-517276810:7,Testability,test,tests,7,In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap. Do you think that the problem occurs when lot of cells/genes are plotted?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517276810
https://github.com/scverse/scanpy/issues/637#issuecomment-517332847:9,Testability,test,tests,9,> In the tests that I have the heatmap seems to be ok. See https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Visualize-marker-genes-using-heatmap; > ; > Do you think that the problem occurs when lot of cells/genes are plotted?. It's possible.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517332847
https://github.com/scverse/scanpy/issues/637#issuecomment-517510719:4,Testability,test,test,4,"The test is not good neither. If you look carefully at the heatmap generated with sc.pl.rank_genes_groups_heatmap(pbmc, n_genes=3, standard_scale='var'), you would find it is not aligned perfectly, especially for the local magnified heatmap. @fidelram @brianpenghe ; ![Figure_1](https://user-images.githubusercontent.com/29703450/62337090-c4a32180-b505-11e9-8757-73bc248d7754.png); ![1](https://user-images.githubusercontent.com/29703450/62337095-c66ce500-b505-11e9-8391-74b7b9948ab2.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-517510719
https://github.com/scverse/scanpy/issues/638#issuecomment-491638466:19,Usability,feedback,feedback,19,"Hi, thanks for the feedback! Another interesting option is [AUCell](https://github.com/aertslab/pySCENIC/blob/master/src/pyscenic/aucell.py) from the [SCENIC workflow](https://www.nature.com/articles/nmeth.4463) that does the comparison based on ranked gene expression - haven't tried it myself though. Best wishes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/638#issuecomment-491638466
https://github.com/scverse/scanpy/issues/639#issuecomment-491470751:112,Availability,error,error,112,"Hi,. Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; 3. Your data may have been pre-processed to take out mitochondrial genes. I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491470751
https://github.com/scverse/scanpy/issues/639#issuecomment-491473602:120,Availability,error,error,120,"> Hi,; > ; > Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; > ; > 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); > 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; > 3. Your data may have been pre-processed to take out mitochondrial genes.; > ; > I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`. It really helps! Thanks very much!(by the way I am using zebrafish data and it still should be lower case, but I was just not aware of this)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491473602
https://github.com/scverse/scanpy/pull/640#issuecomment-495542139:35,Testability,test,test,35,"@gokceneraslan Do you know why the test is failing? Did you change some of the defaults? I like the change, is really an improvement.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495542139
https://github.com/scverse/scanpy/pull/640#issuecomment-495574383:38,Testability,Test,Test,38,"I didn't change any defaults I think. Test fails in rename_category of pandas in pbmc, not sure it's related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/640#issuecomment-495574383
https://github.com/scverse/scanpy/issues/641#issuecomment-491765979:279,Availability,error,error,279,"Hi,. This bug report may be better placed in the single-cell-tutorial repo as you're having issues with how the tools are chained. A few things to check:; - Are you using sparse matrices in your data?; - are the size factors you get all real numbers (not `NaN`)?. I've seen this error before... just can't remember what the issue was. I think it was sparse matrices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491765979
https://github.com/scverse/scanpy/issues/641#issuecomment-491768644:19,Testability,test,test,19,"Hi,. I just made a test and it seems that it is indeed a problem of non-sparse matrix. How can I render the matrix sparse again from one that is dense? Is there something similar to the `adata.X.todense()` command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491768644
https://github.com/scverse/scanpy/issues/643#issuecomment-492050558:17,Deployability,install,install,17,"Hi, I just tried install a higher version of scipy, and it works now.; ```; pip install scipy==1.2.1; ```; Refer to: https://www.scipy.org",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-492050558
https://github.com/scverse/scanpy/issues/643#issuecomment-492050558:80,Deployability,install,install,80,"Hi, I just tried install a higher version of scipy, and it works now.; ```; pip install scipy==1.2.1; ```; Refer to: https://www.scipy.org",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-492050558
https://github.com/scverse/scanpy/issues/643#issuecomment-494058404:93,Deployability,install,installed,93,I also ran into this issue when using scanpy==1.4.2 and scipy==1.3.0 (which are the versions installed when I install using conda). Enforcing scipy==1.2.1 in my conda environment file fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-494058404
https://github.com/scverse/scanpy/issues/643#issuecomment-494058404:110,Deployability,install,install,110,I also ran into this issue when using scanpy==1.4.2 and scipy==1.3.0 (which are the versions installed when I install using conda). Enforcing scipy==1.2.1 in my conda environment file fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-494058404
https://github.com/scverse/scanpy/issues/643#issuecomment-691921390:266,Availability,error,error,266,"Hi. I'm struggling with the same issue that is not resolved with the suggestions above (using other scipy version==1.2.1). I have scanpy==1.6.0 and scipy==1.5.2 in my environment. I am using Ubuntu in Windows. And when I import scanpy in jupyter notebook, I get the error:. **`ImportError: cannot import name 'IndexMixin' from 'scipy.sparse.sputils' (/home/levinbioinformatics/anaconda3/envs/scgen-env/lib/python3.7/site-packages/scipy/sparse/sputils.py)`**. Please advise!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-691921390
https://github.com/scverse/scanpy/issues/643#issuecomment-720711607:17,Availability,Down,Downgrading,17,Same issue here. Downgrading scipy from 1.5.4 to 1.2.1 helps.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-720711607
https://github.com/scverse/scanpy/pull/644#issuecomment-492920628:66,Testability,test,tests,66,"> There’s a few items I’d like to see changed, and you should add tests. I have modified your suggestions , thanks. For tests you mean the 'test cases' or some 'example' data to run the program? . Thanks ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628
https://github.com/scverse/scanpy/pull/644#issuecomment-492920628:120,Testability,test,tests,120,"> There’s a few items I’d like to see changed, and you should add tests. I have modified your suggestions , thanks. For tests you mean the 'test cases' or some 'example' data to run the program? . Thanks ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628
https://github.com/scverse/scanpy/pull/644#issuecomment-492920628:140,Testability,test,test,140,"> There’s a few items I’d like to see changed, and you should add tests. I have modified your suggestions , thanks. For tests you mean the 'test cases' or some 'example' data to run the program? . Thanks ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-492920628
https://github.com/scverse/scanpy/pull/644#issuecomment-493022431:17,Testability,test,tests,17,Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”. See here: https://github.com/theislab/scanpy/tree/master/scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493022431
https://github.com/scverse/scanpy/pull/644#issuecomment-493022431:63,Testability,assert,assert,63,Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”. See here: https://github.com/theislab/scanpy/tree/master/scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493022431
https://github.com/scverse/scanpy/pull/644#issuecomment-493022431:159,Testability,test,tests,159,Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”. See here: https://github.com/theislab/scanpy/tree/master/scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493022431
https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:230,Deployability,update,updated,230,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243
https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:19,Testability,test,tests,19,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243
https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:65,Testability,assert,assert,65,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243
https://github.com/scverse/scanpy/pull/644#issuecomment-493362243:115,Usability,guid,guidance,115,"> Thank you! With “tests” I mean “functions named `test_*` with `assert ...` statements inside”; ; Thanks for your guidance, I have added `test_weightedSampling.py` with a folder named `weighted_sampled` in _data folder. . I have updated scanpy for weighted sampling for later tasks (clustering, finding marking genes and plotting). I also suggest to support it for initial tasks like PCA for data where each observation has weight (as in MATLAB). . Regards, ; Khalid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493362243
https://github.com/scverse/scanpy/pull/644#issuecomment-493836759:50,Testability,test,testing,50,"I have removed issue from the pull request by the testing tool, now the tools showed me duplications, which are mostly from other code and 1-2 from my code. Please have a look into it. It's my first pull request and its taking too much time :(. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493836759
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:550,Testability,test,tests,550,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:585,Testability,assert,assertions,585,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:643,Testability,assert,assert,643,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:743,Testability,test,tests,743,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:785,Testability,test,test,785,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:885,Testability,test,tests,885,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1003,Testability,test,tests,1003,"Hi, looks great!. Ignore the tool, I think it’s a bit broken. I need to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1046,Testability,test,test,1046,"d to figure out what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your con",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1284,Testability,test,tests,1284,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1317,Testability,test,tests,1317,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1374,Testability,test,test,1374,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1393,Testability,test,tests,1393,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1425,Testability,test,test,1425,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1501,Testability,test,tests,1501,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1524,Testability,test,test,1524,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1671,Testability,test,test,1671,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1750,Testability,test,test,1750,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-493907412:1958,Usability,learn,learning,1958,"what’s wrong with it. The only duplicated code left is that `_prepare_weighted_dataframe` is very similar to `_prepare_dataframe`. I think you can delete `_prepare_weighted_dataframe` and just change `_prepare_dataframe` so it does `return categories, obs_tidy, categorical`. Then you can change each line like `categories, obs_tidy = _prepare_dataframe(…)` to `categories, obs_tidy, _ = _prepare_dataframe(…)`. Other than that, there’s only few things left:. 1. The tests without plots should contain assertions. I.e. in `test_genes_ranking()` you should do `assert np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...])` or so!; 2. For the plot tests, you need to add these lines to the test file:. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L4. https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L8-L13. And do each test like this (replace “xyz” with whatever you want):. ```py; def test_xyz(image_comparer):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); […]; sc.pl.xyz(adata, …); save_and_compare_images('xyz'); ```. This will make the tests save your plots to `scanpy/tests/figures` and compare them to the images in `scanpy/test/_images`. The tests will fail because `scanpy/test/_images/xyz.png` doesn’t exist. You need to copy the pngs from `scanpy/tests/figures`→`scanpy/test/_images` and `git commit` them.; 3. This needs to be fixed: https://github.com/theislab/scanpy/pull/644#discussion_r284652144; 4. I think the test data might be too large. @falexwolf do we have a recommended size for new test data?. @Khalid-Usman I’m sorry if you find that this takes long and is frustrating. If this is the case, just step away for a while and do something else! But I think you won’t regret doing this. You’re learning good coding practices here that will come in handy in the future, I promise!. Thank you for your contribution :tada:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-493907412
https://github.com/scverse/scanpy/pull/644#issuecomment-494098188:128,Performance,perform,perform,128,"E.g. if your original input matrix has 1,000,000 number of cells and 100; genes. You don't want to process all rows, so you can perform either; uniform sampling or weighted sampling on the data. I have performed; weighted sampling and sampled e.g. only 1,000 rows then each rows will have; a weight. On Tue, May 21, 2019 at 2:19 AM MalteDLuecken <notifications@github.com>; wrote:. > I don't quite understand what sampled data with weights on the rows are.; > How do you weight individual cells in a dataset? What do weights like this; > mean?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODJ5CPJTB4HKVOI4M3PWLTUXA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZVDRQ#issuecomment-494096838>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOAGG3AY6DAVVZREM3TPWLTUXANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098188
https://github.com/scverse/scanpy/pull/644#issuecomment-494098188:202,Performance,perform,performed,202,"E.g. if your original input matrix has 1,000,000 number of cells and 100; genes. You don't want to process all rows, so you can perform either; uniform sampling or weighted sampling on the data. I have performed; weighted sampling and sampled e.g. only 1,000 rows then each rows will have; a weight. On Tue, May 21, 2019 at 2:19 AM MalteDLuecken <notifications@github.com>; wrote:. > I don't quite understand what sampled data with weights on the rows are.; > How do you weight individual cells in a dataset? What do weights like this; > mean?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODJ5CPJTB4HKVOI4M3PWLTUXA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZVDRQ#issuecomment-494096838>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOAGG3AY6DAVVZREM3TPWLTUXANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098188
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:20,Deployability,update,updated,20,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:712,Testability,test,tests,712,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:747,Testability,assert,assertions,747,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:805,Testability,assert,assert,805,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:918,Testability,test,tests,918,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:960,Testability,test,test,960,"Hi Philipp,. I have updated accordingly, again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1068,Testability,test,tests,1068,"again no issue but the duplication and i; analysed most of them are from previous code. Regards,; Khalid. On Mon, May 20, 2019 at 5:23 PM Philipp A. <notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1116,Testability,test,test,1116,"<notifications@github.com> wrote:. > Hi, looks great!; >; > The only duplicated code left is that _prepare_weighted_dataframe is very; > similar to _prepare_dataframe. I think you can delete; > _prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding pra",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1372,Testability,test,tests,1372,"prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email direc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1404,Testability,test,tests,1404,"prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email direc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1462,Testability,test,test,1462,"prepare_weighted_dataframe and just change _prepare_dataframe so it does return; > categories, obs_tidy, categorical. Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email direc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1480,Testability,test,tests,1480,"Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOD",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1514,Testability,test,test,1514,"Then you can change each line like categories,; > obs_tidy = _prepare_dataframe(…) to categories, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOD",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1591,Testability,test,tests,1591,"s, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZG",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1612,Testability,test,test,1612,"s, obs_tidy, _ =; > _prepare_dataframe(…); >; > Other than that, there’s only few things left:; >; > 1.; >; > The tests without plots should contain assertions. I.e. in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZG",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1795,Testability,test,test,1795,". in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYG3VA#issuecomment-493907412>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOG73UUYPXGY7UICKODPWJUZNANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:1911,Testability,test,test,1911,". in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYG3VA#issuecomment-493907412>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOG73UUYPXGY7UICKODPWJUZNANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494098578:2167,Usability,learn,learning,2167,". in; > test_genes_ranking() you should do assert; > np.all(adata.uns['wilcoxon']['names'][:5] == ['Gene1, 'Gene2, ...]) or; > so!; > 2.; >; > For the plot tests, you need to add these lines to the test file:; >; >; > https://github.com/theislab/scanpy/blob/d979267f48607fd609954c96cd5c586b6135dc30/scanpy/tests/test_plotting.py#L3-L13; >; > And do each test like this (replace “xyz” with whatever you want):; >; > def test_xyz(image_comparer):; >; > save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); >; > […]; >; > sc.pl.xyz(adata, …); >; > save_and_compare_images('xyz'); >; > This will make the tests save your plots to scanpy/tests/figures and; > compare them to the images in scanpy/test/_images. The tests will fail; > because scanpy/test/_images/xyz.png doesn’t exist. You need to copy; > the pngs from scanpy/tests/figures→scanpy/test/_images and git commit; > them.; > 3.; >; > This needs to be fixed: #644 (comment); > <https://github.com/theislab/scanpy/pull/644#discussion_r284652144>; > 4.; >; > I think the test data might be too large. @falexwolf; > <https://github.com/falexwolf> do we have a recommended size for new; > test data?; >; > @Khalid-Usman <https://github.com/Khalid-Usman> I’m sorry if you find; > that this takes long and is frustrating. If this is the case, just step; > away for a while and do something else! But I think you won’t regret doing; > this. You’re learning good coding practices here that will come in handy in; > the future, I promise!; >; > Thank you for your contribution 🎉; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODHLQPIDWZGLGTKXGLPWJUZNA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVYG3VA#issuecomment-493907412>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOG73UUYPXGY7UICKODPWJUZNANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494098578
https://github.com/scverse/scanpy/pull/644#issuecomment-494111085:21,Availability,down,downweight,21,"So you want to e.g., downweight the likelihood of sampling cells with a particular feature (like a common cell type), and upweight others. What do you want to use this weighting for now in the `sc.tl.rank_genes_groups` function? Or in the visualization functions you changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494111085
https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:878,Availability,down,downweight,878,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134
https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:219,Deployability,update,updated,219,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134
https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:647,Deployability,update,update,647,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134
https://github.com/scverse/scanpy/pull/644#issuecomment-494122404:584,Availability,error,error,584,I'm not sure I entirely understand what the weights are based on. I'm trying to understand when you would suggest someone use your approach. Why do you give one cell a weight of 125? With this type of weight distribution you are basically manually changing the marker gene calculation focusing nearly only on a single cell. That seems strange to me. I'm trying to understand the need for scanpy to support weighted observations. At the moment I don't see when you would want to differently weight the observations... I'm familiar with using weights if I have some form of measurement error or uncertainty between samples. I don't really see how that holds here. Do you weight the cells based on some kind of quality score?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494122404
https://github.com/scverse/scanpy/pull/644#issuecomment-494124913:866,Availability,error,error,866,"I am using a sampling technique, which samples few rows without descreasing; performance. So speed is more than 10X time faster for larger dataset with; similar accuracy. On Tue, May 21, 2019 at 3:37 AM MalteDLuecken <notifications@github.com>; wrote:. > I'm not sure I entirely understand what the weights are based on. I'm; > trying to understand when you would suggest someone use your approach. Why; > do you give one cell a weight of 125? With this type of weight distribution; > you are basically manually changing the marker gene calculation focusing; > nearly only on a single cell. That seems strange to me.; >; > I'm trying to understand the need for scanpy to support weighted; > observations. At the moment I don't see when you would want to differently; > weight the observations... I'm familiar with using weights if I have some; > form of measurement error or uncertainty between samples. I don't really; > see how that holds here. Do you weight the cells based on some kind of; > quality score?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4EI2YTU53XEGMJI3PWL4XZA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZ3LJA#issuecomment-494122404>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOFRJXHAWVT6W4YKY63PWL4XZANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913
https://github.com/scverse/scanpy/pull/644#issuecomment-494124913:77,Performance,perform,performance,77,"I am using a sampling technique, which samples few rows without descreasing; performance. So speed is more than 10X time faster for larger dataset with; similar accuracy. On Tue, May 21, 2019 at 3:37 AM MalteDLuecken <notifications@github.com>; wrote:. > I'm not sure I entirely understand what the weights are based on. I'm; > trying to understand when you would suggest someone use your approach. Why; > do you give one cell a weight of 125? With this type of weight distribution; > you are basically manually changing the marker gene calculation focusing; > nearly only on a single cell. That seems strange to me.; >; > I'm trying to understand the need for scanpy to support weighted; > observations. At the moment I don't see when you would want to differently; > weight the observations... I'm familiar with using weights if I have some; > form of measurement error or uncertainty between samples. I don't really; > see how that holds here. Do you weight the cells based on some kind of; > quality score?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4EI2YTU53XEGMJI3PWL4XZA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZ3LJA#issuecomment-494122404>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOFRJXHAWVT6W4YKY63PWL4XZANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913
https://github.com/scverse/scanpy/pull/644#issuecomment-494314699:150,Performance,perform,perform,150,"I understand the benefits of sampling regarding computational speed up. What I'm not clear on is how you choose your weights for the calculations you perform here. You mentioned that you get wrong marker gene results when you sample and don't use weights. That makes sense if you get a non-representative set of cells in your sample. I wonder how you select the weights to fix this. I guess you don't just try a lot of different values until one works, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494314699
https://github.com/scverse/scanpy/pull/644#issuecomment-494314699:85,Usability,clear,clear,85,"I understand the benefits of sampling regarding computational speed up. What I'm not clear on is how you choose your weights for the calculations you perform here. You mentioned that you get wrong marker gene results when you sample and don't use weights. That makes sense if you get a non-representative set of cells in your sample. I wonder how you select the weights to fix this. I guess you don't just try a lot of different values until one works, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494314699
https://github.com/scverse/scanpy/pull/644#issuecomment-494327494:322,Performance,perform,perform,322,"Yes , the sampling is done with weights and I used the coreset technique; for it. On Tue, May 21, 2019 at 5:29 PM MalteDLuecken <notifications@github.com>; wrote:. > I understand the benefits of sampling regarding computational speed up.; > What I'm not clear on is how you choose your weights for the calculations; > you perform here. You mentioned that you get wrong marker gene results when; > you sample and don't use weights. That makes sense if you get a; > non-representative set of cells in your sample. I wonder how you select the; > weights to fix this. I guess you don't just try a lot of different values; > until one works, right?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODYC4N7U5Y3T5XAEG3PWO6HTA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV3KJSY#issuecomment-494314699>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGODAWNXYF2AZPHG25P3PWO6HTANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494327494
https://github.com/scverse/scanpy/pull/644#issuecomment-494327494:254,Usability,clear,clear,254,"Yes , the sampling is done with weights and I used the coreset technique; for it. On Tue, May 21, 2019 at 5:29 PM MalteDLuecken <notifications@github.com>; wrote:. > I understand the benefits of sampling regarding computational speed up.; > What I'm not clear on is how you choose your weights for the calculations; > you perform here. You mentioned that you get wrong marker gene results when; > you sample and don't use weights. That makes sense if you get a; > non-representative set of cells in your sample. I wonder how you select the; > weights to fix this. I guess you don't just try a lot of different values; > until one works, right?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGODYC4N7U5Y3T5XAEG3PWO6HTA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV3KJSY#issuecomment-494314699>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGODAWNXYF2AZPHG25P3PWO6HTANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494327494
https://github.com/scverse/scanpy/pull/644#issuecomment-494336456:149,Performance,perform,perform,149,"Ah, okay... so you sample based on how representative a cell is of its neighbours, and then you use that weight to calculated PCA, marker genes, and perform visualizations. Is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494336456
https://github.com/scverse/scanpy/pull/644#issuecomment-494348675:366,Testability,test,tests,366,"> This is how I understood it anyway. You circumvent the problems caused by random sampling by doing a biased sampling, and the weights correspond to the size of the represented community. If the weights are just cluster-size-related, then this would not be necessary as you are calculating cluster-specific values to compare them in e.g., dot plots and statistical tests. This is a weighting that affects the relative importance of cells in the same cluster.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494348675
https://github.com/scverse/scanpy/pull/644#issuecomment-494718710:272,Usability,simpl,simply,272,"Long-term, we should think about the design here: Passing weights in every function call is possible, but not very nice for users. So a few questions come to mind:. Should we add `scanpy.pp.coreset`, which would create a sampling and add `adata.obs['coreset_weights']` or simply `adata.obs['weights']`?. If we do that or plan to in the future, how should the added `weights` parameter to all these functions work?. I think it might default to `'coreset_weights'`/`'weights'`, and the functions would automatically use that `.obs` column if it exists. Users should also still be able to specify weights manually as in this PR. So the type of the parameter would be `Union[str, Sequence[Union[float, int]]]`. ---. All of that doesn’t really affect this PR, as we can merge it as it is and include anndata-stored weights later.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494718710
https://github.com/scverse/scanpy/pull/644#issuecomment-494724138:763,Usability,simpl,simply,763,"Thanks ,. But i will suggest to just support weights instead of coreset, may be user; want to sample data with some other weighting technique. So we should ask; them to just put the weights for observations, then we need to modify PCA; as well and i think my code will support most of plots and marker genes,; but not PCA, because my input is PCA matrix with weights for each; observations. Thanks,; Khalid. On Wed, May 22, 2019 at 5:04 PM Philipp A. <notifications@github.com> wrote:. > Long-term, we should think about the design here: Specifying weights all; > the time is possible, but not very nice for users. So a few questions come; > to mind:; >; > Should we add scanpy.pp.coreset, which would create a sampling and add; > adata.obs['coreset_weights'] or simply adata.obs['weights']?; >; > If we do that or plan to in the future, how should the added weights; > parameter to all these functions work?; >; > I think it might default to 'coreset_weights', and the functions would; > automatically use that .obs column if it exists. Users should also still; > be able to specify weights manually as in this PR.; >; > So the type of the parameter would be Union[str, pd.DataFrame,; > Sequence[Union[float, int]]].; > ------------------------------; >; > All of that doesn’t really affect this PR, as we can merge it as it is and; > include anndata-stored weights later.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4K5CCAJSUVYSIAFDPWUEC5A5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV6M55Q#issuecomment-494718710>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGODWOGS6RD2JQ4LW5LDPWUEC5ANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494724138
https://github.com/scverse/scanpy/pull/644#issuecomment-494846004:23,Deployability,update,updated,23,"Thanks Philipp, I have updated and push the code. I hope you will accept; this pull request now. To support PCA and scanpy for weighted sampling, you; can just set a parameter , observations/samples weights at the time user; input matrix and then we can modify PCA and remaining this code is fine. I; am asking for weights because user may extracted those weights either with; sampling technique or may be sometime user can give weights of his own; desired e.g. he want to focus one cell type etc. So we should support; weights generally rather specifically. Thanks,; Khalid. On Wed, May 22, 2019 at 5:21 PM khalid usman <khalid0491@gmail.com> wrote:. > Thanks ,; >; > But i will suggest to just support weights instead of coreset, may be user; > want to sample data with some other weighting technique. So we should ask; > them to just put the weights for observations, then we need to modify PCA; > as well and i think my code will support most of plots and marker genes,; > but not PCA, because my input is PCA matrix with weights for each; > observations.; >; > Thanks,; > Khalid; >; > On Wed, May 22, 2019 at 5:04 PM Philipp A. <notifications@github.com>; > wrote:; >; >> Long-term, we should think about the design here: Specifying weights all; >> the time is possible, but not very nice for users. So a few questions come; >> to mind:; >>; >> Should we add scanpy.pp.coreset, which would create a sampling and add; >> adata.obs['coreset_weights'] or simply adata.obs['weights']?; >>; >> If we do that or plan to in the future, how should the added weights; >> parameter to all these functions work?; >>; >> I think it might default to 'coreset_weights', and the functions would; >> automatically use that .obs column if it exists. Users should also still; >> be able to specify weights manually as in this PR.; >>; >> So the type of the parameter would be Union[str, pd.DataFrame,; >> Sequence[Union[float, int]]].; >> ------------------------------; >>; >> All of that doesn’t really affect th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494846004
https://github.com/scverse/scanpy/pull/644#issuecomment-494846004:1457,Usability,simpl,simply,1457,"esired e.g. he want to focus one cell type etc. So we should support; weights generally rather specifically. Thanks,; Khalid. On Wed, May 22, 2019 at 5:21 PM khalid usman <khalid0491@gmail.com> wrote:. > Thanks ,; >; > But i will suggest to just support weights instead of coreset, may be user; > want to sample data with some other weighting technique. So we should ask; > them to just put the weights for observations, then we need to modify PCA; > as well and i think my code will support most of plots and marker genes,; > but not PCA, because my input is PCA matrix with weights for each; > observations.; >; > Thanks,; > Khalid; >; > On Wed, May 22, 2019 at 5:04 PM Philipp A. <notifications@github.com>; > wrote:; >; >> Long-term, we should think about the design here: Specifying weights all; >> the time is possible, but not very nice for users. So a few questions come; >> to mind:; >>; >> Should we add scanpy.pp.coreset, which would create a sampling and add; >> adata.obs['coreset_weights'] or simply adata.obs['weights']?; >>; >> If we do that or plan to in the future, how should the added weights; >> parameter to all these functions work?; >>; >> I think it might default to 'coreset_weights', and the functions would; >> automatically use that .obs column if it exists. Users should also still; >> be able to specify weights manually as in this PR.; >>; >> So the type of the parameter would be Union[str, pd.DataFrame,; >> Sequence[Union[float, int]]].; >> ------------------------------; >>; >> All of that doesn’t really affect this PR, as we can merge it as it is; >> and include anndata-stored weights later.; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4K5CCAJSUVYSIAFDPWUEC5A5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV6M55Q#issuecomment-494718710>,; >> or mute the thread; >> ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494846004
https://github.com/scverse/scanpy/pull/644#issuecomment-494969183:394,Testability,log,log,394,"Yeah, mostly. There’s still a bit to do, some of which I did (see the commits). The things left are that. 1. all functions should only accept sequences (lists, ndarray, …) as `weights`, not dataframes.; 2. there are multiple blocks that all look like this and can be replaced by a helper function:. ```py; categories, obs_tidy, catego = _prepare_dataframe(; adata, var_names, groupby, use_raw, log, num_categories, layer=layer,; ); if weights is not None:; mean_obs = _compute_gw_Avg_of_dataframe(obs_tidy, weights, catego, groupby); mean_obs = mean_obs.drop('Wt', axis=1); else:; mean_obs = obs_tidy.groupby(level=0).mean(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494969183
https://github.com/scverse/scanpy/issues/645#issuecomment-492292184:34,Deployability,update,updated,34,"Hi,. I think it would help if you updated anndata to 0.6.19. there was a change in 0.6.18 that wrote unordered categoricals, where before categoricals were changed to ordered by default. Hope that helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/645#issuecomment-492292184
https://github.com/scverse/scanpy/issues/646#issuecomment-492693756:65,Integrability,wrap,wrapper,65,Cool... I haven't used the new plots yet. Looks very handy. Your wrapper is an automated use of `var_group_X` to label marker genes of particular clusters in these plots?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-492693756
https://github.com/scverse/scanpy/issues/646#issuecomment-493156408:581,Availability,avail,available,581,"I know this is a bit specific, but the current sc.pl.rank_genes_groups() and sc.pl.rank_genes_groups_violin() have a 'gene_symbols' argument to allow display based on other columns in .var. For example, if I have this in Var:. ```; Var columns:; gene_symbol; index ; ENSMUSG00000000001 Gnai3; ENSMUSG00000000028 Cdc45; ENSMUSG00000000031 H19; ENSMUSG00000000037 Scml2; ENSMUSG00000000049 Apoh; ```. I can just pass 'gene_symbol' as the column I want to be used for any/all displays instead of the ensembl ID all the time. It would be great if something like this were consistently available anywhere gene labels were needed in the plotting functions. Perhaps the common argument would be better called 'display_label' or something like that instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-493156408
https://github.com/scverse/scanpy/issues/646#issuecomment-493234847:37,Deployability,update,updated,37,"Quite possibly, I need to look. Just updated from 1.3.x to 1.4.3 this week.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-493234847
https://github.com/scverse/scanpy/issues/646#issuecomment-493780398:67,Integrability,wrap,wrapper,67,"> Cool... I haven't used the new plots yet. Looks very handy. Your wrapper is an automated use of `var_group_X` to label marker genes of particular clusters in these plots?. Just to clarify what I meant, current API:. ```python; sc.pl.stacked_violin(pbmc, marker_genes, groupby='bulk_labels', ; var_group_positions=[(7, 8)], var_group_labels=['NK']); ```. My suggestion:. ```python; markers = {'NK': ['GNLY', 'NKG7']}; sc.pl.stacked_violin(pbmc, marker_genes, groupby='bulk_labels', var_groups=markers); ```. It's ok to keep var_group_* parameters I think, for backward compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-493780398
https://github.com/scverse/scanpy/issues/647#issuecomment-492876929:38,Usability,learn,learning,38,"Hello All,; I am a totally new one in learning single cell RNA_seq. When I was doing quality control, I met this problem. Can anyone help me? Thank you so much",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-492876929
https://github.com/scverse/scanpy/issues/647#issuecomment-492964767:129,Availability,error,error,129,"Hi,. Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-492964767
https://github.com/scverse/scanpy/issues/647#issuecomment-493067273:137,Availability,error,error,137,"> Hi,; > ; > Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess. Thank you for your reply. I think the 'mito_genes' vector was all boolean. Maybe it has a zero-sum. So, how can I resolve this problem, Do you have any suggestions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-493067273
https://github.com/scverse/scanpy/pull/648#issuecomment-815457252:61,Availability,error,errors,61,"I don't like codacy, it's really flaky with its checks (e.g. errors appear and disappear at random). That's why we disabled it in the first place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/648#issuecomment-815457252
https://github.com/scverse/scanpy/issues/650#issuecomment-496960546:180,Energy Efficiency,reduce,reduce,180,"Any suggestions around this? Without reading in backed mode just loading the dataset of around 200,000 cells by 30,000 genes is using over 40GB of RAM. The filtering steps help us reduce this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-496960546
https://github.com/scverse/scanpy/issues/650#issuecomment-496960546:65,Performance,load,loading,65,"Any suggestions around this? Without reading in backed mode just loading the dataset of around 200,000 cells by 30,000 genes is using over 40GB of RAM. The filtering steps help us reduce this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-496960546
https://github.com/scverse/scanpy/issues/650#issuecomment-499511619:87,Deployability,pipeline,pipeline,87,"OK, that's helpful, thanks. I really just want to get through the [standard clustering pipeline](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), but in backed mode since we have some datasets which are too expensive to load into RAM (40-50GB). We'll accept the speed trade-off of backed mode to allow for scalability here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-499511619
https://github.com/scverse/scanpy/issues/650#issuecomment-499511619:235,Performance,load,load,235,"OK, that's helpful, thanks. I really just want to get through the [standard clustering pipeline](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), but in backed mode since we have some datasets which are too expensive to load into RAM (40-50GB). We'll accept the speed trade-off of backed mode to allow for scalability here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-499511619
https://github.com/scverse/scanpy/issues/650#issuecomment-499511619:321,Performance,scalab,scalability,321,"OK, that's helpful, thanks. I really just want to get through the [standard clustering pipeline](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), but in backed mode since we have some datasets which are too expensive to load into RAM (40-50GB). We'll accept the speed trade-off of backed mode to allow for scalability here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-499511619
https://github.com/scverse/scanpy/issues/650#issuecomment-499770209:57,Performance,load,load,57,"Hmm. If I'm understanding correctly, are you not able to load the full dataset into memory on your machine? Can you give me an idea of what your memory restrictions are?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650#issuecomment-499770209
https://github.com/scverse/scanpy/pull/651#issuecomment-510218093:76,Testability,benchmark,benchmarks,76,@falexwolf ; some usage examples; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/use_Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-510218093
https://github.com/scverse/scanpy/pull/651#issuecomment-515261645:87,Testability,benchmark,benchmarks,87,@falexwolf @ivirshup ; New Ingest api usage; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-515261645
https://github.com/scverse/scanpy/pull/651#issuecomment-515764313:82,Integrability,depend,depending,82,"@LuckyMD `ingest.to_adata` just returns a copy of `adata_new` (or the same object depending on inplace) with all mapped representations (pca, umap) and labels.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-515764313
https://github.com/scverse/scanpy/pull/651#issuecomment-517078460:0,Deployability,Update,Updated,0,Updated the notebook above with `to_adata_joint` example - this function returns the concatenation of `adata_ref` and `adata_new` with projected representations and mapped labels.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-517078460
https://github.com/scverse/scanpy/pull/651#issuecomment-517224731:0,Testability,Test,Test,0,Test are failing because of the new version of dask.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-517224731
https://github.com/scverse/scanpy/pull/651#issuecomment-519155566:104,Testability,benchmark,benchmarks,104,I think it is more or less complete.; Here are the tutorials; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-realistic.ipynb; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-simple.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566
https://github.com/scverse/scanpy/pull/651#issuecomment-519155566:193,Testability,benchmark,benchmarks,193,I think it is more or less complete.; Here are the tutorials; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-realistic.ipynb; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-simple.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566
https://github.com/scverse/scanpy/pull/651#issuecomment-519155566:223,Usability,simpl,simple,223,I think it is more or less complete.; Here are the tutorials; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-realistic.ipynb; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/Ingest-simple.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519155566
https://github.com/scverse/scanpy/pull/651#issuecomment-519508063:2411,Deployability,release,release,2411,"columns = unique_names; return new_annot. def process(dset):; dset.layers[""counts""] = dset.X.copy(); sc.pp.normalize_total(dset); sc.pp.log1p(dset); sc.pp.highly_variable_genes(dset); sc.pp.pca(dset); sc.pp.neighbors(dset, n_neighbors=30); sc.tl.umap(dset). dset1 = sc.datasets.ebi_expression_atlas(""E-GEOD-81608"", filter_boring=True) ; dset2 = sc.datasets.ebi_expression_atlas(""E-GEOD-83139"", filter_boring=True); # dset3 = sc.datasets.ebi_expression_atlas(""E-ENAD-27"", filter_boring=True). # dsets = [dset1, dset2, dset3]; dsets = [dset1, dset2]; for dset in dsets:; dset.obs = simplify_annot(dset.obs); sc.pp.calculate_qc_metrics(dset, inplace=True). shared_genes = reduce(np.intersect1d, [dset.var_names for dset in dsets]); dsets = [dset[:, shared_genes].copy() for dset in dsets]. for dset in dsets:; process(dset). # dset1, dset2, dset3 = dsets; dset1, dset2 = dsets. dset1.obs[""inferred cell type (dset1)""] = dset1.obs[""inferred cell type""]. dset12 = ingest(dset2, dset1, obs=""inferred cell type (dset1)"", return_joint=True); ```. Traceback:. ```python; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 33, in ingest; return ing.to_adata(inplace) if not return_joint else ing.to_adata_joint(); File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 222, in to_adata_joint; adata = AnnData(np.vstack((self._adata_ref.X, self._adata_new.X))); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 566, in __init__; filename=filename, filemode=filemode); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 735, in _init_as_actual; X = X.astype(dtype, copy=False); ValueError: setting an array element with a sequence.; ```. </details>. I've reproduced on 2bffd6a1400 and after merging master with that. This occurs whether inplace is true or not. It also occurs on anndata master as well as the current release. As you'd expect, it doesn't happen with `return_joint=False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519508063
https://github.com/scverse/scanpy/pull/651#issuecomment-519508063:272,Energy Efficiency,reduce,reduce,272,"Just starting to try this out, but I hit a bug. Here's a script to reproduce and the traceback:. <details>; <summary>Script </summary>. ```python; import scanpy as sc; from scanpy.tools._ingest import ingest; import numpy as np; import pandas as pd; from functools import reduce. def simplify_annot(annot):; names = annot.columns.str.extract(r""\[(.*)\].*$"", expand=False); unique_names, idxs = np.unique(names, return_index=True); new_annot = annot.iloc[:, idxs].copy(); new_annot.columns = unique_names; return new_annot. def process(dset):; dset.layers[""counts""] = dset.X.copy(); sc.pp.normalize_total(dset); sc.pp.log1p(dset); sc.pp.highly_variable_genes(dset); sc.pp.pca(dset); sc.pp.neighbors(dset, n_neighbors=30); sc.tl.umap(dset). dset1 = sc.datasets.ebi_expression_atlas(""E-GEOD-81608"", filter_boring=True) ; dset2 = sc.datasets.ebi_expression_atlas(""E-GEOD-83139"", filter_boring=True); # dset3 = sc.datasets.ebi_expression_atlas(""E-ENAD-27"", filter_boring=True). # dsets = [dset1, dset2, dset3]; dsets = [dset1, dset2]; for dset in dsets:; dset.obs = simplify_annot(dset.obs); sc.pp.calculate_qc_metrics(dset, inplace=True). shared_genes = reduce(np.intersect1d, [dset.var_names for dset in dsets]); dsets = [dset[:, shared_genes].copy() for dset in dsets]. for dset in dsets:; process(dset). # dset1, dset2, dset3 = dsets; dset1, dset2 = dsets. dset1.obs[""inferred cell type (dset1)""] = dset1.obs[""inferred cell type""]. dset12 = ingest(dset2, dset1, obs=""inferred cell type (dset1)"", return_joint=True); ```. Traceback:. ```python; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 33, in ingest; return ing.to_adata(inplace) if not return_joint else ing.to_adata_joint(); File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 222, in to_adata_joint; adata = AnnData(np.vstack((self._adata_ref.X, self._adata_new.X))); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 566, in _",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519508063
https://github.com/scverse/scanpy/pull/651#issuecomment-519508063:1150,Energy Efficiency,reduce,reduce,1150,"import scanpy as sc; from scanpy.tools._ingest import ingest; import numpy as np; import pandas as pd; from functools import reduce. def simplify_annot(annot):; names = annot.columns.str.extract(r""\[(.*)\].*$"", expand=False); unique_names, idxs = np.unique(names, return_index=True); new_annot = annot.iloc[:, idxs].copy(); new_annot.columns = unique_names; return new_annot. def process(dset):; dset.layers[""counts""] = dset.X.copy(); sc.pp.normalize_total(dset); sc.pp.log1p(dset); sc.pp.highly_variable_genes(dset); sc.pp.pca(dset); sc.pp.neighbors(dset, n_neighbors=30); sc.tl.umap(dset). dset1 = sc.datasets.ebi_expression_atlas(""E-GEOD-81608"", filter_boring=True) ; dset2 = sc.datasets.ebi_expression_atlas(""E-GEOD-83139"", filter_boring=True); # dset3 = sc.datasets.ebi_expression_atlas(""E-ENAD-27"", filter_boring=True). # dsets = [dset1, dset2, dset3]; dsets = [dset1, dset2]; for dset in dsets:; dset.obs = simplify_annot(dset.obs); sc.pp.calculate_qc_metrics(dset, inplace=True). shared_genes = reduce(np.intersect1d, [dset.var_names for dset in dsets]); dsets = [dset[:, shared_genes].copy() for dset in dsets]. for dset in dsets:; process(dset). # dset1, dset2, dset3 = dsets; dset1, dset2 = dsets. dset1.obs[""inferred cell type (dset1)""] = dset1.obs[""inferred cell type""]. dset12 = ingest(dset2, dset1, obs=""inferred cell type (dset1)"", return_joint=True); ```. Traceback:. ```python; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 33, in ingest; return ing.to_adata(inplace) if not return_joint else ing.to_adata_joint(); File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 222, in to_adata_joint; adata = AnnData(np.vstack((self._adata_ref.X, self._adata_new.X))); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 566, in __init__; filename=filename, filemode=filemode); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 735, in _init_as_actual; X = X.as",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519508063
https://github.com/scverse/scanpy/pull/651#issuecomment-519508063:548,Modifiability,layers,layers,548,"Just starting to try this out, but I hit a bug. Here's a script to reproduce and the traceback:. <details>; <summary>Script </summary>. ```python; import scanpy as sc; from scanpy.tools._ingest import ingest; import numpy as np; import pandas as pd; from functools import reduce. def simplify_annot(annot):; names = annot.columns.str.extract(r""\[(.*)\].*$"", expand=False); unique_names, idxs = np.unique(names, return_index=True); new_annot = annot.iloc[:, idxs].copy(); new_annot.columns = unique_names; return new_annot. def process(dset):; dset.layers[""counts""] = dset.X.copy(); sc.pp.normalize_total(dset); sc.pp.log1p(dset); sc.pp.highly_variable_genes(dset); sc.pp.pca(dset); sc.pp.neighbors(dset, n_neighbors=30); sc.tl.umap(dset). dset1 = sc.datasets.ebi_expression_atlas(""E-GEOD-81608"", filter_boring=True) ; dset2 = sc.datasets.ebi_expression_atlas(""E-GEOD-83139"", filter_boring=True); # dset3 = sc.datasets.ebi_expression_atlas(""E-ENAD-27"", filter_boring=True). # dsets = [dset1, dset2, dset3]; dsets = [dset1, dset2]; for dset in dsets:; dset.obs = simplify_annot(dset.obs); sc.pp.calculate_qc_metrics(dset, inplace=True). shared_genes = reduce(np.intersect1d, [dset.var_names for dset in dsets]); dsets = [dset[:, shared_genes].copy() for dset in dsets]. for dset in dsets:; process(dset). # dset1, dset2, dset3 = dsets; dset1, dset2 = dsets. dset1.obs[""inferred cell type (dset1)""] = dset1.obs[""inferred cell type""]. dset12 = ingest(dset2, dset1, obs=""inferred cell type (dset1)"", return_joint=True); ```. Traceback:. ```python; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 33, in ingest; return ing.to_adata(inplace) if not return_joint else ing.to_adata_joint(); File ""/Users/isaac/github/scanpy/scanpy/tools/_ingest.py"", line 222, in to_adata_joint; adata = AnnData(np.vstack((self._adata_ref.X, self._adata_new.X))); File ""/Users/isaac/github/anndata/anndata/core/anndata.py"", line 566, in _",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519508063
https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:167,Deployability,integrat,integration,167,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857
https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:167,Integrability,integrat,integration,167,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857
https://github.com/scverse/scanpy/pull/651#issuecomment-519798857:107,Testability,test,tests,107,"Great! I'll check it out when I have a chance. If this is close to ready, could it also start getting some tests?. Just to clarify, would a notebook with the pancreas integration stuff be useful to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-519798857
https://github.com/scverse/scanpy/pull/651#issuecomment-520006052:29,Testability,test,tests,29,"Hi, yes, i will start adding tests. ; And i think it can be useful but only if you have time for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-520006052
https://github.com/scverse/scanpy/pull/651#issuecomment-524670031:23,Testability,Test,Tests,23,@falexwolf @ivirshup ; Tests are also ready.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-524670031
https://github.com/scverse/scanpy/pull/651#issuecomment-527675546:75,Testability,benchmark,benchmarks,75,Some things on pancreas dataset; https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/ingest_pancreas.ipynb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-527675546
https://github.com/scverse/scanpy/pull/651#issuecomment-557132848:172,Deployability,release,release,172,"Guys, I'll merge this for now so that I can conveniently play around with it in practical settings and potentially improve. We don't need to advertise for now and the next release might be a bit ahead anyway. I'm reading the latest comments as you being essentially positive. ☺️",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/651#issuecomment-557132848
https://github.com/scverse/scanpy/issues/653#issuecomment-494316752:254,Testability,test,testing,254,"Hey!. Just something that crossed my mind... could it be that after subsetting, you have 0 variance in some genes? You may have to rerun `sc.pp.filter_genes()` to take out genes that are 0 everywhere after subsetting. This would give you an `NaN` in the testing. Maybe check that the genes you filter out are the ones that gave you the issues in the initial run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494316752
https://github.com/scverse/scanpy/issues/653#issuecomment-494330011:285,Availability,error,error,285,"So my idea was the following:; If you have a full dataset and some genes are 0 everywhere, except in the cells in cluster A, then you filter out cluster A in your new dataset, and recompute everything... those genes now have 0 variance in your filtered dataset. That would give you an error that didn't appear before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494330011
https://github.com/scverse/scanpy/issues/653#issuecomment-494332488:218,Integrability,message,message,218,"@LuckyMD Dear Malter, Thanks, now I got your point. I just filtered my cells and genes again using ; `sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3)`; but I still get the same warning message",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494332488
https://github.com/scverse/scanpy/issues/653#issuecomment-494342325:206,Integrability,message,message,206,"@LuckyMD The thing is after imputation for sure I do get some negative values and I have observed it but such warning was not popping up before and NaN I am doubtful because otherwise I could see a warning message when I ran the imputation for all of my genes. . p.s. This is how I made my subset. > adata_magic_sub=adata_magic[(adata_magic.obs.louvain_04==""3"")|(adata_magic.obs.louvain_04==""7"")|(adata_magic.obs.louvain_04==""8"")|(adata_magic.obs.louvain_04==""11"")]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494342325
https://github.com/scverse/scanpy/issues/653#issuecomment-494347969:807,Testability,test,testing,807,"I think you are using a view of the anndata object, rather than the object with that method of subsetting. That shouldn't be related to the issue, but if you want to work with the subset, I would use `.copy()` at the end. Also, does this give you the number of cells and genes as intended? I typically put a `:` for the genes to get something like `adata[cell_filter,:].copy()`. Not sure if that's necessary though. So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. . It is likely that this only pops up now, as the average expression value for the e.g., ""not cluster 3"" data is now negative, where before it wasn't as there was different data to average over. If this is the issue, I'm not entirely sure what to do about this... fold changes aren't defined for such a case. I would either:; 1. rescale the data to be between two non-negative values.; 2. Set all negative values to 0. You could take the code in the `sc.tl.rank_genes_groups()` function and calculate the fold changes for your genes step by step to see if this is the problem. I assume that it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494347969
https://github.com/scverse/scanpy/issues/653#issuecomment-494351528:564,Availability,down,downstream,564,"@LuckyMD Dear Malte, Thanks a lot for your hint and reply.; Regarding to the subset, well I got actually the cells that I needed with same number of the genes that I had before so I assume it is fine.; I did a rescale of my data to 10 again but unfortunately the same warning is happening! ; I don't know really if turning all negative values to zero would really make sense because first of all as I mentioned I had negative values before and it was not a problem and if I turn all those negative values to zero I guess I will lose quite a bit of genes during my downstream analysis. What I can imagine is those problematic values are anyway not considered during the marker analysis so in the case they are NaN turning them to zero wouldn't affect my result. my fear was mainly that those genes may be really something and due to a bug or a miscommand I am not getting them but I think it is a rare probability. I guess I should leave it as it is. I will though try to take the sc.tl.rank_genes_groups function code and run it step by step",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494351528
https://github.com/scverse/scanpy/issues/653#issuecomment-494353628:397,Testability,log,logged,397,"So the reason you didn't get this before, would be that if you do a `sc.tl.rank_genes_groups()` call with default parameters, you compare the expression in one cluster with the expression in the rest of the dataset. The ""rest of the dataset"" has changed, so you could now get -ve average expression for genes in the ""rest of the dataset"". This will likely create -ve fold changes, which cannot be logged and probably give you `NaN`. This is hiding a signal that is actually there, and not because the gene is not actually differentially expressed. > I did a rescale of my data to 10 again but unfortunately the same warning is happening!; What do you mean by this?. Turning negative values to 0, doesn't mean you lose the data. You have some expression space, of which 0 is a valid number. The question is really what does a negative expression value mean after MAGIC? Is it just a confidence of the gene not being expressed? Then putting it to zero makes sense. Again... if you ignore this, you will just ignore particular genes which are likely differentially expression, because MAGIC has rescaled the expression values in the ""rest of the dataset"" to a negative value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494353628
https://github.com/scverse/scanpy/issues/653#issuecomment-494539920:56,Usability,simpl,simply,56,@LuckyMD Ok so I basically found the reason of it. it's simply the scaling! What I used to do is that after imputation and selecting HVG I was scaling my data and then getting the clusters and subsetting and running hvg agaian. But apparently the scaled data cause the warning but I am not sure why ! because it doesn't turn any of my expression to NaN when I checked my adata.X and negative values shouldn't be the source of the warning too because I already had negative values after imputation and didn't cause any warning. One thing I also should mention is that this warning happens too if I compute the HVG so its not really cluster specific or so,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494539920
https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:588,Availability,error,error,588,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028
https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:393,Testability,test,testing,393,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028
https://github.com/scverse/scanpy/issues/653#issuecomment-494571722:255,Availability,down,downstream,255,@LuckyMD yea after some further investigation I do agree with you! do you already know a method which can I use to scale my data to non-negative values? then I can scale my data only once and right after imputation and that should be fine for the rest of downstream analysis including the sub-clustering,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494571722
https://github.com/scverse/scanpy/issues/653#issuecomment-494730898:179,Usability,simpl,simply,179,"I guess negative values can mean different things across imputation methods. So having one standard way to scale is maybe not the best approach. That being said, I would probably simply do this:. ![CodeCogsEqn](https://user-images.githubusercontent.com/13019956/58164949-15390b80-7c87-11e9-9534-65ddf492ebd5.gif). Here, you would also put expression values to 0 if all expression values are +ve and non-zero. Otherwise, you should only do this for genes where the min() is -ve. The above scaling solution would keep the relative scale between the genes. If you however prefer to scale to values between 0 and 1 (which I usually don't do, but others advocate; this would ensure equal weighting between genes for PCA), you can also rescale by expression range like this:. ![CodeCogsEqn(1)](https://user-images.githubusercontent.com/13019956/58165629-6dbcd880-7c88-11e9-8c29-d3b2684b7bb7.gif). Overall though, I'm not a big fan of imputation... especially after this [paper](https://f1000research.com/articles/7-1740/v1)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494730898
https://github.com/scverse/scanpy/issues/653#issuecomment-494737289:511,Modifiability,variab,variability,511,Interesting paper... the question is which is worse false signals from experiment or from the imputation.; Anyway. Great. Just the last thing that came to my mind is that the whole thingy is happening because I am doing imputation on my already normalized and transformed data. Wouldn't it make more sense if i do imputation on raw data after filtering and then normalize and transform my data or transform the data but normalizing it afterward? With this I won't face this problem and also I keep the original variability within my data,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494737289
https://github.com/scverse/scanpy/issues/653#issuecomment-494742140:45,Modifiability,variab,variability,45,"After imputation you don't have your initial variability in your data. Ideally you have only the biologically relevant variability, but that's another question. Also, imputation methods take different data as input. Our DCA method takes count data, but MAGIC takes pre-processed data I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494742140
https://github.com/scverse/scanpy/issues/653#issuecomment-494742140:119,Modifiability,variab,variability,119,"After imputation you don't have your initial variability in your data. Ideally you have only the biologically relevant variability, but that's another question. Also, imputation methods take different data as input. Our DCA method takes count data, but MAGIC takes pre-processed data I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494742140
https://github.com/scverse/scanpy/issues/654#issuecomment-494386051:131,Integrability,depend,depending,131,"Just to add to this, PCA plots look fine with the newer `scikit-learn` I believe. Maybe it's the umap neighbourhood graph function depending on sklearn for something?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494386051
https://github.com/scverse/scanpy/issues/654#issuecomment-494386051:64,Usability,learn,learn,64,"Just to add to this, PCA plots look fine with the newer `scikit-learn` I believe. Maybe it's the umap neighbourhood graph function depending on sklearn for something?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494386051
https://github.com/scverse/scanpy/issues/654#issuecomment-494454599:241,Usability,learn,learn,241,Oh that's reaaaally bad. I did a quick git bisect on sklearn:. ![image](https://user-images.githubusercontent.com/1140359/58111323-40582800-7bbf-11e9-8905-e7f3a73cd057.png). Here is the commit that broke our umaps: https://github.com/scikit-learn/scikit-learn/pull/13554,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494454599
https://github.com/scverse/scanpy/issues/654#issuecomment-494454599:254,Usability,learn,learn,254,Oh that's reaaaally bad. I did a quick git bisect on sklearn:. ![image](https://user-images.githubusercontent.com/1140359/58111323-40582800-7bbf-11e9-8905-e7f3a73cd057.png). Here is the commit that broke our umaps: https://github.com/scikit-learn/scikit-learn/pull/13554,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494454599
https://github.com/scverse/scanpy/issues/654#issuecomment-494457995:33,Usability,learn,learn,33,"Should this be relayed to scikit-learn then? If so, that should probably be done by someone who knows where in the `sc.pp.neighbors()` function this is breaking...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494457995
https://github.com/scverse/scanpy/issues/654#issuecomment-494485672:352,Deployability,upgrade,upgraded,352,"OK, seems to be fixed in sklearn master branch (probably https://github.com/scikit-learn/scikit-learn/pull/13910), but this is such a huge bug and it has been going on since May 9th :( We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no? Some colleagues mentioned weird UMAP results with scanpy actually, it turns out they upgraded their sklearn...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494485672
https://github.com/scverse/scanpy/issues/654#issuecomment-494485672:83,Usability,learn,learn,83,"OK, seems to be fixed in sklearn master branch (probably https://github.com/scikit-learn/scikit-learn/pull/13910), but this is such a huge bug and it has been going on since May 9th :( We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no? Some colleagues mentioned weird UMAP results with scanpy actually, it turns out they upgraded their sklearn...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494485672
https://github.com/scverse/scanpy/issues/654#issuecomment-494485672:96,Usability,learn,learn,96,"OK, seems to be fixed in sklearn master branch (probably https://github.com/scikit-learn/scikit-learn/pull/13910), but this is such a huge bug and it has been going on since May 9th :( We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no? Some colleagues mentioned weird UMAP results with scanpy actually, it turns out they upgraded their sklearn...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494485672
https://github.com/scverse/scanpy/issues/654#issuecomment-494706587:112,Deployability,update,update,112,"> @flying-sheep mentioned this was known and already fixed though?. I meant the other breakage due to the scipy update, sorry. > We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no?. We should do that now. We can do `sklearn >= 0.19.1, != 0.21.0, != 0.21.1` I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494706587
https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:101,Availability,redundant,redundant,101,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880
https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:132,Energy Efficiency,efficient,efficient,132,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880
https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:101,Safety,redund,redundant,101,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880
https://github.com/scverse/scanpy/issues/658#issuecomment-495248091:28,Energy Efficiency,efficient,efficient,28,Categoricals being 95% more efficient than datetime is quite interesting. I wasn't aware of how efficient they are... I am however referring to a larger size reduction though. With multiple patients you often have ~5000 cells per patient. If you have patient-level (clinical) measurements you would essentially reduce it from a n_pat*5000 x n_annotations dataframe (if everything is stored in `.obs`) to an n_pat x n_annotations dataframe (stored in `.uns`). This would of course require us to be able to write dataframes in `.uns` to h5ad files.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495248091
https://github.com/scverse/scanpy/issues/658#issuecomment-495248091:96,Energy Efficiency,efficient,efficient,96,Categoricals being 95% more efficient than datetime is quite interesting. I wasn't aware of how efficient they are... I am however referring to a larger size reduction though. With multiple patients you often have ~5000 cells per patient. If you have patient-level (clinical) measurements you would essentially reduce it from a n_pat*5000 x n_annotations dataframe (if everything is stored in `.obs`) to an n_pat x n_annotations dataframe (stored in `.uns`). This would of course require us to be able to write dataframes in `.uns` to h5ad files.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495248091
https://github.com/scverse/scanpy/issues/658#issuecomment-495248091:311,Energy Efficiency,reduce,reduce,311,Categoricals being 95% more efficient than datetime is quite interesting. I wasn't aware of how efficient they are... I am however referring to a larger size reduction though. With multiple patients you often have ~5000 cells per patient. If you have patient-level (clinical) measurements you would essentially reduce it from a n_pat*5000 x n_annotations dataframe (if everything is stored in `.obs`) to an n_pat x n_annotations dataframe (stored in `.uns`). This would of course require us to be able to write dataframes in `.uns` to h5ad files.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495248091
https://github.com/scverse/scanpy/pull/659#issuecomment-495163867:111,Integrability,depend,dependency,111,"The code in UMAP and pynndescent is very close now, but I don't know when UMAP is going to use the pyyndescent dependency. So I thought it would be useful to have this PR in the meantime.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495163867
https://github.com/scverse/scanpy/pull/659#issuecomment-495225646:49,Security,expose,exposed,49,This is super cool!. Is the level of parallelism exposed here amenable to multi-machine parallelism (like the MapReduce strategy mentioned in the nn-descent paper)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495225646
https://github.com/scverse/scanpy/pull/659#issuecomment-495256545:708,Deployability,update,updates,708,"Thanks @ivirshup. The parallelism is achieved using a MapReduce scheme operating on a single NumPy array, as described here: https://github.com/lmcinnes/pynndescent/pull/12. This would be amenable to multi-machine parallelism, and in fact I have started a [Dask implementation](https://github.com/tomwhite/pynndescent/tree/dask) that should work on a cluster. However, I haven't benchmarked the Dask implementation, so I don't know how competitive it is with the single (multi-core) machine version using threads. I have successfully run pynndescent on 10^7 rows on a single machine (50 columns, 96 cores), and I don't see why it wouldn't go further than that, although the bottleneck is memory for the heap updates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495256545
https://github.com/scverse/scanpy/pull/659#issuecomment-495256545:674,Performance,bottleneck,bottleneck,674,"Thanks @ivirshup. The parallelism is achieved using a MapReduce scheme operating on a single NumPy array, as described here: https://github.com/lmcinnes/pynndescent/pull/12. This would be amenable to multi-machine parallelism, and in fact I have started a [Dask implementation](https://github.com/tomwhite/pynndescent/tree/dask) that should work on a cluster. However, I haven't benchmarked the Dask implementation, so I don't know how competitive it is with the single (multi-core) machine version using threads. I have successfully run pynndescent on 10^7 rows on a single machine (50 columns, 96 cores), and I don't see why it wouldn't go further than that, although the bottleneck is memory for the heap updates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495256545
https://github.com/scverse/scanpy/pull/659#issuecomment-495256545:379,Testability,benchmark,benchmarked,379,"Thanks @ivirshup. The parallelism is achieved using a MapReduce scheme operating on a single NumPy array, as described here: https://github.com/lmcinnes/pynndescent/pull/12. This would be amenable to multi-machine parallelism, and in fact I have started a [Dask implementation](https://github.com/tomwhite/pynndescent/tree/dask) that should work on a cluster. However, I haven't benchmarked the Dask implementation, so I don't know how competitive it is with the single (multi-core) machine version using threads. I have successfully run pynndescent on 10^7 rows on a single machine (50 columns, 96 cores), and I don't see why it wouldn't go further than that, although the bottleneck is memory for the heap updates.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495256545
https://github.com/scverse/scanpy/pull/659#issuecomment-495306812:344,Deployability,integrat,integration,344,Even cooler!. Do you recall whether the memory usage for a million cells was anything prohibitive?. I was actually thinking of utilizing distribution across machines as a way to scale out if memory usage started becoming an issue (or even just using the same batching strategy on one machine). This could be very useful for large scale dataset integration. Though I'm curious if using nn-descent could introduce some bias towards merging data.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495306812
https://github.com/scverse/scanpy/pull/659#issuecomment-495306812:344,Integrability,integrat,integration,344,Even cooler!. Do you recall whether the memory usage for a million cells was anything prohibitive?. I was actually thinking of utilizing distribution across machines as a way to scale out if memory usage started becoming an issue (or even just using the same batching strategy on one machine). This could be very useful for large scale dataset integration. Though I'm curious if using nn-descent could introduce some bias towards merging data.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-495306812
https://github.com/scverse/scanpy/pull/659#issuecomment-500175833:87,Testability,test,tested,87,We might consider waiting until the sparse matrix support of pynndescent is thoroughly tested (e.g. https://github.com/lmcinnes/pynndescent/issues/65),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-500175833
https://github.com/scverse/scanpy/pull/659#issuecomment-534951024:49,Deployability,release,released,49,"This is no longer needed since UMAP 0.4 (not yet released) will use pynndescent if it is installed, see https://github.com/lmcinnes/umap/pull/278.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-534951024
https://github.com/scverse/scanpy/pull/659#issuecomment-534951024:89,Deployability,install,installed,89,"This is no longer needed since UMAP 0.4 (not yet released) will use pynndescent if it is installed, see https://github.com/lmcinnes/umap/pull/278.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/659#issuecomment-534951024
https://github.com/scverse/scanpy/issues/660#issuecomment-495141236:83,Availability,down,downgrade,83,There is an issue with the new Scipy. `statsmodels` is conflicting with it. Either downgrade scipy or upgrade statsmodels as soon as they fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236
https://github.com/scverse/scanpy/issues/660#issuecomment-495141236:102,Deployability,upgrade,upgrade,102,There is an issue with the new Scipy. `statsmodels` is conflicting with it. Either downgrade scipy or upgrade statsmodels as soon as they fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236
https://github.com/scverse/scanpy/pull/661#issuecomment-495233581:12,Testability,test,tests,12,Some of the tests fail for reasons unrelated to the PR (`test_preprocessing`). Locally all tests pass for me. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581
https://github.com/scverse/scanpy/pull/661#issuecomment-495233581:91,Testability,test,tests,91,Some of the tests fail for reasons unrelated to the PR (`test_preprocessing`). Locally all tests pass for me. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495233581
https://github.com/scverse/scanpy/pull/661#issuecomment-495239336:42,Integrability,depend,dependency,42,I think it’s again some flakiness of some dependency (or our interaction with it),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495239336
https://github.com/scverse/scanpy/pull/661#issuecomment-495543522:34,Testability,test,tests,34,@flying-sheep I see that the same tests are failing in other PRs. Do you have any idea what and when some change was introduced that broke the tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522
https://github.com/scverse/scanpy/pull/661#issuecomment-495543522:143,Testability,test,tests,143,@flying-sheep I see that the same tests are failing in other PRs. Do you have any idea what and when some change was introduced that broke the tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495543522
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:523,Availability,error,errors,523,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:626,Availability,error,errors,626,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:1128,Availability,down,downgrade,1128,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:215,Deployability,release,release,215,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:398,Deployability,update,updated,398,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:957,Deployability,update,updated,957,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:1072,Deployability,install,install,1072,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:383,Integrability,depend,dependency,383,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:47,Testability,test,tests,47,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:131,Testability,test,test,131,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:356,Testability,test,test,356,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166
https://github.com/scverse/scanpy/pull/661#issuecomment-495629061:33,Availability,error,errors,33,setting scipy==1.2 fixes several errors but there is another one maybe related to matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495629061
https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:110,Availability,error,error,110,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015
https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:237,Deployability,upgrade,upgrade,237,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015
https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:249,Integrability,depend,dependencies,249,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015
https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:21,Testability,test,test,21,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015
https://github.com/scverse/scanpy/issues/662#issuecomment-499112975:4,Deployability,update,updates,4,Any updates on this one @flying-sheep? I keep having the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/662#issuecomment-499112975
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:87,Availability,down,downgrade,87,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:941,Availability,error,error,941,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:113,Deployability,update,updated,113,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:205,Deployability,update,update,205,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:596,Deployability,update,update,596,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:125,Integrability,depend,dependencies,125,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:217,Integrability,depend,dependencies,217,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:778,Usability,learn,learn,778,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:1048,Usability,learn,learn,1048,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076
https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:235,Availability,down,downgrading,235,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520
https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:26,Testability,log,logging,26,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520
https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:150,Usability,learn,learn,150,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520
https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:258,Usability,learn,learn,258,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520
https://github.com/scverse/scanpy/issues/666#issuecomment-496837522:0,Availability,Down,Downgrading,0,Downgrading `scikit-learn` to `0.20.3` does not resolve the error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522
https://github.com/scverse/scanpy/issues/666#issuecomment-496837522:60,Availability,error,error,60,Downgrading `scikit-learn` to `0.20.3` does not resolve the error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522
https://github.com/scverse/scanpy/issues/666#issuecomment-496837522:20,Usability,learn,learn,20,Downgrading `scikit-learn` to `0.20.3` does not resolve the error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522
https://github.com/scverse/scanpy/issues/666#issuecomment-496845038:78,Testability,log,logarithmization,78,"> What I basically do from raw UMI counts:; > 1. total counts normalization / logarithmization; > 2. PCA, bbknn, louvain; > 3. combat, HVG, PCA, UMAP (works well). Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845038
https://github.com/scverse/scanpy/issues/666#issuecomment-496845071:4,Availability,error,error,4,The error seems to be that [`rdist`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L663) is called from [`umap.umap_.optimize_layout`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L776) with float64 arrays while it can only handle float32 arrays. There seem to have been a few changes in umap [between 0.3.8 and 0.3.9](https://github.com/lmcinnes/umap/compare/0.3.8...0.3.9) maybe you should try 0.3.9.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071
https://github.com/scverse/scanpy/issues/666#issuecomment-496848304:589,Deployability,update,updated,589,"> Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization. @LuckyMD I found that the clustering using the bbknn kNN graph is much cleaner on UMAP, compared to e.g. `sc.pp.neighbors`. From combat, I just obtain the adjusted data, not a kNN graph. . > There seem to have been a few changes in umap between 0.3.8 and 0.3.9 maybe you should try 0.3.9. @flying-sheep Thanks! With `scikit-learn` pinned to `0.20.3` the `umap` version was updated to `0.3.9` (I use a container and rebuilt it). . I guess I will try to create a reproducible example and open an issue in umap.; Edit: https://github.com/lmcinnes/umap/issues/179",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496848304
https://github.com/scverse/scanpy/issues/666#issuecomment-496848304:540,Usability,learn,learn,540,"> Just out of curiousity, you use both BBKNN and combat? Does Louvain after ComBat, HVG, and PCA not work as well for you? It's interesting that you go with two different knn graphs for clustering and visualization. @LuckyMD I found that the clustering using the bbknn kNN graph is much cleaner on UMAP, compared to e.g. `sc.pp.neighbors`. From combat, I just obtain the adjusted data, not a kNN graph. . > There seem to have been a few changes in umap between 0.3.8 and 0.3.9 maybe you should try 0.3.9. @flying-sheep Thanks! With `scikit-learn` pinned to `0.20.3` the `umap` version was updated to `0.3.9` (I use a container and rebuilt it). . I guess I will try to create a reproducible example and open an issue in umap.; Edit: https://github.com/lmcinnes/umap/issues/179",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496848304
https://github.com/scverse/scanpy/issues/666#issuecomment-496866953:98,Testability,test,test,98,"I think umap works on the connectivities matrix generated from `sc.pp.neighbors`. I guess you can test this by omitting `sc.pp.neighbors` before running umap. Or just running umap after your step 2 and look at the difference. >Yes, my batches have very similar (if not the same) cell type composition. In that case it would make sense for both bbknn and combat to work quite well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496866953
https://github.com/scverse/scanpy/issues/666#issuecomment-497630093:747,Testability,log,logging,747,"> Although it states so:. UMAP only uses the representation of a data matrix for determining the number of connected components of the graph for the init conditions [if these aren't explicitly defined (they are if choosing `init_pos='paga'`): https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/umap_.py#L958-L965. In fact, the only place where it enters is for the computation of the mean positions of the disconnected components: https://github.com/lmcinnes/umap/blob/948f60ff0caf7ccef0ab68626c7b99a11e66f1bb/umap/spectral.py#L50. Implementation-wise, it's a bit unfortunate that the data matrix is carried through all these functions just for that reason... But it's not a problem for the results. The confusing logging is fixed via; https://github.com/theislab/scanpy/commit/a5bd1ecd8ab04ec79369f60d3656f578a4cde40c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-497630093
https://github.com/scverse/scanpy/issues/667#issuecomment-497027543:185,Modifiability,variab,variable,185,"Hi,. I wonder whether you have a gene with constant expression value in there... that sounds like it might break the regression step. Otherwise, I would argue that subsetting to highly variable genes for regressing out a covariate is completely fine. In the end you are probably regressing out a covariate to improve the embedding. That is anyway only done on the highly variable genes, so other genes won't affect that. The only thing that might not be ideal is that you don't have the ""corrected"" data (data after regressing out your covariate) for plotting gene expression values, as you probably don't want to do any testing on the corrected data anyway. Still... it should be possible to do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543
https://github.com/scverse/scanpy/issues/667#issuecomment-497027543:371,Modifiability,variab,variable,371,"Hi,. I wonder whether you have a gene with constant expression value in there... that sounds like it might break the regression step. Otherwise, I would argue that subsetting to highly variable genes for regressing out a covariate is completely fine. In the end you are probably regressing out a covariate to improve the embedding. That is anyway only done on the highly variable genes, so other genes won't affect that. The only thing that might not be ideal is that you don't have the ""corrected"" data (data after regressing out your covariate) for plotting gene expression values, as you probably don't want to do any testing on the corrected data anyway. Still... it should be possible to do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543
https://github.com/scverse/scanpy/issues/667#issuecomment-497027543:621,Testability,test,testing,621,"Hi,. I wonder whether you have a gene with constant expression value in there... that sounds like it might break the regression step. Otherwise, I would argue that subsetting to highly variable genes for regressing out a covariate is completely fine. In the end you are probably regressing out a covariate to improve the embedding. That is anyway only done on the highly variable genes, so other genes won't affect that. The only thing that might not be ideal is that you don't have the ""corrected"" data (data after regressing out your covariate) for plotting gene expression values, as you probably don't want to do any testing on the corrected data anyway. Still... it should be possible to do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-497027543
https://github.com/scverse/scanpy/issues/667#issuecomment-519987040:20,Availability,error,error,20,"+1, I have the same error (on different data), which also only seems to appear when I don't filter to leave only the highly variable genes. In my case,. ```; np.any(adata.X.sum(axis=0) == 0); np.any(adata.X.sum(axis=1) == 0); ```; both return `False`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040
https://github.com/scverse/scanpy/issues/667#issuecomment-519987040:124,Modifiability,variab,variable,124,"+1, I have the same error (on different data), which also only seems to appear when I don't filter to leave only the highly variable genes. In my case,. ```; np.any(adata.X.sum(axis=0) == 0); np.any(adata.X.sum(axis=1) == 0); ```; both return `False`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040
https://github.com/scverse/scanpy/issues/667#issuecomment-520159182:50,Availability,error,error,50,"Hi @chris-rands . It would help to have the whole error traceback here to be able to diagnose this a bit better. @jorvis Did you find the solution to your issue, and if so could you post it here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520159182
https://github.com/scverse/scanpy/issues/667#issuecomment-520178937:27,Availability,error,error,27,"Right now I do not get the error if I do these steps:. ```py; sc.pp.normalize_per_cell(adata, counts_per_cell_after=norm_counts_per_cell); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=n_top_genes); sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520178937
https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:307,Deployability,integrat,integrated,307,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928
https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:307,Integrability,integrat,integrated,307,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928
https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:47,Performance,perform,performed,47,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928
https://github.com/scverse/scanpy/issues/669#issuecomment-497118928:29,Testability,test,testing,29,"Hi,. You are correct that DE testing should be performed on raw or normalized data, but not on batch-corrected data. `sc.tl.rank_genes_groups()` doesn't let you include covariates, but there are plenty of methods that do. You could look into `diffxpy` for this, which is also based on AnnData and is easily integrated into a scanpy script. Otherwise, I have a case study for a best practices workflow, which uses MAST. You could reuse code from there as well. You can find the case study [here](https://www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497118928
https://github.com/scverse/scanpy/issues/669#issuecomment-497725644:93,Testability,log,logistic,93,Thanks a lot @LuckyMD!; MAST seems to be what I was looking for. An alternative might be the logistic regression with covariates Seurat offers within their FindMarkers function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/669#issuecomment-497725644
https://github.com/scverse/scanpy/issues/670#issuecomment-498046271:773,Deployability,integrat,integrate,773,"I only can advice you on your second part of questions there is no rule of thumb for that. I also don't know what do you exactly mean by best suggestion resolution and how did you assess that. This is a general problem for many supervised clustering methods such as k-mean that user has to provide number of clusters or in this case the resolution which determines the number of clusters. Although there are some indirect ways to assess the clustering quality for example silhouette coefficient which gives you a score between -1 to 1 that tell you how similar your point in each clusters are. The other possibility is that you already expect the number of clusters so you can optimize the resolution based on your previous knowledge. ; @falexwolf Out of curiosity, can we integrate such methods like silhouette coefficient inside scanpy? that would be cool!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271
https://github.com/scverse/scanpy/issues/670#issuecomment-498046271:773,Integrability,integrat,integrate,773,"I only can advice you on your second part of questions there is no rule of thumb for that. I also don't know what do you exactly mean by best suggestion resolution and how did you assess that. This is a general problem for many supervised clustering methods such as k-mean that user has to provide number of clusters or in this case the resolution which determines the number of clusters. Although there are some indirect ways to assess the clustering quality for example silhouette coefficient which gives you a score between -1 to 1 that tell you how similar your point in each clusters are. The other possibility is that you already expect the number of clusters so you can optimize the resolution based on your previous knowledge. ; @falexwolf Out of curiosity, can we integrate such methods like silhouette coefficient inside scanpy? that would be cool!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271
https://github.com/scverse/scanpy/issues/670#issuecomment-498046271:677,Performance,optimiz,optimize,677,"I only can advice you on your second part of questions there is no rule of thumb for that. I also don't know what do you exactly mean by best suggestion resolution and how did you assess that. This is a general problem for many supervised clustering methods such as k-mean that user has to provide number of clusters or in this case the resolution which determines the number of clusters. Although there are some indirect ways to assess the clustering quality for example silhouette coefficient which gives you a score between -1 to 1 that tell you how similar your point in each clusters are. The other possibility is that you already expect the number of clusters so you can optimize the resolution based on your previous knowledge. ; @falexwolf Out of curiosity, can we integrate such methods like silhouette coefficient inside scanpy? that would be cool!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498046271
https://github.com/scverse/scanpy/issues/670#issuecomment-498057572:249,Performance,optimiz,optimizing,249,"Thanks @bioguy2018 for your kind reply. Actually I was confused as for Pbmc3k, Scanpy and previous version of Seurat says it has 8 clusters, but in new version of Seurat clusters are 9. I think it's totally based on biological knowledge rather than optimizing paramters, like resolution. It will be great to add something like silhouette coefficient in scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498057572
https://github.com/scverse/scanpy/issues/670#issuecomment-498066846:199,Integrability,depend,dependent,199,"You can easily access the silhouette coefficient via scikit-learn. . I would be hesitant to base optimal numbers of clusters on the silhouette coefficient though. The number of clusters is typically dependent on the biological question of interest. There's not really a scale at which all biological questions can be answered. Therefore you have a resolution parameter to check multiple resolutions. For example, T cells could be taken as one cluster or sub-clustered into CD4+ and CD8+ (which is typically done). Here a problem with the silhouette coefficient also shows: often you have one big cluster of T-cells which reluctantly cluster into the CD4+ and CD8+ subtypes (early 10X datasets show this nicely). This will have a lower silhouette coefficient, but it is probably more informative for many people.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498066846
https://github.com/scverse/scanpy/issues/670#issuecomment-498066846:15,Security,access,access,15,"You can easily access the silhouette coefficient via scikit-learn. . I would be hesitant to base optimal numbers of clusters on the silhouette coefficient though. The number of clusters is typically dependent on the biological question of interest. There's not really a scale at which all biological questions can be answered. Therefore you have a resolution parameter to check multiple resolutions. For example, T cells could be taken as one cluster or sub-clustered into CD4+ and CD8+ (which is typically done). Here a problem with the silhouette coefficient also shows: often you have one big cluster of T-cells which reluctantly cluster into the CD4+ and CD8+ subtypes (early 10X datasets show this nicely). This will have a lower silhouette coefficient, but it is probably more informative for many people.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498066846
https://github.com/scverse/scanpy/issues/670#issuecomment-498066846:60,Usability,learn,learn,60,"You can easily access the silhouette coefficient via scikit-learn. . I would be hesitant to base optimal numbers of clusters on the silhouette coefficient though. The number of clusters is typically dependent on the biological question of interest. There's not really a scale at which all biological questions can be answered. Therefore you have a resolution parameter to check multiple resolutions. For example, T cells could be taken as one cluster or sub-clustered into CD4+ and CD8+ (which is typically done). Here a problem with the silhouette coefficient also shows: often you have one big cluster of T-cells which reluctantly cluster into the CD4+ and CD8+ subtypes (early 10X datasets show this nicely). This will have a lower silhouette coefficient, but it is probably more informative for many people.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498066846
https://github.com/scverse/scanpy/issues/670#issuecomment-498068973:253,Usability,clear,clear,253,"@LuckyMD I am wondering have you tried it before? or did someone try it with the pbmc data with regards to the t-cells that you mentioned? I agree with you that it can not be an option for answering biological questions but in the case that there is no clear biological knowledge like looking for new sub-types or so it can be an option to get some idea (mathematically). . p.s. it just crossed my mind so I am pushing a technical question also here 😄 Since we would need to calculate the distance matrix, would the input for the function be adata.X ? should it be the raw file?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498068973
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:847,Availability,recover,recovers,847,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:102,Integrability,depend,depends,102,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:253,Integrability,depend,depends,253,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:417,Performance,perform,performed,417,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:847,Safety,recover,recovers,847,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:1134,Safety,detect,detected,1134,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336
https://github.com/scverse/scanpy/issues/670#issuecomment-498155327:45,Energy Efficiency,efficient,efficient,45,@LuckyMD I think we cann't use Silhouette co-efficient for the data like single cell. Where the are chances we have clusters with few points and silhouette won't be able to detect it separate cluster. E.g. in Pbmc3k dataset 'Megakaryocytes' and 'Dendritic' cell type will not be marked as a separate cluster by using your suggested co-efficient.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498155327
https://github.com/scverse/scanpy/issues/670#issuecomment-498155327:335,Energy Efficiency,efficient,efficient,335,@LuckyMD I think we cann't use Silhouette co-efficient for the data like single cell. Where the are chances we have clusters with few points and silhouette won't be able to detect it separate cluster. E.g. in Pbmc3k dataset 'Megakaryocytes' and 'Dendritic' cell type will not be marked as a separate cluster by using your suggested co-efficient.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498155327
https://github.com/scverse/scanpy/issues/670#issuecomment-498155327:173,Safety,detect,detect,173,@LuckyMD I think we cann't use Silhouette co-efficient for the data like single cell. Where the are chances we have clusters with few points and silhouette won't be able to detect it separate cluster. E.g. in Pbmc3k dataset 'Megakaryocytes' and 'Dendritic' cell type will not be marked as a separate cluster by using your suggested co-efficient.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498155327
https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:253,Performance,optimiz,optimize,253,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:362,Performance,optimiz,optimizing,362,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:452,Performance,optimiz,optimized,452,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
https://github.com/scverse/scanpy/issues/670#issuecomment-498158306:22,Testability,log,logical,22,"@grst Thanks it seems logical, but,. It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. ; In louvain and leiden we usually optimize 'modularity' value, what if we just calculate modularity values for different resolution instead of optimizing for given resolution and then for resolution where 'modularity' is maximum, we optimized 'modalarity'. Is this ok ? But i also think that 'modularity' increases when we have small number of clusters. Any suggestion ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498158306
https://github.com/scverse/scanpy/issues/670#issuecomment-498161514:382,Integrability,depend,dependent,382,"> It is mentioned in Seurat Pbmc3k example that best resolution parameter is 0.6-1.2 , but you used less and get more clusters. May be because i didn't explore random seed in leiden. I suspect this is because I processed the dataset with `sc.tl.diffmap`. The random seed tends to make only minor differences (+/- 1). As far as I can tell, the resolution parameter really is dataset dependent. But maybe someone with a better knowledge of the actual algorithm can comment on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498161514
https://github.com/scverse/scanpy/issues/670#issuecomment-498181103:142,Integrability,depend,depending,142,"@Khalid-Usman Of course you can use silhouette coefficient for any kind of clustering in principal. you just need to choose the ""best option"" depending on your dataset which is again depending on what you are interested in and then you can validate it by looking into your clusters markers. I am actually very curious to see the T-cells case that was mentioned here....you can also have a look here: https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set; Again I would like to mention using such control parameters are mathematical methods to assess your clustering quality it might has nothing to do with the biological side and they can be actually helpful when you have no clue over the number of clusters you would look for so you would reply only on mathematics ! your question is really topic specific that what you look for and in which case you want to assess your data...if you already have an estimation or no.......there are also other ways to look for the quality of the data as grst mentioned but again it really depends on what you look into.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103
https://github.com/scverse/scanpy/issues/670#issuecomment-498181103:183,Integrability,depend,depending,183,"@Khalid-Usman Of course you can use silhouette coefficient for any kind of clustering in principal. you just need to choose the ""best option"" depending on your dataset which is again depending on what you are interested in and then you can validate it by looking into your clusters markers. I am actually very curious to see the T-cells case that was mentioned here....you can also have a look here: https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set; Again I would like to mention using such control parameters are mathematical methods to assess your clustering quality it might has nothing to do with the biological side and they can be actually helpful when you have no clue over the number of clusters you would look for so you would reply only on mathematics ! your question is really topic specific that what you look for and in which case you want to assess your data...if you already have an estimation or no.......there are also other ways to look for the quality of the data as grst mentioned but again it really depends on what you look into.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103
https://github.com/scverse/scanpy/issues/670#issuecomment-498181103:1051,Integrability,depend,depends,1051,"@Khalid-Usman Of course you can use silhouette coefficient for any kind of clustering in principal. you just need to choose the ""best option"" depending on your dataset which is again depending on what you are interested in and then you can validate it by looking into your clusters markers. I am actually very curious to see the T-cells case that was mentioned here....you can also have a look here: https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set; Again I would like to mention using such control parameters are mathematical methods to assess your clustering quality it might has nothing to do with the biological side and they can be actually helpful when you have no clue over the number of clusters you would look for so you would reply only on mathematics ! your question is really topic specific that what you look for and in which case you want to assess your data...if you already have an estimation or no.......there are also other ways to look for the quality of the data as grst mentioned but again it really depends on what you look into.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103
https://github.com/scverse/scanpy/issues/670#issuecomment-498181103:240,Security,validat,validate,240,"@Khalid-Usman Of course you can use silhouette coefficient for any kind of clustering in principal. you just need to choose the ""best option"" depending on your dataset which is again depending on what you are interested in and then you can validate it by looking into your clusters markers. I am actually very curious to see the T-cells case that was mentioned here....you can also have a look here: https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set; Again I would like to mention using such control parameters are mathematical methods to assess your clustering quality it might has nothing to do with the biological side and they can be actually helpful when you have no clue over the number of clusters you would look for so you would reply only on mathematics ! your question is really topic specific that what you look for and in which case you want to assess your data...if you already have an estimation or no.......there are also other ways to look for the quality of the data as grst mentioned but again it really depends on what you look into.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498181103
https://github.com/scverse/scanpy/issues/670#issuecomment-776593368:86,Deployability,integrat,integrates,86,Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-776593368
https://github.com/scverse/scanpy/issues/670#issuecomment-776593368:86,Integrability,integrat,integrates,86,Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-776593368
https://github.com/scverse/scanpy/issues/670#issuecomment-785309409:88,Deployability,integrat,integrates,88,"> Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?. I have resorted to writing a small Rscript that takes a saved adata.h5ad file as input, loads it using `reticulate`, runs Clustree, saves it. I then run the script from a notebook using `invoke.run` from the `invoke` package as a function in a notebook and load the output figure as an image in the notebook. Here is the script I use in case it helps:. ```R. suppressPackageStartupMessages({; library(reticulate); library(SingleCellExperiment); library(glue); library(clustree); }); sc <- import(""scanpy""). args <- commandArgs(trailingOnly = TRUE); H5AD_PATH = args[1]; OUT_PATH = args[2]. print(glue(""H5AD_PATH: {H5AD_PATH}"")); print(glue(""OUT_PATH: {OUT_PATH}"")). load_adata = function(h5ad_path) {; adata <- sc$read_h5ad(h5ad_path). return(adata); }. count_clusterings = function(adata){; # Ryan suggests:; # length(grep(""leiden"",names(adata$obs))). clusterings = c(); for (x in adata$obs_keys()){; if (startsWith(x, ""leiden"")){; clusterings = append(clusterings, x); }; }; ; return(length(clusterings)); }. set_fig_dimensions = function(num_clusterings){; width = 10; height = (0.6 * num_clusterings); ; if (height < 8){; height = 8; }; ; png(width = width, height = height); options(repr.plot.width = width, repr.plot.height = height); ; return(list(width=width,height=height)); }. adata = load_adata(h5ad_path=H5AD_PATH). dims = set_fig_dimensions(num_clusterings = count_clusterings(adata)); # dims. # options(repr.plot.width = 10, repr.plot.height = 10). g = clustree(; x=adata$obs,; prefix=""leiden_"",; # suffix = NULL,; # metadata = NULL,; # count_filter = 0,; # prop_filter = 0.1,; # layout = ""sugiyama"",; # layout = ""tree"",; # use_core_edges = FALSE,; # highlight_core = FALSE,; # node_colour = prefix,; # node_colour_aggr = NULL,; # node_size = ""size"",; # node_size_aggr = NULL,; # node_size_range = c(4, 15),; # node_alpha = 1,; # node_alpha_aggr = NULL,; # node_text_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409
https://github.com/scverse/scanpy/issues/670#issuecomment-785309409:88,Integrability,integrat,integrates,88,"> Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?. I have resorted to writing a small Rscript that takes a saved adata.h5ad file as input, loads it using `reticulate`, runs Clustree, saves it. I then run the script from a notebook using `invoke.run` from the `invoke` package as a function in a notebook and load the output figure as an image in the notebook. Here is the script I use in case it helps:. ```R. suppressPackageStartupMessages({; library(reticulate); library(SingleCellExperiment); library(glue); library(clustree); }); sc <- import(""scanpy""). args <- commandArgs(trailingOnly = TRUE); H5AD_PATH = args[1]; OUT_PATH = args[2]. print(glue(""H5AD_PATH: {H5AD_PATH}"")); print(glue(""OUT_PATH: {OUT_PATH}"")). load_adata = function(h5ad_path) {; adata <- sc$read_h5ad(h5ad_path). return(adata); }. count_clusterings = function(adata){; # Ryan suggests:; # length(grep(""leiden"",names(adata$obs))). clusterings = c(); for (x in adata$obs_keys()){; if (startsWith(x, ""leiden"")){; clusterings = append(clusterings, x); }; }; ; return(length(clusterings)); }. set_fig_dimensions = function(num_clusterings){; width = 10; height = (0.6 * num_clusterings); ; if (height < 8){; height = 8; }; ; png(width = width, height = height); options(repr.plot.width = width, repr.plot.height = height); ; return(list(width=width,height=height)); }. adata = load_adata(h5ad_path=H5AD_PATH). dims = set_fig_dimensions(num_clusterings = count_clusterings(adata)); # dims. # options(repr.plot.width = 10, repr.plot.height = 10). g = clustree(; x=adata$obs,; prefix=""leiden_"",; # suffix = NULL,; # metadata = NULL,; # count_filter = 0,; # prop_filter = 0.1,; # layout = ""sugiyama"",; # layout = ""tree"",; # use_core_edges = FALSE,; # highlight_core = FALSE,; # node_colour = prefix,; # node_colour_aggr = NULL,; # node_size = ""size"",; # node_size_aggr = NULL,; # node_size_range = c(4, 15),; # node_alpha = 1,; # node_alpha_aggr = NULL,; # node_text_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409
https://github.com/scverse/scanpy/issues/670#issuecomment-785309409:208,Performance,load,loads,208,"> Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?. I have resorted to writing a small Rscript that takes a saved adata.h5ad file as input, loads it using `reticulate`, runs Clustree, saves it. I then run the script from a notebook using `invoke.run` from the `invoke` package as a function in a notebook and load the output figure as an image in the notebook. Here is the script I use in case it helps:. ```R. suppressPackageStartupMessages({; library(reticulate); library(SingleCellExperiment); library(glue); library(clustree); }); sc <- import(""scanpy""). args <- commandArgs(trailingOnly = TRUE); H5AD_PATH = args[1]; OUT_PATH = args[2]. print(glue(""H5AD_PATH: {H5AD_PATH}"")); print(glue(""OUT_PATH: {OUT_PATH}"")). load_adata = function(h5ad_path) {; adata <- sc$read_h5ad(h5ad_path). return(adata); }. count_clusterings = function(adata){; # Ryan suggests:; # length(grep(""leiden"",names(adata$obs))). clusterings = c(); for (x in adata$obs_keys()){; if (startsWith(x, ""leiden"")){; clusterings = append(clusterings, x); }; }; ; return(length(clusterings)); }. set_fig_dimensions = function(num_clusterings){; width = 10; height = (0.6 * num_clusterings); ; if (height < 8){; height = 8; }; ; png(width = width, height = height); options(repr.plot.width = width, repr.plot.height = height); ; return(list(width=width,height=height)); }. adata = load_adata(h5ad_path=H5AD_PATH). dims = set_fig_dimensions(num_clusterings = count_clusterings(adata)); # dims. # options(repr.plot.width = 10, repr.plot.height = 10). g = clustree(; x=adata$obs,; prefix=""leiden_"",; # suffix = NULL,; # metadata = NULL,; # count_filter = 0,; # prop_filter = 0.1,; # layout = ""sugiyama"",; # layout = ""tree"",; # use_core_edges = FALSE,; # highlight_core = FALSE,; # node_colour = prefix,; # node_colour_aggr = NULL,; # node_size = ""size"",; # node_size_aggr = NULL,; # node_size_range = c(4, 15),; # node_alpha = 1,; # node_alpha_aggr = NULL,; # node_text_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409
https://github.com/scverse/scanpy/issues/670#issuecomment-785309409:377,Performance,load,load,377,"> Is there anything like [clustree](https://github.com/lazappi/clustree) in python that integrates nicely with scanpy?. I have resorted to writing a small Rscript that takes a saved adata.h5ad file as input, loads it using `reticulate`, runs Clustree, saves it. I then run the script from a notebook using `invoke.run` from the `invoke` package as a function in a notebook and load the output figure as an image in the notebook. Here is the script I use in case it helps:. ```R. suppressPackageStartupMessages({; library(reticulate); library(SingleCellExperiment); library(glue); library(clustree); }); sc <- import(""scanpy""). args <- commandArgs(trailingOnly = TRUE); H5AD_PATH = args[1]; OUT_PATH = args[2]. print(glue(""H5AD_PATH: {H5AD_PATH}"")); print(glue(""OUT_PATH: {OUT_PATH}"")). load_adata = function(h5ad_path) {; adata <- sc$read_h5ad(h5ad_path). return(adata); }. count_clusterings = function(adata){; # Ryan suggests:; # length(grep(""leiden"",names(adata$obs))). clusterings = c(); for (x in adata$obs_keys()){; if (startsWith(x, ""leiden"")){; clusterings = append(clusterings, x); }; }; ; return(length(clusterings)); }. set_fig_dimensions = function(num_clusterings){; width = 10; height = (0.6 * num_clusterings); ; if (height < 8){; height = 8; }; ; png(width = width, height = height); options(repr.plot.width = width, repr.plot.height = height); ; return(list(width=width,height=height)); }. adata = load_adata(h5ad_path=H5AD_PATH). dims = set_fig_dimensions(num_clusterings = count_clusterings(adata)); # dims. # options(repr.plot.width = 10, repr.plot.height = 10). g = clustree(; x=adata$obs,; prefix=""leiden_"",; # suffix = NULL,; # metadata = NULL,; # count_filter = 0,; # prop_filter = 0.1,; # layout = ""sugiyama"",; # layout = ""tree"",; # use_core_edges = FALSE,; # highlight_core = FALSE,; # node_colour = prefix,; # node_colour_aggr = NULL,; # node_size = ""size"",; # node_size_aggr = NULL,; # node_size_range = c(4, 15),; # node_alpha = 1,; # node_alpha_aggr = NULL,; # node_text_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785309409
https://github.com/scverse/scanpy/issues/670#issuecomment-785722015:420,Deployability,release,release,420,"I don't have a lot to add. As far as I know there's no native Python implementation of clustering trees. If you want to use the R **{clustree}** package you will need to transfer your data from R to Python in some way. Using straight **{reticulate}** to read a `.h5ad` file like you have here is one option but there are packages that will do it for you including [**{zellkonverter}**](https://bioconductor.org/packages/release/bioc/html/zellkonverter.html), [**{anndata}**](https://cran.r-project.org/web/packages/anndata/index.html) and [**{SeuratDisk}**](https://github.com/mojaveazure/seurat-disk). Once you have a `SingleCellExperiment` or `Seurat` you can plug that directly into **{clustree}**. It should also be possible to call **{clustree}** from Python using [**anndata2ri**](https://github.com/theislab/anndata2ri) but I'm not sure of the details of how to do that. If you only want a basic clustering tree you could just transfer the clustering assignments (by saving to CSV for example). That would probably be easier/quicker than transferring the whole dataset but you would lose the opportunity to overlay other information such as marker gene expression (which is often really helpful). Unless you plan ahead and append that to whatever you save to disk. Sorry, that was longer than I thought 😸! Hope it helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785722015
https://github.com/scverse/scanpy/issues/670#issuecomment-785816727:125,Usability,clear,clearly,125,"Thank you both for taking the time to answer. I was hoping there is a python port/re-implementation of clustree, but this is clearly not the case. Nonetheless, the workarounds you suggest are helpful",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-785816727
https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678:57,Modifiability,Extend,Extending,57,"Hopefully I am not too out of date to ask this question. Extending on this discussion, I was wondering how a few of you @bioguy2018 @Khalid-Usman @LuckyMD calculate the Silhouette Scores for your graphs? The simplest way I can think of to extract the vectors required for the calculation will be to use the adjacency matrices as vectors. However, I quickly run into memory issues on large datasets with >= 100K nodes? (Each vector will contain 100K elements) I couldn't even load the matrix into memory to perform any form of dimension reduction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678
https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678:475,Performance,load,load,475,"Hopefully I am not too out of date to ask this question. Extending on this discussion, I was wondering how a few of you @bioguy2018 @Khalid-Usman @LuckyMD calculate the Silhouette Scores for your graphs? The simplest way I can think of to extract the vectors required for the calculation will be to use the adjacency matrices as vectors. However, I quickly run into memory issues on large datasets with >= 100K nodes? (Each vector will contain 100K elements) I couldn't even load the matrix into memory to perform any form of dimension reduction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678
https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678:506,Performance,perform,perform,506,"Hopefully I am not too out of date to ask this question. Extending on this discussion, I was wondering how a few of you @bioguy2018 @Khalid-Usman @LuckyMD calculate the Silhouette Scores for your graphs? The simplest way I can think of to extract the vectors required for the calculation will be to use the adjacency matrices as vectors. However, I quickly run into memory issues on large datasets with >= 100K nodes? (Each vector will contain 100K elements) I couldn't even load the matrix into memory to perform any form of dimension reduction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678
https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678:208,Usability,simpl,simplest,208,"Hopefully I am not too out of date to ask this question. Extending on this discussion, I was wondering how a few of you @bioguy2018 @Khalid-Usman @LuckyMD calculate the Silhouette Scores for your graphs? The simplest way I can think of to extract the vectors required for the calculation will be to use the adjacency matrices as vectors. However, I quickly run into memory issues on large datasets with >= 100K nodes? (Each vector will contain 100K elements) I couldn't even load the matrix into memory to perform any form of dimension reduction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-1465574678
https://github.com/scverse/scanpy/issues/671#issuecomment-497596529:145,Testability,log,logarithmized,145,You are absolutely right; it's removed: https://github.com/theislab/scanpy/commit/c319ac0699937278e2a231988e72e432c8950c0a. The function expects logarithmized data.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/671#issuecomment-497596529
https://github.com/scverse/scanpy/issues/673#issuecomment-502551963:222,Safety,detect,detecting,222,"Yeah, so it appears that the function expects log-transformed data. Otherwise the use of `np.expm1()` doesn't make sense. If you don't log transform your data, you would get the wrong values. It might be worth either auto-detecting whether data was log-transformed or not, or adding it as a parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963
https://github.com/scverse/scanpy/issues/673#issuecomment-502551963:46,Testability,log,log-transformed,46,"Yeah, so it appears that the function expects log-transformed data. Otherwise the use of `np.expm1()` doesn't make sense. If you don't log transform your data, you would get the wrong values. It might be worth either auto-detecting whether data was log-transformed or not, or adding it as a parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963
https://github.com/scverse/scanpy/issues/673#issuecomment-502551963:135,Testability,log,log,135,"Yeah, so it appears that the function expects log-transformed data. Otherwise the use of `np.expm1()` doesn't make sense. If you don't log transform your data, you would get the wrong values. It might be worth either auto-detecting whether data was log-transformed or not, or adding it as a parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963
https://github.com/scverse/scanpy/issues/673#issuecomment-502551963:249,Testability,log,log-transformed,249,"Yeah, so it appears that the function expects log-transformed data. Otherwise the use of `np.expm1()` doesn't make sense. If you don't log transform your data, you would get the wrong values. It might be worth either auto-detecting whether data was log-transformed or not, or adding it as a parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-502551963
https://github.com/scverse/scanpy/issues/673#issuecomment-528510773:82,Testability,log,log-transformed,82,"Hi! Sorry for the very late reply! But yes, this function is assuming the data is log-transformed before ranking genes. That's the typical workflow. It originally had a parameter to check for this, but then we decided to simplify and remove it (#519). There was some brief discussions here about adding an attribute when pp.log1p is run to handle non-transformed data, but I don't think was ever implemented. Might be worth revisiting though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773
https://github.com/scverse/scanpy/issues/673#issuecomment-528510773:221,Usability,simpl,simplify,221,"Hi! Sorry for the very late reply! But yes, this function is assuming the data is log-transformed before ranking genes. That's the typical workflow. It originally had a parameter to check for this, but then we decided to simplify and remove it (#519). There was some brief discussions here about adding an attribute when pp.log1p is run to handle non-transformed data, but I don't think was ever implemented. Might be worth revisiting though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/673#issuecomment-528510773
https://github.com/scverse/scanpy/issues/675#issuecomment-508997047:100,Availability,error,error,100,"Hi Isaac,. When I try to set n_comps equal to 2 (trying to do a diffmap in 2; components), I get an error message saying that it must be greater than 2.; I was wondering why?. On Sun, Jul 7, 2019 at 4:25 AM Isaac Virshup <notifications@github.com>; wrote:. > I'm not sure what you're asking about here. Could you provide a little; > more context?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/675?email_source=notifications&email_token=AKIOHVNZFKCE63C4KLO45KTP6GSAPA5CNFSM4HSIFHXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZLG7PQ#issuecomment-508981182>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AKIOHVL7254C36JSP374JOTP6GSAPANCNFSM4HSIFHXA>; > .; >; -- ; Harvard-MIT MD-PhD Student; G1, Biophysics; Lander Lab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047
https://github.com/scverse/scanpy/issues/675#issuecomment-508997047:106,Integrability,message,message,106,"Hi Isaac,. When I try to set n_comps equal to 2 (trying to do a diffmap in 2; components), I get an error message saying that it must be greater than 2.; I was wondering why?. On Sun, Jul 7, 2019 at 4:25 AM Isaac Virshup <notifications@github.com>; wrote:. > I'm not sure what you're asking about here. Could you provide a little; > more context?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/675?email_source=notifications&email_token=AKIOHVNZFKCE63C4KLO45KTP6GSAPA5CNFSM4HSIFHXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZLG7PQ#issuecomment-508981182>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AKIOHVL7254C36JSP374JOTP6GSAPANCNFSM4HSIFHXA>; > .; >; -- ; Harvard-MIT MD-PhD Student; G1, Biophysics; Lander Lab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047
https://github.com/scverse/scanpy/pull/676#issuecomment-498591518:156,Testability,log,logg,156,"Very cool, @flying-sheep! Really the only concern I have is whether we need an option to prevent setting the timer (or for setting the timer) when calling `logg.info`...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-498591518
https://github.com/scverse/scanpy/pull/676#issuecomment-498701054:18,Testability,test,tests,18,"I’m doing all the tests @ivirshup proposed. If my explanations to the questions I left open are sufficient, I’ll merge this! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-498701054
https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:25,Testability,log,log,25,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256
https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:167,Testability,log,logged,167,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256
https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:191,Testability,log,log,191,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256
https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:220,Testability,log,log,220,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256
https://github.com/scverse/scanpy/pull/676#issuecomment-499002256:321,Testability,log,log,321,"OK, one more change. The log functions now all return the current time and have the optional parameter `time: datetime`. If you pass something there, the time will be logged:. ```py; start = log.info('foo'); # do stuff; log.hint('bar', time=start) # --> bar (00:00:02); ```. You can customize where the time ends up via `log.*('blah {time_passed}: blub', time=...)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499002256
https://github.com/scverse/scanpy/pull/676#issuecomment-499025670:31,Testability,log,logging,31,Cool solution! Really cool new logging module! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499025670
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:366,Availability,error,errors,366,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:219,Energy Efficiency,adapt,adapted,219,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:219,Modifiability,adapt,adapted,219,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:1,Testability,log,logg,1,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:20,Testability,log,logg,20,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:150,Testability,log,logging,150,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:236,Testability,log,logging,236,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:299,Testability,log,logg,299,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:314,Testability,log,logg,314,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:388,Testability,log,logg,388,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:504,Testability,log,logg,504,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754
https://github.com/scverse/scanpy/pull/676#issuecomment-499043170:10,Testability,log,logging,10,"Well, the logging module is undocumented, only `logging.print_versions()` is public. And I changed the signature, it no longer works like `print`, so they’ll have to change it anyway. But I think the new API is pretty sweet, so we can stabilize and document it now. Python has `warnings.warn` and `logging.warning`. I think we should follow suit. You can of course always do `from warnings import warn` and use that. It doesn’t interact with our logging system (yet), though!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499043170
https://github.com/scverse/scanpy/pull/676#issuecomment-499043170:48,Testability,log,logging,48,"Well, the logging module is undocumented, only `logging.print_versions()` is public. And I changed the signature, it no longer works like `print`, so they’ll have to change it anyway. But I think the new API is pretty sweet, so we can stabilize and document it now. Python has `warnings.warn` and `logging.warning`. I think we should follow suit. You can of course always do `from warnings import warn` and use that. It doesn’t interact with our logging system (yet), though!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499043170
https://github.com/scverse/scanpy/pull/676#issuecomment-499043170:298,Testability,log,logging,298,"Well, the logging module is undocumented, only `logging.print_versions()` is public. And I changed the signature, it no longer works like `print`, so they’ll have to change it anyway. But I think the new API is pretty sweet, so we can stabilize and document it now. Python has `warnings.warn` and `logging.warning`. I think we should follow suit. You can of course always do `from warnings import warn` and use that. It doesn’t interact with our logging system (yet), though!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499043170
https://github.com/scverse/scanpy/pull/676#issuecomment-499043170:446,Testability,log,logging,446,"Well, the logging module is undocumented, only `logging.print_versions()` is public. And I changed the signature, it no longer works like `print`, so they’ll have to change it anyway. But I think the new API is pretty sweet, so we can stabilize and document it now. Python has `warnings.warn` and `logging.warning`. I think we should follow suit. You can of course always do `from warnings import warn` and use that. It doesn’t interact with our logging system (yet), though!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499043170
https://github.com/scverse/scanpy/pull/676#issuecomment-499043170:28,Usability,undo,undocumented,28,"Well, the logging module is undocumented, only `logging.print_versions()` is public. And I changed the signature, it no longer works like `print`, so they’ll have to change it anyway. But I think the new API is pretty sweet, so we can stabilize and document it now. Python has `warnings.warn` and `logging.warning`. I think we should follow suit. You can of course always do `from warnings import warn` and use that. It doesn’t interact with our logging system (yet), though!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499043170
https://github.com/scverse/scanpy/issues/680#issuecomment-498837162:0,Deployability,UPDATE,UPDATE,0,"UPDATE: ; So after running `sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)` I was able to run PAGA w/ Seurat clusters using:; `sc.tl.paga(adata, groups='seurat_clusters')`. . Would you guys say this is a legal move to make statistically speaking? . I am visualizing the trajectory inferences using `scanpy.pl.paga(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680#issuecomment-498837162
https://github.com/scverse/scanpy/issues/680#issuecomment-498843181:177,Modifiability,variab,variable,177,"sounds to me like you know what you're doing. Where do you get your PCA from? Seurat? Otherwise I would consider running `sc.pp.pca(adata, svd_solver='arpack')` with the highly variable gene set and your pre-processed data from Seurat. Also, for the future, an easier way to go between Seurat and Scanpy might be [anndata2ri](https://www.github.com/flying-sheep/anndata2ri). I have an example notebook for that [here](https://www.github.com/LuckyMD/Code_snippets).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680#issuecomment-498843181
https://github.com/scverse/scanpy/issues/680#issuecomment-498856082:156,Performance,perform,performed,156,"Wow well that certainly makes things a lot easier, thank you for creating that code snippet! It seems as though Scanpy was smart enough to realize I hadn't performed PCA and thus did it for me using the default settings. However as you have suggested I should be using 'arpack' to make my results reproducible, will do! . Thank you for your reply!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680#issuecomment-498856082
https://github.com/scverse/scanpy/issues/680#issuecomment-1756713620:2,Deployability,UPDATE,UPDATE,2,"> UPDATE: So after running `sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)` I was able to run PAGA w/ Seurat clusters using: `sc.tl.paga(adata, groups='seurat_clusters')`.; > ; > Would you guys say this is a legal move to make statistically speaking?; > ; > I am visualizing the trajectory inferences using `scanpy.pl.paga(adata)`. Hi thank you very much for your information. I'm running the same purpose, using the Seurat object with clustering information for Scanpy trajectory analysis. May I ask why your adata object has so much information inside. Mine is: ; ![image](https://github.com/scverse/scanpy/assets/82354685/ef2554df-a067-45f5-8e4f-8527540a7994). What I do is reading the h5ad file and running sc.tl.paga(adata, groups='seurat_clusters'). May I ask if it is correct or not. Thanks again for your kind help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/680#issuecomment-1756713620
https://github.com/scverse/scanpy/issues/681#issuecomment-499118751:169,Availability,robust,robust,169,"Hi,. Check your `sc.pp.pca()` results. This is normally the origin of the differences. If you use `svd_solver='arpack'` it's more reproducible between systems (and more robust in general), but there will still be some differences due to the underlying numeric libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681#issuecomment-499118751
https://github.com/scverse/scanpy/issues/684#issuecomment-500209907:20,Testability,log,logging,20,"First step: removed logging of `asctime`, which we never had before: https://github.com/theislab/scanpy/commit/4650568cf61d8a654e64abd1ec0807e19423f1ff",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500209907
https://github.com/scverse/scanpy/issues/684#issuecomment-500211162:39,Testability,log,logged,39,"Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. a37efc71876f1cd9ace1165d7f774e390d30343d. The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened].",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500211162
https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:28,Testability,log,logging,28,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994
https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:99,Testability,log,logging,99,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994
https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:344,Testability,log,logged,344,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994
https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:422,Testability,log,log,422,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994
https://github.com/scverse/scanpy/issues/684#issuecomment-500225994:750,Testability,test,testing,750,"Thank you!. > step: removed logging of `asctime`, which we never had before. I took that from your logging code in the data science bowl notebook, but I agree: People should add `{asctime}` to all formatting themselves if they use scanpy in some non-interactive code. We should document how to do that. > Second step: reverted things that were logged at a level equal or higher than 4 to `debug`. Good! FYI: I changed the log levels because the initial version of the overhaul only allowed timing information in `info`. > The only thing that remains is to reformat the time output, which now displays many useless digits after the seconds comma [and fix all other places in which similar things happened]. I’m on it. Seems like I missed that because testing code only uses full seconds, which prevents the milliseconds from showing up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/684#issuecomment-500225994
https://github.com/scverse/scanpy/pull/685#issuecomment-503473477:37,Testability,test,test,37,"multiple are fine, I like having the test setup in the tests directory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685#issuecomment-503473477
https://github.com/scverse/scanpy/pull/685#issuecomment-503473477:55,Testability,test,tests,55,"multiple are fine, I like having the test setup in the tests directory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/685#issuecomment-503473477
https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:22,Availability,error,error,22,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575
https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:141,Availability,error,error,141,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575
https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:40,Deployability,install,installation,40,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575
https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:64,Deployability,install,install,64,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575
https://github.com/scverse/scanpy/issues/687#issuecomment-503484684:97,Deployability,install,installing,97,That’s statsmodels/statsmodels#5759. We already require compatible versions from everything. try installing scanpy from git and it should work,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-503484684
https://github.com/scverse/scanpy/issues/688#issuecomment-504451555:191,Availability,error,errors,191,"https://docs.python.org/3/library/warnings.html#temporarily-suppressing-warnings. ```py; import numba; import warnings. with warnings.catch_warnings():; warnings.simplefilter('ignore', numba.errors.NumbaDeprecationWarning):; do_thing(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555
https://github.com/scverse/scanpy/issues/688#issuecomment-504451555:162,Usability,simpl,simplefilter,162,"https://docs.python.org/3/library/warnings.html#temporarily-suppressing-warnings. ```py; import numba; import warnings. with warnings.catch_warnings():; warnings.simplefilter('ignore', numba.errors.NumbaDeprecationWarning):; do_thing(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555
https://github.com/scverse/scanpy/issues/688#issuecomment-1180404535:70,Integrability,wrap,wrapper,70,"@rcannood,. I have the same issue while using PAGA_tree from the dyno wrapper.; Do you know where I can add the chunk of code that @flying-sheep suggested to remove the warnings?; My first guess would be to change the python files in the container built from PAGA_tree, however the latter (from dyno) builds a new container every time it is called. How should I procedd?. Best,; Andy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688#issuecomment-1180404535
https://github.com/scverse/scanpy/issues/689#issuecomment-502412783:71,Modifiability,flexible,flexible,71,"Hi,; Problem solved! Thanks a lot.; I am new to scanpy and now find it flexible and well designed. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689#issuecomment-502412783
https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:523,Availability,error,error,523,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:422,Performance,perform,performing,422,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:105,Testability,test,test,105,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:158,Testability,log,logistic,158,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:488,Testability,test,tests,488,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720
